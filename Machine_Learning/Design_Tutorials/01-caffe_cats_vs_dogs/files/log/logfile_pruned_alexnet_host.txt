##
##* © Copyright (C) 2016-2020 Xilinx, Inc
##*
##* Licensed under the Apache License, Version 2.0 (the "License"). You may
##* not use this file except in compliance with the License. A copy of the
##* License is located at
##*
##*     http://www.apache.org/licenses/LICENSE-2.0
##*
##* Unless required by applicable law or agreed to in writing, software
##* distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
##* WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
##* License for the specific language governing permissions and limitations
##* under the License.
##*/

(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

I0108 19:50:10.529495   473 sens_analyser.cpp:165] Starting analysis of pruning/alexnetBNnoLRN/float.caffemodel
I0108 19:50:12.669077   473 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0108 19:50:12.669111   473 gpu_memory.cpp:55] Total memory: 25620447232, Free: 25022103552, dev_info[0]: total=25620447232 free=25022103552
I0108 19:50:12.670511   473 caffe_interface.cpp:82] Use GPU with device ID 0
I0108 19:50:12.670883   473 caffe_interface.cpp:86] GPU device name: Quadro P6000
W0108 19:50:13.563694   473 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0108 19:50:13.563848   473 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0108 19:50:13.563879   473 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0108 19:50:13.563946   473 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0108 19:50:13.563961   473 net.cpp:52] Initializing net from parameters:
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0108 19:50:13.564561   473 layer_factory.hpp:77] Creating layer data
I0108 19:50:13.564622   473 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 19:50:13.566587   473 net.cpp:94] Creating Layer data
I0108 19:50:13.566601   473 net.cpp:409] data -> data
I0108 19:50:13.566610   473 net.cpp:409] data -> label
I0108 19:50:13.568145   508 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0108 19:50:13.568151   508 db_lmdb.cpp:38] Items count: 4000
I0108 19:50:13.568164   508 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0108 19:50:13.568946   473 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0108 19:50:13.569160   473 data_layer.cpp:83] output data size: 50,3,227,227
I0108 19:50:13.676231   473 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 19:50:13.676329   473 net.cpp:144] Setting up data
I0108 19:50:13.676338   473 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0108 19:50:13.676347   473 net.cpp:151] Top shape: 50 (50)
I0108 19:50:13.676350   473 net.cpp:159] Memory required for data: 30917600
I0108 19:50:13.676354   473 layer_factory.hpp:77] Creating layer label_data_1_split
I0108 19:50:13.676362   473 net.cpp:94] Creating Layer label_data_1_split
I0108 19:50:13.676386   473 net.cpp:435] label_data_1_split <- label
I0108 19:50:13.676409   473 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0108 19:50:13.676417   473 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0108 19:50:13.676424   473 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0108 19:50:13.676479   473 net.cpp:144] Setting up label_data_1_split
I0108 19:50:13.676484   473 net.cpp:151] Top shape: 50 (50)
I0108 19:50:13.676498   473 net.cpp:151] Top shape: 50 (50)
I0108 19:50:13.676501   473 net.cpp:151] Top shape: 50 (50)
I0108 19:50:13.676506   473 net.cpp:159] Memory required for data: 30918200
I0108 19:50:13.676508   473 layer_factory.hpp:77] Creating layer conv1
I0108 19:50:13.676519   473 net.cpp:94] Creating Layer conv1
I0108 19:50:13.676524   473 net.cpp:435] conv1 <- data
I0108 19:50:13.676529   473 net.cpp:409] conv1 -> conv1
I0108 19:50:13.677428   473 net.cpp:144] Setting up conv1
I0108 19:50:13.677436   473 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0108 19:50:13.677441   473 net.cpp:159] Memory required for data: 88998200
I0108 19:50:13.677453   473 layer_factory.hpp:77] Creating layer bn1
I0108 19:50:13.677469   473 net.cpp:94] Creating Layer bn1
I0108 19:50:13.677474   473 net.cpp:435] bn1 <- conv1
I0108 19:50:13.677480   473 net.cpp:409] bn1 -> bn1
I0108 19:50:13.678011   473 net.cpp:144] Setting up bn1
I0108 19:50:13.678018   473 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0108 19:50:13.678023   473 net.cpp:159] Memory required for data: 147078200
I0108 19:50:13.678033   473 layer_factory.hpp:77] Creating layer relu1
I0108 19:50:13.678040   473 net.cpp:94] Creating Layer relu1
I0108 19:50:13.678043   473 net.cpp:435] relu1 <- bn1
I0108 19:50:13.678047   473 net.cpp:409] relu1 -> relu1
I0108 19:50:13.678069   473 net.cpp:144] Setting up relu1
I0108 19:50:13.678076   473 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0108 19:50:13.678081   473 net.cpp:159] Memory required for data: 205158200
I0108 19:50:13.678083   473 layer_factory.hpp:77] Creating layer pool1
I0108 19:50:13.678088   473 net.cpp:94] Creating Layer pool1
I0108 19:50:13.678092   473 net.cpp:435] pool1 <- relu1
I0108 19:50:13.678097   473 net.cpp:409] pool1 -> pool1
I0108 19:50:13.678124   473 net.cpp:144] Setting up pool1
I0108 19:50:13.678130   473 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0108 19:50:13.678134   473 net.cpp:159] Memory required for data: 219155000
I0108 19:50:13.678138   473 layer_factory.hpp:77] Creating layer conv2
I0108 19:50:13.678145   473 net.cpp:94] Creating Layer conv2
I0108 19:50:13.678149   473 net.cpp:435] conv2 <- pool1
I0108 19:50:13.678155   473 net.cpp:409] conv2 -> conv2
I0108 19:50:13.685248   473 net.cpp:144] Setting up conv2
I0108 19:50:13.685264   473 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0108 19:50:13.685271   473 net.cpp:159] Memory required for data: 256479800
I0108 19:50:13.685281   473 layer_factory.hpp:77] Creating layer bn2
I0108 19:50:13.685289   473 net.cpp:94] Creating Layer bn2
I0108 19:50:13.685294   473 net.cpp:435] bn2 <- conv2
I0108 19:50:13.685300   473 net.cpp:409] bn2 -> bn2
I0108 19:50:13.685811   473 net.cpp:144] Setting up bn2
I0108 19:50:13.685817   473 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0108 19:50:13.685823   473 net.cpp:159] Memory required for data: 293804600
I0108 19:50:13.685832   473 layer_factory.hpp:77] Creating layer relu2
I0108 19:50:13.685838   473 net.cpp:94] Creating Layer relu2
I0108 19:50:13.685842   473 net.cpp:435] relu2 <- bn2
I0108 19:50:13.685847   473 net.cpp:409] relu2 -> relu2
I0108 19:50:13.685863   473 net.cpp:144] Setting up relu2
I0108 19:50:13.685866   473 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0108 19:50:13.685870   473 net.cpp:159] Memory required for data: 331129400
I0108 19:50:13.685874   473 layer_factory.hpp:77] Creating layer pool2
I0108 19:50:13.685881   473 net.cpp:94] Creating Layer pool2
I0108 19:50:13.685884   473 net.cpp:435] pool2 <- relu2
I0108 19:50:13.685889   473 net.cpp:409] pool2 -> pool2
I0108 19:50:13.685914   473 net.cpp:144] Setting up pool2
I0108 19:50:13.685917   473 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0108 19:50:13.685921   473 net.cpp:159] Memory required for data: 339782200
I0108 19:50:13.685925   473 layer_factory.hpp:77] Creating layer conv3
I0108 19:50:13.685932   473 net.cpp:94] Creating Layer conv3
I0108 19:50:13.685935   473 net.cpp:435] conv3 <- pool2
I0108 19:50:13.685940   473 net.cpp:409] conv3 -> conv3
I0108 19:50:13.696084   473 net.cpp:144] Setting up conv3
I0108 19:50:13.696116   473 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 19:50:13.696125   473 net.cpp:159] Memory required for data: 352761400
I0108 19:50:13.696133   473 layer_factory.hpp:77] Creating layer relu3
I0108 19:50:13.696139   473 net.cpp:94] Creating Layer relu3
I0108 19:50:13.696144   473 net.cpp:435] relu3 <- conv3
I0108 19:50:13.696151   473 net.cpp:409] relu3 -> relu3
I0108 19:50:13.696171   473 net.cpp:144] Setting up relu3
I0108 19:50:13.696177   473 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 19:50:13.696182   473 net.cpp:159] Memory required for data: 365740600
I0108 19:50:13.696185   473 layer_factory.hpp:77] Creating layer conv4
I0108 19:50:13.696194   473 net.cpp:94] Creating Layer conv4
I0108 19:50:13.696198   473 net.cpp:435] conv4 <- relu3
I0108 19:50:13.696203   473 net.cpp:409] conv4 -> conv4
I0108 19:50:13.710542   473 net.cpp:144] Setting up conv4
I0108 19:50:13.710561   473 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 19:50:13.710568   473 net.cpp:159] Memory required for data: 378719800
I0108 19:50:13.710595   473 layer_factory.hpp:77] Creating layer relu4
I0108 19:50:13.710602   473 net.cpp:94] Creating Layer relu4
I0108 19:50:13.710608   473 net.cpp:435] relu4 <- conv4
I0108 19:50:13.710615   473 net.cpp:409] relu4 -> relu4
I0108 19:50:13.710636   473 net.cpp:144] Setting up relu4
I0108 19:50:13.710639   473 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 19:50:13.710644   473 net.cpp:159] Memory required for data: 391699000
I0108 19:50:13.710646   473 layer_factory.hpp:77] Creating layer conv5
I0108 19:50:13.710654   473 net.cpp:94] Creating Layer conv5
I0108 19:50:13.710657   473 net.cpp:435] conv5 <- relu4
I0108 19:50:13.710662   473 net.cpp:409] conv5 -> conv5
I0108 19:50:13.721084   473 net.cpp:144] Setting up conv5
I0108 19:50:13.721101   473 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0108 19:50:13.721109   473 net.cpp:159] Memory required for data: 400351800
I0108 19:50:13.721118   473 layer_factory.hpp:77] Creating layer relu5
I0108 19:50:13.721125   473 net.cpp:94] Creating Layer relu5
I0108 19:50:13.721129   473 net.cpp:435] relu5 <- conv5
I0108 19:50:13.721135   473 net.cpp:409] relu5 -> relu5
I0108 19:50:13.721158   473 net.cpp:144] Setting up relu5
I0108 19:50:13.721160   473 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0108 19:50:13.721164   473 net.cpp:159] Memory required for data: 409004600
I0108 19:50:13.721168   473 layer_factory.hpp:77] Creating layer pool5
I0108 19:50:13.721174   473 net.cpp:94] Creating Layer pool5
I0108 19:50:13.721176   473 net.cpp:435] pool5 <- relu5
I0108 19:50:13.721196   473 net.cpp:409] pool5 -> pool5
I0108 19:50:13.721220   473 net.cpp:144] Setting up pool5
I0108 19:50:13.721225   473 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0108 19:50:13.721230   473 net.cpp:159] Memory required for data: 410847800
I0108 19:50:13.721233   473 layer_factory.hpp:77] Creating layer fc6
I0108 19:50:13.721241   473 net.cpp:94] Creating Layer fc6
I0108 19:50:13.721244   473 net.cpp:435] fc6 <- pool5
I0108 19:50:13.721249   473 net.cpp:409] fc6 -> fc6
I0108 19:50:14.061691   473 net.cpp:144] Setting up fc6
I0108 19:50:14.061714   473 net.cpp:151] Top shape: 50 4096 (204800)
I0108 19:50:14.061723   473 net.cpp:159] Memory required for data: 411667000
I0108 19:50:14.061733   473 layer_factory.hpp:77] Creating layer relu6
I0108 19:50:14.061739   473 net.cpp:94] Creating Layer relu6
I0108 19:50:14.061743   473 net.cpp:435] relu6 <- fc6
I0108 19:50:14.061748   473 net.cpp:409] relu6 -> relu6
I0108 19:50:14.061774   473 net.cpp:144] Setting up relu6
I0108 19:50:14.061776   473 net.cpp:151] Top shape: 50 4096 (204800)
I0108 19:50:14.061780   473 net.cpp:159] Memory required for data: 412486200
I0108 19:50:14.061784   473 layer_factory.hpp:77] Creating layer drop6
I0108 19:50:14.061794   473 net.cpp:94] Creating Layer drop6
I0108 19:50:14.061813   473 net.cpp:435] drop6 <- relu6
I0108 19:50:14.061817   473 net.cpp:409] drop6 -> drop6
I0108 19:50:14.061841   473 net.cpp:144] Setting up drop6
I0108 19:50:14.061844   473 net.cpp:151] Top shape: 50 4096 (204800)
I0108 19:50:14.061866   473 net.cpp:159] Memory required for data: 413305400
I0108 19:50:14.061868   473 layer_factory.hpp:77] Creating layer fc7
I0108 19:50:14.061875   473 net.cpp:94] Creating Layer fc7
I0108 19:50:14.061878   473 net.cpp:435] fc7 <- drop6
I0108 19:50:14.061884   473 net.cpp:409] fc7 -> fc7
I0108 19:50:14.206321   473 net.cpp:144] Setting up fc7
I0108 19:50:14.206342   473 net.cpp:151] Top shape: 50 4096 (204800)
I0108 19:50:14.206349   473 net.cpp:159] Memory required for data: 414124600
I0108 19:50:14.206359   473 layer_factory.hpp:77] Creating layer bn7
I0108 19:50:14.206367   473 net.cpp:94] Creating Layer bn7
I0108 19:50:14.206372   473 net.cpp:435] bn7 <- fc7
I0108 19:50:14.206378   473 net.cpp:409] bn7 -> bn7
I0108 19:50:14.206857   473 net.cpp:144] Setting up bn7
I0108 19:50:14.206864   473 net.cpp:151] Top shape: 50 4096 (204800)
I0108 19:50:14.206868   473 net.cpp:159] Memory required for data: 414943800
I0108 19:50:14.206876   473 layer_factory.hpp:77] Creating layer relu7
I0108 19:50:14.206881   473 net.cpp:94] Creating Layer relu7
I0108 19:50:14.206885   473 net.cpp:435] relu7 <- bn7
I0108 19:50:14.206889   473 net.cpp:409] relu7 -> relu7
I0108 19:50:14.206907   473 net.cpp:144] Setting up relu7
I0108 19:50:14.206912   473 net.cpp:151] Top shape: 50 4096 (204800)
I0108 19:50:14.206915   473 net.cpp:159] Memory required for data: 415763000
I0108 19:50:14.206919   473 layer_factory.hpp:77] Creating layer drop7
I0108 19:50:14.206925   473 net.cpp:94] Creating Layer drop7
I0108 19:50:14.206929   473 net.cpp:435] drop7 <- relu7
I0108 19:50:14.206933   473 net.cpp:409] drop7 -> drop7
I0108 19:50:14.206974   473 net.cpp:144] Setting up drop7
I0108 19:50:14.206979   473 net.cpp:151] Top shape: 50 4096 (204800)
I0108 19:50:14.206984   473 net.cpp:159] Memory required for data: 416582200
I0108 19:50:14.206987   473 layer_factory.hpp:77] Creating layer fc8
I0108 19:50:14.206993   473 net.cpp:94] Creating Layer fc8
I0108 19:50:14.206997   473 net.cpp:435] fc8 <- drop7
I0108 19:50:14.207002   473 net.cpp:409] fc8 -> fc8
I0108 19:50:14.207168   473 net.cpp:144] Setting up fc8
I0108 19:50:14.207173   473 net.cpp:151] Top shape: 50 2 (100)
I0108 19:50:14.207178   473 net.cpp:159] Memory required for data: 416582600
I0108 19:50:14.207183   473 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0108 19:50:14.207190   473 net.cpp:94] Creating Layer fc8_fc8_0_split
I0108 19:50:14.207193   473 net.cpp:435] fc8_fc8_0_split <- fc8
I0108 19:50:14.207197   473 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0108 19:50:14.207203   473 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0108 19:50:14.207209   473 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0108 19:50:14.207242   473 net.cpp:144] Setting up fc8_fc8_0_split
I0108 19:50:14.207247   473 net.cpp:151] Top shape: 50 2 (100)
I0108 19:50:14.207252   473 net.cpp:151] Top shape: 50 2 (100)
I0108 19:50:14.207257   473 net.cpp:151] Top shape: 50 2 (100)
I0108 19:50:14.207260   473 net.cpp:159] Memory required for data: 416583800
I0108 19:50:14.207263   473 layer_factory.hpp:77] Creating layer accuracy
I0108 19:50:14.207270   473 net.cpp:94] Creating Layer accuracy
I0108 19:50:14.207273   473 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0108 19:50:14.207278   473 net.cpp:435] accuracy <- label_data_1_split_0
I0108 19:50:14.207283   473 net.cpp:409] accuracy -> accuracy
I0108 19:50:14.207290   473 net.cpp:144] Setting up accuracy
I0108 19:50:14.207294   473 net.cpp:151] Top shape: (1)
I0108 19:50:14.207298   473 net.cpp:159] Memory required for data: 416583804
I0108 19:50:14.207301   473 layer_factory.hpp:77] Creating layer loss
I0108 19:50:14.207309   473 net.cpp:94] Creating Layer loss
I0108 19:50:14.207312   473 net.cpp:435] loss <- fc8_fc8_0_split_1
I0108 19:50:14.207316   473 net.cpp:435] loss <- label_data_1_split_1
I0108 19:50:14.207321   473 net.cpp:409] loss -> loss
I0108 19:50:14.207329   473 layer_factory.hpp:77] Creating layer loss
I0108 19:50:14.207404   473 net.cpp:144] Setting up loss
I0108 19:50:14.208663   473 net.cpp:151] Top shape: (1)
I0108 19:50:14.208691   473 net.cpp:154]     with loss weight 1
I0108 19:50:14.208717   473 net.cpp:159] Memory required for data: 416583808
I0108 19:50:14.208731   473 layer_factory.hpp:77] Creating layer accuracy-top1
I0108 19:50:14.208763   473 net.cpp:94] Creating Layer accuracy-top1
I0108 19:50:14.208781   473 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0108 19:50:14.208797   473 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0108 19:50:14.208819   473 net.cpp:409] accuracy-top1 -> top-1
I0108 19:50:14.208853   473 net.cpp:144] Setting up accuracy-top1
I0108 19:50:14.208868   473 net.cpp:151] Top shape: (1)
I0108 19:50:14.208881   473 net.cpp:159] Memory required for data: 416583812
I0108 19:50:14.208894   473 net.cpp:222] accuracy-top1 does not need backward computation.
I0108 19:50:14.208907   473 net.cpp:220] loss needs backward computation.
I0108 19:50:14.208925   473 net.cpp:222] accuracy does not need backward computation.
I0108 19:50:14.208940   473 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0108 19:50:14.208954   473 net.cpp:220] fc8 needs backward computation.
I0108 19:50:14.208967   473 net.cpp:220] drop7 needs backward computation.
I0108 19:50:14.208979   473 net.cpp:220] relu7 needs backward computation.
I0108 19:50:14.208992   473 net.cpp:220] bn7 needs backward computation.
I0108 19:50:14.209004   473 net.cpp:220] fc7 needs backward computation.
I0108 19:50:14.209017   473 net.cpp:220] drop6 needs backward computation.
I0108 19:50:14.209029   473 net.cpp:220] relu6 needs backward computation.
I0108 19:50:14.209043   473 net.cpp:220] fc6 needs backward computation.
I0108 19:50:14.209054   473 net.cpp:220] pool5 needs backward computation.
I0108 19:50:14.209067   473 net.cpp:220] relu5 needs backward computation.
I0108 19:50:14.209092   473 net.cpp:220] conv5 needs backward computation.
I0108 19:50:14.209101   473 net.cpp:220] relu4 needs backward computation.
I0108 19:50:14.209110   473 net.cpp:220] conv4 needs backward computation.
I0108 19:50:14.209117   473 net.cpp:220] relu3 needs backward computation.
I0108 19:50:14.209126   473 net.cpp:220] conv3 needs backward computation.
I0108 19:50:14.209134   473 net.cpp:220] pool2 needs backward computation.
I0108 19:50:14.209142   473 net.cpp:220] relu2 needs backward computation.
I0108 19:50:14.209151   473 net.cpp:220] bn2 needs backward computation.
I0108 19:50:14.209159   473 net.cpp:220] conv2 needs backward computation.
I0108 19:50:14.209168   473 net.cpp:220] pool1 needs backward computation.
I0108 19:50:14.209177   473 net.cpp:220] relu1 needs backward computation.
I0108 19:50:14.209184   473 net.cpp:220] bn1 needs backward computation.
I0108 19:50:14.209192   473 net.cpp:220] conv1 needs backward computation.
I0108 19:50:14.209203   473 net.cpp:222] label_data_1_split does not need backward computation.
I0108 19:50:14.209218   473 net.cpp:222] data does not need backward computation.
I0108 19:50:14.209228   473 net.cpp:264] This network produces output accuracy
I0108 19:50:14.209236   473 net.cpp:264] This network produces output loss
I0108 19:50:14.209245   473 net.cpp:264] This network produces output top-1
I0108 19:50:14.209298   473 net.cpp:284] Network initialization done.
I0108 19:50:14.292841   473 caffe_interface.cpp:379] Running for 80 iterations.
I0108 19:50:14.336258   473 caffe_interface.cpp:141] Batch 0, accuracy = 1
I0108 19:50:14.336318   473 caffe_interface.cpp:141] Batch 0, loss = 0.0184509
I0108 19:50:14.336323   473 caffe_interface.cpp:141] Batch 0, top-1 = 1
I0108 19:50:14.354302   473 caffe_interface.cpp:141] Batch 1, accuracy = 0.98
I0108 19:50:14.354322   473 caffe_interface.cpp:141] Batch 1, loss = 0.0644124
I0108 19:50:14.354326   473 caffe_interface.cpp:141] Batch 1, top-1 = 0.98
I0108 19:50:14.373781   473 caffe_interface.cpp:141] Batch 2, accuracy = 0.94
I0108 19:50:14.373800   473 caffe_interface.cpp:141] Batch 2, loss = 0.11436
I0108 19:50:14.373803   473 caffe_interface.cpp:141] Batch 2, top-1 = 0.94
I0108 19:50:14.391506   473 caffe_interface.cpp:141] Batch 3, accuracy = 0.94
I0108 19:50:14.391541   473 caffe_interface.cpp:141] Batch 3, loss = 0.225233
I0108 19:50:14.391544   473 caffe_interface.cpp:141] Batch 3, top-1 = 0.94
I0108 19:50:14.410207   473 caffe_interface.cpp:141] Batch 4, accuracy = 0.9
I0108 19:50:14.410225   473 caffe_interface.cpp:141] Batch 4, loss = 0.463844
I0108 19:50:14.410228   473 caffe_interface.cpp:141] Batch 4, top-1 = 0.9
I0108 19:50:14.428580   473 caffe_interface.cpp:141] Batch 5, accuracy = 0.96
I0108 19:50:14.428597   473 caffe_interface.cpp:141] Batch 5, loss = 0.0976843
I0108 19:50:14.428601   473 caffe_interface.cpp:141] Batch 5, top-1 = 0.96
I0108 19:50:14.447731   473 caffe_interface.cpp:141] Batch 6, accuracy = 0.98
I0108 19:50:14.447747   473 caffe_interface.cpp:141] Batch 6, loss = 0.0332405
I0108 19:50:14.447751   473 caffe_interface.cpp:141] Batch 6, top-1 = 0.98
I0108 19:50:14.466094   473 caffe_interface.cpp:141] Batch 7, accuracy = 0.92
I0108 19:50:14.466111   473 caffe_interface.cpp:141] Batch 7, loss = 0.348369
I0108 19:50:14.466115   473 caffe_interface.cpp:141] Batch 7, top-1 = 0.92
I0108 19:50:14.485172   473 caffe_interface.cpp:141] Batch 8, accuracy = 0.96
I0108 19:50:14.485188   473 caffe_interface.cpp:141] Batch 8, loss = 0.040212
I0108 19:50:14.485191   473 caffe_interface.cpp:141] Batch 8, top-1 = 0.96
I0108 19:50:14.503294   473 caffe_interface.cpp:141] Batch 9, accuracy = 0.92
I0108 19:50:14.503311   473 caffe_interface.cpp:141] Batch 9, loss = 0.194303
I0108 19:50:14.503314   473 caffe_interface.cpp:141] Batch 9, top-1 = 0.92
I0108 19:50:14.522116   473 caffe_interface.cpp:141] Batch 10, accuracy = 0.94
I0108 19:50:14.522135   473 caffe_interface.cpp:141] Batch 10, loss = 0.173532
I0108 19:50:14.522137   473 caffe_interface.cpp:141] Batch 10, top-1 = 0.94
I0108 19:50:14.540537   473 caffe_interface.cpp:141] Batch 11, accuracy = 0.98
I0108 19:50:14.540555   473 caffe_interface.cpp:141] Batch 11, loss = 0.120499
I0108 19:50:14.540558   473 caffe_interface.cpp:141] Batch 11, top-1 = 0.98
I0108 19:50:14.559500   473 caffe_interface.cpp:141] Batch 12, accuracy = 0.94
I0108 19:50:14.559518   473 caffe_interface.cpp:141] Batch 12, loss = 0.274857
I0108 19:50:14.559521   473 caffe_interface.cpp:141] Batch 12, top-1 = 0.94
I0108 19:50:14.577623   473 caffe_interface.cpp:141] Batch 13, accuracy = 0.92
I0108 19:50:14.577641   473 caffe_interface.cpp:141] Batch 13, loss = 0.326927
I0108 19:50:14.577644   473 caffe_interface.cpp:141] Batch 13, top-1 = 0.92
I0108 19:50:14.596670   473 caffe_interface.cpp:141] Batch 14, accuracy = 0.92
I0108 19:50:14.596689   473 caffe_interface.cpp:141] Batch 14, loss = 0.313873
I0108 19:50:14.596693   473 caffe_interface.cpp:141] Batch 14, top-1 = 0.92
I0108 19:50:14.614969   473 caffe_interface.cpp:141] Batch 15, accuracy = 0.88
I0108 19:50:14.614987   473 caffe_interface.cpp:141] Batch 15, loss = 0.307534
I0108 19:50:14.614990   473 caffe_interface.cpp:141] Batch 15, top-1 = 0.88
I0108 19:50:14.633621   473 caffe_interface.cpp:141] Batch 16, accuracy = 0.92
I0108 19:50:14.633639   473 caffe_interface.cpp:141] Batch 16, loss = 0.295025
I0108 19:50:14.633643   473 caffe_interface.cpp:141] Batch 16, top-1 = 0.92
I0108 19:50:14.651726   473 caffe_interface.cpp:141] Batch 17, accuracy = 0.94
I0108 19:50:14.651743   473 caffe_interface.cpp:141] Batch 17, loss = 0.391794
I0108 19:50:14.651746   473 caffe_interface.cpp:141] Batch 17, top-1 = 0.94
I0108 19:50:14.670681   473 caffe_interface.cpp:141] Batch 18, accuracy = 0.88
I0108 19:50:14.670698   473 caffe_interface.cpp:141] Batch 18, loss = 0.468911
I0108 19:50:14.670701   473 caffe_interface.cpp:141] Batch 18, top-1 = 0.88
I0108 19:50:14.688683   473 caffe_interface.cpp:141] Batch 19, accuracy = 0.96
I0108 19:50:14.688700   473 caffe_interface.cpp:141] Batch 19, loss = 0.189798
I0108 19:50:14.688704   473 caffe_interface.cpp:141] Batch 19, top-1 = 0.96
I0108 19:50:14.707800   473 caffe_interface.cpp:141] Batch 20, accuracy = 0.98
I0108 19:50:14.707818   473 caffe_interface.cpp:141] Batch 20, loss = 0.15378
I0108 19:50:14.707820   473 caffe_interface.cpp:141] Batch 20, top-1 = 0.98
I0108 19:50:14.726174   473 caffe_interface.cpp:141] Batch 21, accuracy = 0.94
I0108 19:50:14.726191   473 caffe_interface.cpp:141] Batch 21, loss = 0.249427
I0108 19:50:14.726195   473 caffe_interface.cpp:141] Batch 21, top-1 = 0.94
I0108 19:50:14.745122   473 caffe_interface.cpp:141] Batch 22, accuracy = 0.98
I0108 19:50:14.745139   473 caffe_interface.cpp:141] Batch 22, loss = 0.254519
I0108 19:50:14.745142   473 caffe_interface.cpp:141] Batch 22, top-1 = 0.98
I0108 19:50:14.762866   473 caffe_interface.cpp:141] Batch 23, accuracy = 0.96
I0108 19:50:14.762884   473 caffe_interface.cpp:141] Batch 23, loss = 0.111724
I0108 19:50:14.762888   473 caffe_interface.cpp:141] Batch 23, top-1 = 0.96
I0108 19:50:14.781688   473 caffe_interface.cpp:141] Batch 24, accuracy = 0.96
I0108 19:50:14.781705   473 caffe_interface.cpp:141] Batch 24, loss = 0.0667351
I0108 19:50:14.781709   473 caffe_interface.cpp:141] Batch 24, top-1 = 0.96
I0108 19:50:14.799765   473 caffe_interface.cpp:141] Batch 25, accuracy = 0.98
I0108 19:50:14.799782   473 caffe_interface.cpp:141] Batch 25, loss = 0.0436229
I0108 19:50:14.799785   473 caffe_interface.cpp:141] Batch 25, top-1 = 0.98
I0108 19:50:14.818430   473 caffe_interface.cpp:141] Batch 26, accuracy = 0.98
I0108 19:50:14.818447   473 caffe_interface.cpp:141] Batch 26, loss = 0.205658
I0108 19:50:14.818451   473 caffe_interface.cpp:141] Batch 26, top-1 = 0.98
I0108 19:50:14.836364   473 caffe_interface.cpp:141] Batch 27, accuracy = 0.96
I0108 19:50:14.836380   473 caffe_interface.cpp:141] Batch 27, loss = 0.172664
I0108 19:50:14.836383   473 caffe_interface.cpp:141] Batch 27, top-1 = 0.96
I0108 19:50:14.855461   473 caffe_interface.cpp:141] Batch 28, accuracy = 0.96
I0108 19:50:14.855477   473 caffe_interface.cpp:141] Batch 28, loss = 0.0841417
I0108 19:50:14.855481   473 caffe_interface.cpp:141] Batch 28, top-1 = 0.96
I0108 19:50:14.873795   473 caffe_interface.cpp:141] Batch 29, accuracy = 0.94
I0108 19:50:14.873812   473 caffe_interface.cpp:141] Batch 29, loss = 0.436298
I0108 19:50:14.873816   473 caffe_interface.cpp:141] Batch 29, top-1 = 0.94
I0108 19:50:14.892706   473 caffe_interface.cpp:141] Batch 30, accuracy = 0.84
I0108 19:50:14.892722   473 caffe_interface.cpp:141] Batch 30, loss = 0.593984
I0108 19:50:14.892725   473 caffe_interface.cpp:141] Batch 30, top-1 = 0.84
I0108 19:50:14.911005   473 caffe_interface.cpp:141] Batch 31, accuracy = 0.92
I0108 19:50:14.911021   473 caffe_interface.cpp:141] Batch 31, loss = 0.381408
I0108 19:50:14.911024   473 caffe_interface.cpp:141] Batch 31, top-1 = 0.92
I0108 19:50:14.930141   473 caffe_interface.cpp:141] Batch 32, accuracy = 0.92
I0108 19:50:14.930158   473 caffe_interface.cpp:141] Batch 32, loss = 0.344538
I0108 19:50:14.930162   473 caffe_interface.cpp:141] Batch 32, top-1 = 0.92
I0108 19:50:14.948668   473 caffe_interface.cpp:141] Batch 33, accuracy = 0.96
I0108 19:50:14.948685   473 caffe_interface.cpp:141] Batch 33, loss = 0.172907
I0108 19:50:14.948688   473 caffe_interface.cpp:141] Batch 33, top-1 = 0.96
I0108 19:50:14.968410   473 caffe_interface.cpp:141] Batch 34, accuracy = 0.86
I0108 19:50:14.968428   473 caffe_interface.cpp:141] Batch 34, loss = 0.496395
I0108 19:50:14.968432   473 caffe_interface.cpp:141] Batch 34, top-1 = 0.86
I0108 19:50:14.986513   473 caffe_interface.cpp:141] Batch 35, accuracy = 0.98
I0108 19:50:14.986529   473 caffe_interface.cpp:141] Batch 35, loss = 0.035403
I0108 19:50:14.986533   473 caffe_interface.cpp:141] Batch 35, top-1 = 0.98
I0108 19:50:15.005954   473 caffe_interface.cpp:141] Batch 36, accuracy = 0.96
I0108 19:50:15.005970   473 caffe_interface.cpp:141] Batch 36, loss = 0.0942552
I0108 19:50:15.005975   473 caffe_interface.cpp:141] Batch 36, top-1 = 0.96
I0108 19:50:15.024185   473 caffe_interface.cpp:141] Batch 37, accuracy = 0.98
I0108 19:50:15.024201   473 caffe_interface.cpp:141] Batch 37, loss = 0.0330283
I0108 19:50:15.024204   473 caffe_interface.cpp:141] Batch 37, top-1 = 0.98
I0108 19:50:15.043208   473 caffe_interface.cpp:141] Batch 38, accuracy = 1
I0108 19:50:15.043238   473 caffe_interface.cpp:141] Batch 38, loss = 0.0181847
I0108 19:50:15.043242   473 caffe_interface.cpp:141] Batch 38, top-1 = 1
I0108 19:50:15.061316   473 caffe_interface.cpp:141] Batch 39, accuracy = 0.96
I0108 19:50:15.061333   473 caffe_interface.cpp:141] Batch 39, loss = 0.062675
I0108 19:50:15.061336   473 caffe_interface.cpp:141] Batch 39, top-1 = 0.96
I0108 19:50:15.079903   473 caffe_interface.cpp:141] Batch 40, accuracy = 0.96
I0108 19:50:15.079919   473 caffe_interface.cpp:141] Batch 40, loss = 0.135651
I0108 19:50:15.079922   473 caffe_interface.cpp:141] Batch 40, top-1 = 0.96
I0108 19:50:15.097741   473 caffe_interface.cpp:141] Batch 41, accuracy = 0.9
I0108 19:50:15.097757   473 caffe_interface.cpp:141] Batch 41, loss = 0.313794
I0108 19:50:15.097761   473 caffe_interface.cpp:141] Batch 41, top-1 = 0.9
I0108 19:50:15.116361   473 caffe_interface.cpp:141] Batch 42, accuracy = 0.88
I0108 19:50:15.116379   473 caffe_interface.cpp:141] Batch 42, loss = 0.375712
I0108 19:50:15.116381   473 caffe_interface.cpp:141] Batch 42, top-1 = 0.88
I0108 19:50:15.134430   473 caffe_interface.cpp:141] Batch 43, accuracy = 0.96
I0108 19:50:15.134446   473 caffe_interface.cpp:141] Batch 43, loss = 0.0970911
I0108 19:50:15.134449   473 caffe_interface.cpp:141] Batch 43, top-1 = 0.96
I0108 19:50:15.153406   473 caffe_interface.cpp:141] Batch 44, accuracy = 0.94
I0108 19:50:15.153422   473 caffe_interface.cpp:141] Batch 44, loss = 0.305823
I0108 19:50:15.153425   473 caffe_interface.cpp:141] Batch 44, top-1 = 0.94
I0108 19:50:15.171248   473 caffe_interface.cpp:141] Batch 45, accuracy = 0.98
I0108 19:50:15.171262   473 caffe_interface.cpp:141] Batch 45, loss = 0.0394441
I0108 19:50:15.171267   473 caffe_interface.cpp:141] Batch 45, top-1 = 0.98
I0108 19:50:15.189939   473 caffe_interface.cpp:141] Batch 46, accuracy = 0.98
I0108 19:50:15.189949   473 caffe_interface.cpp:141] Batch 46, loss = 0.0331518
I0108 19:50:15.189951   473 caffe_interface.cpp:141] Batch 46, top-1 = 0.98
I0108 19:50:15.208153   473 caffe_interface.cpp:141] Batch 47, accuracy = 0.94
I0108 19:50:15.208163   473 caffe_interface.cpp:141] Batch 47, loss = 0.281649
I0108 19:50:15.208165   473 caffe_interface.cpp:141] Batch 47, top-1 = 0.94
I0108 19:50:15.226828   473 caffe_interface.cpp:141] Batch 48, accuracy = 0.94
I0108 19:50:15.226838   473 caffe_interface.cpp:141] Batch 48, loss = 0.153278
I0108 19:50:15.226841   473 caffe_interface.cpp:141] Batch 48, top-1 = 0.94
I0108 19:50:15.244755   473 caffe_interface.cpp:141] Batch 49, accuracy = 0.92
I0108 19:50:15.244765   473 caffe_interface.cpp:141] Batch 49, loss = 0.229353
I0108 19:50:15.244768   473 caffe_interface.cpp:141] Batch 49, top-1 = 0.92
I0108 19:50:15.263440   473 caffe_interface.cpp:141] Batch 50, accuracy = 0.96
I0108 19:50:15.263449   473 caffe_interface.cpp:141] Batch 50, loss = 0.173725
I0108 19:50:15.263453   473 caffe_interface.cpp:141] Batch 50, top-1 = 0.96
I0108 19:50:15.281621   473 caffe_interface.cpp:141] Batch 51, accuracy = 0.94
I0108 19:50:15.281630   473 caffe_interface.cpp:141] Batch 51, loss = 0.263024
I0108 19:50:15.281635   473 caffe_interface.cpp:141] Batch 51, top-1 = 0.94
I0108 19:50:15.300519   473 caffe_interface.cpp:141] Batch 52, accuracy = 0.94
I0108 19:50:15.300529   473 caffe_interface.cpp:141] Batch 52, loss = 0.216095
I0108 19:50:15.300531   473 caffe_interface.cpp:141] Batch 52, top-1 = 0.94
I0108 19:50:15.318513   473 caffe_interface.cpp:141] Batch 53, accuracy = 0.98
I0108 19:50:15.318521   473 caffe_interface.cpp:141] Batch 53, loss = 0.0423726
I0108 19:50:15.318526   473 caffe_interface.cpp:141] Batch 53, top-1 = 0.98
I0108 19:50:15.337682   473 caffe_interface.cpp:141] Batch 54, accuracy = 0.96
I0108 19:50:15.337690   473 caffe_interface.cpp:141] Batch 54, loss = 0.107185
I0108 19:50:15.337693   473 caffe_interface.cpp:141] Batch 54, top-1 = 0.96
I0108 19:50:15.355449   473 caffe_interface.cpp:141] Batch 55, accuracy = 0.94
I0108 19:50:15.355458   473 caffe_interface.cpp:141] Batch 55, loss = 0.167788
I0108 19:50:15.355461   473 caffe_interface.cpp:141] Batch 55, top-1 = 0.94
I0108 19:50:15.373903   473 caffe_interface.cpp:141] Batch 56, accuracy = 0.92
I0108 19:50:15.373914   473 caffe_interface.cpp:141] Batch 56, loss = 0.271528
I0108 19:50:15.373916   473 caffe_interface.cpp:141] Batch 56, top-1 = 0.92
I0108 19:50:15.391841   473 caffe_interface.cpp:141] Batch 57, accuracy = 0.9
I0108 19:50:15.391850   473 caffe_interface.cpp:141] Batch 57, loss = 0.328954
I0108 19:50:15.391853   473 caffe_interface.cpp:141] Batch 57, top-1 = 0.9
I0108 19:50:15.410367   473 caffe_interface.cpp:141] Batch 58, accuracy = 0.94
I0108 19:50:15.410377   473 caffe_interface.cpp:141] Batch 58, loss = 0.407835
I0108 19:50:15.410379   473 caffe_interface.cpp:141] Batch 58, top-1 = 0.94
I0108 19:50:15.428303   473 caffe_interface.cpp:141] Batch 59, accuracy = 0.94
I0108 19:50:15.428311   473 caffe_interface.cpp:141] Batch 59, loss = 0.306757
I0108 19:50:15.428314   473 caffe_interface.cpp:141] Batch 59, top-1 = 0.94
I0108 19:50:15.446815   473 caffe_interface.cpp:141] Batch 60, accuracy = 1
I0108 19:50:15.446823   473 caffe_interface.cpp:141] Batch 60, loss = 0.0143488
I0108 19:50:15.446827   473 caffe_interface.cpp:141] Batch 60, top-1 = 1
I0108 19:50:15.464993   473 caffe_interface.cpp:141] Batch 61, accuracy = 0.92
I0108 19:50:15.465001   473 caffe_interface.cpp:141] Batch 61, loss = 0.220167
I0108 19:50:15.465005   473 caffe_interface.cpp:141] Batch 61, top-1 = 0.92
I0108 19:50:15.483734   473 caffe_interface.cpp:141] Batch 62, accuracy = 0.9
I0108 19:50:15.483743   473 caffe_interface.cpp:141] Batch 62, loss = 0.500921
I0108 19:50:15.483747   473 caffe_interface.cpp:141] Batch 62, top-1 = 0.9
I0108 19:50:15.501505   473 caffe_interface.cpp:141] Batch 63, accuracy = 0.96
I0108 19:50:15.501514   473 caffe_interface.cpp:141] Batch 63, loss = 0.0727668
I0108 19:50:15.501518   473 caffe_interface.cpp:141] Batch 63, top-1 = 0.96
I0108 19:50:15.520382   473 caffe_interface.cpp:141] Batch 64, accuracy = 0.92
I0108 19:50:15.520391   473 caffe_interface.cpp:141] Batch 64, loss = 0.10706
I0108 19:50:15.520395   473 caffe_interface.cpp:141] Batch 64, top-1 = 0.92
I0108 19:50:15.538555   473 caffe_interface.cpp:141] Batch 65, accuracy = 1
I0108 19:50:15.538564   473 caffe_interface.cpp:141] Batch 65, loss = 0.0162013
I0108 19:50:15.538568   473 caffe_interface.cpp:141] Batch 65, top-1 = 1
I0108 19:50:15.557480   473 caffe_interface.cpp:141] Batch 66, accuracy = 0.92
I0108 19:50:15.557489   473 caffe_interface.cpp:141] Batch 66, loss = 0.145662
I0108 19:50:15.557492   473 caffe_interface.cpp:141] Batch 66, top-1 = 0.92
I0108 19:50:15.575476   473 caffe_interface.cpp:141] Batch 67, accuracy = 0.96
I0108 19:50:15.575485   473 caffe_interface.cpp:141] Batch 67, loss = 0.151433
I0108 19:50:15.575489   473 caffe_interface.cpp:141] Batch 67, top-1 = 0.96
I0108 19:50:15.594318   473 caffe_interface.cpp:141] Batch 68, accuracy = 0.94
I0108 19:50:15.594327   473 caffe_interface.cpp:141] Batch 68, loss = 0.187715
I0108 19:50:15.594331   473 caffe_interface.cpp:141] Batch 68, top-1 = 0.94
I0108 19:50:15.612324   473 caffe_interface.cpp:141] Batch 69, accuracy = 0.96
I0108 19:50:15.612334   473 caffe_interface.cpp:141] Batch 69, loss = 0.146695
I0108 19:50:15.612336   473 caffe_interface.cpp:141] Batch 69, top-1 = 0.96
I0108 19:50:15.630859   473 caffe_interface.cpp:141] Batch 70, accuracy = 0.9
I0108 19:50:15.630868   473 caffe_interface.cpp:141] Batch 70, loss = 0.297502
I0108 19:50:15.630872   473 caffe_interface.cpp:141] Batch 70, top-1 = 0.9
I0108 19:50:15.649075   473 caffe_interface.cpp:141] Batch 71, accuracy = 0.98
I0108 19:50:15.649083   473 caffe_interface.cpp:141] Batch 71, loss = 0.156307
I0108 19:50:15.649086   473 caffe_interface.cpp:141] Batch 71, top-1 = 0.98
I0108 19:50:15.667583   473 caffe_interface.cpp:141] Batch 72, accuracy = 0.98
I0108 19:50:15.667593   473 caffe_interface.cpp:141] Batch 72, loss = 0.0682823
I0108 19:50:15.667596   473 caffe_interface.cpp:141] Batch 72, top-1 = 0.98
I0108 19:50:15.685220   473 caffe_interface.cpp:141] Batch 73, accuracy = 0.96
I0108 19:50:15.685240   473 caffe_interface.cpp:141] Batch 73, loss = 0.132476
I0108 19:50:15.685242   473 caffe_interface.cpp:141] Batch 73, top-1 = 0.96
I0108 19:50:15.703771   473 caffe_interface.cpp:141] Batch 74, accuracy = 0.9
I0108 19:50:15.703781   473 caffe_interface.cpp:141] Batch 74, loss = 0.437895
I0108 19:50:15.703784   473 caffe_interface.cpp:141] Batch 74, top-1 = 0.9
I0108 19:50:15.721910   473 caffe_interface.cpp:141] Batch 75, accuracy = 0.94
I0108 19:50:15.721920   473 caffe_interface.cpp:141] Batch 75, loss = 0.25716
I0108 19:50:15.721923   473 caffe_interface.cpp:141] Batch 75, top-1 = 0.94
I0108 19:50:15.740559   473 caffe_interface.cpp:141] Batch 76, accuracy = 0.9
I0108 19:50:15.740569   473 caffe_interface.cpp:141] Batch 76, loss = 0.351994
I0108 19:50:15.740572   473 caffe_interface.cpp:141] Batch 76, top-1 = 0.9
I0108 19:50:15.758554   473 caffe_interface.cpp:141] Batch 77, accuracy = 0.92
I0108 19:50:15.758564   473 caffe_interface.cpp:141] Batch 77, loss = 0.443028
I0108 19:50:15.758567   473 caffe_interface.cpp:141] Batch 77, top-1 = 0.92
I0108 19:50:15.777474   473 caffe_interface.cpp:141] Batch 78, accuracy = 0.96
I0108 19:50:15.777483   473 caffe_interface.cpp:141] Batch 78, loss = 0.115496
I0108 19:50:15.777487   473 caffe_interface.cpp:141] Batch 78, top-1 = 0.96
I0108 19:50:15.795635   473 caffe_interface.cpp:141] Batch 79, accuracy = 0.96
I0108 19:50:15.795644   473 caffe_interface.cpp:141] Batch 79, loss = 0.0854766
I0108 19:50:15.795647   473 caffe_interface.cpp:141] Batch 79, top-1 = 0.96
I0108 19:50:15.795650   473 caffe_interface.cpp:146] Loss: 0.207913
I0108 19:50:15.795655   473 caffe_interface.cpp:158] accuracy = 0.94375
I0108 19:50:15.795661   473 caffe_interface.cpp:158] loss = 0.207913 (* 1 = 0.207913 loss)
I0108 19:50:15.795665   473 caffe_interface.cpp:158] top-1 = 0.94375
I0108 19:50:15.962184   473 sens_analyser.cpp:191] Analysis may take a long time, please wait patiently
I0108 19:50:15.962198   473 sens_analyser.cpp:192] Analysis completed 0%
I0108 19:50:21.264431   473 sens_analyser.cpp:260] Analysis completed 2%
I0108 19:50:27.162887   473 sens_analyser.cpp:260] Analysis completed 4%
I0108 19:50:33.220479   473 sens_analyser.cpp:260] Analysis completed 6%
I0108 19:50:39.158033   473 sens_analyser.cpp:260] Analysis completed 8%
I0108 19:50:45.114491   473 sens_analyser.cpp:260] Analysis completed 11%
I0108 19:50:51.126055   473 sens_analyser.cpp:260] Analysis completed 13%
I0108 19:50:57.311591   473 sens_analyser.cpp:260] Analysis completed 15%
I0108 19:51:03.321681   473 sens_analyser.cpp:260] Analysis completed 17%
I0108 19:51:09.440495   473 sens_analyser.cpp:260] Analysis completed 20%
I0108 19:51:15.521601   473 sens_analyser.cpp:260] Analysis completed 22%
I0108 19:51:21.645817   473 sens_analyser.cpp:260] Analysis completed 24%
I0108 19:51:27.919340   473 sens_analyser.cpp:260] Analysis completed 26%
I0108 19:51:33.889940   473 sens_analyser.cpp:260] Analysis completed 28%
I0108 19:51:39.852555   473 sens_analyser.cpp:260] Analysis completed 31%
I0108 19:51:45.841212   473 sens_analyser.cpp:260] Analysis completed 33%
I0108 19:51:51.863601   473 sens_analyser.cpp:260] Analysis completed 35%
I0108 19:51:57.834745   473 sens_analyser.cpp:260] Analysis completed 37%
I0108 19:52:04.111629   473 sens_analyser.cpp:260] Analysis completed 40%
I0108 19:52:10.080034   473 sens_analyser.cpp:260] Analysis completed 42%
I0108 19:52:16.037959   473 sens_analyser.cpp:260] Analysis completed 44%
I0108 19:52:22.051301   473 sens_analyser.cpp:260] Analysis completed 46%
I0108 19:52:28.020521   473 sens_analyser.cpp:260] Analysis completed 48%
I0108 19:52:33.991191   473 sens_analyser.cpp:260] Analysis completed 51%
I0108 19:52:40.001245   473 sens_analyser.cpp:260] Analysis completed 53%
I0108 19:52:46.269981   473 sens_analyser.cpp:260] Analysis completed 55%
I0108 19:52:52.229633   473 sens_analyser.cpp:260] Analysis completed 57%
I0108 19:52:58.222606   473 sens_analyser.cpp:260] Analysis completed 60%
I0108 19:53:04.238916   473 sens_analyser.cpp:260] Analysis completed 62%
I0108 19:53:10.244392   473 sens_analyser.cpp:260] Analysis completed 64%
I0108 19:53:16.221976   473 sens_analyser.cpp:260] Analysis completed 66%
I0108 19:53:22.176033   473 sens_analyser.cpp:260] Analysis completed 68%
I0108 19:53:28.130218   473 sens_analyser.cpp:260] Analysis completed 71%
I0108 19:53:34.050207   473 sens_analyser.cpp:260] Analysis completed 73%
I0108 19:53:40.034344   473 sens_analyser.cpp:260] Analysis completed 75%
I0108 19:53:45.996814   473 sens_analyser.cpp:260] Analysis completed 77%
I0108 19:53:51.967569   473 sens_analyser.cpp:260] Analysis completed 80%
I0108 19:53:57.949620   473 sens_analyser.cpp:260] Analysis completed 82%
I0108 19:54:03.980281   473 sens_analyser.cpp:260] Analysis completed 84%
I0108 19:54:10.008425   473 sens_analyser.cpp:260] Analysis completed 86%
I0108 19:54:15.935792   473 sens_analyser.cpp:260] Analysis completed 88%
I0108 19:54:21.984915   473 sens_analyser.cpp:260] Analysis completed 91%
I0108 19:54:27.954975   473 sens_analyser.cpp:260] Analysis completed 93%
I0108 19:54:33.918876   473 sens_analyser.cpp:260] Analysis completed 95%
I0108 19:54:39.870354   473 sens_analyser.cpp:260] Analysis completed 97%
I0108 19:54:45.802664   473 sens_analyser.cpp:260] Analysis completed 100%
I0108 19:54:45.822824   473 vai_p_caffe.cpp:259] Analysis done.
Now you can prune the model with the following command:
vai_p_caffe prune -config /workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/config0.prototxt
(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

I0108 19:54:46.294786  1888 pruning_runner.cpp:206] Analysis info found.
I0108 19:54:47.265209  1888 pruning_runner.cpp:237] Start pruning, please wait...
I0108 19:54:55.924801  1888 pruning_runner.cpp:337] pruning done, output model: pruning/alexnetBNnoLRN/regular_rate_0/sparse.caffemodel
I0108 19:54:55.924827  1888 pruning_runner.cpp:351] summary of REGULAR compression with rate 0:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.943749785    | 0.943749785    | 0              |
+-------------------------------------------------------------------+
| Weights        | 3.7649951 M    | 3.7649951 M    | 0%             |
+-------------------------------------------------------------------+
| Operations     | 2.1539185 G    | 2.1539185 G    | 0%             |
+-------------------------------------------------------------------+
To fine-tune the pruned model, please run:
vai_p_caffe finetune -config /workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/config0.prototxt
(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

W0108 19:54:56.065382  2043 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0108 19:54:56.065568  2043 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0108 19:54:56.065599  2043 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0108 19:54:56.071724  2043 vai_p_caffe.cpp:287] pruning/alexnetBNnoLRN/regular_rate_0/net_finetune.prototxt
I0108 19:54:56.239785  2043 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0108 19:54:56.239804  2043 gpu_memory.cpp:55] Total memory: 25620447232, Free: 25022103552, dev_info[0]: total=25620447232 free=25022103552
I0108 19:54:56.240674  2043 caffe_interface.cpp:509] Using GPUs 0
I0108 19:54:56.240923  2043 caffe_interface.cpp:514] GPU 0: Quadro P6000
I0108 19:54:57.109719  2043 solver.cpp:51] Initializing solver from parameters:
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 6000
snapshot_prefix: "pruning/alexnetBNnoLRN/regular_rate_0/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "pruning/alexnetBNnoLRN/regular_rate_0/net_finetune.prototxt"
type: "Adam"
I0108 19:54:57.109885  2043 solver.cpp:99] Creating training net from net file: pruning/alexnetBNnoLRN/regular_rate_0/net_finetune.prototxt
I0108 19:54:57.110174  2043 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0108 19:54:57.110186  2043 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0108 19:54:57.110190  2043 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0108 19:54:57.110194  2043 net.cpp:52] Initializing net from parameters:
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0108 19:54:57.110424  2043 layer_factory.hpp:77] Creating layer data
I0108 19:54:57.110584  2043 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 19:54:57.112262  2043 net.cpp:94] Creating Layer data
I0108 19:54:57.112275  2043 net.cpp:409] data -> data
I0108 19:54:57.112287  2043 net.cpp:409] data -> label
I0108 19:54:57.113540  2080 db_lmdb.cpp:35] Opened lmdb input/lmdb/train_lmdb
I0108 19:54:57.113561  2080 db_lmdb.cpp:38] Items count: 20000
I0108 19:54:57.113582  2080 data_reader.cpp:124] TRAIN: reading data using 1 channel(s)
I0108 19:54:57.113839  2043 data_layer.cpp:78] ReshapePrefetch 256, 3, 227, 227
I0108 19:54:57.113924  2043 data_layer.cpp:83] output data size: 256,3,227,227
I0108 19:54:57.591315  2043 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 19:54:57.591400  2043 net.cpp:144] Setting up data
I0108 19:54:57.591405  2043 net.cpp:151] Top shape: 256 3 227 227 (39574272)
I0108 19:54:57.591429  2043 net.cpp:151] Top shape: 256 (256)
I0108 19:54:57.591434  2043 net.cpp:159] Memory required for data: 158298112
I0108 19:54:57.591439  2043 layer_factory.hpp:77] Creating layer conv1
I0108 19:54:57.591449  2043 net.cpp:94] Creating Layer conv1
I0108 19:54:57.591462  2043 net.cpp:435] conv1 <- data
I0108 19:54:57.591468  2043 net.cpp:409] conv1 -> conv1
I0108 19:54:57.592092  2043 net.cpp:144] Setting up conv1
I0108 19:54:57.592098  2043 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0108 19:54:57.592104  2043 net.cpp:159] Memory required for data: 455667712
I0108 19:54:57.592114  2043 layer_factory.hpp:77] Creating layer bn1
I0108 19:54:57.592123  2043 net.cpp:94] Creating Layer bn1
I0108 19:54:57.592125  2043 net.cpp:435] bn1 <- conv1
I0108 19:54:57.592130  2043 net.cpp:409] bn1 -> bn1
I0108 19:54:57.592648  2043 net.cpp:144] Setting up bn1
I0108 19:54:57.592653  2043 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0108 19:54:57.592658  2043 net.cpp:159] Memory required for data: 753037312
I0108 19:54:57.592665  2043 layer_factory.hpp:77] Creating layer relu1
I0108 19:54:57.592670  2043 net.cpp:94] Creating Layer relu1
I0108 19:54:57.592674  2043 net.cpp:435] relu1 <- bn1
I0108 19:54:57.592679  2043 net.cpp:409] relu1 -> relu1
I0108 19:54:57.592694  2043 net.cpp:144] Setting up relu1
I0108 19:54:57.592696  2043 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0108 19:54:57.592700  2043 net.cpp:159] Memory required for data: 1050406912
I0108 19:54:57.592705  2043 layer_factory.hpp:77] Creating layer pool1
I0108 19:54:57.592710  2043 net.cpp:94] Creating Layer pool1
I0108 19:54:57.592712  2043 net.cpp:435] pool1 <- relu1
I0108 19:54:57.592717  2043 net.cpp:409] pool1 -> pool1
I0108 19:54:57.592738  2043 net.cpp:144] Setting up pool1
I0108 19:54:57.592741  2043 net.cpp:151] Top shape: 256 96 27 27 (17915904)
I0108 19:54:57.592746  2043 net.cpp:159] Memory required for data: 1122070528
I0108 19:54:57.592749  2043 layer_factory.hpp:77] Creating layer conv2
I0108 19:54:57.592756  2043 net.cpp:94] Creating Layer conv2
I0108 19:54:57.592759  2043 net.cpp:435] conv2 <- pool1
I0108 19:54:57.592764  2043 net.cpp:409] conv2 -> conv2
I0108 19:54:57.607954  2043 net.cpp:144] Setting up conv2
I0108 19:54:57.607967  2043 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0108 19:54:57.607975  2043 net.cpp:159] Memory required for data: 1313173504
I0108 19:54:57.608000  2043 layer_factory.hpp:77] Creating layer bn2
I0108 19:54:57.608007  2043 net.cpp:94] Creating Layer bn2
I0108 19:54:57.608011  2043 net.cpp:435] bn2 <- conv2
I0108 19:54:57.608016  2043 net.cpp:409] bn2 -> bn2
I0108 19:54:57.608588  2043 net.cpp:144] Setting up bn2
I0108 19:54:57.608597  2043 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0108 19:54:57.608603  2043 net.cpp:159] Memory required for data: 1504276480
I0108 19:54:57.608611  2043 layer_factory.hpp:77] Creating layer relu2
I0108 19:54:57.608618  2043 net.cpp:94] Creating Layer relu2
I0108 19:54:57.608621  2043 net.cpp:435] relu2 <- bn2
I0108 19:54:57.608625  2043 net.cpp:409] relu2 -> relu2
I0108 19:54:57.608642  2043 net.cpp:144] Setting up relu2
I0108 19:54:57.608649  2043 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0108 19:54:57.608655  2043 net.cpp:159] Memory required for data: 1695379456
I0108 19:54:57.608659  2043 layer_factory.hpp:77] Creating layer pool2
I0108 19:54:57.608716  2043 net.cpp:94] Creating Layer pool2
I0108 19:54:57.608741  2043 net.cpp:435] pool2 <- relu2
I0108 19:54:57.608754  2043 net.cpp:409] pool2 -> pool2
I0108 19:54:57.608882  2043 net.cpp:144] Setting up pool2
I0108 19:54:57.608897  2043 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0108 19:54:57.608911  2043 net.cpp:159] Memory required for data: 1739681792
I0108 19:54:57.608919  2043 layer_factory.hpp:77] Creating layer conv3
I0108 19:54:57.608976  2043 net.cpp:94] Creating Layer conv3
I0108 19:54:57.608985  2043 net.cpp:435] conv3 <- pool2
I0108 19:54:57.608996  2043 net.cpp:409] conv3 -> conv3
I0108 19:54:57.627166  2043 net.cpp:144] Setting up conv3
I0108 19:54:57.627193  2043 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 19:54:57.627213  2043 net.cpp:159] Memory required for data: 1806135296
I0108 19:54:57.627228  2043 layer_factory.hpp:77] Creating layer relu3
I0108 19:54:57.627243  2043 net.cpp:94] Creating Layer relu3
I0108 19:54:57.627260  2043 net.cpp:435] relu3 <- conv3
I0108 19:54:57.627275  2043 net.cpp:409] relu3 -> relu3
I0108 19:54:57.627337  2043 net.cpp:144] Setting up relu3
I0108 19:54:57.627349  2043 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 19:54:57.627360  2043 net.cpp:159] Memory required for data: 1872588800
I0108 19:54:57.627367  2043 layer_factory.hpp:77] Creating layer conv4
I0108 19:54:57.627382  2043 net.cpp:94] Creating Layer conv4
I0108 19:54:57.627388  2043 net.cpp:435] conv4 <- relu3
I0108 19:54:57.627398  2043 net.cpp:409] conv4 -> conv4
I0108 19:54:57.654783  2043 net.cpp:144] Setting up conv4
I0108 19:54:57.654811  2043 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 19:54:57.654826  2043 net.cpp:159] Memory required for data: 1939042304
I0108 19:54:57.654848  2043 layer_factory.hpp:77] Creating layer relu4
I0108 19:54:57.654876  2043 net.cpp:94] Creating Layer relu4
I0108 19:54:57.654886  2043 net.cpp:435] relu4 <- conv4
I0108 19:54:57.654897  2043 net.cpp:409] relu4 -> relu4
I0108 19:54:57.654944  2043 net.cpp:144] Setting up relu4
I0108 19:54:57.654955  2043 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 19:54:57.654964  2043 net.cpp:159] Memory required for data: 2005495808
I0108 19:54:57.654970  2043 layer_factory.hpp:77] Creating layer conv5
I0108 19:54:57.654986  2043 net.cpp:94] Creating Layer conv5
I0108 19:54:57.654992  2043 net.cpp:435] conv5 <- relu4
I0108 19:54:57.655000  2043 net.cpp:409] conv5 -> conv5
I0108 19:54:57.669008  2043 net.cpp:144] Setting up conv5
I0108 19:54:57.669034  2043 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0108 19:54:57.669044  2043 net.cpp:159] Memory required for data: 2049798144
I0108 19:54:57.669055  2043 layer_factory.hpp:77] Creating layer relu5
I0108 19:54:57.669064  2043 net.cpp:94] Creating Layer relu5
I0108 19:54:57.669070  2043 net.cpp:435] relu5 <- conv5
I0108 19:54:57.669082  2043 net.cpp:409] relu5 -> relu5
I0108 19:54:57.669133  2043 net.cpp:144] Setting up relu5
I0108 19:54:57.669144  2043 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0108 19:54:57.669162  2043 net.cpp:159] Memory required for data: 2094100480
I0108 19:54:57.669168  2043 layer_factory.hpp:77] Creating layer pool5
I0108 19:54:57.669179  2043 net.cpp:94] Creating Layer pool5
I0108 19:54:57.669188  2043 net.cpp:435] pool5 <- relu5
I0108 19:54:57.669199  2043 net.cpp:409] pool5 -> pool5
I0108 19:54:57.669248  2043 net.cpp:144] Setting up pool5
I0108 19:54:57.669255  2043 net.cpp:151] Top shape: 256 256 6 6 (2359296)
I0108 19:54:57.669262  2043 net.cpp:159] Memory required for data: 2103537664
I0108 19:54:57.669267  2043 layer_factory.hpp:77] Creating layer fc6
I0108 19:54:57.669284  2043 net.cpp:94] Creating Layer fc6
I0108 19:54:57.669293  2043 net.cpp:435] fc6 <- pool5
I0108 19:54:57.669303  2043 net.cpp:409] fc6 -> fc6
I0108 19:54:58.039837  2043 net.cpp:144] Setting up fc6
I0108 19:54:58.039870  2043 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 19:54:58.039885  2043 net.cpp:159] Memory required for data: 2107731968
I0108 19:54:58.039901  2043 layer_factory.hpp:77] Creating layer relu6
I0108 19:54:58.039912  2043 net.cpp:94] Creating Layer relu6
I0108 19:54:58.039925  2043 net.cpp:435] relu6 <- fc6
I0108 19:54:58.039935  2043 net.cpp:409] relu6 -> relu6
I0108 19:54:58.039965  2043 net.cpp:144] Setting up relu6
I0108 19:54:58.039974  2043 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 19:54:58.039983  2043 net.cpp:159] Memory required for data: 2111926272
I0108 19:54:58.039989  2043 layer_factory.hpp:77] Creating layer drop6
I0108 19:54:58.040007  2043 net.cpp:94] Creating Layer drop6
I0108 19:54:58.040030  2043 net.cpp:435] drop6 <- relu6
I0108 19:54:58.040036  2043 net.cpp:409] drop6 -> drop6
I0108 19:54:58.040071  2043 net.cpp:144] Setting up drop6
I0108 19:54:58.040077  2043 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 19:54:58.040084  2043 net.cpp:159] Memory required for data: 2116120576
I0108 19:54:58.040089  2043 layer_factory.hpp:77] Creating layer fc7
I0108 19:54:58.040097  2043 net.cpp:94] Creating Layer fc7
I0108 19:54:58.040102  2043 net.cpp:435] fc7 <- drop6
I0108 19:54:58.040109  2043 net.cpp:409] fc7 -> fc7
I0108 19:54:58.199179  2043 net.cpp:144] Setting up fc7
I0108 19:54:58.199203  2043 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 19:54:58.199216  2043 net.cpp:159] Memory required for data: 2120314880
I0108 19:54:58.199229  2043 layer_factory.hpp:77] Creating layer bn7
I0108 19:54:58.199240  2043 net.cpp:94] Creating Layer bn7
I0108 19:54:58.199249  2043 net.cpp:435] bn7 <- fc7
I0108 19:54:58.199259  2043 net.cpp:409] bn7 -> bn7
I0108 19:54:58.199808  2043 net.cpp:144] Setting up bn7
I0108 19:54:58.199816  2043 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 19:54:58.199828  2043 net.cpp:159] Memory required for data: 2124509184
I0108 19:54:58.199842  2043 layer_factory.hpp:77] Creating layer relu7
I0108 19:54:58.199852  2043 net.cpp:94] Creating Layer relu7
I0108 19:54:58.199858  2043 net.cpp:435] relu7 <- bn7
I0108 19:54:58.199867  2043 net.cpp:409] relu7 -> relu7
I0108 19:54:58.199887  2043 net.cpp:144] Setting up relu7
I0108 19:54:58.199898  2043 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 19:54:58.199906  2043 net.cpp:159] Memory required for data: 2128703488
I0108 19:54:58.199909  2043 layer_factory.hpp:77] Creating layer drop7
I0108 19:54:58.199915  2043 net.cpp:94] Creating Layer drop7
I0108 19:54:58.199919  2043 net.cpp:435] drop7 <- relu7
I0108 19:54:58.199928  2043 net.cpp:409] drop7 -> drop7
I0108 19:54:58.199950  2043 net.cpp:144] Setting up drop7
I0108 19:54:58.199954  2043 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 19:54:58.199959  2043 net.cpp:159] Memory required for data: 2132897792
I0108 19:54:58.199962  2043 layer_factory.hpp:77] Creating layer fc8
I0108 19:54:58.199971  2043 net.cpp:94] Creating Layer fc8
I0108 19:54:58.199976  2043 net.cpp:435] fc8 <- drop7
I0108 19:54:58.199983  2043 net.cpp:409] fc8 -> fc8
I0108 19:54:58.200139  2043 net.cpp:144] Setting up fc8
I0108 19:54:58.200145  2043 net.cpp:151] Top shape: 256 2 (512)
I0108 19:54:58.200150  2043 net.cpp:159] Memory required for data: 2132899840
I0108 19:54:58.200158  2043 layer_factory.hpp:77] Creating layer loss
I0108 19:54:58.200165  2043 net.cpp:94] Creating Layer loss
I0108 19:54:58.200170  2043 net.cpp:435] loss <- fc8
I0108 19:54:58.200176  2043 net.cpp:435] loss <- label
I0108 19:54:58.200181  2043 net.cpp:409] loss -> loss
I0108 19:54:58.200187  2043 layer_factory.hpp:77] Creating layer loss
I0108 19:54:58.200248  2043 net.cpp:144] Setting up loss
I0108 19:54:58.200253  2043 net.cpp:151] Top shape: (1)
I0108 19:54:58.200258  2043 net.cpp:154]     with loss weight 1
I0108 19:54:58.200269  2043 net.cpp:159] Memory required for data: 2132899844
I0108 19:54:58.200273  2043 net.cpp:220] loss needs backward computation.
I0108 19:54:58.200276  2043 net.cpp:220] fc8 needs backward computation.
I0108 19:54:58.200279  2043 net.cpp:220] drop7 needs backward computation.
I0108 19:54:58.200284  2043 net.cpp:220] relu7 needs backward computation.
I0108 19:54:58.200289  2043 net.cpp:220] bn7 needs backward computation.
I0108 19:54:58.200294  2043 net.cpp:220] fc7 needs backward computation.
I0108 19:54:58.200299  2043 net.cpp:220] drop6 needs backward computation.
I0108 19:54:58.200304  2043 net.cpp:220] relu6 needs backward computation.
I0108 19:54:58.200307  2043 net.cpp:220] fc6 needs backward computation.
I0108 19:54:58.200312  2043 net.cpp:220] pool5 needs backward computation.
I0108 19:54:58.200318  2043 net.cpp:220] relu5 needs backward computation.
I0108 19:54:58.200323  2043 net.cpp:220] conv5 needs backward computation.
I0108 19:54:58.200330  2043 net.cpp:220] relu4 needs backward computation.
I0108 19:54:58.200345  2043 net.cpp:220] conv4 needs backward computation.
I0108 19:54:58.200351  2043 net.cpp:220] relu3 needs backward computation.
I0108 19:54:58.200356  2043 net.cpp:220] conv3 needs backward computation.
I0108 19:54:58.200361  2043 net.cpp:220] pool2 needs backward computation.
I0108 19:54:58.200367  2043 net.cpp:220] relu2 needs backward computation.
I0108 19:54:58.200373  2043 net.cpp:220] bn2 needs backward computation.
I0108 19:54:58.200378  2043 net.cpp:220] conv2 needs backward computation.
I0108 19:54:58.200383  2043 net.cpp:220] pool1 needs backward computation.
I0108 19:54:58.200389  2043 net.cpp:220] relu1 needs backward computation.
I0108 19:54:58.200393  2043 net.cpp:220] bn1 needs backward computation.
I0108 19:54:58.200397  2043 net.cpp:220] conv1 needs backward computation.
I0108 19:54:58.200402  2043 net.cpp:222] data does not need backward computation.
I0108 19:54:58.200404  2043 net.cpp:264] This network produces output loss
I0108 19:54:58.200448  2043 net.cpp:284] Network initialization done.
I0108 19:54:58.200835  2043 solver.cpp:189] Creating test net (#0) specified by net file: pruning/alexnetBNnoLRN/regular_rate_0/net_finetune.prototxt
I0108 19:54:58.200871  2043 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0108 19:54:58.200887  2043 net.cpp:52] Initializing net from parameters:
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0108 19:54:58.201154  2043 layer_factory.hpp:77] Creating layer data
I0108 19:54:58.201216  2043 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 19:54:58.202999  2043 net.cpp:94] Creating Layer data
I0108 19:54:58.203016  2043 net.cpp:409] data -> data
I0108 19:54:58.203027  2043 net.cpp:409] data -> label
I0108 19:54:58.204632  2110 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0108 19:54:58.204654  2110 db_lmdb.cpp:38] Items count: 4000
I0108 19:54:58.204675  2110 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0108 19:54:58.204988  2043 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0108 19:54:58.205085  2043 data_layer.cpp:83] output data size: 50,3,227,227
I0108 19:54:58.304117  2043 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 19:54:58.304222  2043 net.cpp:144] Setting up data
I0108 19:54:58.304229  2043 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0108 19:54:58.304237  2043 net.cpp:151] Top shape: 50 (50)
I0108 19:54:58.304241  2043 net.cpp:159] Memory required for data: 30917600
I0108 19:54:58.304246  2043 layer_factory.hpp:77] Creating layer label_data_1_split
I0108 19:54:58.304255  2043 net.cpp:94] Creating Layer label_data_1_split
I0108 19:54:58.304263  2043 net.cpp:435] label_data_1_split <- label
I0108 19:54:58.304268  2043 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0108 19:54:58.304277  2043 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0108 19:54:58.304281  2043 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0108 19:54:58.304355  2043 net.cpp:144] Setting up label_data_1_split
I0108 19:54:58.304361  2043 net.cpp:151] Top shape: 50 (50)
I0108 19:54:58.304366  2043 net.cpp:151] Top shape: 50 (50)
I0108 19:54:58.304370  2043 net.cpp:151] Top shape: 50 (50)
I0108 19:54:58.304373  2043 net.cpp:159] Memory required for data: 30918200
I0108 19:54:58.304378  2043 layer_factory.hpp:77] Creating layer conv1
I0108 19:54:58.304388  2043 net.cpp:94] Creating Layer conv1
I0108 19:54:58.304394  2043 net.cpp:435] conv1 <- data
I0108 19:54:58.304400  2043 net.cpp:409] conv1 -> conv1
I0108 19:54:58.305022  2043 net.cpp:144] Setting up conv1
I0108 19:54:58.305028  2043 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0108 19:54:58.305033  2043 net.cpp:159] Memory required for data: 88998200
I0108 19:54:58.305044  2043 layer_factory.hpp:77] Creating layer bn1
I0108 19:54:58.305052  2043 net.cpp:94] Creating Layer bn1
I0108 19:54:58.305055  2043 net.cpp:435] bn1 <- conv1
I0108 19:54:58.305061  2043 net.cpp:409] bn1 -> bn1
I0108 19:54:58.305600  2043 net.cpp:144] Setting up bn1
I0108 19:54:58.305606  2043 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0108 19:54:58.305613  2043 net.cpp:159] Memory required for data: 147078200
I0108 19:54:58.305621  2043 layer_factory.hpp:77] Creating layer relu1
I0108 19:54:58.305626  2043 net.cpp:94] Creating Layer relu1
I0108 19:54:58.305630  2043 net.cpp:435] relu1 <- bn1
I0108 19:54:58.305635  2043 net.cpp:409] relu1 -> relu1
I0108 19:54:58.305652  2043 net.cpp:144] Setting up relu1
I0108 19:54:58.305657  2043 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0108 19:54:58.305663  2043 net.cpp:159] Memory required for data: 205158200
I0108 19:54:58.305666  2043 layer_factory.hpp:77] Creating layer pool1
I0108 19:54:58.305671  2043 net.cpp:94] Creating Layer pool1
I0108 19:54:58.305675  2043 net.cpp:435] pool1 <- relu1
I0108 19:54:58.305680  2043 net.cpp:409] pool1 -> pool1
I0108 19:54:58.305704  2043 net.cpp:144] Setting up pool1
I0108 19:54:58.305709  2043 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0108 19:54:58.305714  2043 net.cpp:159] Memory required for data: 219155000
I0108 19:54:58.305718  2043 layer_factory.hpp:77] Creating layer conv2
I0108 19:54:58.305727  2043 net.cpp:94] Creating Layer conv2
I0108 19:54:58.305730  2043 net.cpp:435] conv2 <- pool1
I0108 19:54:58.305734  2043 net.cpp:409] conv2 -> conv2
I0108 19:54:58.313427  2043 net.cpp:144] Setting up conv2
I0108 19:54:58.313444  2043 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0108 19:54:58.313452  2043 net.cpp:159] Memory required for data: 256479800
I0108 19:54:58.313462  2043 layer_factory.hpp:77] Creating layer bn2
I0108 19:54:58.313521  2043 net.cpp:94] Creating Layer bn2
I0108 19:54:58.313552  2043 net.cpp:435] bn2 <- conv2
I0108 19:54:58.313570  2043 net.cpp:409] bn2 -> bn2
I0108 19:54:58.315059  2043 net.cpp:144] Setting up bn2
I0108 19:54:58.315083  2043 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0108 19:54:58.315101  2043 net.cpp:159] Memory required for data: 293804600
I0108 19:54:58.315129  2043 layer_factory.hpp:77] Creating layer relu2
I0108 19:54:58.315150  2043 net.cpp:94] Creating Layer relu2
I0108 19:54:58.315161  2043 net.cpp:435] relu2 <- bn2
I0108 19:54:58.315176  2043 net.cpp:409] relu2 -> relu2
I0108 19:54:58.315217  2043 net.cpp:144] Setting up relu2
I0108 19:54:58.315248  2043 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0108 19:54:58.315259  2043 net.cpp:159] Memory required for data: 331129400
I0108 19:54:58.315268  2043 layer_factory.hpp:77] Creating layer pool2
I0108 19:54:58.315279  2043 net.cpp:94] Creating Layer pool2
I0108 19:54:58.315286  2043 net.cpp:435] pool2 <- relu2
I0108 19:54:58.315296  2043 net.cpp:409] pool2 -> pool2
I0108 19:54:58.315349  2043 net.cpp:144] Setting up pool2
I0108 19:54:58.315361  2043 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0108 19:54:58.315371  2043 net.cpp:159] Memory required for data: 339782200
I0108 19:54:58.315378  2043 layer_factory.hpp:77] Creating layer conv3
I0108 19:54:58.315397  2043 net.cpp:94] Creating Layer conv3
I0108 19:54:58.315407  2043 net.cpp:435] conv3 <- pool2
I0108 19:54:58.315418  2043 net.cpp:409] conv3 -> conv3
I0108 19:54:58.335055  2043 net.cpp:144] Setting up conv3
I0108 19:54:58.335076  2043 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 19:54:58.335083  2043 net.cpp:159] Memory required for data: 352761400
I0108 19:54:58.335093  2043 layer_factory.hpp:77] Creating layer relu3
I0108 19:54:58.335100  2043 net.cpp:94] Creating Layer relu3
I0108 19:54:58.335104  2043 net.cpp:435] relu3 <- conv3
I0108 19:54:58.335110  2043 net.cpp:409] relu3 -> relu3
I0108 19:54:58.335136  2043 net.cpp:144] Setting up relu3
I0108 19:54:58.335140  2043 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 19:54:58.335145  2043 net.cpp:159] Memory required for data: 365740600
I0108 19:54:58.335148  2043 layer_factory.hpp:77] Creating layer conv4
I0108 19:54:58.335157  2043 net.cpp:94] Creating Layer conv4
I0108 19:54:58.335160  2043 net.cpp:435] conv4 <- relu3
I0108 19:54:58.335165  2043 net.cpp:409] conv4 -> conv4
I0108 19:54:58.352344  2043 net.cpp:144] Setting up conv4
I0108 19:54:58.352376  2043 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 19:54:58.352383  2043 net.cpp:159] Memory required for data: 378719800
I0108 19:54:58.352411  2043 layer_factory.hpp:77] Creating layer relu4
I0108 19:54:58.352416  2043 net.cpp:94] Creating Layer relu4
I0108 19:54:58.352421  2043 net.cpp:435] relu4 <- conv4
I0108 19:54:58.352427  2043 net.cpp:409] relu4 -> relu4
I0108 19:54:58.352449  2043 net.cpp:144] Setting up relu4
I0108 19:54:58.352452  2043 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 19:54:58.352456  2043 net.cpp:159] Memory required for data: 391699000
I0108 19:54:58.352459  2043 layer_factory.hpp:77] Creating layer conv5
I0108 19:54:58.352466  2043 net.cpp:94] Creating Layer conv5
I0108 19:54:58.352469  2043 net.cpp:435] conv5 <- relu4
I0108 19:54:58.352479  2043 net.cpp:409] conv5 -> conv5
I0108 19:54:58.366001  2043 net.cpp:144] Setting up conv5
I0108 19:54:58.366027  2043 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0108 19:54:58.366055  2043 net.cpp:159] Memory required for data: 400351800
I0108 19:54:58.366067  2043 layer_factory.hpp:77] Creating layer relu5
I0108 19:54:58.366076  2043 net.cpp:94] Creating Layer relu5
I0108 19:54:58.366084  2043 net.cpp:435] relu5 <- conv5
I0108 19:54:58.366094  2043 net.cpp:409] relu5 -> relu5
I0108 19:54:58.366130  2043 net.cpp:144] Setting up relu5
I0108 19:54:58.366138  2043 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0108 19:54:58.366145  2043 net.cpp:159] Memory required for data: 409004600
I0108 19:54:58.366150  2043 layer_factory.hpp:77] Creating layer pool5
I0108 19:54:58.366161  2043 net.cpp:94] Creating Layer pool5
I0108 19:54:58.366166  2043 net.cpp:435] pool5 <- relu5
I0108 19:54:58.366173  2043 net.cpp:409] pool5 -> pool5
I0108 19:54:58.366209  2043 net.cpp:144] Setting up pool5
I0108 19:54:58.366217  2043 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0108 19:54:58.366225  2043 net.cpp:159] Memory required for data: 410847800
I0108 19:54:58.366230  2043 layer_factory.hpp:77] Creating layer fc6
I0108 19:54:58.366237  2043 net.cpp:94] Creating Layer fc6
I0108 19:54:58.366242  2043 net.cpp:435] fc6 <- pool5
I0108 19:54:58.366263  2043 net.cpp:409] fc6 -> fc6
I0108 19:54:58.693894  2043 net.cpp:144] Setting up fc6
I0108 19:54:58.693919  2043 net.cpp:151] Top shape: 50 4096 (204800)
I0108 19:54:58.693943  2043 net.cpp:159] Memory required for data: 411667000
I0108 19:54:58.693951  2043 layer_factory.hpp:77] Creating layer relu6
I0108 19:54:58.693958  2043 net.cpp:94] Creating Layer relu6
I0108 19:54:58.693961  2043 net.cpp:435] relu6 <- fc6
I0108 19:54:58.693969  2043 net.cpp:409] relu6 -> relu6
I0108 19:54:58.693992  2043 net.cpp:144] Setting up relu6
I0108 19:54:58.693995  2043 net.cpp:151] Top shape: 50 4096 (204800)
I0108 19:54:58.694000  2043 net.cpp:159] Memory required for data: 412486200
I0108 19:54:58.694018  2043 layer_factory.hpp:77] Creating layer drop6
I0108 19:54:58.694022  2043 net.cpp:94] Creating Layer drop6
I0108 19:54:58.694026  2043 net.cpp:435] drop6 <- relu6
I0108 19:54:58.694029  2043 net.cpp:409] drop6 -> drop6
I0108 19:54:58.694051  2043 net.cpp:144] Setting up drop6
I0108 19:54:58.694057  2043 net.cpp:151] Top shape: 50 4096 (204800)
I0108 19:54:58.694061  2043 net.cpp:159] Memory required for data: 413305400
I0108 19:54:58.694064  2043 layer_factory.hpp:77] Creating layer fc7
I0108 19:54:58.694072  2043 net.cpp:94] Creating Layer fc7
I0108 19:54:58.694074  2043 net.cpp:435] fc7 <- drop6
I0108 19:54:58.694078  2043 net.cpp:409] fc7 -> fc7
I0108 19:54:58.838022  2043 net.cpp:144] Setting up fc7
I0108 19:54:58.838047  2043 net.cpp:151] Top shape: 50 4096 (204800)
I0108 19:54:58.838055  2043 net.cpp:159] Memory required for data: 414124600
I0108 19:54:58.838064  2043 layer_factory.hpp:77] Creating layer bn7
I0108 19:54:58.838073  2043 net.cpp:94] Creating Layer bn7
I0108 19:54:58.838078  2043 net.cpp:435] bn7 <- fc7
I0108 19:54:58.838083  2043 net.cpp:409] bn7 -> bn7
I0108 19:54:58.838585  2043 net.cpp:144] Setting up bn7
I0108 19:54:58.838593  2043 net.cpp:151] Top shape: 50 4096 (204800)
I0108 19:54:58.838598  2043 net.cpp:159] Memory required for data: 414943800
I0108 19:54:58.838605  2043 layer_factory.hpp:77] Creating layer relu7
I0108 19:54:58.838610  2043 net.cpp:94] Creating Layer relu7
I0108 19:54:58.838613  2043 net.cpp:435] relu7 <- bn7
I0108 19:54:58.838619  2043 net.cpp:409] relu7 -> relu7
I0108 19:54:58.838635  2043 net.cpp:144] Setting up relu7
I0108 19:54:58.838641  2043 net.cpp:151] Top shape: 50 4096 (204800)
I0108 19:54:58.838645  2043 net.cpp:159] Memory required for data: 415763000
I0108 19:54:58.838649  2043 layer_factory.hpp:77] Creating layer drop7
I0108 19:54:58.838654  2043 net.cpp:94] Creating Layer drop7
I0108 19:54:58.838658  2043 net.cpp:435] drop7 <- relu7
I0108 19:54:58.838662  2043 net.cpp:409] drop7 -> drop7
I0108 19:54:58.838701  2043 net.cpp:144] Setting up drop7
I0108 19:54:58.838706  2043 net.cpp:151] Top shape: 50 4096 (204800)
I0108 19:54:58.838711  2043 net.cpp:159] Memory required for data: 416582200
I0108 19:54:58.838714  2043 layer_factory.hpp:77] Creating layer fc8
I0108 19:54:58.838722  2043 net.cpp:94] Creating Layer fc8
I0108 19:54:58.838726  2043 net.cpp:435] fc8 <- drop7
I0108 19:54:58.838730  2043 net.cpp:409] fc8 -> fc8
I0108 19:54:58.838891  2043 net.cpp:144] Setting up fc8
I0108 19:54:58.838896  2043 net.cpp:151] Top shape: 50 2 (100)
I0108 19:54:58.838901  2043 net.cpp:159] Memory required for data: 416582600
I0108 19:54:58.838907  2043 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0108 19:54:58.838912  2043 net.cpp:94] Creating Layer fc8_fc8_0_split
I0108 19:54:58.838915  2043 net.cpp:435] fc8_fc8_0_split <- fc8
I0108 19:54:58.838920  2043 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0108 19:54:58.838927  2043 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0108 19:54:58.838932  2043 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0108 19:54:58.838963  2043 net.cpp:144] Setting up fc8_fc8_0_split
I0108 19:54:58.838968  2043 net.cpp:151] Top shape: 50 2 (100)
I0108 19:54:58.838973  2043 net.cpp:151] Top shape: 50 2 (100)
I0108 19:54:58.838977  2043 net.cpp:151] Top shape: 50 2 (100)
I0108 19:54:58.838981  2043 net.cpp:159] Memory required for data: 416583800
I0108 19:54:58.838984  2043 layer_factory.hpp:77] Creating layer accuracy
I0108 19:54:58.838992  2043 net.cpp:94] Creating Layer accuracy
I0108 19:54:58.839007  2043 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0108 19:54:58.839012  2043 net.cpp:435] accuracy <- label_data_1_split_0
I0108 19:54:58.839017  2043 net.cpp:409] accuracy -> accuracy
I0108 19:54:58.839025  2043 net.cpp:144] Setting up accuracy
I0108 19:54:58.839028  2043 net.cpp:151] Top shape: (1)
I0108 19:54:58.839032  2043 net.cpp:159] Memory required for data: 416583804
I0108 19:54:58.839036  2043 layer_factory.hpp:77] Creating layer loss
I0108 19:54:58.839041  2043 net.cpp:94] Creating Layer loss
I0108 19:54:58.839044  2043 net.cpp:435] loss <- fc8_fc8_0_split_1
I0108 19:54:58.839049  2043 net.cpp:435] loss <- label_data_1_split_1
I0108 19:54:58.839053  2043 net.cpp:409] loss -> loss
I0108 19:54:58.839066  2043 layer_factory.hpp:77] Creating layer loss
I0108 19:54:58.839139  2043 net.cpp:144] Setting up loss
I0108 19:54:58.839144  2043 net.cpp:151] Top shape: (1)
I0108 19:54:58.839148  2043 net.cpp:154]     with loss weight 1
I0108 19:54:58.839161  2043 net.cpp:159] Memory required for data: 416583808
I0108 19:54:58.839164  2043 layer_factory.hpp:77] Creating layer accuracy-top1
I0108 19:54:58.839169  2043 net.cpp:94] Creating Layer accuracy-top1
I0108 19:54:58.839174  2043 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0108 19:54:58.839179  2043 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0108 19:54:58.839184  2043 net.cpp:409] accuracy-top1 -> top-1
I0108 19:54:58.839190  2043 net.cpp:144] Setting up accuracy-top1
I0108 19:54:58.839192  2043 net.cpp:151] Top shape: (1)
I0108 19:54:58.839196  2043 net.cpp:159] Memory required for data: 416583812
I0108 19:54:58.839200  2043 net.cpp:222] accuracy-top1 does not need backward computation.
I0108 19:54:58.839205  2043 net.cpp:220] loss needs backward computation.
I0108 19:54:58.839210  2043 net.cpp:222] accuracy does not need backward computation.
I0108 19:54:58.839215  2043 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0108 19:54:58.839218  2043 net.cpp:220] fc8 needs backward computation.
I0108 19:54:58.839222  2043 net.cpp:220] drop7 needs backward computation.
I0108 19:54:58.839226  2043 net.cpp:220] relu7 needs backward computation.
I0108 19:54:58.839229  2043 net.cpp:220] bn7 needs backward computation.
I0108 19:54:58.839233  2043 net.cpp:220] fc7 needs backward computation.
I0108 19:54:58.839237  2043 net.cpp:220] drop6 needs backward computation.
I0108 19:54:58.839241  2043 net.cpp:220] relu6 needs backward computation.
I0108 19:54:58.839244  2043 net.cpp:220] fc6 needs backward computation.
I0108 19:54:58.839248  2043 net.cpp:220] pool5 needs backward computation.
I0108 19:54:58.839252  2043 net.cpp:220] relu5 needs backward computation.
I0108 19:54:58.839257  2043 net.cpp:220] conv5 needs backward computation.
I0108 19:54:58.839262  2043 net.cpp:220] relu4 needs backward computation.
I0108 19:54:58.839265  2043 net.cpp:220] conv4 needs backward computation.
I0108 19:54:58.839269  2043 net.cpp:220] relu3 needs backward computation.
I0108 19:54:58.839274  2043 net.cpp:220] conv3 needs backward computation.
I0108 19:54:58.839277  2043 net.cpp:220] pool2 needs backward computation.
I0108 19:54:58.839282  2043 net.cpp:220] relu2 needs backward computation.
I0108 19:54:58.839287  2043 net.cpp:220] bn2 needs backward computation.
I0108 19:54:58.839290  2043 net.cpp:220] conv2 needs backward computation.
I0108 19:54:58.839294  2043 net.cpp:220] pool1 needs backward computation.
I0108 19:54:58.839298  2043 net.cpp:220] relu1 needs backward computation.
I0108 19:54:58.839301  2043 net.cpp:220] bn1 needs backward computation.
I0108 19:54:58.839305  2043 net.cpp:220] conv1 needs backward computation.
I0108 19:54:58.839310  2043 net.cpp:222] label_data_1_split does not need backward computation.
I0108 19:54:58.839315  2043 net.cpp:222] data does not need backward computation.
I0108 19:54:58.839318  2043 net.cpp:264] This network produces output accuracy
I0108 19:54:58.839323  2043 net.cpp:264] This network produces output loss
I0108 19:54:58.839326  2043 net.cpp:264] This network produces output top-1
I0108 19:54:58.839359  2043 net.cpp:284] Network initialization done.
I0108 19:54:58.839432  2043 solver.cpp:63] Solver scaffolding done.
I0108 19:54:58.840523  2043 caffe_interface.cpp:109] Finetuning from pruning/alexnetBNnoLRN/regular_rate_0/sparse.caffemodel
I0108 19:55:01.144385  2043 caffe_interface.cpp:543] Starting Optimization
I0108 19:55:01.144410  2043 solver.cpp:341] Solving
I0108 19:55:01.144414  2043 solver.cpp:342] Learning Rate Policy: step
I0108 19:55:01.145871  2043 solver.cpp:424] Iteration 0, Testing net (#0)
I0108 19:55:02.664196  2043 solver.cpp:523]     Test net output #0: accuracy = 0.94375
I0108 19:55:02.664228  2043 solver.cpp:523]     Test net output #1: loss = 0.207913 (* 1 = 0.207913 loss)
I0108 19:55:02.664233  2043 solver.cpp:523]     Test net output #2: top-1 = 0.94375
I0108 19:55:02.924013  2043 solver.cpp:270] Iteration 0 (0 iter/s, 1.77949s/50 iter), loss = 0.02269, remaining 333333 hours and 20 minutes
I0108 19:55:02.924044  2043 solver.cpp:291]     Train net output #0: loss = 0.02269 (* 1 = 0.02269 loss)
I0108 19:55:02.924052  2043 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0108 19:55:15.610533  2043 solver.cpp:270] Iteration 50 (3.94137 iter/s, 12.6859s/50 iter), loss = 0.146924, remaining 0 hours and 50 minutes
I0108 19:55:15.610567  2043 solver.cpp:291]     Train net output #0: loss = 0.146924 (* 1 = 0.146924 loss)
I0108 19:55:15.610590  2043 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0108 19:55:28.380903  2043 solver.cpp:270] Iteration 100 (3.91549 iter/s, 12.7698s/50 iter), loss = 0.156036, remaining 0 hours and 50 minutes
I0108 19:55:28.380941  2043 solver.cpp:291]     Train net output #0: loss = 0.156036 (* 1 = 0.156036 loss)
I0108 19:55:28.380949  2043 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0108 19:55:41.155022  2043 solver.cpp:270] Iteration 150 (3.91434 iter/s, 12.7735s/50 iter), loss = 0.194702, remaining 0 hours and 50 minutes
I0108 19:55:41.155053  2043 solver.cpp:291]     Train net output #0: loss = 0.194702 (* 1 = 0.194702 loss)
I0108 19:55:41.155061  2043 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0108 19:55:54.018375  2043 solver.cpp:270] Iteration 200 (3.88718 iter/s, 12.8628s/50 iter), loss = 0.140979, remaining 0 hours and 50 minutes
I0108 19:55:54.018409  2043 solver.cpp:291]     Train net output #0: loss = 0.140979 (* 1 = 0.140979 loss)
I0108 19:55:54.018416  2043 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0108 19:56:07.001781  2043 solver.cpp:270] Iteration 250 (3.85122 iter/s, 12.9829s/50 iter), loss = 0.188548, remaining 0 hours and 50 minutes
I0108 19:56:07.001827  2043 solver.cpp:291]     Train net output #0: loss = 0.188548 (* 1 = 0.188548 loss)
I0108 19:56:07.001850  2043 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0108 19:56:20.003310  2043 solver.cpp:270] Iteration 300 (3.84585 iter/s, 13.001s/50 iter), loss = 0.124993, remaining 0 hours and 50 minutes
I0108 19:56:20.003343  2043 solver.cpp:291]     Train net output #0: loss = 0.124993 (* 1 = 0.124993 loss)
I0108 19:56:20.003350  2043 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0108 19:56:32.997349  2043 solver.cpp:270] Iteration 350 (3.84807 iter/s, 12.9935s/50 iter), loss = 0.131512, remaining 0 hours and 50 minutes
I0108 19:56:32.997380  2043 solver.cpp:291]     Train net output #0: loss = 0.131512 (* 1 = 0.131512 loss)
I0108 19:56:32.997403  2043 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0108 19:56:46.009436  2043 solver.cpp:270] Iteration 400 (3.84273 iter/s, 13.0116s/50 iter), loss = 0.150846, remaining 0 hours and 50 minutes
I0108 19:56:46.009487  2043 solver.cpp:291]     Train net output #0: loss = 0.150846 (* 1 = 0.150846 loss)
I0108 19:56:46.009511  2043 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0108 19:56:58.992528  2043 solver.cpp:270] Iteration 450 (3.85132 iter/s, 12.9826s/50 iter), loss = 0.136764, remaining 0 hours and 49 minutes
I0108 19:56:58.992561  2043 solver.cpp:291]     Train net output #0: loss = 0.136764 (* 1 = 0.136764 loss)
I0108 19:56:58.992568  2043 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0108 19:57:12.022122  2043 solver.cpp:270] Iteration 500 (3.83757 iter/s, 13.0291s/50 iter), loss = 0.107516, remaining 0 hours and 49 minutes
I0108 19:57:12.022156  2043 solver.cpp:291]     Train net output #0: loss = 0.107516 (* 1 = 0.107516 loss)
I0108 19:57:12.022163  2043 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0108 19:57:25.014151  2043 solver.cpp:270] Iteration 550 (3.84867 iter/s, 12.9915s/50 iter), loss = 0.174823, remaining 0 hours and 49 minutes
I0108 19:57:25.014205  2043 solver.cpp:291]     Train net output #0: loss = 0.174824 (* 1 = 0.174824 loss)
I0108 19:57:25.014212  2043 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0108 19:57:38.030881  2043 solver.cpp:270] Iteration 600 (3.84137 iter/s, 13.0162s/50 iter), loss = 0.107691, remaining 0 hours and 49 minutes
I0108 19:57:38.030915  2043 solver.cpp:291]     Train net output #0: loss = 0.107691 (* 1 = 0.107691 loss)
I0108 19:57:38.030922  2043 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0108 19:57:51.023173  2043 solver.cpp:270] Iteration 650 (3.84859 iter/s, 12.9918s/50 iter), loss = 0.135419, remaining 0 hours and 49 minutes
I0108 19:57:51.023205  2043 solver.cpp:291]     Train net output #0: loss = 0.135419 (* 1 = 0.135419 loss)
I0108 19:57:51.023211  2043 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0108 19:58:04.043931  2043 solver.cpp:270] Iteration 700 (3.84018 iter/s, 13.0202s/50 iter), loss = 0.154808, remaining 0 hours and 48 minutes
I0108 19:58:04.043975  2043 solver.cpp:291]     Train net output #0: loss = 0.154808 (* 1 = 0.154808 loss)
I0108 19:58:04.043998  2043 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0108 19:58:17.032963  2043 solver.cpp:270] Iteration 750 (3.84956 iter/s, 12.9885s/50 iter), loss = 0.14865, remaining 0 hours and 48 minutes
I0108 19:58:17.032996  2043 solver.cpp:291]     Train net output #0: loss = 0.14865 (* 1 = 0.14865 loss)
I0108 19:58:17.033002  2043 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0108 19:58:30.046639  2043 solver.cpp:270] Iteration 800 (3.84227 iter/s, 13.0132s/50 iter), loss = 0.153392, remaining 0 hours and 48 minutes
I0108 19:58:30.046671  2043 solver.cpp:291]     Train net output #0: loss = 0.153392 (* 1 = 0.153392 loss)
I0108 19:58:30.046677  2043 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0108 19:58:43.025897  2043 solver.cpp:270] Iteration 850 (3.85245 iter/s, 12.9787s/50 iter), loss = 0.126185, remaining 0 hours and 48 minutes
I0108 19:58:43.025943  2043 solver.cpp:291]     Train net output #0: loss = 0.126185 (* 1 = 0.126185 loss)
I0108 19:58:43.025965  2043 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0108 19:58:56.018925  2043 solver.cpp:270] Iteration 900 (3.84837 iter/s, 12.9925s/50 iter), loss = 0.123302, remaining 0 hours and 48 minutes
I0108 19:58:56.018959  2043 solver.cpp:291]     Train net output #0: loss = 0.123302 (* 1 = 0.123302 loss)
I0108 19:58:56.018965  2043 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0108 19:59:09.019446  2043 solver.cpp:270] Iteration 950 (3.84615 iter/s, 13s/50 iter), loss = 0.199037, remaining 0 hours and 47 minutes
I0108 19:59:09.019479  2043 solver.cpp:291]     Train net output #0: loss = 0.199037 (* 1 = 0.199037 loss)
I0108 19:59:09.019485  2043 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0108 19:59:21.759186  2043 solver.cpp:424] Iteration 1000, Testing net (#0)
I0108 19:59:23.312238  2043 solver.cpp:523]     Test net output #0: accuracy = 0.86525
I0108 19:59:23.312268  2043 solver.cpp:523]     Test net output #1: loss = 0.543582 (* 1 = 0.543582 loss)
I0108 19:59:23.312273  2043 solver.cpp:523]     Test net output #2: top-1 = 0.86525
I0108 19:59:23.568413  2043 solver.cpp:270] Iteration 1000 (3.43681 iter/s, 14.5484s/50 iter), loss = 0.147069, remaining 0 hours and 53 minutes
I0108 19:59:23.568439  2043 solver.cpp:291]     Train net output #0: loss = 0.147069 (* 1 = 0.147069 loss)
I0108 19:59:23.568445  2043 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0108 19:59:36.563271  2043 solver.cpp:270] Iteration 1050 (3.84783 iter/s, 12.9943s/50 iter), loss = 0.140741, remaining 0 hours and 47 minutes
I0108 19:59:36.563304  2043 solver.cpp:291]     Train net output #0: loss = 0.140741 (* 1 = 0.140741 loss)
I0108 19:59:36.563326  2043 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0108 19:59:49.559288  2043 solver.cpp:270] Iteration 1100 (3.84749 iter/s, 12.9955s/50 iter), loss = 0.15842, remaining 0 hours and 47 minutes
I0108 19:59:49.559319  2043 solver.cpp:291]     Train net output #0: loss = 0.15842 (* 1 = 0.15842 loss)
I0108 19:59:49.559327  2043 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0108 20:00:02.559401  2043 solver.cpp:270] Iteration 1150 (3.84627 iter/s, 12.9996s/50 iter), loss = 0.175659, remaining 0 hours and 46 minutes
I0108 20:00:02.559455  2043 solver.cpp:291]     Train net output #0: loss = 0.175659 (* 1 = 0.175659 loss)
I0108 20:00:02.559463  2043 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0108 20:00:15.547291  2043 solver.cpp:270] Iteration 1200 (3.8499 iter/s, 12.9874s/50 iter), loss = 0.135849, remaining 0 hours and 46 minutes
I0108 20:00:15.547324  2043 solver.cpp:291]     Train net output #0: loss = 0.13585 (* 1 = 0.13585 loss)
I0108 20:00:15.547333  2043 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0108 20:00:28.563138  2043 solver.cpp:270] Iteration 1250 (3.84162 iter/s, 13.0153s/50 iter), loss = 0.134642, remaining 0 hours and 46 minutes
I0108 20:00:28.563171  2043 solver.cpp:291]     Train net output #0: loss = 0.134642 (* 1 = 0.134642 loss)
I0108 20:00:28.563194  2043 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0108 20:00:41.539187  2043 solver.cpp:270] Iteration 1300 (3.85341 iter/s, 12.9755s/50 iter), loss = 0.113707, remaining 0 hours and 46 minutes
I0108 20:00:41.539235  2043 solver.cpp:291]     Train net output #0: loss = 0.113707 (* 1 = 0.113707 loss)
I0108 20:00:41.539243  2043 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0108 20:00:54.539775  2043 solver.cpp:270] Iteration 1350 (3.84614 iter/s, 13.0001s/50 iter), loss = 0.164286, remaining 0 hours and 46 minutes
I0108 20:00:54.539806  2043 solver.cpp:291]     Train net output #0: loss = 0.164286 (* 1 = 0.164286 loss)
I0108 20:00:54.539813  2043 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0108 20:01:07.546121  2043 solver.cpp:270] Iteration 1400 (3.84443 iter/s, 13.0058s/50 iter), loss = 0.198306, remaining 0 hours and 45 minutes
I0108 20:01:07.546154  2043 solver.cpp:291]     Train net output #0: loss = 0.198306 (* 1 = 0.198306 loss)
I0108 20:01:07.546160  2043 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0108 20:01:20.543767  2043 solver.cpp:270] Iteration 1450 (3.847 iter/s, 12.9971s/50 iter), loss = 0.147542, remaining 0 hours and 45 minutes
I0108 20:01:20.543814  2043 solver.cpp:291]     Train net output #0: loss = 0.147542 (* 1 = 0.147542 loss)
I0108 20:01:20.543821  2043 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0108 20:01:33.523564  2043 solver.cpp:270] Iteration 1500 (3.8523 iter/s, 12.9793s/50 iter), loss = 0.153443, remaining 0 hours and 45 minutes
I0108 20:01:33.523597  2043 solver.cpp:291]     Train net output #0: loss = 0.153443 (* 1 = 0.153443 loss)
I0108 20:01:33.523604  2043 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0108 20:01:46.520073  2043 solver.cpp:270] Iteration 1550 (3.84734 iter/s, 12.996s/50 iter), loss = 0.10663, remaining 0 hours and 45 minutes
I0108 20:01:46.520107  2043 solver.cpp:291]     Train net output #0: loss = 0.10663 (* 1 = 0.10663 loss)
I0108 20:01:46.520128  2043 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0108 20:01:59.509905  2043 solver.cpp:270] Iteration 1600 (3.84932 iter/s, 12.9893s/50 iter), loss = 0.1426, remaining 0 hours and 44 minutes
I0108 20:01:59.509968  2043 solver.cpp:291]     Train net output #0: loss = 0.1426 (* 1 = 0.1426 loss)
I0108 20:01:59.509976  2043 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0108 20:02:12.523949  2043 solver.cpp:270] Iteration 1650 (3.84216 iter/s, 13.0135s/50 iter), loss = 0.141381, remaining 0 hours and 44 minutes
I0108 20:02:12.523981  2043 solver.cpp:291]     Train net output #0: loss = 0.141381 (* 1 = 0.141381 loss)
I0108 20:02:12.523989  2043 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0108 20:02:25.519709  2043 solver.cpp:270] Iteration 1700 (3.84756 iter/s, 12.9952s/50 iter), loss = 0.141803, remaining 0 hours and 44 minutes
I0108 20:02:25.519742  2043 solver.cpp:291]     Train net output #0: loss = 0.141804 (* 1 = 0.141804 loss)
I0108 20:02:25.519749  2043 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0108 20:02:38.531373  2043 solver.cpp:270] Iteration 1750 (3.84286 iter/s, 13.0111s/50 iter), loss = 0.118731, remaining 0 hours and 44 minutes
I0108 20:02:38.531430  2043 solver.cpp:291]     Train net output #0: loss = 0.118731 (* 1 = 0.118731 loss)
I0108 20:02:38.531437  2043 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0108 20:02:51.512174  2043 solver.cpp:270] Iteration 1800 (3.852 iter/s, 12.9803s/50 iter), loss = 0.14193, remaining 0 hours and 44 minutes
I0108 20:02:51.512208  2043 solver.cpp:291]     Train net output #0: loss = 0.14193 (* 1 = 0.14193 loss)
I0108 20:02:51.512231  2043 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0108 20:03:04.531620  2043 solver.cpp:270] Iteration 1850 (3.84056 iter/s, 13.0189s/50 iter), loss = 0.107598, remaining 0 hours and 44 minutes
I0108 20:03:04.531651  2043 solver.cpp:291]     Train net output #0: loss = 0.107598 (* 1 = 0.107598 loss)
I0108 20:03:04.531672  2043 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0108 20:03:17.528048  2043 solver.cpp:270] Iteration 1900 (3.84736 iter/s, 12.9959s/50 iter), loss = 0.101055, remaining 0 hours and 43 minutes
I0108 20:03:17.528096  2043 solver.cpp:291]     Train net output #0: loss = 0.101055 (* 1 = 0.101055 loss)
I0108 20:03:17.528120  2043 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0108 20:03:30.531747  2043 solver.cpp:270] Iteration 1950 (3.84522 iter/s, 13.0032s/50 iter), loss = 0.119369, remaining 0 hours and 43 minutes
I0108 20:03:30.531778  2043 solver.cpp:291]     Train net output #0: loss = 0.119369 (* 1 = 0.119369 loss)
I0108 20:03:30.531785  2043 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0108 20:03:43.282609  2043 solver.cpp:424] Iteration 2000, Testing net (#0)
I0108 20:03:44.834296  2043 solver.cpp:523]     Test net output #0: accuracy = 0.90175
I0108 20:03:44.834326  2043 solver.cpp:523]     Test net output #1: loss = 0.272489 (* 1 = 0.272489 loss)
I0108 20:03:44.834331  2043 solver.cpp:523]     Test net output #2: top-1 = 0.90175
I0108 20:03:45.089844  2043 solver.cpp:270] Iteration 2000 (3.43465 iter/s, 14.5575s/50 iter), loss = 0.187026, remaining 0 hours and 48 minutes
I0108 20:03:45.089871  2043 solver.cpp:291]     Train net output #0: loss = 0.187026 (* 1 = 0.187026 loss)
I0108 20:03:45.089879  2043 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0108 20:03:58.083019  2043 solver.cpp:270] Iteration 2050 (3.84833 iter/s, 12.9927s/50 iter), loss = 0.130121, remaining 0 hours and 42 minutes
I0108 20:03:58.083070  2043 solver.cpp:291]     Train net output #0: loss = 0.130121 (* 1 = 0.130121 loss)
I0108 20:03:58.083076  2043 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0108 20:04:11.086236  2043 solver.cpp:270] Iteration 2100 (3.84536 iter/s, 13.0027s/50 iter), loss = 0.0913429, remaining 0 hours and 42 minutes
I0108 20:04:11.086269  2043 solver.cpp:291]     Train net output #0: loss = 0.091343 (* 1 = 0.091343 loss)
I0108 20:04:11.086292  2043 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0108 20:04:24.062223  2043 solver.cpp:270] Iteration 2150 (3.85342 iter/s, 12.9755s/50 iter), loss = 0.115409, remaining 0 hours and 42 minutes
I0108 20:04:24.062258  2043 solver.cpp:291]     Train net output #0: loss = 0.115409 (* 1 = 0.115409 loss)
I0108 20:04:24.062280  2043 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0108 20:04:37.094480  2043 solver.cpp:270] Iteration 2200 (3.83679 iter/s, 13.0317s/50 iter), loss = 0.132396, remaining 0 hours and 42 minutes
I0108 20:04:37.094532  2043 solver.cpp:291]     Train net output #0: loss = 0.132396 (* 1 = 0.132396 loss)
I0108 20:04:37.094538  2043 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0108 20:04:50.071698  2043 solver.cpp:270] Iteration 2250 (3.85306 iter/s, 12.9767s/50 iter), loss = 0.115268, remaining 0 hours and 42 minutes
I0108 20:04:50.071730  2043 solver.cpp:291]     Train net output #0: loss = 0.115268 (* 1 = 0.115268 loss)
I0108 20:04:50.071738  2043 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0108 20:05:03.090140  2043 solver.cpp:270] Iteration 2300 (3.84086 iter/s, 13.0179s/50 iter), loss = 0.148033, remaining 0 hours and 41 minutes
I0108 20:05:03.090173  2043 solver.cpp:291]     Train net output #0: loss = 0.148033 (* 1 = 0.148033 loss)
I0108 20:05:03.090180  2043 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0108 20:05:16.079183  2043 solver.cpp:270] Iteration 2350 (3.84955 iter/s, 12.9885s/50 iter), loss = 0.100005, remaining 0 hours and 41 minutes
I0108 20:05:16.079239  2043 solver.cpp:291]     Train net output #0: loss = 0.100005 (* 1 = 0.100005 loss)
I0108 20:05:16.079246  2043 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0108 20:05:29.076958  2043 solver.cpp:270] Iteration 2400 (3.84697 iter/s, 12.9972s/50 iter), loss = 0.172387, remaining 0 hours and 41 minutes
I0108 20:05:29.076992  2043 solver.cpp:291]     Train net output #0: loss = 0.172387 (* 1 = 0.172387 loss)
I0108 20:05:29.076998  2043 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0108 20:05:42.069383  2043 solver.cpp:270] Iteration 2450 (3.84855 iter/s, 12.9919s/50 iter), loss = 0.10564, remaining 0 hours and 41 minutes
I0108 20:05:42.069417  2043 solver.cpp:291]     Train net output #0: loss = 0.10564 (* 1 = 0.10564 loss)
I0108 20:05:42.069440  2043 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0108 20:05:55.068641  2043 solver.cpp:270] Iteration 2500 (3.84653 iter/s, 12.9987s/50 iter), loss = 0.132198, remaining 0 hours and 41 minutes
I0108 20:05:55.068687  2043 solver.cpp:291]     Train net output #0: loss = 0.132198 (* 1 = 0.132198 loss)
I0108 20:05:55.068711  2043 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0108 20:06:08.069823  2043 solver.cpp:270] Iteration 2550 (3.84596 iter/s, 13.0006s/50 iter), loss = 0.113392, remaining 0 hours and 40 minutes
I0108 20:06:08.069854  2043 solver.cpp:291]     Train net output #0: loss = 0.113392 (* 1 = 0.113392 loss)
I0108 20:06:08.069862  2043 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0108 20:06:21.079088  2043 solver.cpp:270] Iteration 2600 (3.84357 iter/s, 13.0087s/50 iter), loss = 0.0531234, remaining 0 hours and 40 minutes
I0108 20:06:21.079119  2043 solver.cpp:291]     Train net output #0: loss = 0.0531234 (* 1 = 0.0531234 loss)
I0108 20:06:21.079142  2043 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0108 20:06:34.076617  2043 solver.cpp:270] Iteration 2650 (3.84704 iter/s, 12.997s/50 iter), loss = 0.105288, remaining 0 hours and 40 minutes
I0108 20:06:34.076660  2043 solver.cpp:291]     Train net output #0: loss = 0.105288 (* 1 = 0.105288 loss)
I0108 20:06:34.076684  2043 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0108 20:06:47.081933  2043 solver.cpp:270] Iteration 2700 (3.84474 iter/s, 13.0048s/50 iter), loss = 0.0765465, remaining 0 hours and 40 minutes
I0108 20:06:47.081965  2043 solver.cpp:291]     Train net output #0: loss = 0.0765466 (* 1 = 0.0765466 loss)
I0108 20:06:47.081972  2043 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0108 20:07:00.069617  2043 solver.cpp:270] Iteration 2750 (3.84995 iter/s, 12.9872s/50 iter), loss = 0.0543639, remaining 0 hours and 40 minutes
I0108 20:07:00.069648  2043 solver.cpp:291]     Train net output #0: loss = 0.054364 (* 1 = 0.054364 loss)
I0108 20:07:00.069655  2043 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0108 20:07:13.093926  2043 solver.cpp:270] Iteration 2800 (3.83913 iter/s, 13.0238s/50 iter), loss = 0.0736137, remaining 0 hours and 39 minutes
I0108 20:07:13.093973  2043 solver.cpp:291]     Train net output #0: loss = 0.0736138 (* 1 = 0.0736138 loss)
I0108 20:07:13.093981  2043 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0108 20:07:26.081949  2043 solver.cpp:270] Iteration 2850 (3.84986 iter/s, 12.9875s/50 iter), loss = 0.0948483, remaining 0 hours and 39 minutes
I0108 20:07:26.081982  2043 solver.cpp:291]     Train net output #0: loss = 0.0948484 (* 1 = 0.0948484 loss)
I0108 20:07:26.081990  2043 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0108 20:07:39.080826  2043 solver.cpp:270] Iteration 2900 (3.84664 iter/s, 12.9984s/50 iter), loss = 0.0642711, remaining 0 hours and 39 minutes
I0108 20:07:39.080858  2043 solver.cpp:291]     Train net output #0: loss = 0.0642711 (* 1 = 0.0642711 loss)
I0108 20:07:39.080865  2043 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0108 20:07:52.075992  2043 solver.cpp:270] Iteration 2950 (3.84774 iter/s, 12.9946s/50 iter), loss = 0.0517585, remaining 0 hours and 38 minutes
I0108 20:07:52.076047  2043 solver.cpp:291]     Train net output #0: loss = 0.0517585 (* 1 = 0.0517585 loss)
I0108 20:07:52.076054  2043 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0108 20:08:04.821589  2043 solver.cpp:424] Iteration 3000, Testing net (#0)
I0108 20:08:06.374421  2043 solver.cpp:523]     Test net output #0: accuracy = 0.949
I0108 20:08:06.374450  2043 solver.cpp:523]     Test net output #1: loss = 0.139447 (* 1 = 0.139447 loss)
I0108 20:08:06.374455  2043 solver.cpp:523]     Test net output #2: top-1 = 0.949
I0108 20:08:06.629590  2043 solver.cpp:270] Iteration 3000 (3.43572 iter/s, 14.553s/50 iter), loss = 0.0315886, remaining 0 hours and 43 minutes
I0108 20:08:06.629616  2043 solver.cpp:291]     Train net output #0: loss = 0.0315887 (* 1 = 0.0315887 loss)
I0108 20:08:06.629623  2043 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0108 20:08:19.638128  2043 solver.cpp:270] Iteration 3050 (3.84378 iter/s, 13.008s/50 iter), loss = 0.0447941, remaining 0 hours and 38 minutes
I0108 20:08:19.638160  2043 solver.cpp:291]     Train net output #0: loss = 0.0447941 (* 1 = 0.0447941 loss)
I0108 20:08:19.638167  2043 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0108 20:08:32.622553  2043 solver.cpp:270] Iteration 3100 (3.85092 iter/s, 12.9839s/50 iter), loss = 0.0350682, remaining 0 hours and 38 minutes
I0108 20:08:32.622601  2043 solver.cpp:291]     Train net output #0: loss = 0.0350682 (* 1 = 0.0350682 loss)
I0108 20:08:32.622608  2043 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0108 20:08:45.622097  2043 solver.cpp:270] Iteration 3150 (3.84645 iter/s, 12.999s/50 iter), loss = 0.0612933, remaining 0 hours and 38 minutes
I0108 20:08:45.622130  2043 solver.cpp:291]     Train net output #0: loss = 0.0612934 (* 1 = 0.0612934 loss)
I0108 20:08:45.622136  2043 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0108 20:08:58.626257  2043 solver.cpp:270] Iteration 3200 (3.84508 iter/s, 13.0036s/50 iter), loss = 0.0469385, remaining 0 hours and 37 minutes
I0108 20:08:58.626291  2043 solver.cpp:291]     Train net output #0: loss = 0.0469386 (* 1 = 0.0469386 loss)
I0108 20:08:58.626298  2043 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0108 20:09:11.629047  2043 solver.cpp:270] Iteration 3250 (3.84548 iter/s, 13.0023s/50 iter), loss = 0.0506547, remaining 0 hours and 37 minutes
I0108 20:09:11.629097  2043 solver.cpp:291]     Train net output #0: loss = 0.0506547 (* 1 = 0.0506547 loss)
I0108 20:09:11.629104  2043 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0108 20:09:24.621049  2043 solver.cpp:270] Iteration 3300 (3.84868 iter/s, 12.9915s/50 iter), loss = 0.0601457, remaining 0 hours and 37 minutes
I0108 20:09:24.621083  2043 solver.cpp:291]     Train net output #0: loss = 0.0601457 (* 1 = 0.0601457 loss)
I0108 20:09:24.621089  2043 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0108 20:09:37.616443  2043 solver.cpp:270] Iteration 3350 (3.84767 iter/s, 12.9949s/50 iter), loss = 0.0407988, remaining 0 hours and 37 minutes
I0108 20:09:37.616477  2043 solver.cpp:291]     Train net output #0: loss = 0.0407988 (* 1 = 0.0407988 loss)
I0108 20:09:37.616483  2043 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0108 20:09:50.609033  2043 solver.cpp:270] Iteration 3400 (3.8485 iter/s, 12.9921s/50 iter), loss = 0.0679471, remaining 0 hours and 37 minutes
I0108 20:09:50.609077  2043 solver.cpp:291]     Train net output #0: loss = 0.0679471 (* 1 = 0.0679471 loss)
I0108 20:09:50.609100  2043 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0108 20:10:03.616849  2043 solver.cpp:270] Iteration 3450 (3.844 iter/s, 13.0073s/50 iter), loss = 0.0846788, remaining 0 hours and 36 minutes
I0108 20:10:03.616883  2043 solver.cpp:291]     Train net output #0: loss = 0.0846789 (* 1 = 0.0846789 loss)
I0108 20:10:03.616889  2043 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0108 20:10:16.614571  2043 solver.cpp:270] Iteration 3500 (3.84698 iter/s, 12.9972s/50 iter), loss = 0.0394166, remaining 0 hours and 36 minutes
I0108 20:10:16.614603  2043 solver.cpp:291]     Train net output #0: loss = 0.0394167 (* 1 = 0.0394167 loss)
I0108 20:10:16.614626  2043 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0108 20:10:29.600236  2043 solver.cpp:270] Iteration 3550 (3.85055 iter/s, 12.9851s/50 iter), loss = 0.0550979, remaining 0 hours and 36 minutes
I0108 20:10:29.600292  2043 solver.cpp:291]     Train net output #0: loss = 0.0550979 (* 1 = 0.0550979 loss)
I0108 20:10:29.600301  2043 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0108 20:10:42.606173  2043 solver.cpp:270] Iteration 3600 (3.84456 iter/s, 13.0054s/50 iter), loss = 0.0679727, remaining 0 hours and 36 minutes
I0108 20:10:42.606205  2043 solver.cpp:291]     Train net output #0: loss = 0.0679727 (* 1 = 0.0679727 loss)
I0108 20:10:42.606211  2043 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0108 20:10:55.597874  2043 solver.cpp:270] Iteration 3650 (3.84876 iter/s, 12.9912s/50 iter), loss = 0.0572141, remaining 0 hours and 36 minutes
I0108 20:10:55.597908  2043 solver.cpp:291]     Train net output #0: loss = 0.0572141 (* 1 = 0.0572141 loss)
I0108 20:10:55.597914  2043 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0108 20:11:08.602403  2043 solver.cpp:270] Iteration 3700 (3.84497 iter/s, 13.004s/50 iter), loss = 0.0373009, remaining 0 hours and 35 minutes
I0108 20:11:08.602450  2043 solver.cpp:291]     Train net output #0: loss = 0.037301 (* 1 = 0.037301 loss)
I0108 20:11:08.602458  2043 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0108 20:11:21.568960  2043 solver.cpp:270] Iteration 3750 (3.85623 iter/s, 12.966s/50 iter), loss = 0.037512, remaining 0 hours and 35 minutes
I0108 20:11:21.568991  2043 solver.cpp:291]     Train net output #0: loss = 0.0375121 (* 1 = 0.0375121 loss)
I0108 20:11:21.568998  2043 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0108 20:11:34.588786  2043 solver.cpp:270] Iteration 3800 (3.84045 iter/s, 13.0193s/50 iter), loss = 0.0547789, remaining 0 hours and 35 minutes
I0108 20:11:34.588819  2043 solver.cpp:291]     Train net output #0: loss = 0.054779 (* 1 = 0.054779 loss)
I0108 20:11:34.588826  2043 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0108 20:11:47.566951  2043 solver.cpp:270] Iteration 3850 (3.85278 iter/s, 12.9776s/50 iter), loss = 0.0405538, remaining 0 hours and 35 minutes
I0108 20:11:47.566995  2043 solver.cpp:291]     Train net output #0: loss = 0.0405538 (* 1 = 0.0405538 loss)
I0108 20:11:47.567003  2043 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0108 20:12:00.561502  2043 solver.cpp:270] Iteration 3900 (3.84792 iter/s, 12.994s/50 iter), loss = 0.0521231, remaining 0 hours and 35 minutes
I0108 20:12:00.561534  2043 solver.cpp:291]     Train net output #0: loss = 0.0521232 (* 1 = 0.0521232 loss)
I0108 20:12:00.561558  2043 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0108 20:12:13.559078  2043 solver.cpp:270] Iteration 3950 (3.84702 iter/s, 12.9971s/50 iter), loss = 0.0493369, remaining 0 hours and 34 minutes
I0108 20:12:13.559111  2043 solver.cpp:291]     Train net output #0: loss = 0.0493369 (* 1 = 0.0493369 loss)
I0108 20:12:13.559118  2043 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0108 20:12:26.298028  2043 solver.cpp:424] Iteration 4000, Testing net (#0)
I0108 20:12:27.843235  2043 solver.cpp:523]     Test net output #0: accuracy = 0.94275
I0108 20:12:27.843266  2043 solver.cpp:523]     Test net output #1: loss = 0.145663 (* 1 = 0.145663 loss)
I0108 20:12:27.843271  2043 solver.cpp:523]     Test net output #2: top-1 = 0.94275
I0108 20:12:28.098089  2043 solver.cpp:270] Iteration 4000 (3.43916 iter/s, 14.5384s/50 iter), loss = 0.0199708, remaining 0 hours and 38 minutes
I0108 20:12:28.098120  2043 solver.cpp:291]     Train net output #0: loss = 0.0199708 (* 1 = 0.0199708 loss)
I0108 20:12:28.098145  2043 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0108 20:12:41.101107  2043 solver.cpp:270] Iteration 4050 (3.84541 iter/s, 13.0025s/50 iter), loss = 0.0397728, remaining 0 hours and 34 minutes
I0108 20:12:41.101140  2043 solver.cpp:291]     Train net output #0: loss = 0.0397728 (* 1 = 0.0397728 loss)
I0108 20:12:41.101146  2043 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0108 20:12:54.086474  2043 solver.cpp:270] Iteration 4100 (3.85064 iter/s, 12.9848s/50 iter), loss = 0.034294, remaining 0 hours and 34 minutes
I0108 20:12:54.086505  2043 solver.cpp:291]     Train net output #0: loss = 0.0342941 (* 1 = 0.0342941 loss)
I0108 20:12:54.086513  2043 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0108 20:13:07.093019  2043 solver.cpp:270] Iteration 4150 (3.84437 iter/s, 13.006s/50 iter), loss = 0.0400905, remaining 0 hours and 33 minutes
I0108 20:13:07.093075  2043 solver.cpp:291]     Train net output #0: loss = 0.0400905 (* 1 = 0.0400905 loss)
I0108 20:13:07.093082  2043 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0108 20:13:20.076480  2043 solver.cpp:270] Iteration 4200 (3.85121 iter/s, 12.9829s/50 iter), loss = 0.0754045, remaining 0 hours and 33 minutes
I0108 20:13:20.076512  2043 solver.cpp:291]     Train net output #0: loss = 0.0754046 (* 1 = 0.0754046 loss)
I0108 20:13:20.076519  2043 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0108 20:13:33.073092  2043 solver.cpp:270] Iteration 4250 (3.84731 iter/s, 12.9961s/50 iter), loss = 0.01895, remaining 0 hours and 33 minutes
I0108 20:13:33.073123  2043 solver.cpp:291]     Train net output #0: loss = 0.01895 (* 1 = 0.01895 loss)
I0108 20:13:33.073129  2043 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0108 20:13:46.057018  2043 solver.cpp:270] Iteration 4300 (3.85107 iter/s, 12.9834s/50 iter), loss = 0.0171411, remaining 0 hours and 33 minutes
I0108 20:13:46.057060  2043 solver.cpp:291]     Train net output #0: loss = 0.0171412 (* 1 = 0.0171412 loss)
I0108 20:13:46.057067  2043 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0108 20:13:59.051357  2043 solver.cpp:270] Iteration 4350 (3.84799 iter/s, 12.9938s/50 iter), loss = 0.0177465, remaining 0 hours and 33 minutes
I0108 20:13:59.051390  2043 solver.cpp:291]     Train net output #0: loss = 0.0177466 (* 1 = 0.0177466 loss)
I0108 20:13:59.051398  2043 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0108 20:14:12.041240  2043 solver.cpp:270] Iteration 4400 (3.8493 iter/s, 12.9894s/50 iter), loss = 0.0378394, remaining 0 hours and 32 minutes
I0108 20:14:12.041271  2043 solver.cpp:291]     Train net output #0: loss = 0.0378394 (* 1 = 0.0378394 loss)
I0108 20:14:12.041294  2043 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0108 20:14:25.021039  2043 solver.cpp:270] Iteration 4450 (3.85229 iter/s, 12.9793s/50 iter), loss = 0.0332105, remaining 0 hours and 32 minutes
I0108 20:14:25.021086  2043 solver.cpp:291]     Train net output #0: loss = 0.0332106 (* 1 = 0.0332106 loss)
I0108 20:14:25.021095  2043 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0108 20:14:38.026844  2043 solver.cpp:270] Iteration 4500 (3.84459 iter/s, 13.0053s/50 iter), loss = 0.0281305, remaining 0 hours and 32 minutes
I0108 20:14:38.026875  2043 solver.cpp:291]     Train net output #0: loss = 0.0281305 (* 1 = 0.0281305 loss)
I0108 20:14:38.026882  2043 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0108 20:14:51.006207  2043 solver.cpp:270] Iteration 4550 (3.85242 iter/s, 12.9788s/50 iter), loss = 0.0718954, remaining 0 hours and 32 minutes
I0108 20:14:51.006239  2043 solver.cpp:291]     Train net output #0: loss = 0.0718954 (* 1 = 0.0718954 loss)
I0108 20:14:51.006248  2043 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0108 20:15:03.997947  2043 solver.cpp:270] Iteration 4600 (3.84875 iter/s, 12.9912s/50 iter), loss = 0.0366417, remaining 0 hours and 31 minutes
I0108 20:15:03.998000  2043 solver.cpp:291]     Train net output #0: loss = 0.0366418 (* 1 = 0.0366418 loss)
I0108 20:15:03.998008  2043 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0108 20:15:17.001233  2043 solver.cpp:270] Iteration 4650 (3.84534 iter/s, 13.0027s/50 iter), loss = 0.0300057, remaining 0 hours and 31 minutes
I0108 20:15:17.001266  2043 solver.cpp:291]     Train net output #0: loss = 0.0300057 (* 1 = 0.0300057 loss)
I0108 20:15:17.001273  2043 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0108 20:15:29.992871  2043 solver.cpp:270] Iteration 4700 (3.84878 iter/s, 12.9911s/50 iter), loss = 0.0428331, remaining 0 hours and 31 minutes
I0108 20:15:29.992903  2043 solver.cpp:291]     Train net output #0: loss = 0.0428331 (* 1 = 0.0428331 loss)
I0108 20:15:29.992926  2043 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0108 20:15:42.985375  2043 solver.cpp:270] Iteration 4750 (3.84853 iter/s, 12.992s/50 iter), loss = 0.0145397, remaining 0 hours and 31 minutes
I0108 20:15:42.985421  2043 solver.cpp:291]     Train net output #0: loss = 0.0145398 (* 1 = 0.0145398 loss)
I0108 20:15:42.985430  2043 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0108 20:15:55.965075  2043 solver.cpp:270] Iteration 4800 (3.85233 iter/s, 12.9792s/50 iter), loss = 0.0518048, remaining 0 hours and 31 minutes
I0108 20:15:55.965106  2043 solver.cpp:291]     Train net output #0: loss = 0.0518049 (* 1 = 0.0518049 loss)
I0108 20:15:55.965128  2043 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0108 20:16:08.950470  2043 solver.cpp:270] Iteration 4850 (3.85063 iter/s, 12.9849s/50 iter), loss = 0.0482341, remaining 0 hours and 30 minutes
I0108 20:16:08.950503  2043 solver.cpp:291]     Train net output #0: loss = 0.0482341 (* 1 = 0.0482341 loss)
I0108 20:16:08.950526  2043 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0108 20:16:21.937570  2043 solver.cpp:270] Iteration 4900 (3.85013 iter/s, 12.9866s/50 iter), loss = 0.0303896, remaining 0 hours and 30 minutes
I0108 20:16:21.937618  2043 solver.cpp:291]     Train net output #0: loss = 0.0303897 (* 1 = 0.0303897 loss)
I0108 20:16:21.937625  2043 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0108 20:16:34.948731  2043 solver.cpp:270] Iteration 4950 (3.84301 iter/s, 13.0106s/50 iter), loss = 0.0160002, remaining 0 hours and 30 minutes
I0108 20:16:34.948762  2043 solver.cpp:291]     Train net output #0: loss = 0.0160003 (* 1 = 0.0160003 loss)
I0108 20:16:34.948770  2043 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0108 20:16:47.681047  2043 solver.cpp:424] Iteration 5000, Testing net (#0)
I0108 20:16:49.232893  2043 solver.cpp:523]     Test net output #0: accuracy = 0.94275
I0108 20:16:49.232923  2043 solver.cpp:523]     Test net output #1: loss = 0.155149 (* 1 = 0.155149 loss)
I0108 20:16:49.232929  2043 solver.cpp:523]     Test net output #2: top-1 = 0.94275
I0108 20:16:49.488389  2043 solver.cpp:270] Iteration 5000 (3.43901 iter/s, 14.5391s/50 iter), loss = 0.0356914, remaining 0 hours and 33 minutes
I0108 20:16:49.488416  2043 solver.cpp:291]     Train net output #0: loss = 0.0356914 (* 1 = 0.0356914 loss)
I0108 20:16:49.488425  2043 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0108 20:17:02.498065  2043 solver.cpp:270] Iteration 5050 (3.84344 iter/s, 13.0092s/50 iter), loss = 0.0188562, remaining 0 hours and 29 minutes
I0108 20:17:02.498111  2043 solver.cpp:291]     Train net output #0: loss = 0.0188562 (* 1 = 0.0188562 loss)
I0108 20:17:02.498117  2043 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0108 20:17:15.471040  2043 solver.cpp:270] Iteration 5100 (3.85432 iter/s, 12.9724s/50 iter), loss = 0.0143621, remaining 0 hours and 29 minutes
I0108 20:17:15.471072  2043 solver.cpp:291]     Train net output #0: loss = 0.0143621 (* 1 = 0.0143621 loss)
I0108 20:17:15.471079  2043 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0108 20:17:28.465601  2043 solver.cpp:270] Iteration 5150 (3.84792 iter/s, 12.994s/50 iter), loss = 0.032534, remaining 0 hours and 29 minutes
I0108 20:17:28.465632  2043 solver.cpp:291]     Train net output #0: loss = 0.032534 (* 1 = 0.032534 loss)
I0108 20:17:28.465639  2043 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0108 20:17:41.460047  2043 solver.cpp:270] Iteration 5200 (3.84795 iter/s, 12.9939s/50 iter), loss = 0.00773929, remaining 0 hours and 29 minutes
I0108 20:17:41.460103  2043 solver.cpp:291]     Train net output #0: loss = 0.00773933 (* 1 = 0.00773933 loss)
I0108 20:17:41.460110  2043 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0108 20:17:54.438575  2043 solver.cpp:270] Iteration 5250 (3.85268 iter/s, 12.978s/50 iter), loss = 0.0285336, remaining 0 hours and 29 minutes
I0108 20:17:54.438606  2043 solver.cpp:291]     Train net output #0: loss = 0.0285336 (* 1 = 0.0285336 loss)
I0108 20:17:54.438614  2043 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0108 20:18:07.436208  2043 solver.cpp:270] Iteration 5300 (3.84701 iter/s, 12.9971s/50 iter), loss = 0.0373147, remaining 0 hours and 28 minutes
I0108 20:18:07.436239  2043 solver.cpp:291]     Train net output #0: loss = 0.0373147 (* 1 = 0.0373147 loss)
I0108 20:18:07.436246  2043 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0108 20:18:20.407616  2043 solver.cpp:270] Iteration 5350 (3.85478 iter/s, 12.9709s/50 iter), loss = 0.0293855, remaining 0 hours and 28 minutes
I0108 20:18:20.407663  2043 solver.cpp:291]     Train net output #0: loss = 0.0293855 (* 1 = 0.0293855 loss)
I0108 20:18:20.407671  2043 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0108 20:18:33.411648  2043 solver.cpp:270] Iteration 5400 (3.84512 iter/s, 13.0035s/50 iter), loss = 0.0261124, remaining 0 hours and 28 minutes
I0108 20:18:33.411680  2043 solver.cpp:291]     Train net output #0: loss = 0.0261125 (* 1 = 0.0261125 loss)
I0108 20:18:33.411687  2043 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0108 20:18:46.395969  2043 solver.cpp:270] Iteration 5450 (3.85095 iter/s, 12.9838s/50 iter), loss = 0.0296884, remaining 0 hours and 28 minutes
I0108 20:18:46.395999  2043 solver.cpp:291]     Train net output #0: loss = 0.0296884 (* 1 = 0.0296884 loss)
I0108 20:18:46.396006  2043 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0108 20:18:59.367138  2043 solver.cpp:270] Iteration 5500 (3.85486 iter/s, 12.9707s/50 iter), loss = 0.00731074, remaining 0 hours and 28 minutes
I0108 20:18:59.367185  2043 solver.cpp:291]     Train net output #0: loss = 0.00731078 (* 1 = 0.00731078 loss)
I0108 20:18:59.367192  2043 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0108 20:19:12.378366  2043 solver.cpp:270] Iteration 5550 (3.84299 iter/s, 13.0107s/50 iter), loss = 0.0117806, remaining 0 hours and 27 minutes
I0108 20:19:12.378399  2043 solver.cpp:291]     Train net output #0: loss = 0.0117807 (* 1 = 0.0117807 loss)
I0108 20:19:12.378407  2043 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0108 20:19:25.353617  2043 solver.cpp:270] Iteration 5600 (3.85364 iter/s, 12.9747s/50 iter), loss = 0.00585513, remaining 0 hours and 27 minutes
I0108 20:19:25.353649  2043 solver.cpp:291]     Train net output #0: loss = 0.00585517 (* 1 = 0.00585517 loss)
I0108 20:19:25.353657  2043 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0108 20:19:38.344925  2043 solver.cpp:270] Iteration 5650 (3.84888 iter/s, 12.9908s/50 iter), loss = 0.0328516, remaining 0 hours and 27 minutes
I0108 20:19:38.344974  2043 solver.cpp:291]     Train net output #0: loss = 0.0328516 (* 1 = 0.0328516 loss)
I0108 20:19:38.344981  2043 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0108 20:19:51.343869  2043 solver.cpp:270] Iteration 5700 (3.84662 iter/s, 12.9984s/50 iter), loss = 0.0045785, remaining 0 hours and 27 minutes
I0108 20:19:51.343902  2043 solver.cpp:291]     Train net output #0: loss = 0.00457854 (* 1 = 0.00457854 loss)
I0108 20:19:51.343924  2043 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0108 20:20:04.329412  2043 solver.cpp:270] Iteration 5750 (3.85059 iter/s, 12.985s/50 iter), loss = 0.01634, remaining 0 hours and 27 minutes
I0108 20:20:04.329443  2043 solver.cpp:291]     Train net output #0: loss = 0.01634 (* 1 = 0.01634 loss)
I0108 20:20:04.329450  2043 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0108 20:20:17.335151  2043 solver.cpp:270] Iteration 5800 (3.84461 iter/s, 13.0052s/50 iter), loss = 0.0177283, remaining 0 hours and 26 minutes
I0108 20:20:17.335206  2043 solver.cpp:291]     Train net output #0: loss = 0.0177284 (* 1 = 0.0177284 loss)
I0108 20:20:17.335213  2043 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0108 20:20:30.310676  2043 solver.cpp:270] Iteration 5850 (3.85357 iter/s, 12.975s/50 iter), loss = 0.0121553, remaining 0 hours and 26 minutes
I0108 20:20:30.310709  2043 solver.cpp:291]     Train net output #0: loss = 0.0121554 (* 1 = 0.0121554 loss)
I0108 20:20:30.310716  2043 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0108 20:20:43.309721  2043 solver.cpp:270] Iteration 5900 (3.84659 iter/s, 12.9985s/50 iter), loss = 0.0200497, remaining 0 hours and 26 minutes
I0108 20:20:43.309752  2043 solver.cpp:291]     Train net output #0: loss = 0.0200497 (* 1 = 0.0200497 loss)
I0108 20:20:43.309774  2043 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0108 20:20:56.289996  2043 solver.cpp:270] Iteration 5950 (3.85215 iter/s, 12.9798s/50 iter), loss = 0.0252767, remaining 0 hours and 25 minutes
I0108 20:20:56.290041  2043 solver.cpp:291]     Train net output #0: loss = 0.0252768 (* 1 = 0.0252768 loss)
I0108 20:20:56.290048  2043 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0108 20:21:09.030719  2043 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0/snapshots/_iter_6000.caffemodel
I0108 20:21:11.540393  2043 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0/snapshots/_iter_6000.solverstate
I0108 20:21:11.764155  2043 solver.cpp:424] Iteration 6000, Testing net (#0)
I0108 20:21:13.240950  2043 solver.cpp:523]     Test net output #0: accuracy = 0.94725
I0108 20:21:13.240978  2043 solver.cpp:523]     Test net output #1: loss = 0.164583 (* 1 = 0.164583 loss)
I0108 20:21:13.240983  2043 solver.cpp:523]     Test net output #2: top-1 = 0.94725
I0108 20:21:13.486699  2043 solver.cpp:270] Iteration 6000 (2.90765 iter/s, 17.196s/50 iter), loss = 0.0043856, remaining 0 hours and 34 minutes
I0108 20:21:13.486724  2043 solver.cpp:291]     Train net output #0: loss = 0.00438566 (* 1 = 0.00438566 loss)
I0108 20:21:13.486732  2043 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0108 20:21:26.369200  2043 solver.cpp:270] Iteration 6050 (3.88139 iter/s, 12.882s/50 iter), loss = 0.0226102, remaining 0 hours and 25 minutes
I0108 20:21:26.369244  2043 solver.cpp:291]     Train net output #0: loss = 0.0226102 (* 1 = 0.0226102 loss)
I0108 20:21:26.369268  2043 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0108 20:21:39.318526  2043 solver.cpp:270] Iteration 6100 (3.86136 iter/s, 12.9488s/50 iter), loss = 0.0385256, remaining 0 hours and 25 minutes
I0108 20:21:39.318558  2043 solver.cpp:291]     Train net output #0: loss = 0.0385256 (* 1 = 0.0385256 loss)
I0108 20:21:39.318565  2043 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0108 20:21:52.306092  2043 solver.cpp:270] Iteration 6150 (3.84999 iter/s, 12.987s/50 iter), loss = 0.020342, remaining 0 hours and 25 minutes
I0108 20:21:52.306123  2043 solver.cpp:291]     Train net output #0: loss = 0.0203421 (* 1 = 0.0203421 loss)
I0108 20:21:52.306130  2043 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0108 20:22:05.296260  2043 solver.cpp:270] Iteration 6200 (3.84922 iter/s, 12.9897s/50 iter), loss = 0.0256171, remaining 0 hours and 24 minutes
I0108 20:22:05.296308  2043 solver.cpp:291]     Train net output #0: loss = 0.0256172 (* 1 = 0.0256172 loss)
I0108 20:22:05.296314  2043 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0108 20:22:18.287695  2043 solver.cpp:270] Iteration 6250 (3.84885 iter/s, 12.9909s/50 iter), loss = 0.0174903, remaining 0 hours and 24 minutes
I0108 20:22:18.287729  2043 solver.cpp:291]     Train net output #0: loss = 0.0174904 (* 1 = 0.0174904 loss)
I0108 20:22:18.287736  2043 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0108 20:22:31.281687  2043 solver.cpp:270] Iteration 6300 (3.84809 iter/s, 12.9935s/50 iter), loss = 0.00994963, remaining 0 hours and 24 minutes
I0108 20:22:31.281718  2043 solver.cpp:291]     Train net output #0: loss = 0.0099497 (* 1 = 0.0099497 loss)
I0108 20:22:31.281724  2043 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0108 20:22:44.266330  2043 solver.cpp:270] Iteration 6350 (3.85086 iter/s, 12.9841s/50 iter), loss = 0.0083805, remaining 0 hours and 24 minutes
I0108 20:22:44.266382  2043 solver.cpp:291]     Train net output #0: loss = 0.00838057 (* 1 = 0.00838057 loss)
I0108 20:22:44.266389  2043 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0108 20:22:57.265403  2043 solver.cpp:270] Iteration 6400 (3.84659 iter/s, 12.9985s/50 iter), loss = 0.0220978, remaining 0 hours and 24 minutes
I0108 20:22:57.265434  2043 solver.cpp:291]     Train net output #0: loss = 0.0220979 (* 1 = 0.0220979 loss)
I0108 20:22:57.265441  2043 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0108 20:23:10.244379  2043 solver.cpp:270] Iteration 6450 (3.85254 iter/s, 12.9785s/50 iter), loss = 0.0278214, remaining 0 hours and 23 minutes
I0108 20:23:10.244411  2043 solver.cpp:291]     Train net output #0: loss = 0.0278215 (* 1 = 0.0278215 loss)
I0108 20:23:10.244418  2043 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0108 20:23:23.235093  2043 solver.cpp:270] Iteration 6500 (3.84906 iter/s, 12.9902s/50 iter), loss = 0.0103309, remaining 0 hours and 23 minutes
I0108 20:23:23.235138  2043 solver.cpp:291]     Train net output #0: loss = 0.010331 (* 1 = 0.010331 loss)
I0108 20:23:23.235146  2043 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0108 20:23:36.225203  2043 solver.cpp:270] Iteration 6550 (3.84924 iter/s, 12.9896s/50 iter), loss = 0.0254956, remaining 0 hours and 23 minutes
I0108 20:23:36.225235  2043 solver.cpp:291]     Train net output #0: loss = 0.0254957 (* 1 = 0.0254957 loss)
I0108 20:23:36.225242  2043 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0108 20:23:49.202435  2043 solver.cpp:270] Iteration 6600 (3.85306 iter/s, 12.9767s/50 iter), loss = 0.00932434, remaining 0 hours and 23 minutes
I0108 20:23:49.202466  2043 solver.cpp:291]     Train net output #0: loss = 0.00932441 (* 1 = 0.00932441 loss)
I0108 20:23:49.202473  2043 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0108 20:24:02.207502  2043 solver.cpp:270] Iteration 6650 (3.84481 iter/s, 13.0046s/50 iter), loss = 0.0132777, remaining 0 hours and 23 minutes
I0108 20:24:02.207548  2043 solver.cpp:291]     Train net output #0: loss = 0.0132778 (* 1 = 0.0132778 loss)
I0108 20:24:02.207556  2043 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0108 20:24:15.185220  2043 solver.cpp:270] Iteration 6700 (3.85292 iter/s, 12.9772s/50 iter), loss = 0.00421872, remaining 0 hours and 22 minutes
I0108 20:24:15.185250  2043 solver.cpp:291]     Train net output #0: loss = 0.0042188 (* 1 = 0.0042188 loss)
I0108 20:24:15.185256  2043 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0108 20:24:28.168524  2043 solver.cpp:270] Iteration 6750 (3.85125 iter/s, 12.9828s/50 iter), loss = 0.0148994, remaining 0 hours and 22 minutes
I0108 20:24:28.168555  2043 solver.cpp:291]     Train net output #0: loss = 0.0148994 (* 1 = 0.0148994 loss)
I0108 20:24:28.168562  2043 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0108 20:24:41.179901  2043 solver.cpp:270] Iteration 6800 (3.84294 iter/s, 13.0109s/50 iter), loss = 0.0269174, remaining 0 hours and 22 minutes
I0108 20:24:41.179946  2043 solver.cpp:291]     Train net output #0: loss = 0.0269175 (* 1 = 0.0269175 loss)
I0108 20:24:41.179970  2043 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0108 20:24:54.154865  2043 solver.cpp:270] Iteration 6850 (3.85373 iter/s, 12.9744s/50 iter), loss = 0.00217024, remaining 0 hours and 22 minutes
I0108 20:24:54.154898  2043 solver.cpp:291]     Train net output #0: loss = 0.00217032 (* 1 = 0.00217032 loss)
I0108 20:24:54.154906  2043 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0108 20:25:07.173822  2043 solver.cpp:270] Iteration 6900 (3.84071 iter/s, 13.0184s/50 iter), loss = 0.0175707, remaining 0 hours and 22 minutes
I0108 20:25:07.173854  2043 solver.cpp:291]     Train net output #0: loss = 0.0175708 (* 1 = 0.0175708 loss)
I0108 20:25:07.173861  2043 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0108 20:25:20.160804  2043 solver.cpp:270] Iteration 6950 (3.85016 iter/s, 12.9865s/50 iter), loss = 0.0221402, remaining 0 hours and 21 minutes
I0108 20:25:20.160856  2043 solver.cpp:291]     Train net output #0: loss = 0.0221403 (* 1 = 0.0221403 loss)
I0108 20:25:20.160863  2043 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0108 20:25:32.898106  2043 solver.cpp:424] Iteration 7000, Testing net (#0)
I0108 20:25:34.461187  2043 solver.cpp:523]     Test net output #0: accuracy = 0.94575
I0108 20:25:34.461215  2043 solver.cpp:523]     Test net output #1: loss = 0.181759 (* 1 = 0.181759 loss)
I0108 20:25:34.461220  2043 solver.cpp:523]     Test net output #2: top-1 = 0.94575
I0108 20:25:34.716408  2043 solver.cpp:270] Iteration 7000 (3.43524 iter/s, 14.555s/50 iter), loss = 0.00817608, remaining 0 hours and 24 minutes
I0108 20:25:34.716434  2043 solver.cpp:291]     Train net output #0: loss = 0.00817616 (* 1 = 0.00817616 loss)
I0108 20:25:34.716441  2043 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0108 20:25:47.716225  2043 solver.cpp:270] Iteration 7050 (3.84636 iter/s, 12.9993s/50 iter), loss = 0.0551651, remaining 0 hours and 21 minutes
I0108 20:25:47.716256  2043 solver.cpp:291]     Train net output #0: loss = 0.0551652 (* 1 = 0.0551652 loss)
I0108 20:25:47.716279  2043 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0108 20:26:00.710938  2043 solver.cpp:270] Iteration 7100 (3.84787 iter/s, 12.9942s/50 iter), loss = 0.0039212, remaining 0 hours and 21 minutes
I0108 20:26:00.710983  2043 solver.cpp:291]     Train net output #0: loss = 0.00392127 (* 1 = 0.00392127 loss)
I0108 20:26:00.711007  2043 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0108 20:26:13.698531  2043 solver.cpp:270] Iteration 7150 (3.84999 iter/s, 12.9871s/50 iter), loss = 0.0144921, remaining 0 hours and 20 minutes
I0108 20:26:13.698562  2043 solver.cpp:291]     Train net output #0: loss = 0.0144922 (* 1 = 0.0144922 loss)
I0108 20:26:13.698580  2043 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0108 20:26:26.706360  2043 solver.cpp:270] Iteration 7200 (3.84399 iter/s, 13.0073s/50 iter), loss = 0.0159058, remaining 0 hours and 20 minutes
I0108 20:26:26.706393  2043 solver.cpp:291]     Train net output #0: loss = 0.0159059 (* 1 = 0.0159059 loss)
I0108 20:26:26.706399  2043 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0108 20:26:39.680114  2043 solver.cpp:270] Iteration 7250 (3.85409 iter/s, 12.9732s/50 iter), loss = 0.0373228, remaining 0 hours and 20 minutes
I0108 20:26:39.680162  2043 solver.cpp:291]     Train net output #0: loss = 0.0373229 (* 1 = 0.0373229 loss)
I0108 20:26:39.680169  2043 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0108 20:26:52.676261  2043 solver.cpp:270] Iteration 7300 (3.84745 iter/s, 12.9956s/50 iter), loss = 0.0181946, remaining 0 hours and 20 minutes
I0108 20:26:52.676292  2043 solver.cpp:291]     Train net output #0: loss = 0.0181947 (* 1 = 0.0181947 loss)
I0108 20:26:52.676299  2043 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0108 20:27:05.665380  2043 solver.cpp:270] Iteration 7350 (3.84953 iter/s, 12.9886s/50 iter), loss = 0.0490026, remaining 0 hours and 20 minutes
I0108 20:27:05.665412  2043 solver.cpp:291]     Train net output #0: loss = 0.0490026 (* 1 = 0.0490026 loss)
I0108 20:27:05.665421  2043 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0108 20:27:18.655124  2043 solver.cpp:270] Iteration 7400 (3.84934 iter/s, 12.9892s/50 iter), loss = 0.0257111, remaining 0 hours and 19 minutes
I0108 20:27:18.655169  2043 solver.cpp:291]     Train net output #0: loss = 0.0257112 (* 1 = 0.0257112 loss)
I0108 20:27:18.655176  2043 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0108 20:27:31.657637  2043 solver.cpp:270] Iteration 7450 (3.84557 iter/s, 13.002s/50 iter), loss = 0.0222371, remaining 0 hours and 19 minutes
I0108 20:27:31.657670  2043 solver.cpp:291]     Train net output #0: loss = 0.0222372 (* 1 = 0.0222372 loss)
I0108 20:27:31.657676  2043 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0108 20:27:44.642880  2043 solver.cpp:270] Iteration 7500 (3.85068 iter/s, 12.9847s/50 iter), loss = 0.0304243, remaining 0 hours and 19 minutes
I0108 20:27:44.642912  2043 solver.cpp:291]     Train net output #0: loss = 0.0304244 (* 1 = 0.0304244 loss)
I0108 20:27:44.642920  2043 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0108 20:27:57.636950  2043 solver.cpp:270] Iteration 7550 (3.84806 iter/s, 12.9936s/50 iter), loss = 0.01886, remaining 0 hours and 19 minutes
I0108 20:27:57.637004  2043 solver.cpp:291]     Train net output #0: loss = 0.01886 (* 1 = 0.01886 loss)
I0108 20:27:57.637012  2043 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0108 20:28:10.621279  2043 solver.cpp:270] Iteration 7600 (3.85096 iter/s, 12.9838s/50 iter), loss = 0.00473929, remaining 0 hours and 18 minutes
I0108 20:28:10.621311  2043 solver.cpp:291]     Train net output #0: loss = 0.00473938 (* 1 = 0.00473938 loss)
I0108 20:28:10.621318  2043 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0108 20:28:23.597693  2043 solver.cpp:270] Iteration 7650 (3.8533 iter/s, 12.9759s/50 iter), loss = 0.00513183, remaining 0 hours and 18 minutes
I0108 20:28:23.597724  2043 solver.cpp:291]     Train net output #0: loss = 0.00513192 (* 1 = 0.00513192 loss)
I0108 20:28:23.597731  2043 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0108 20:28:36.587010  2043 solver.cpp:270] Iteration 7700 (3.84947 iter/s, 12.9888s/50 iter), loss = 0.00400655, remaining 0 hours and 18 minutes
I0108 20:28:36.587054  2043 solver.cpp:291]     Train net output #0: loss = 0.00400663 (* 1 = 0.00400663 loss)
I0108 20:28:36.587078  2043 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0108 20:28:49.587003  2043 solver.cpp:270] Iteration 7750 (3.84631 iter/s, 12.9995s/50 iter), loss = 0.023957, remaining 0 hours and 18 minutes
I0108 20:28:49.587034  2043 solver.cpp:291]     Train net output #0: loss = 0.0239571 (* 1 = 0.0239571 loss)
I0108 20:28:49.587042  2043 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0108 20:29:02.599809  2043 solver.cpp:270] Iteration 7800 (3.84252 iter/s, 13.0123s/50 iter), loss = 0.003415, remaining 0 hours and 18 minutes
I0108 20:29:02.599841  2043 solver.cpp:291]     Train net output #0: loss = 0.00341509 (* 1 = 0.00341509 loss)
I0108 20:29:02.599849  2043 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0108 20:29:15.570772  2043 solver.cpp:270] Iteration 7850 (3.85492 iter/s, 12.9704s/50 iter), loss = 0.00626481, remaining 0 hours and 17 minutes
I0108 20:29:15.570819  2043 solver.cpp:291]     Train net output #0: loss = 0.0062649 (* 1 = 0.0062649 loss)
I0108 20:29:15.570827  2043 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0108 20:29:28.562477  2043 solver.cpp:270] Iteration 7900 (3.84877 iter/s, 12.9912s/50 iter), loss = 0.016749, remaining 0 hours and 17 minutes
I0108 20:29:28.562510  2043 solver.cpp:291]     Train net output #0: loss = 0.0167491 (* 1 = 0.0167491 loss)
I0108 20:29:28.562532  2043 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0108 20:29:41.552547  2043 solver.cpp:270] Iteration 7950 (3.84925 iter/s, 12.9896s/50 iter), loss = 0.00368901, remaining 0 hours and 17 minutes
I0108 20:29:41.552579  2043 solver.cpp:291]     Train net output #0: loss = 0.00368911 (* 1 = 0.00368911 loss)
I0108 20:29:41.552587  2043 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0108 20:29:54.292856  2043 solver.cpp:424] Iteration 8000, Testing net (#0)
I0108 20:29:55.843832  2043 solver.cpp:523]     Test net output #0: accuracy = 0.947
I0108 20:29:55.843860  2043 solver.cpp:523]     Test net output #1: loss = 0.206811 (* 1 = 0.206811 loss)
I0108 20:29:55.843865  2043 solver.cpp:523]     Test net output #2: top-1 = 0.947
I0108 20:29:56.098572  2043 solver.cpp:270] Iteration 8000 (3.4375 iter/s, 14.5455s/50 iter), loss = 0.0139144, remaining 0 hours and 19 minutes
I0108 20:29:56.098598  2043 solver.cpp:291]     Train net output #0: loss = 0.0139145 (* 1 = 0.0139145 loss)
I0108 20:29:56.098604  2043 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0108 20:30:09.102694  2043 solver.cpp:270] Iteration 8050 (3.84509 iter/s, 13.0036s/50 iter), loss = 0.00874254, remaining 0 hours and 16 minutes
I0108 20:30:09.102735  2043 solver.cpp:291]     Train net output #0: loss = 0.00874263 (* 1 = 0.00874263 loss)
I0108 20:30:09.102757  2043 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0108 20:30:22.084280  2043 solver.cpp:270] Iteration 8100 (3.85177 iter/s, 12.9811s/50 iter), loss = 0.00422669, remaining 0 hours and 16 minutes
I0108 20:30:22.084313  2043 solver.cpp:291]     Train net output #0: loss = 0.00422678 (* 1 = 0.00422678 loss)
I0108 20:30:22.084336  2043 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0108 20:30:35.083698  2043 solver.cpp:270] Iteration 8150 (3.84648 iter/s, 12.9989s/50 iter), loss = 0.017769, remaining 0 hours and 16 minutes
I0108 20:30:35.083752  2043 solver.cpp:291]     Train net output #0: loss = 0.0177691 (* 1 = 0.0177691 loss)
I0108 20:30:35.083760  2043 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0108 20:30:48.070461  2043 solver.cpp:270] Iteration 8200 (3.85023 iter/s, 12.9862s/50 iter), loss = 0.0269247, remaining 0 hours and 16 minutes
I0108 20:30:48.070490  2043 solver.cpp:291]     Train net output #0: loss = 0.0269248 (* 1 = 0.0269248 loss)
I0108 20:30:48.070513  2043 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0108 20:31:01.051033  2043 solver.cpp:270] Iteration 8250 (3.85206 iter/s, 12.9801s/50 iter), loss = 0.00960797, remaining 0 hours and 16 minutes
I0108 20:31:01.051065  2043 solver.cpp:291]     Train net output #0: loss = 0.00960807 (* 1 = 0.00960807 loss)
I0108 20:31:01.051074  2043 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0108 20:31:14.029989  2043 solver.cpp:270] Iteration 8300 (3.85254 iter/s, 12.9784s/50 iter), loss = 0.0129628, remaining 0 hours and 15 minutes
I0108 20:31:14.030033  2043 solver.cpp:291]     Train net output #0: loss = 0.0129629 (* 1 = 0.0129629 loss)
I0108 20:31:14.030041  2043 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0108 20:31:27.034826  2043 solver.cpp:270] Iteration 8350 (3.84488 iter/s, 13.0043s/50 iter), loss = 0.0178114, remaining 0 hours and 15 minutes
I0108 20:31:27.034857  2043 solver.cpp:291]     Train net output #0: loss = 0.0178115 (* 1 = 0.0178115 loss)
I0108 20:31:27.034881  2043 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0108 20:31:40.010653  2043 solver.cpp:270] Iteration 8400 (3.85347 iter/s, 12.9753s/50 iter), loss = 0.00611607, remaining 0 hours and 15 minutes
I0108 20:31:40.010684  2043 solver.cpp:291]     Train net output #0: loss = 0.00611617 (* 1 = 0.00611617 loss)
I0108 20:31:40.010691  2043 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0108 20:31:53.007416  2043 solver.cpp:270] Iteration 8450 (3.84726 iter/s, 12.9962s/50 iter), loss = 0.00587694, remaining 0 hours and 15 minutes
I0108 20:31:53.007460  2043 solver.cpp:291]     Train net output #0: loss = 0.00587703 (* 1 = 0.00587703 loss)
I0108 20:31:53.007468  2043 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0108 20:32:06.001348  2043 solver.cpp:270] Iteration 8500 (3.84811 iter/s, 12.9934s/50 iter), loss = 0.0135693, remaining 0 hours and 15 minutes
I0108 20:32:06.001379  2043 solver.cpp:291]     Train net output #0: loss = 0.0135694 (* 1 = 0.0135694 loss)
I0108 20:32:06.001387  2043 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0108 20:32:18.983211  2043 solver.cpp:270] Iteration 8550 (3.85168 iter/s, 12.9813s/50 iter), loss = 0.029854, remaining 0 hours and 14 minutes
I0108 20:32:18.983243  2043 solver.cpp:291]     Train net output #0: loss = 0.0298541 (* 1 = 0.0298541 loss)
I0108 20:32:18.983251  2043 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0108 20:32:31.981863  2043 solver.cpp:270] Iteration 8600 (3.84671 iter/s, 12.9981s/50 iter), loss = 0.0374032, remaining 0 hours and 14 minutes
I0108 20:32:31.981909  2043 solver.cpp:291]     Train net output #0: loss = 0.0374033 (* 1 = 0.0374033 loss)
I0108 20:32:31.981933  2043 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0108 20:32:44.965209  2043 solver.cpp:270] Iteration 8650 (3.85124 iter/s, 12.9828s/50 iter), loss = 0.012818, remaining 0 hours and 14 minutes
I0108 20:32:44.965240  2043 solver.cpp:291]     Train net output #0: loss = 0.0128181 (* 1 = 0.0128181 loss)
I0108 20:32:44.965262  2043 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0108 20:32:57.959436  2043 solver.cpp:270] Iteration 8700 (3.84802 iter/s, 12.9937s/50 iter), loss = 0.0294585, remaining 0 hours and 14 minutes
I0108 20:32:57.959468  2043 solver.cpp:291]     Train net output #0: loss = 0.0294586 (* 1 = 0.0294586 loss)
I0108 20:32:57.959476  2043 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0108 20:33:10.945431  2043 solver.cpp:270] Iteration 8750 (3.85046 iter/s, 12.9855s/50 iter), loss = 0.0142438, remaining 0 hours and 14 minutes
I0108 20:33:10.945488  2043 solver.cpp:291]     Train net output #0: loss = 0.0142439 (* 1 = 0.0142439 loss)
I0108 20:33:10.945497  2043 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0108 20:33:23.934197  2043 solver.cpp:270] Iteration 8800 (3.84964 iter/s, 12.9882s/50 iter), loss = 0.0345942, remaining 0 hours and 13 minutes
I0108 20:33:23.934229  2043 solver.cpp:291]     Train net output #0: loss = 0.0345943 (* 1 = 0.0345943 loss)
I0108 20:33:23.934253  2043 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0108 20:33:36.923800  2043 solver.cpp:270] Iteration 8850 (3.84939 iter/s, 12.9891s/50 iter), loss = 0.00501651, remaining 0 hours and 13 minutes
I0108 20:33:36.923833  2043 solver.cpp:291]     Train net output #0: loss = 0.0050166 (* 1 = 0.0050166 loss)
I0108 20:33:36.923856  2043 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0108 20:33:49.885411  2043 solver.cpp:270] Iteration 8900 (3.8577 iter/s, 12.9611s/50 iter), loss = 0.0151579, remaining 0 hours and 13 minutes
I0108 20:33:49.885459  2043 solver.cpp:291]     Train net output #0: loss = 0.015158 (* 1 = 0.015158 loss)
I0108 20:33:49.885468  2043 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0108 20:34:02.881501  2043 solver.cpp:270] Iteration 8950 (3.84747 iter/s, 12.9956s/50 iter), loss = 0.0136269, remaining 0 hours and 12 minutes
I0108 20:34:02.881533  2043 solver.cpp:291]     Train net output #0: loss = 0.013627 (* 1 = 0.013627 loss)
I0108 20:34:02.881541  2043 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0108 20:34:15.606671  2043 solver.cpp:424] Iteration 9000, Testing net (#0)
I0108 20:34:17.164654  2043 solver.cpp:523]     Test net output #0: accuracy = 0.946
I0108 20:34:17.164682  2043 solver.cpp:523]     Test net output #1: loss = 0.224896 (* 1 = 0.224896 loss)
I0108 20:34:17.164687  2043 solver.cpp:523]     Test net output #2: top-1 = 0.946
I0108 20:34:17.420168  2043 solver.cpp:270] Iteration 9000 (3.43924 iter/s, 14.5381s/50 iter), loss = 0.0120788, remaining 0 hours and 14 minutes
I0108 20:34:17.420195  2043 solver.cpp:291]     Train net output #0: loss = 0.0120789 (* 1 = 0.0120789 loss)
I0108 20:34:17.420203  2043 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0108 20:34:30.396224  2043 solver.cpp:270] Iteration 9050 (3.8534 iter/s, 12.9755s/50 iter), loss = 0.00193213, remaining 0 hours and 12 minutes
I0108 20:34:30.396271  2043 solver.cpp:291]     Train net output #0: loss = 0.00193222 (* 1 = 0.00193222 loss)
I0108 20:34:30.396296  2043 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0108 20:34:43.389550  2043 solver.cpp:270] Iteration 9100 (3.84829 iter/s, 12.9928s/50 iter), loss = 0.0086327, remaining 0 hours and 12 minutes
I0108 20:34:43.389581  2043 solver.cpp:291]     Train net output #0: loss = 0.00863279 (* 1 = 0.00863279 loss)
I0108 20:34:43.389605  2043 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0108 20:34:56.367498  2043 solver.cpp:270] Iteration 9150 (3.85284 iter/s, 12.9774s/50 iter), loss = 0.0114046, remaining 0 hours and 12 minutes
I0108 20:34:56.367530  2043 solver.cpp:291]     Train net output #0: loss = 0.0114046 (* 1 = 0.0114046 loss)
I0108 20:34:56.367553  2043 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0108 20:35:09.370954  2043 solver.cpp:270] Iteration 9200 (3.84528 iter/s, 13.0029s/50 iter), loss = 0.00409176, remaining 0 hours and 11 minutes
I0108 20:35:09.371003  2043 solver.cpp:291]     Train net output #0: loss = 0.00409185 (* 1 = 0.00409185 loss)
I0108 20:35:09.371011  2043 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0108 20:35:22.352928  2043 solver.cpp:270] Iteration 9250 (3.85165 iter/s, 12.9814s/50 iter), loss = 0.00272459, remaining 0 hours and 11 minutes
I0108 20:35:22.352960  2043 solver.cpp:291]     Train net output #0: loss = 0.00272467 (* 1 = 0.00272467 loss)
I0108 20:35:22.352968  2043 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0108 20:35:35.339901  2043 solver.cpp:270] Iteration 9300 (3.85016 iter/s, 12.9865s/50 iter), loss = 0.00838036, remaining 0 hours and 11 minutes
I0108 20:35:35.339936  2043 solver.cpp:291]     Train net output #0: loss = 0.00838044 (* 1 = 0.00838044 loss)
I0108 20:35:35.339942  2043 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0108 20:35:48.323925  2043 solver.cpp:270] Iteration 9350 (3.85104 iter/s, 12.9835s/50 iter), loss = 0.0136432, remaining 0 hours and 11 minutes
I0108 20:35:48.323976  2043 solver.cpp:291]     Train net output #0: loss = 0.0136433 (* 1 = 0.0136433 loss)
I0108 20:35:48.323984  2043 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0108 20:36:01.291592  2043 solver.cpp:270] Iteration 9400 (3.8559 iter/s, 12.9671s/50 iter), loss = 0.00883034, remaining 0 hours and 11 minutes
I0108 20:36:01.291625  2043 solver.cpp:291]     Train net output #0: loss = 0.00883041 (* 1 = 0.00883041 loss)
I0108 20:36:01.291648  2043 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0108 20:36:14.299681  2043 solver.cpp:270] Iteration 9450 (3.84392 iter/s, 13.0076s/50 iter), loss = 0.00745199, remaining 0 hours and 10 minutes
I0108 20:36:14.299712  2043 solver.cpp:291]     Train net output #0: loss = 0.00745206 (* 1 = 0.00745206 loss)
I0108 20:36:14.299736  2043 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0108 20:36:27.281728  2043 solver.cpp:270] Iteration 9500 (3.85163 iter/s, 12.9815s/50 iter), loss = 0.0058124, remaining 0 hours and 10 minutes
I0108 20:36:27.281777  2043 solver.cpp:291]     Train net output #0: loss = 0.00581248 (* 1 = 0.00581248 loss)
I0108 20:36:27.281785  2043 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0108 20:36:40.278673  2043 solver.cpp:270] Iteration 9550 (3.84722 iter/s, 12.9964s/50 iter), loss = 0.00172547, remaining 0 hours and 10 minutes
I0108 20:36:40.278704  2043 solver.cpp:291]     Train net output #0: loss = 0.00172555 (* 1 = 0.00172555 loss)
I0108 20:36:40.278712  2043 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0108 20:36:53.287431  2043 solver.cpp:270] Iteration 9600 (3.84372 iter/s, 13.0082s/50 iter), loss = 0.00109844, remaining 0 hours and 10 minutes
I0108 20:36:53.287464  2043 solver.cpp:291]     Train net output #0: loss = 0.00109853 (* 1 = 0.00109853 loss)
I0108 20:36:53.287472  2043 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0108 20:37:06.280606  2043 solver.cpp:270] Iteration 9650 (3.84833 iter/s, 12.9927s/50 iter), loss = 0.0289438, remaining 0 hours and 10 minutes
I0108 20:37:06.280652  2043 solver.cpp:291]     Train net output #0: loss = 0.0289439 (* 1 = 0.0289439 loss)
I0108 20:37:06.280675  2043 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0108 20:37:19.263164  2043 solver.cpp:270] Iteration 9700 (3.85148 iter/s, 12.982s/50 iter), loss = 0.0153314, remaining 0 hours and 9 minutes
I0108 20:37:19.263195  2043 solver.cpp:291]     Train net output #0: loss = 0.0153315 (* 1 = 0.0153315 loss)
I0108 20:37:19.263201  2043 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0108 20:37:32.247622  2043 solver.cpp:270] Iteration 9750 (3.85091 iter/s, 12.9839s/50 iter), loss = 0.0133866, remaining 0 hours and 9 minutes
I0108 20:37:32.247665  2043 solver.cpp:291]     Train net output #0: loss = 0.0133867 (* 1 = 0.0133867 loss)
I0108 20:37:32.247689  2043 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0108 20:37:45.228076  2043 solver.cpp:270] Iteration 9800 (3.8521 iter/s, 12.9799s/50 iter), loss = 0.0274162, remaining 0 hours and 9 minutes
I0108 20:37:45.228123  2043 solver.cpp:291]     Train net output #0: loss = 0.0274163 (* 1 = 0.0274163 loss)
I0108 20:37:45.228130  2043 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0108 20:37:58.214424  2043 solver.cpp:270] Iteration 9850 (3.85035 iter/s, 12.9858s/50 iter), loss = 0.0418656, remaining 0 hours and 9 minutes
I0108 20:37:58.214455  2043 solver.cpp:291]     Train net output #0: loss = 0.0418657 (* 1 = 0.0418657 loss)
I0108 20:37:58.214463  2043 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0108 20:38:11.199585  2043 solver.cpp:270] Iteration 9900 (3.8507 iter/s, 12.9846s/50 iter), loss = 0.00497537, remaining 0 hours and 9 minutes
I0108 20:38:11.199616  2043 solver.cpp:291]     Train net output #0: loss = 0.00497546 (* 1 = 0.00497546 loss)
I0108 20:38:11.199625  2043 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0108 20:38:24.180030  2043 solver.cpp:270] Iteration 9950 (3.8521 iter/s, 12.9799s/50 iter), loss = 0.0154693, remaining 0 hours and 8 minutes
I0108 20:38:24.180083  2043 solver.cpp:291]     Train net output #0: loss = 0.0154694 (* 1 = 0.0154694 loss)
I0108 20:38:24.180106  2043 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0108 20:38:36.910547  2043 solver.cpp:424] Iteration 10000, Testing net (#0)
I0108 20:38:38.478289  2043 solver.cpp:523]     Test net output #0: accuracy = 0.9465
I0108 20:38:38.478318  2043 solver.cpp:523]     Test net output #1: loss = 0.237784 (* 1 = 0.237784 loss)
I0108 20:38:38.478322  2043 solver.cpp:523]     Test net output #2: top-1 = 0.9465
I0108 20:38:38.734670  2043 solver.cpp:270] Iteration 10000 (3.43547 iter/s, 14.554s/50 iter), loss = 0.0171149, remaining 0 hours and 9 minutes
I0108 20:38:38.734696  2043 solver.cpp:291]     Train net output #0: loss = 0.017115 (* 1 = 0.017115 loss)
I0108 20:38:38.734704  2043 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0108 20:38:51.738698  2043 solver.cpp:270] Iteration 10050 (3.84511 iter/s, 13.0035s/50 iter), loss = 0.00379044, remaining 0 hours and 8 minutes
I0108 20:38:51.738729  2043 solver.cpp:291]     Train net output #0: loss = 0.00379053 (* 1 = 0.00379053 loss)
I0108 20:38:51.738736  2043 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0108 20:39:04.741495  2043 solver.cpp:270] Iteration 10100 (3.84548 iter/s, 13.0023s/50 iter), loss = 0.00224889, remaining 0 hours and 8 minutes
I0108 20:39:04.741547  2043 solver.cpp:291]     Train net output #0: loss = 0.00224898 (* 1 = 0.00224898 loss)
I0108 20:39:04.741559  2043 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0108 20:39:17.717104  2043 solver.cpp:270] Iteration 10150 (3.85354 iter/s, 12.9751s/50 iter), loss = 0.0126901, remaining 0 hours and 7 minutes
I0108 20:39:17.717136  2043 solver.cpp:291]     Train net output #0: loss = 0.0126902 (* 1 = 0.0126902 loss)
I0108 20:39:17.717159  2043 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0108 20:39:30.691246  2043 solver.cpp:270] Iteration 10200 (3.85397 iter/s, 12.9736s/50 iter), loss = 0.0106655, remaining 0 hours and 7 minutes
I0108 20:39:30.691277  2043 solver.cpp:291]     Train net output #0: loss = 0.0106655 (* 1 = 0.0106655 loss)
I0108 20:39:30.691301  2043 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0108 20:39:43.673688  2043 solver.cpp:270] Iteration 10250 (3.85151 iter/s, 12.9819s/50 iter), loss = 0.0048271, remaining 0 hours and 7 minutes
I0108 20:39:43.673736  2043 solver.cpp:291]     Train net output #0: loss = 0.00482719 (* 1 = 0.00482719 loss)
I0108 20:39:43.673743  2043 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0108 20:39:56.642266  2043 solver.cpp:270] Iteration 10300 (3.85563 iter/s, 12.968s/50 iter), loss = 0.00366926, remaining 0 hours and 7 minutes
I0108 20:39:56.642297  2043 solver.cpp:291]     Train net output #0: loss = 0.00366936 (* 1 = 0.00366936 loss)
I0108 20:39:56.642319  2043 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0108 20:40:09.625746  2043 solver.cpp:270] Iteration 10350 (3.8512 iter/s, 12.983s/50 iter), loss = 0.00193397, remaining 0 hours and 7 minutes
I0108 20:40:09.625779  2043 solver.cpp:291]     Train net output #0: loss = 0.00193407 (* 1 = 0.00193407 loss)
I0108 20:40:09.625787  2043 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0108 20:40:22.600821  2043 solver.cpp:270] Iteration 10400 (3.8537 iter/s, 12.9746s/50 iter), loss = 0.018992, remaining 0 hours and 6 minutes
I0108 20:40:22.600867  2043 solver.cpp:291]     Train net output #0: loss = 0.0189921 (* 1 = 0.0189921 loss)
I0108 20:40:22.600874  2043 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0108 20:40:35.594177  2043 solver.cpp:270] Iteration 10450 (3.84828 iter/s, 12.9928s/50 iter), loss = 0.0277911, remaining 0 hours and 6 minutes
I0108 20:40:35.594209  2043 solver.cpp:291]     Train net output #0: loss = 0.0277912 (* 1 = 0.0277912 loss)
I0108 20:40:35.594233  2043 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0108 20:40:48.589056  2043 solver.cpp:270] Iteration 10500 (3.84782 iter/s, 12.9944s/50 iter), loss = 0.00487431, remaining 0 hours and 6 minutes
I0108 20:40:48.589088  2043 solver.cpp:291]     Train net output #0: loss = 0.00487441 (* 1 = 0.00487441 loss)
I0108 20:40:48.589097  2043 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0108 20:41:01.587898  2043 solver.cpp:270] Iteration 10550 (3.84665 iter/s, 12.9983s/50 iter), loss = 0.0175868, remaining 0 hours and 6 minutes
I0108 20:41:01.587955  2043 solver.cpp:291]     Train net output #0: loss = 0.0175869 (* 1 = 0.0175869 loss)
I0108 20:41:01.587963  2043 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0108 20:41:14.570433  2043 solver.cpp:270] Iteration 10600 (3.85149 iter/s, 12.982s/50 iter), loss = 0.0013288, remaining 0 hours and 5 minutes
I0108 20:41:14.570466  2043 solver.cpp:291]     Train net output #0: loss = 0.00132891 (* 1 = 0.00132891 loss)
I0108 20:41:14.570488  2043 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0108 20:41:27.565806  2043 solver.cpp:270] Iteration 10650 (3.84768 iter/s, 12.9949s/50 iter), loss = 0.0155158, remaining 0 hours and 5 minutes
I0108 20:41:27.565838  2043 solver.cpp:291]     Train net output #0: loss = 0.0155159 (* 1 = 0.0155159 loss)
I0108 20:41:27.565861  2043 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0108 20:41:40.553093  2043 solver.cpp:270] Iteration 10700 (3.85007 iter/s, 12.9868s/50 iter), loss = 0.0128788, remaining 0 hours and 5 minutes
I0108 20:41:40.553140  2043 solver.cpp:291]     Train net output #0: loss = 0.0128789 (* 1 = 0.0128789 loss)
I0108 20:41:40.553148  2043 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0108 20:41:53.532339  2043 solver.cpp:270] Iteration 10750 (3.85246 iter/s, 12.9787s/50 iter), loss = 0.0247148, remaining 0 hours and 5 minutes
I0108 20:41:53.532371  2043 solver.cpp:291]     Train net output #0: loss = 0.0247149 (* 1 = 0.0247149 loss)
I0108 20:41:53.532394  2043 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0108 20:42:06.510329  2043 solver.cpp:270] Iteration 10800 (3.85283 iter/s, 12.9775s/50 iter), loss = 0.0587679, remaining 0 hours and 5 minutes
I0108 20:42:06.510360  2043 solver.cpp:291]     Train net output #0: loss = 0.058768 (* 1 = 0.058768 loss)
I0108 20:42:06.510383  2043 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0108 20:42:19.487623  2043 solver.cpp:270] Iteration 10850 (3.85304 iter/s, 12.9768s/50 iter), loss = 0.00994552, remaining 0 hours and 4 minutes
I0108 20:42:19.487674  2043 solver.cpp:291]     Train net output #0: loss = 0.00994564 (* 1 = 0.00994564 loss)
I0108 20:42:19.487697  2043 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0108 20:42:32.492218  2043 solver.cpp:270] Iteration 10900 (3.84495 iter/s, 13.0041s/50 iter), loss = 0.0192587, remaining 0 hours and 4 minutes
I0108 20:42:32.492249  2043 solver.cpp:291]     Train net output #0: loss = 0.0192588 (* 1 = 0.0192588 loss)
I0108 20:42:32.492272  2043 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0108 20:42:45.479169  2043 solver.cpp:270] Iteration 10950 (3.85017 iter/s, 12.9864s/50 iter), loss = 0.0126744, remaining 0 hours and 4 minutes
I0108 20:42:45.479204  2043 solver.cpp:291]     Train net output #0: loss = 0.0126745 (* 1 = 0.0126745 loss)
I0108 20:42:45.479212  2043 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0108 20:42:58.215354  2043 solver.cpp:424] Iteration 11000, Testing net (#0)
I0108 20:42:59.781594  2043 solver.cpp:523]     Test net output #0: accuracy = 0.9455
I0108 20:42:59.781621  2043 solver.cpp:523]     Test net output #1: loss = 0.244156 (* 1 = 0.244156 loss)
I0108 20:42:59.781625  2043 solver.cpp:523]     Test net output #2: top-1 = 0.9455
I0108 20:43:00.037791  2043 solver.cpp:270] Iteration 11000 (3.43453 iter/s, 14.558s/50 iter), loss = 0.0242507, remaining 0 hours and 4 minutes
I0108 20:43:00.037817  2043 solver.cpp:291]     Train net output #0: loss = 0.0242508 (* 1 = 0.0242508 loss)
I0108 20:43:00.037825  2043 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0108 20:43:13.031337  2043 solver.cpp:270] Iteration 11050 (3.84822 iter/s, 12.993s/50 iter), loss = 0.0246277, remaining 0 hours and 3 minutes
I0108 20:43:13.031368  2043 solver.cpp:291]     Train net output #0: loss = 0.0246278 (* 1 = 0.0246278 loss)
I0108 20:43:13.031376  2043 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0108 20:43:26.004886  2043 solver.cpp:270] Iteration 11100 (3.85415 iter/s, 12.973s/50 iter), loss = 0.037453, remaining 0 hours and 3 minutes
I0108 20:43:26.004920  2043 solver.cpp:291]     Train net output #0: loss = 0.0374531 (* 1 = 0.0374531 loss)
I0108 20:43:26.004927  2043 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0108 20:43:39.001087  2043 solver.cpp:270] Iteration 11150 (3.84743 iter/s, 12.9957s/50 iter), loss = 0.0106889, remaining 0 hours and 3 minutes
I0108 20:43:39.001144  2043 solver.cpp:291]     Train net output #0: loss = 0.010689 (* 1 = 0.010689 loss)
I0108 20:43:39.001153  2043 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0108 20:43:51.991315  2043 solver.cpp:270] Iteration 11200 (3.84921 iter/s, 12.9897s/50 iter), loss = 0.0198661, remaining 0 hours and 3 minutes
I0108 20:43:51.991345  2043 solver.cpp:291]     Train net output #0: loss = 0.0198662 (* 1 = 0.0198662 loss)
I0108 20:43:51.991353  2043 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0108 20:44:04.984630  2043 solver.cpp:270] Iteration 11250 (3.84829 iter/s, 12.9928s/50 iter), loss = 0.012322, remaining 0 hours and 3 minutes
I0108 20:44:04.984663  2043 solver.cpp:291]     Train net output #0: loss = 0.0123221 (* 1 = 0.0123221 loss)
I0108 20:44:04.984671  2043 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0108 20:44:17.974745  2043 solver.cpp:270] Iteration 11300 (3.84923 iter/s, 12.9896s/50 iter), loss = 0.0211301, remaining 0 hours and 2 minutes
I0108 20:44:17.974790  2043 solver.cpp:291]     Train net output #0: loss = 0.0211302 (* 1 = 0.0211302 loss)
I0108 20:44:17.974798  2043 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0108 20:44:30.942137  2043 solver.cpp:270] Iteration 11350 (3.85598 iter/s, 12.9669s/50 iter), loss = 0.00230408, remaining 0 hours and 2 minutes
I0108 20:44:30.942169  2043 solver.cpp:291]     Train net output #0: loss = 0.00230419 (* 1 = 0.00230419 loss)
I0108 20:44:30.942176  2043 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0108 20:44:43.941505  2043 solver.cpp:270] Iteration 11400 (3.84649 iter/s, 12.9989s/50 iter), loss = 0.00952553, remaining 0 hours and 2 minutes
I0108 20:44:43.941538  2043 solver.cpp:291]     Train net output #0: loss = 0.00952565 (* 1 = 0.00952565 loss)
I0108 20:44:43.941545  2043 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0108 20:44:56.910143  2043 solver.cpp:270] Iteration 11450 (3.85561 iter/s, 12.9681s/50 iter), loss = 0.00395488, remaining 0 hours and 2 minutes
I0108 20:44:56.910192  2043 solver.cpp:291]     Train net output #0: loss = 0.00395499 (* 1 = 0.00395499 loss)
I0108 20:44:56.910199  2043 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0108 20:45:09.898280  2043 solver.cpp:270] Iteration 11500 (3.84982 iter/s, 12.9876s/50 iter), loss = 0.00838434, remaining 0 hours and 2 minutes
I0108 20:45:09.898313  2043 solver.cpp:291]     Train net output #0: loss = 0.00838445 (* 1 = 0.00838445 loss)
I0108 20:45:09.898321  2043 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0108 20:45:22.897404  2043 solver.cpp:270] Iteration 11550 (3.84657 iter/s, 12.9986s/50 iter), loss = 0.016257, remaining 0 hours and 1 minutes
I0108 20:45:22.897436  2043 solver.cpp:291]     Train net output #0: loss = 0.0162571 (* 1 = 0.0162571 loss)
I0108 20:45:22.897444  2043 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0108 20:45:35.865617  2043 solver.cpp:270] Iteration 11600 (3.85574 iter/s, 12.9677s/50 iter), loss = 0.00943479, remaining 0 hours and 1 minutes
I0108 20:45:35.865666  2043 solver.cpp:291]     Train net output #0: loss = 0.00943491 (* 1 = 0.00943491 loss)
I0108 20:45:35.865674  2043 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0108 20:45:48.856968  2043 solver.cpp:270] Iteration 11650 (3.84887 iter/s, 12.9908s/50 iter), loss = 0.0373349, remaining 0 hours and 1 minutes
I0108 20:45:48.857000  2043 solver.cpp:291]     Train net output #0: loss = 0.037335 (* 1 = 0.037335 loss)
I0108 20:45:48.857007  2043 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0108 20:46:01.827610  2043 solver.cpp:270] Iteration 11700 (3.85501 iter/s, 12.9701s/50 iter), loss = 0.00550182, remaining 0 hours and 1 minutes
I0108 20:46:01.827641  2043 solver.cpp:291]     Train net output #0: loss = 0.00550194 (* 1 = 0.00550194 loss)
I0108 20:46:01.827648  2043 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0108 20:46:14.832492  2043 solver.cpp:270] Iteration 11750 (3.84486 iter/s, 13.0044s/50 iter), loss = 0.0139423, remaining 0 hours and 1 minutes
I0108 20:46:14.832543  2043 solver.cpp:291]     Train net output #0: loss = 0.0139425 (* 1 = 0.0139425 loss)
I0108 20:46:14.832551  2043 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0108 20:46:27.799896  2043 solver.cpp:270] Iteration 11800 (3.85598 iter/s, 12.9669s/50 iter), loss = 0.0140218, remaining 0 hours and 0 minutes
I0108 20:46:27.799926  2043 solver.cpp:291]     Train net output #0: loss = 0.014022 (* 1 = 0.014022 loss)
I0108 20:46:27.799948  2043 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0108 20:46:40.798481  2043 solver.cpp:270] Iteration 11850 (3.84672 iter/s, 12.9981s/50 iter), loss = 0.0043454, remaining 0 hours and 0 minutes
I0108 20:46:40.798514  2043 solver.cpp:291]     Train net output #0: loss = 0.00434553 (* 1 = 0.00434553 loss)
I0108 20:46:40.798522  2043 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0108 20:46:53.783407  2043 solver.cpp:270] Iteration 11900 (3.85077 iter/s, 12.9844s/50 iter), loss = 0.0116569, remaining 0 hours and 0 minutes
I0108 20:46:53.783453  2043 solver.cpp:291]     Train net output #0: loss = 0.011657 (* 1 = 0.011657 loss)
I0108 20:46:53.783461  2043 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0108 20:47:06.765123  2043 solver.cpp:270] Iteration 11950 (3.85173 iter/s, 12.9812s/50 iter), loss = 0.00456519, remaining 0 hours and 0 minutes
I0108 20:47:06.765156  2043 solver.cpp:291]     Train net output #0: loss = 0.00456532 (* 1 = 0.00456532 loss)
I0108 20:47:06.765163  2043 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0108 20:47:19.486078  2043 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0/snapshots/_iter_12000.caffemodel
I0108 20:47:21.904224  2043 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0/snapshots/_iter_12000.solverstate
I0108 20:47:22.217679  2043 solver.cpp:384] Iteration 12000, loss = 0.00345507
I0108 20:47:22.217705  2043 solver.cpp:424] Iteration 12000, Testing net (#0)
I0108 20:47:23.687584  2043 solver.cpp:523]     Test net output #0: accuracy = 0.9455
I0108 20:47:23.687611  2043 solver.cpp:523]     Test net output #1: loss = 0.2473 (* 1 = 0.2473 loss)
I0108 20:47:23.687616  2043 solver.cpp:523]     Test net output #2: top-1 = 0.9455
I0108 20:47:23.687621  2043 solver.cpp:392] Optimization Done (3.83939 iter/s).
I0108 20:47:23.687625  2043 caffe_interface.cpp:546] Optimization Done.
(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

I0108 20:47:24.379884  2140 pruning_runner.cpp:206] Analysis info found.
I0108 20:47:25.926096  2140 pruning_runner.cpp:237] Start pruning, please wait...
I0108 20:47:34.818562  2140 pruning_runner.cpp:337] pruning done, output model: pruning/alexnetBNnoLRN/regular_rate_0.1/sparse.caffemodel
I0108 20:47:34.818589  2140 pruning_runner.cpp:351] summary of REGULAR compression with rate 0.1:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.943749785    | 0.944999695    | 0.0012499094   |
+-------------------------------------------------------------------+
| Weights        | 3.7649951 M    | 1.037413 M     | -72.4458313%   |
+-------------------------------------------------------------------+
| Operations     | 2.1539185 G    | 1.23211837 G   | -42.7964211%   |
+-------------------------------------------------------------------+
To fine-tune the pruned model, please run:
vai_p_caffe finetune -config /workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/config1.prototxt
(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

W0108 20:47:34.969024  2295 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0108 20:47:34.969220  2295 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0108 20:47:34.969238  2295 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0108 20:47:34.973423  2295 vai_p_caffe.cpp:287] pruning/alexnetBNnoLRN/regular_rate_0.1/net_finetune.prototxt
I0108 20:47:35.133211  2295 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0108 20:47:35.133234  2295 gpu_memory.cpp:55] Total memory: 25620447232, Free: 25022103552, dev_info[0]: total=25620447232 free=25022103552
I0108 20:47:35.134016  2295 caffe_interface.cpp:509] Using GPUs 0
I0108 20:47:35.134270  2295 caffe_interface.cpp:514] GPU 0: Quadro P6000
I0108 20:47:36.004458  2295 solver.cpp:51] Initializing solver from parameters:
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 6000
snapshot_prefix: "pruning/alexnetBNnoLRN/regular_rate_0.1/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "pruning/alexnetBNnoLRN/regular_rate_0.1/net_finetune.prototxt"
type: "Adam"
I0108 20:47:36.004619  2295 solver.cpp:99] Creating training net from net file: pruning/alexnetBNnoLRN/regular_rate_0.1/net_finetune.prototxt
I0108 20:47:36.004905  2295 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0108 20:47:36.004920  2295 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0108 20:47:36.004922  2295 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0108 20:47:36.004926  2295 net.cpp:52] Initializing net from parameters:
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0108 20:47:36.005146  2295 layer_factory.hpp:77] Creating layer data
I0108 20:47:36.005300  2295 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 20:47:36.006914  2295 net.cpp:94] Creating Layer data
I0108 20:47:36.006928  2295 net.cpp:409] data -> data
I0108 20:47:36.006938  2295 net.cpp:409] data -> label
I0108 20:47:36.008183  2332 db_lmdb.cpp:35] Opened lmdb input/lmdb/train_lmdb
I0108 20:47:36.008205  2332 db_lmdb.cpp:38] Items count: 20000
I0108 20:47:36.008225  2332 data_reader.cpp:124] TRAIN: reading data using 1 channel(s)
I0108 20:47:36.008535  2295 data_layer.cpp:78] ReshapePrefetch 256, 3, 227, 227
I0108 20:47:36.008649  2295 data_layer.cpp:83] output data size: 256,3,227,227
I0108 20:47:36.479876  2295 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 20:47:36.479972  2295 net.cpp:144] Setting up data
I0108 20:47:36.479977  2295 net.cpp:151] Top shape: 256 3 227 227 (39574272)
I0108 20:47:36.479985  2295 net.cpp:151] Top shape: 256 (256)
I0108 20:47:36.479990  2295 net.cpp:159] Memory required for data: 158298112
I0108 20:47:36.480010  2295 layer_factory.hpp:77] Creating layer conv1
I0108 20:47:36.480021  2295 net.cpp:94] Creating Layer conv1
I0108 20:47:36.480032  2295 net.cpp:435] conv1 <- data
I0108 20:47:36.480038  2295 net.cpp:409] conv1 -> conv1
I0108 20:47:36.480628  2295 net.cpp:144] Setting up conv1
I0108 20:47:36.480633  2295 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0108 20:47:36.480638  2295 net.cpp:159] Memory required for data: 455667712
I0108 20:47:36.480649  2295 layer_factory.hpp:77] Creating layer bn1
I0108 20:47:36.480656  2295 net.cpp:94] Creating Layer bn1
I0108 20:47:36.480660  2295 net.cpp:435] bn1 <- conv1
I0108 20:47:36.480664  2295 net.cpp:409] bn1 -> bn1
I0108 20:47:36.481186  2295 net.cpp:144] Setting up bn1
I0108 20:47:36.481190  2295 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0108 20:47:36.481195  2295 net.cpp:159] Memory required for data: 753037312
I0108 20:47:36.481204  2295 layer_factory.hpp:77] Creating layer relu1
I0108 20:47:36.481210  2295 net.cpp:94] Creating Layer relu1
I0108 20:47:36.481215  2295 net.cpp:435] relu1 <- bn1
I0108 20:47:36.481218  2295 net.cpp:409] relu1 -> relu1
I0108 20:47:36.481238  2295 net.cpp:144] Setting up relu1
I0108 20:47:36.481242  2295 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0108 20:47:36.481246  2295 net.cpp:159] Memory required for data: 1050406912
I0108 20:47:36.481249  2295 layer_factory.hpp:77] Creating layer pool1
I0108 20:47:36.481254  2295 net.cpp:94] Creating Layer pool1
I0108 20:47:36.481258  2295 net.cpp:435] pool1 <- relu1
I0108 20:47:36.481263  2295 net.cpp:409] pool1 -> pool1
I0108 20:47:36.481287  2295 net.cpp:144] Setting up pool1
I0108 20:47:36.481289  2295 net.cpp:151] Top shape: 256 96 27 27 (17915904)
I0108 20:47:36.481293  2295 net.cpp:159] Memory required for data: 1122070528
I0108 20:47:36.481297  2295 layer_factory.hpp:77] Creating layer conv2
I0108 20:47:36.481303  2295 net.cpp:94] Creating Layer conv2
I0108 20:47:36.481307  2295 net.cpp:435] conv2 <- pool1
I0108 20:47:36.481312  2295 net.cpp:409] conv2 -> conv2
I0108 20:47:36.496717  2295 net.cpp:144] Setting up conv2
I0108 20:47:36.496732  2295 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0108 20:47:36.496740  2295 net.cpp:159] Memory required for data: 1313173504
I0108 20:47:36.496752  2295 layer_factory.hpp:77] Creating layer bn2
I0108 20:47:36.496760  2295 net.cpp:94] Creating Layer bn2
I0108 20:47:36.496764  2295 net.cpp:435] bn2 <- conv2
I0108 20:47:36.496770  2295 net.cpp:409] bn2 -> bn2
I0108 20:47:36.497376  2295 net.cpp:144] Setting up bn2
I0108 20:47:36.497385  2295 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0108 20:47:36.497390  2295 net.cpp:159] Memory required for data: 1504276480
I0108 20:47:36.497400  2295 layer_factory.hpp:77] Creating layer relu2
I0108 20:47:36.497406  2295 net.cpp:94] Creating Layer relu2
I0108 20:47:36.497411  2295 net.cpp:435] relu2 <- bn2
I0108 20:47:36.497416  2295 net.cpp:409] relu2 -> relu2
I0108 20:47:36.497526  2295 net.cpp:144] Setting up relu2
I0108 20:47:36.497550  2295 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0108 20:47:36.497578  2295 net.cpp:159] Memory required for data: 1695379456
I0108 20:47:36.497606  2295 layer_factory.hpp:77] Creating layer pool2
I0108 20:47:36.497623  2295 net.cpp:94] Creating Layer pool2
I0108 20:47:36.497637  2295 net.cpp:435] pool2 <- relu2
I0108 20:47:36.497661  2295 net.cpp:409] pool2 -> pool2
I0108 20:47:36.497745  2295 net.cpp:144] Setting up pool2
I0108 20:47:36.497756  2295 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0108 20:47:36.497773  2295 net.cpp:159] Memory required for data: 1739681792
I0108 20:47:36.497784  2295 layer_factory.hpp:77] Creating layer conv3
I0108 20:47:36.497834  2295 net.cpp:94] Creating Layer conv3
I0108 20:47:36.497848  2295 net.cpp:435] conv3 <- pool2
I0108 20:47:36.497866  2295 net.cpp:409] conv3 -> conv3
I0108 20:47:36.521360  2295 net.cpp:144] Setting up conv3
I0108 20:47:36.521385  2295 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 20:47:36.521400  2295 net.cpp:159] Memory required for data: 1806135296
I0108 20:47:36.521417  2295 layer_factory.hpp:77] Creating layer relu3
I0108 20:47:36.521435  2295 net.cpp:94] Creating Layer relu3
I0108 20:47:36.521445  2295 net.cpp:435] relu3 <- conv3
I0108 20:47:36.521457  2295 net.cpp:409] relu3 -> relu3
I0108 20:47:36.521497  2295 net.cpp:144] Setting up relu3
I0108 20:47:36.521504  2295 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 20:47:36.521514  2295 net.cpp:159] Memory required for data: 1872588800
I0108 20:47:36.521525  2295 layer_factory.hpp:77] Creating layer conv4
I0108 20:47:36.521545  2295 net.cpp:94] Creating Layer conv4
I0108 20:47:36.521553  2295 net.cpp:435] conv4 <- relu3
I0108 20:47:36.521564  2295 net.cpp:409] conv4 -> conv4
I0108 20:47:36.542352  2295 net.cpp:144] Setting up conv4
I0108 20:47:36.542373  2295 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 20:47:36.542384  2295 net.cpp:159] Memory required for data: 1939042304
I0108 20:47:36.542402  2295 layer_factory.hpp:77] Creating layer relu4
I0108 20:47:36.542415  2295 net.cpp:94] Creating Layer relu4
I0108 20:47:36.542423  2295 net.cpp:435] relu4 <- conv4
I0108 20:47:36.542435  2295 net.cpp:409] relu4 -> relu4
I0108 20:47:36.542470  2295 net.cpp:144] Setting up relu4
I0108 20:47:36.542496  2295 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 20:47:36.542507  2295 net.cpp:159] Memory required for data: 2005495808
I0108 20:47:36.542515  2295 layer_factory.hpp:77] Creating layer conv5
I0108 20:47:36.542538  2295 net.cpp:94] Creating Layer conv5
I0108 20:47:36.542551  2295 net.cpp:435] conv5 <- relu4
I0108 20:47:36.542563  2295 net.cpp:409] conv5 -> conv5
I0108 20:47:36.553103  2295 net.cpp:144] Setting up conv5
I0108 20:47:36.553128  2295 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0108 20:47:36.553140  2295 net.cpp:159] Memory required for data: 2049798144
I0108 20:47:36.553154  2295 layer_factory.hpp:77] Creating layer relu5
I0108 20:47:36.553170  2295 net.cpp:94] Creating Layer relu5
I0108 20:47:36.553179  2295 net.cpp:435] relu5 <- conv5
I0108 20:47:36.553192  2295 net.cpp:409] relu5 -> relu5
I0108 20:47:36.553269  2295 net.cpp:144] Setting up relu5
I0108 20:47:36.553297  2295 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0108 20:47:36.553323  2295 net.cpp:159] Memory required for data: 2094100480
I0108 20:47:36.553351  2295 layer_factory.hpp:77] Creating layer pool5
I0108 20:47:36.553380  2295 net.cpp:94] Creating Layer pool5
I0108 20:47:36.553409  2295 net.cpp:435] pool5 <- relu5
I0108 20:47:36.553436  2295 net.cpp:409] pool5 -> pool5
I0108 20:47:36.553517  2295 net.cpp:144] Setting up pool5
I0108 20:47:36.553542  2295 net.cpp:151] Top shape: 256 256 6 6 (2359296)
I0108 20:47:36.553567  2295 net.cpp:159] Memory required for data: 2103537664
I0108 20:47:36.553589  2295 layer_factory.hpp:77] Creating layer fc6
I0108 20:47:36.553619  2295 net.cpp:94] Creating Layer fc6
I0108 20:47:36.553642  2295 net.cpp:435] fc6 <- pool5
I0108 20:47:36.553673  2295 net.cpp:409] fc6 -> fc6
I0108 20:47:36.913470  2295 net.cpp:144] Setting up fc6
I0108 20:47:36.913509  2295 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 20:47:36.913525  2295 net.cpp:159] Memory required for data: 2107731968
I0108 20:47:36.913542  2295 layer_factory.hpp:77] Creating layer relu6
I0108 20:47:36.913555  2295 net.cpp:94] Creating Layer relu6
I0108 20:47:36.913574  2295 net.cpp:435] relu6 <- fc6
I0108 20:47:36.913586  2295 net.cpp:409] relu6 -> relu6
I0108 20:47:36.913625  2295 net.cpp:144] Setting up relu6
I0108 20:47:36.913633  2295 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 20:47:36.913640  2295 net.cpp:159] Memory required for data: 2111926272
I0108 20:47:36.913648  2295 layer_factory.hpp:77] Creating layer drop6
I0108 20:47:36.913661  2295 net.cpp:94] Creating Layer drop6
I0108 20:47:36.913684  2295 net.cpp:435] drop6 <- relu6
I0108 20:47:36.913691  2295 net.cpp:409] drop6 -> drop6
I0108 20:47:36.913727  2295 net.cpp:144] Setting up drop6
I0108 20:47:36.913733  2295 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 20:47:36.913740  2295 net.cpp:159] Memory required for data: 2116120576
I0108 20:47:36.913744  2295 layer_factory.hpp:77] Creating layer fc7
I0108 20:47:36.913753  2295 net.cpp:94] Creating Layer fc7
I0108 20:47:36.913758  2295 net.cpp:435] fc7 <- drop6
I0108 20:47:36.913765  2295 net.cpp:409] fc7 -> fc7
I0108 20:47:37.066435  2295 net.cpp:144] Setting up fc7
I0108 20:47:37.066462  2295 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 20:47:37.066473  2295 net.cpp:159] Memory required for data: 2120314880
I0108 20:47:37.066485  2295 layer_factory.hpp:77] Creating layer bn7
I0108 20:47:37.066499  2295 net.cpp:94] Creating Layer bn7
I0108 20:47:37.066506  2295 net.cpp:435] bn7 <- fc7
I0108 20:47:37.066515  2295 net.cpp:409] bn7 -> bn7
I0108 20:47:37.067018  2295 net.cpp:144] Setting up bn7
I0108 20:47:37.067029  2295 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 20:47:37.067039  2295 net.cpp:159] Memory required for data: 2124509184
I0108 20:47:37.067052  2295 layer_factory.hpp:77] Creating layer relu7
I0108 20:47:37.067065  2295 net.cpp:94] Creating Layer relu7
I0108 20:47:37.067070  2295 net.cpp:435] relu7 <- bn7
I0108 20:47:37.067077  2295 net.cpp:409] relu7 -> relu7
I0108 20:47:37.067112  2295 net.cpp:144] Setting up relu7
I0108 20:47:37.067119  2295 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 20:47:37.067123  2295 net.cpp:159] Memory required for data: 2128703488
I0108 20:47:37.067126  2295 layer_factory.hpp:77] Creating layer drop7
I0108 20:47:37.067131  2295 net.cpp:94] Creating Layer drop7
I0108 20:47:37.067135  2295 net.cpp:435] drop7 <- relu7
I0108 20:47:37.067139  2295 net.cpp:409] drop7 -> drop7
I0108 20:47:37.067160  2295 net.cpp:144] Setting up drop7
I0108 20:47:37.067165  2295 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 20:47:37.067171  2295 net.cpp:159] Memory required for data: 2132897792
I0108 20:47:37.067175  2295 layer_factory.hpp:77] Creating layer fc8
I0108 20:47:37.067183  2295 net.cpp:94] Creating Layer fc8
I0108 20:47:37.067186  2295 net.cpp:435] fc8 <- drop7
I0108 20:47:37.067191  2295 net.cpp:409] fc8 -> fc8
I0108 20:47:37.067373  2295 net.cpp:144] Setting up fc8
I0108 20:47:37.067379  2295 net.cpp:151] Top shape: 256 2 (512)
I0108 20:47:37.067384  2295 net.cpp:159] Memory required for data: 2132899840
I0108 20:47:37.067390  2295 layer_factory.hpp:77] Creating layer loss
I0108 20:47:37.067399  2295 net.cpp:94] Creating Layer loss
I0108 20:47:37.067407  2295 net.cpp:435] loss <- fc8
I0108 20:47:37.067414  2295 net.cpp:435] loss <- label
I0108 20:47:37.067420  2295 net.cpp:409] loss -> loss
I0108 20:47:37.067430  2295 layer_factory.hpp:77] Creating layer loss
I0108 20:47:37.067502  2295 net.cpp:144] Setting up loss
I0108 20:47:37.067510  2295 net.cpp:151] Top shape: (1)
I0108 20:47:37.067517  2295 net.cpp:154]     with loss weight 1
I0108 20:47:37.067535  2295 net.cpp:159] Memory required for data: 2132899844
I0108 20:47:37.067540  2295 net.cpp:220] loss needs backward computation.
I0108 20:47:37.067546  2295 net.cpp:220] fc8 needs backward computation.
I0108 20:47:37.067553  2295 net.cpp:220] drop7 needs backward computation.
I0108 20:47:37.067557  2295 net.cpp:220] relu7 needs backward computation.
I0108 20:47:37.067561  2295 net.cpp:220] bn7 needs backward computation.
I0108 20:47:37.067564  2295 net.cpp:220] fc7 needs backward computation.
I0108 20:47:37.067569  2295 net.cpp:220] drop6 needs backward computation.
I0108 20:47:37.067572  2295 net.cpp:220] relu6 needs backward computation.
I0108 20:47:37.067576  2295 net.cpp:220] fc6 needs backward computation.
I0108 20:47:37.067579  2295 net.cpp:220] pool5 needs backward computation.
I0108 20:47:37.067584  2295 net.cpp:220] relu5 needs backward computation.
I0108 20:47:37.067587  2295 net.cpp:220] conv5 needs backward computation.
I0108 20:47:37.067591  2295 net.cpp:220] relu4 needs backward computation.
I0108 20:47:37.067605  2295 net.cpp:220] conv4 needs backward computation.
I0108 20:47:37.067610  2295 net.cpp:220] relu3 needs backward computation.
I0108 20:47:37.067612  2295 net.cpp:220] conv3 needs backward computation.
I0108 20:47:37.067616  2295 net.cpp:220] pool2 needs backward computation.
I0108 20:47:37.067620  2295 net.cpp:220] relu2 needs backward computation.
I0108 20:47:37.067625  2295 net.cpp:220] bn2 needs backward computation.
I0108 20:47:37.067628  2295 net.cpp:220] conv2 needs backward computation.
I0108 20:47:37.067631  2295 net.cpp:220] pool1 needs backward computation.
I0108 20:47:37.067636  2295 net.cpp:220] relu1 needs backward computation.
I0108 20:47:37.067639  2295 net.cpp:220] bn1 needs backward computation.
I0108 20:47:37.067642  2295 net.cpp:220] conv1 needs backward computation.
I0108 20:47:37.067646  2295 net.cpp:222] data does not need backward computation.
I0108 20:47:37.067651  2295 net.cpp:264] This network produces output loss
I0108 20:47:37.067672  2295 net.cpp:284] Network initialization done.
I0108 20:47:37.068065  2295 solver.cpp:189] Creating test net (#0) specified by net file: pruning/alexnetBNnoLRN/regular_rate_0.1/net_finetune.prototxt
I0108 20:47:37.068100  2295 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0108 20:47:37.068116  2295 net.cpp:52] Initializing net from parameters:
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0108 20:47:37.068387  2295 layer_factory.hpp:77] Creating layer data
I0108 20:47:37.068440  2295 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 20:47:37.070138  2295 net.cpp:94] Creating Layer data
I0108 20:47:37.070149  2295 net.cpp:409] data -> data
I0108 20:47:37.070158  2295 net.cpp:409] data -> label
I0108 20:47:37.071768  2362 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0108 20:47:37.071790  2362 db_lmdb.cpp:38] Items count: 4000
I0108 20:47:37.071812  2362 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0108 20:47:37.072124  2295 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0108 20:47:37.072218  2295 data_layer.cpp:83] output data size: 50,3,227,227
I0108 20:47:37.172679  2295 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 20:47:37.172801  2295 net.cpp:144] Setting up data
I0108 20:47:37.172807  2295 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0108 20:47:37.172814  2295 net.cpp:151] Top shape: 50 (50)
I0108 20:47:37.172819  2295 net.cpp:159] Memory required for data: 30917600
I0108 20:47:37.172824  2295 layer_factory.hpp:77] Creating layer label_data_1_split
I0108 20:47:37.172832  2295 net.cpp:94] Creating Layer label_data_1_split
I0108 20:47:37.172837  2295 net.cpp:435] label_data_1_split <- label
I0108 20:47:37.172842  2295 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0108 20:47:37.172850  2295 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0108 20:47:37.172855  2295 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0108 20:47:37.172909  2295 net.cpp:144] Setting up label_data_1_split
I0108 20:47:37.172914  2295 net.cpp:151] Top shape: 50 (50)
I0108 20:47:37.172917  2295 net.cpp:151] Top shape: 50 (50)
I0108 20:47:37.172920  2295 net.cpp:151] Top shape: 50 (50)
I0108 20:47:37.172924  2295 net.cpp:159] Memory required for data: 30918200
I0108 20:47:37.172926  2295 layer_factory.hpp:77] Creating layer conv1
I0108 20:47:37.172936  2295 net.cpp:94] Creating Layer conv1
I0108 20:47:37.172940  2295 net.cpp:435] conv1 <- data
I0108 20:47:37.172945  2295 net.cpp:409] conv1 -> conv1
I0108 20:47:37.173593  2295 net.cpp:144] Setting up conv1
I0108 20:47:37.173602  2295 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0108 20:47:37.173609  2295 net.cpp:159] Memory required for data: 88998200
I0108 20:47:37.173619  2295 layer_factory.hpp:77] Creating layer bn1
I0108 20:47:37.173627  2295 net.cpp:94] Creating Layer bn1
I0108 20:47:37.173633  2295 net.cpp:435] bn1 <- conv1
I0108 20:47:37.173640  2295 net.cpp:409] bn1 -> bn1
I0108 20:47:37.174208  2295 net.cpp:144] Setting up bn1
I0108 20:47:37.174216  2295 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0108 20:47:37.174221  2295 net.cpp:159] Memory required for data: 147078200
I0108 20:47:37.174229  2295 layer_factory.hpp:77] Creating layer relu1
I0108 20:47:37.174237  2295 net.cpp:94] Creating Layer relu1
I0108 20:47:37.174240  2295 net.cpp:435] relu1 <- bn1
I0108 20:47:37.174244  2295 net.cpp:409] relu1 -> relu1
I0108 20:47:37.174266  2295 net.cpp:144] Setting up relu1
I0108 20:47:37.174273  2295 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0108 20:47:37.174276  2295 net.cpp:159] Memory required for data: 205158200
I0108 20:47:37.174280  2295 layer_factory.hpp:77] Creating layer pool1
I0108 20:47:37.174286  2295 net.cpp:94] Creating Layer pool1
I0108 20:47:37.174290  2295 net.cpp:435] pool1 <- relu1
I0108 20:47:37.174294  2295 net.cpp:409] pool1 -> pool1
I0108 20:47:37.174319  2295 net.cpp:144] Setting up pool1
I0108 20:47:37.174324  2295 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0108 20:47:37.174329  2295 net.cpp:159] Memory required for data: 219155000
I0108 20:47:37.174331  2295 layer_factory.hpp:77] Creating layer conv2
I0108 20:47:37.174340  2295 net.cpp:94] Creating Layer conv2
I0108 20:47:37.174345  2295 net.cpp:435] conv2 <- pool1
I0108 20:47:37.174350  2295 net.cpp:409] conv2 -> conv2
I0108 20:47:37.181193  2295 net.cpp:144] Setting up conv2
I0108 20:47:37.181210  2295 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0108 20:47:37.181218  2295 net.cpp:159] Memory required for data: 256479800
I0108 20:47:37.181229  2295 layer_factory.hpp:77] Creating layer bn2
I0108 20:47:37.181237  2295 net.cpp:94] Creating Layer bn2
I0108 20:47:37.181242  2295 net.cpp:435] bn2 <- conv2
I0108 20:47:37.181250  2295 net.cpp:409] bn2 -> bn2
I0108 20:47:37.181886  2295 net.cpp:144] Setting up bn2
I0108 20:47:37.181893  2295 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0108 20:47:37.181898  2295 net.cpp:159] Memory required for data: 293804600
I0108 20:47:37.181907  2295 layer_factory.hpp:77] Creating layer relu2
I0108 20:47:37.181913  2295 net.cpp:94] Creating Layer relu2
I0108 20:47:37.181916  2295 net.cpp:435] relu2 <- bn2
I0108 20:47:37.181922  2295 net.cpp:409] relu2 -> relu2
I0108 20:47:37.181941  2295 net.cpp:144] Setting up relu2
I0108 20:47:37.181957  2295 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0108 20:47:37.181962  2295 net.cpp:159] Memory required for data: 331129400
I0108 20:47:37.181967  2295 layer_factory.hpp:77] Creating layer pool2
I0108 20:47:37.181972  2295 net.cpp:94] Creating Layer pool2
I0108 20:47:37.181977  2295 net.cpp:435] pool2 <- relu2
I0108 20:47:37.181980  2295 net.cpp:409] pool2 -> pool2
I0108 20:47:37.182005  2295 net.cpp:144] Setting up pool2
I0108 20:47:37.182011  2295 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0108 20:47:37.182018  2295 net.cpp:159] Memory required for data: 339782200
I0108 20:47:37.182020  2295 layer_factory.hpp:77] Creating layer conv3
I0108 20:47:37.182029  2295 net.cpp:94] Creating Layer conv3
I0108 20:47:37.182034  2295 net.cpp:435] conv3 <- pool2
I0108 20:47:37.182039  2295 net.cpp:409] conv3 -> conv3
I0108 20:47:37.202915  2295 net.cpp:144] Setting up conv3
I0108 20:47:37.202939  2295 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 20:47:37.202948  2295 net.cpp:159] Memory required for data: 352761400
I0108 20:47:37.202960  2295 layer_factory.hpp:77] Creating layer relu3
I0108 20:47:37.202968  2295 net.cpp:94] Creating Layer relu3
I0108 20:47:37.202973  2295 net.cpp:435] relu3 <- conv3
I0108 20:47:37.202981  2295 net.cpp:409] relu3 -> relu3
I0108 20:47:37.203013  2295 net.cpp:144] Setting up relu3
I0108 20:47:37.203020  2295 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 20:47:37.203027  2295 net.cpp:159] Memory required for data: 365740600
I0108 20:47:37.203032  2295 layer_factory.hpp:77] Creating layer conv4
I0108 20:47:37.203043  2295 net.cpp:94] Creating Layer conv4
I0108 20:47:37.203050  2295 net.cpp:435] conv4 <- relu3
I0108 20:47:37.203058  2295 net.cpp:409] conv4 -> conv4
I0108 20:47:37.221069  2295 net.cpp:144] Setting up conv4
I0108 20:47:37.221089  2295 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 20:47:37.221096  2295 net.cpp:159] Memory required for data: 378719800
I0108 20:47:37.221107  2295 layer_factory.hpp:77] Creating layer relu4
I0108 20:47:37.221114  2295 net.cpp:94] Creating Layer relu4
I0108 20:47:37.221118  2295 net.cpp:435] relu4 <- conv4
I0108 20:47:37.221123  2295 net.cpp:409] relu4 -> relu4
I0108 20:47:37.221146  2295 net.cpp:144] Setting up relu4
I0108 20:47:37.221150  2295 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 20:47:37.221154  2295 net.cpp:159] Memory required for data: 391699000
I0108 20:47:37.221156  2295 layer_factory.hpp:77] Creating layer conv5
I0108 20:47:37.221164  2295 net.cpp:94] Creating Layer conv5
I0108 20:47:37.221168  2295 net.cpp:435] conv5 <- relu4
I0108 20:47:37.221171  2295 net.cpp:409] conv5 -> conv5
I0108 20:47:37.234450  2295 net.cpp:144] Setting up conv5
I0108 20:47:37.234491  2295 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0108 20:47:37.234501  2295 net.cpp:159] Memory required for data: 400351800
I0108 20:47:37.234514  2295 layer_factory.hpp:77] Creating layer relu5
I0108 20:47:37.234540  2295 net.cpp:94] Creating Layer relu5
I0108 20:47:37.234547  2295 net.cpp:435] relu5 <- conv5
I0108 20:47:37.234556  2295 net.cpp:409] relu5 -> relu5
I0108 20:47:37.234591  2295 net.cpp:144] Setting up relu5
I0108 20:47:37.234598  2295 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0108 20:47:37.234606  2295 net.cpp:159] Memory required for data: 409004600
I0108 20:47:37.234611  2295 layer_factory.hpp:77] Creating layer pool5
I0108 20:47:37.234624  2295 net.cpp:94] Creating Layer pool5
I0108 20:47:37.234637  2295 net.cpp:435] pool5 <- relu5
I0108 20:47:37.234644  2295 net.cpp:409] pool5 -> pool5
I0108 20:47:37.234681  2295 net.cpp:144] Setting up pool5
I0108 20:47:37.234716  2295 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0108 20:47:37.234745  2295 net.cpp:159] Memory required for data: 410847800
I0108 20:47:37.234767  2295 layer_factory.hpp:77] Creating layer fc6
I0108 20:47:37.234793  2295 net.cpp:94] Creating Layer fc6
I0108 20:47:37.234820  2295 net.cpp:435] fc6 <- pool5
I0108 20:47:37.234845  2295 net.cpp:409] fc6 -> fc6
I0108 20:47:37.575382  2295 net.cpp:144] Setting up fc6
I0108 20:47:37.575407  2295 net.cpp:151] Top shape: 50 4096 (204800)
I0108 20:47:37.575433  2295 net.cpp:159] Memory required for data: 411667000
I0108 20:47:37.575443  2295 layer_factory.hpp:77] Creating layer relu6
I0108 20:47:37.575448  2295 net.cpp:94] Creating Layer relu6
I0108 20:47:37.575453  2295 net.cpp:435] relu6 <- fc6
I0108 20:47:37.575460  2295 net.cpp:409] relu6 -> relu6
I0108 20:47:37.575487  2295 net.cpp:144] Setting up relu6
I0108 20:47:37.575490  2295 net.cpp:151] Top shape: 50 4096 (204800)
I0108 20:47:37.575510  2295 net.cpp:159] Memory required for data: 412486200
I0108 20:47:37.575513  2295 layer_factory.hpp:77] Creating layer drop6
I0108 20:47:37.575518  2295 net.cpp:94] Creating Layer drop6
I0108 20:47:37.575522  2295 net.cpp:435] drop6 <- relu6
I0108 20:47:37.575525  2295 net.cpp:409] drop6 -> drop6
I0108 20:47:37.575547  2295 net.cpp:144] Setting up drop6
I0108 20:47:37.575553  2295 net.cpp:151] Top shape: 50 4096 (204800)
I0108 20:47:37.575556  2295 net.cpp:159] Memory required for data: 413305400
I0108 20:47:37.575559  2295 layer_factory.hpp:77] Creating layer fc7
I0108 20:47:37.575567  2295 net.cpp:94] Creating Layer fc7
I0108 20:47:37.575569  2295 net.cpp:435] fc7 <- drop6
I0108 20:47:37.575574  2295 net.cpp:409] fc7 -> fc7
I0108 20:47:37.725078  2295 net.cpp:144] Setting up fc7
I0108 20:47:37.725103  2295 net.cpp:151] Top shape: 50 4096 (204800)
I0108 20:47:37.725111  2295 net.cpp:159] Memory required for data: 414124600
I0108 20:47:37.725121  2295 layer_factory.hpp:77] Creating layer bn7
I0108 20:47:37.725129  2295 net.cpp:94] Creating Layer bn7
I0108 20:47:37.725133  2295 net.cpp:435] bn7 <- fc7
I0108 20:47:37.725139  2295 net.cpp:409] bn7 -> bn7
I0108 20:47:37.725641  2295 net.cpp:144] Setting up bn7
I0108 20:47:37.725648  2295 net.cpp:151] Top shape: 50 4096 (204800)
I0108 20:47:37.725653  2295 net.cpp:159] Memory required for data: 414943800
I0108 20:47:37.725661  2295 layer_factory.hpp:77] Creating layer relu7
I0108 20:47:37.725666  2295 net.cpp:94] Creating Layer relu7
I0108 20:47:37.725669  2295 net.cpp:435] relu7 <- bn7
I0108 20:47:37.725674  2295 net.cpp:409] relu7 -> relu7
I0108 20:47:37.725692  2295 net.cpp:144] Setting up relu7
I0108 20:47:37.725697  2295 net.cpp:151] Top shape: 50 4096 (204800)
I0108 20:47:37.725701  2295 net.cpp:159] Memory required for data: 415763000
I0108 20:47:37.725704  2295 layer_factory.hpp:77] Creating layer drop7
I0108 20:47:37.725709  2295 net.cpp:94] Creating Layer drop7
I0108 20:47:37.725714  2295 net.cpp:435] drop7 <- relu7
I0108 20:47:37.725718  2295 net.cpp:409] drop7 -> drop7
I0108 20:47:37.725744  2295 net.cpp:144] Setting up drop7
I0108 20:47:37.725749  2295 net.cpp:151] Top shape: 50 4096 (204800)
I0108 20:47:37.725754  2295 net.cpp:159] Memory required for data: 416582200
I0108 20:47:37.725756  2295 layer_factory.hpp:77] Creating layer fc8
I0108 20:47:37.725764  2295 net.cpp:94] Creating Layer fc8
I0108 20:47:37.725767  2295 net.cpp:435] fc8 <- drop7
I0108 20:47:37.725772  2295 net.cpp:409] fc8 -> fc8
I0108 20:47:37.725948  2295 net.cpp:144] Setting up fc8
I0108 20:47:37.725955  2295 net.cpp:151] Top shape: 50 2 (100)
I0108 20:47:37.725960  2295 net.cpp:159] Memory required for data: 416582600
I0108 20:47:37.725965  2295 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0108 20:47:37.725970  2295 net.cpp:94] Creating Layer fc8_fc8_0_split
I0108 20:47:37.725975  2295 net.cpp:435] fc8_fc8_0_split <- fc8
I0108 20:47:37.725980  2295 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0108 20:47:37.725986  2295 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0108 20:47:37.725992  2295 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0108 20:47:37.726025  2295 net.cpp:144] Setting up fc8_fc8_0_split
I0108 20:47:37.726030  2295 net.cpp:151] Top shape: 50 2 (100)
I0108 20:47:37.726035  2295 net.cpp:151] Top shape: 50 2 (100)
I0108 20:47:37.726039  2295 net.cpp:151] Top shape: 50 2 (100)
I0108 20:47:37.726043  2295 net.cpp:159] Memory required for data: 416583800
I0108 20:47:37.726047  2295 layer_factory.hpp:77] Creating layer accuracy
I0108 20:47:37.726053  2295 net.cpp:94] Creating Layer accuracy
I0108 20:47:37.726068  2295 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0108 20:47:37.726073  2295 net.cpp:435] accuracy <- label_data_1_split_0
I0108 20:47:37.726079  2295 net.cpp:409] accuracy -> accuracy
I0108 20:47:37.726086  2295 net.cpp:144] Setting up accuracy
I0108 20:47:37.726090  2295 net.cpp:151] Top shape: (1)
I0108 20:47:37.726094  2295 net.cpp:159] Memory required for data: 416583804
I0108 20:47:37.726097  2295 layer_factory.hpp:77] Creating layer loss
I0108 20:47:37.726104  2295 net.cpp:94] Creating Layer loss
I0108 20:47:37.726106  2295 net.cpp:435] loss <- fc8_fc8_0_split_1
I0108 20:47:37.726110  2295 net.cpp:435] loss <- label_data_1_split_1
I0108 20:47:37.726115  2295 net.cpp:409] loss -> loss
I0108 20:47:37.726126  2295 layer_factory.hpp:77] Creating layer loss
I0108 20:47:37.726204  2295 net.cpp:144] Setting up loss
I0108 20:47:37.726210  2295 net.cpp:151] Top shape: (1)
I0108 20:47:37.726214  2295 net.cpp:154]     with loss weight 1
I0108 20:47:37.726227  2295 net.cpp:159] Memory required for data: 416583808
I0108 20:47:37.726230  2295 layer_factory.hpp:77] Creating layer accuracy-top1
I0108 20:47:37.726235  2295 net.cpp:94] Creating Layer accuracy-top1
I0108 20:47:37.726239  2295 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0108 20:47:37.726243  2295 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0108 20:47:37.726256  2295 net.cpp:409] accuracy-top1 -> top-1
I0108 20:47:37.726263  2295 net.cpp:144] Setting up accuracy-top1
I0108 20:47:37.726265  2295 net.cpp:151] Top shape: (1)
I0108 20:47:37.726269  2295 net.cpp:159] Memory required for data: 416583812
I0108 20:47:37.726274  2295 net.cpp:222] accuracy-top1 does not need backward computation.
I0108 20:47:37.726277  2295 net.cpp:220] loss needs backward computation.
I0108 20:47:37.726282  2295 net.cpp:222] accuracy does not need backward computation.
I0108 20:47:37.726286  2295 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0108 20:47:37.726291  2295 net.cpp:220] fc8 needs backward computation.
I0108 20:47:37.726295  2295 net.cpp:220] drop7 needs backward computation.
I0108 20:47:37.726300  2295 net.cpp:220] relu7 needs backward computation.
I0108 20:47:37.726302  2295 net.cpp:220] bn7 needs backward computation.
I0108 20:47:37.726306  2295 net.cpp:220] fc7 needs backward computation.
I0108 20:47:37.726310  2295 net.cpp:220] drop6 needs backward computation.
I0108 20:47:37.726315  2295 net.cpp:220] relu6 needs backward computation.
I0108 20:47:37.726318  2295 net.cpp:220] fc6 needs backward computation.
I0108 20:47:37.726322  2295 net.cpp:220] pool5 needs backward computation.
I0108 20:47:37.726325  2295 net.cpp:220] relu5 needs backward computation.
I0108 20:47:37.726330  2295 net.cpp:220] conv5 needs backward computation.
I0108 20:47:37.726333  2295 net.cpp:220] relu4 needs backward computation.
I0108 20:47:37.726337  2295 net.cpp:220] conv4 needs backward computation.
I0108 20:47:37.726341  2295 net.cpp:220] relu3 needs backward computation.
I0108 20:47:37.726346  2295 net.cpp:220] conv3 needs backward computation.
I0108 20:47:37.726349  2295 net.cpp:220] pool2 needs backward computation.
I0108 20:47:37.726353  2295 net.cpp:220] relu2 needs backward computation.
I0108 20:47:37.726357  2295 net.cpp:220] bn2 needs backward computation.
I0108 20:47:37.726361  2295 net.cpp:220] conv2 needs backward computation.
I0108 20:47:37.726364  2295 net.cpp:220] pool1 needs backward computation.
I0108 20:47:37.726368  2295 net.cpp:220] relu1 needs backward computation.
I0108 20:47:37.726372  2295 net.cpp:220] bn1 needs backward computation.
I0108 20:47:37.726377  2295 net.cpp:220] conv1 needs backward computation.
I0108 20:47:37.726380  2295 net.cpp:222] label_data_1_split does not need backward computation.
I0108 20:47:37.726387  2295 net.cpp:222] data does not need backward computation.
I0108 20:47:37.726389  2295 net.cpp:264] This network produces output accuracy
I0108 20:47:37.726393  2295 net.cpp:264] This network produces output loss
I0108 20:47:37.726397  2295 net.cpp:264] This network produces output top-1
I0108 20:47:37.726430  2295 net.cpp:284] Network initialization done.
I0108 20:47:37.726500  2295 solver.cpp:63] Solver scaffolding done.
I0108 20:47:37.727623  2295 caffe_interface.cpp:109] Finetuning from pruning/alexnetBNnoLRN/regular_rate_0.1/sparse.caffemodel
I0108 20:47:40.067250  2295 caffe_interface.cpp:543] Starting Optimization
I0108 20:47:40.067270  2295 solver.cpp:341] Solving
I0108 20:47:40.067274  2295 solver.cpp:342] Learning Rate Policy: step
I0108 20:47:40.068616  2295 solver.cpp:424] Iteration 0, Testing net (#0)
I0108 20:47:41.583072  2295 solver.cpp:523]     Test net output #0: accuracy = 0.945
I0108 20:47:41.583106  2295 solver.cpp:523]     Test net output #1: loss = 0.245337 (* 1 = 0.245337 loss)
I0108 20:47:41.583110  2295 solver.cpp:523]     Test net output #2: top-1 = 0.945
I0108 20:47:41.847016  2295 solver.cpp:270] Iteration 0 (0 iter/s, 1.77963s/50 iter), loss = 0.0156403, remaining 333333 hours and 20 minutes
I0108 20:47:41.847048  2295 solver.cpp:291]     Train net output #0: loss = 0.0156403 (* 1 = 0.0156403 loss)
I0108 20:47:41.847056  2295 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0108 20:47:54.651285  2295 solver.cpp:270] Iteration 50 (3.9051 iter/s, 12.8038s/50 iter), loss = 0.114728, remaining 0 hours and 50 minutes
I0108 20:47:54.651317  2295 solver.cpp:291]     Train net output #0: loss = 0.114728 (* 1 = 0.114728 loss)
I0108 20:47:54.651324  2295 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0108 20:48:07.485543  2295 solver.cpp:270] Iteration 100 (3.89598 iter/s, 12.8337s/50 iter), loss = 0.130346, remaining 0 hours and 50 minutes
I0108 20:48:07.485590  2295 solver.cpp:291]     Train net output #0: loss = 0.130346 (* 1 = 0.130346 loss)
I0108 20:48:07.485597  2295 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0108 20:48:20.319537  2295 solver.cpp:270] Iteration 150 (3.89606 iter/s, 12.8335s/50 iter), loss = 0.139638, remaining 0 hours and 50 minutes
I0108 20:48:20.319569  2295 solver.cpp:291]     Train net output #0: loss = 0.139638 (* 1 = 0.139638 loss)
I0108 20:48:20.319576  2295 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0108 20:48:33.164820  2295 solver.cpp:270] Iteration 200 (3.89263 iter/s, 12.8448s/50 iter), loss = 0.115144, remaining 0 hours and 50 minutes
I0108 20:48:33.164853  2295 solver.cpp:291]     Train net output #0: loss = 0.115144 (* 1 = 0.115144 loss)
I0108 20:48:33.164860  2295 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0108 20:48:46.061034  2295 solver.cpp:270] Iteration 250 (3.87726 iter/s, 12.8957s/50 iter), loss = 0.1032, remaining 0 hours and 50 minutes
I0108 20:48:46.061079  2295 solver.cpp:291]     Train net output #0: loss = 0.1032 (* 1 = 0.1032 loss)
I0108 20:48:46.061085  2295 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0108 20:48:59.015859  2295 solver.cpp:270] Iteration 300 (3.85972 iter/s, 12.9543s/50 iter), loss = 0.119718, remaining 0 hours and 50 minutes
I0108 20:48:59.015892  2295 solver.cpp:291]     Train net output #0: loss = 0.119718 (* 1 = 0.119718 loss)
I0108 20:48:59.015899  2295 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0108 20:49:12.023612  2295 solver.cpp:270] Iteration 350 (3.84401 iter/s, 13.0072s/50 iter), loss = 0.125505, remaining 0 hours and 50 minutes
I0108 20:49:12.023645  2295 solver.cpp:291]     Train net output #0: loss = 0.125505 (* 1 = 0.125505 loss)
I0108 20:49:12.023669  2295 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0108 20:49:25.019639  2295 solver.cpp:270] Iteration 400 (3.84748 iter/s, 12.9955s/50 iter), loss = 0.113571, remaining 0 hours and 50 minutes
I0108 20:49:25.019686  2295 solver.cpp:291]     Train net output #0: loss = 0.113571 (* 1 = 0.113571 loss)
I0108 20:49:25.019695  2295 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0108 20:49:38.045791  2295 solver.cpp:270] Iteration 450 (3.83859 iter/s, 13.0256s/50 iter), loss = 0.0949957, remaining 0 hours and 50 minutes
I0108 20:49:38.045825  2295 solver.cpp:291]     Train net output #0: loss = 0.0949957 (* 1 = 0.0949957 loss)
I0108 20:49:38.045830  2295 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0108 20:49:51.025399  2295 solver.cpp:270] Iteration 500 (3.85235 iter/s, 12.9791s/50 iter), loss = 0.0763173, remaining 0 hours and 49 minutes
I0108 20:49:51.025431  2295 solver.cpp:291]     Train net output #0: loss = 0.0763173 (* 1 = 0.0763173 loss)
I0108 20:49:51.025439  2295 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0108 20:50:04.028074  2295 solver.cpp:270] Iteration 550 (3.84552 iter/s, 13.0022s/50 iter), loss = 0.197649, remaining 0 hours and 49 minutes
I0108 20:50:04.028126  2295 solver.cpp:291]     Train net output #0: loss = 0.197649 (* 1 = 0.197649 loss)
I0108 20:50:04.028151  2295 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0108 20:50:17.020726  2295 solver.cpp:270] Iteration 600 (3.84849 iter/s, 12.9921s/50 iter), loss = 0.0537897, remaining 0 hours and 49 minutes
I0108 20:50:17.020759  2295 solver.cpp:291]     Train net output #0: loss = 0.0537897 (* 1 = 0.0537897 loss)
I0108 20:50:17.020766  2295 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0108 20:50:30.018615  2295 solver.cpp:270] Iteration 650 (3.84693 iter/s, 12.9974s/50 iter), loss = 0.166028, remaining 0 hours and 49 minutes
I0108 20:50:30.018647  2295 solver.cpp:291]     Train net output #0: loss = 0.166028 (* 1 = 0.166028 loss)
I0108 20:50:30.018654  2295 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0108 20:50:43.012959  2295 solver.cpp:270] Iteration 700 (3.84798 iter/s, 12.9938s/50 iter), loss = 0.114564, remaining 0 hours and 48 minutes
I0108 20:50:43.013003  2295 solver.cpp:291]     Train net output #0: loss = 0.114564 (* 1 = 0.114564 loss)
I0108 20:50:43.013010  2295 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0108 20:50:56.019018  2295 solver.cpp:270] Iteration 750 (3.84452 iter/s, 13.0055s/50 iter), loss = 0.128564, remaining 0 hours and 48 minutes
I0108 20:50:56.019050  2295 solver.cpp:291]     Train net output #0: loss = 0.128564 (* 1 = 0.128564 loss)
I0108 20:50:56.019057  2295 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0108 20:51:09.023072  2295 solver.cpp:270] Iteration 800 (3.84511 iter/s, 13.0035s/50 iter), loss = 0.112542, remaining 0 hours and 48 minutes
I0108 20:51:09.023103  2295 solver.cpp:291]     Train net output #0: loss = 0.112542 (* 1 = 0.112542 loss)
I0108 20:51:09.023110  2295 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0108 20:51:22.022636  2295 solver.cpp:270] Iteration 850 (3.84644 iter/s, 12.999s/50 iter), loss = 0.095714, remaining 0 hours and 48 minutes
I0108 20:51:22.022682  2295 solver.cpp:291]     Train net output #0: loss = 0.095714 (* 1 = 0.095714 loss)
I0108 20:51:22.022691  2295 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0108 20:51:35.029338  2295 solver.cpp:270] Iteration 900 (3.84433 iter/s, 13.0062s/50 iter), loss = 0.102076, remaining 0 hours and 48 minutes
I0108 20:51:35.029371  2295 solver.cpp:291]     Train net output #0: loss = 0.102076 (* 1 = 0.102076 loss)
I0108 20:51:35.029392  2295 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0108 20:51:48.017485  2295 solver.cpp:270] Iteration 950 (3.84982 iter/s, 12.9876s/50 iter), loss = 0.152113, remaining 0 hours and 47 minutes
I0108 20:51:48.017518  2295 solver.cpp:291]     Train net output #0: loss = 0.152113 (* 1 = 0.152113 loss)
I0108 20:51:48.017524  2295 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0108 20:52:00.766393  2295 solver.cpp:424] Iteration 1000, Testing net (#0)
I0108 20:52:02.329383  2295 solver.cpp:523]     Test net output #0: accuracy = 0.91275
I0108 20:52:02.329411  2295 solver.cpp:523]     Test net output #1: loss = 0.303296 (* 1 = 0.303296 loss)
I0108 20:52:02.329416  2295 solver.cpp:523]     Test net output #2: top-1 = 0.91275
I0108 20:52:02.585443  2295 solver.cpp:270] Iteration 1000 (3.43233 iter/s, 14.5674s/50 iter), loss = 0.0943246, remaining 0 hours and 53 minutes
I0108 20:52:02.585469  2295 solver.cpp:291]     Train net output #0: loss = 0.0943246 (* 1 = 0.0943246 loss)
I0108 20:52:02.585476  2295 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0108 20:52:15.584427  2295 solver.cpp:270] Iteration 1050 (3.84661 iter/s, 12.9985s/50 iter), loss = 0.110094, remaining 0 hours and 47 minutes
I0108 20:52:15.584458  2295 solver.cpp:291]     Train net output #0: loss = 0.110094 (* 1 = 0.110094 loss)
I0108 20:52:15.584481  2295 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0108 20:52:28.598207  2295 solver.cpp:270] Iteration 1100 (3.84223 iter/s, 13.0133s/50 iter), loss = 0.13228, remaining 0 hours and 47 minutes
I0108 20:52:28.598240  2295 solver.cpp:291]     Train net output #0: loss = 0.13228 (* 1 = 0.13228 loss)
I0108 20:52:28.598265  2295 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0108 20:52:41.579053  2295 solver.cpp:270] Iteration 1150 (3.85198 iter/s, 12.9803s/50 iter), loss = 0.178101, remaining 0 hours and 46 minutes
I0108 20:52:41.579111  2295 solver.cpp:291]     Train net output #0: loss = 0.178101 (* 1 = 0.178101 loss)
I0108 20:52:41.579119  2295 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0108 20:52:54.583739  2295 solver.cpp:270] Iteration 1200 (3.84493 iter/s, 13.0041s/50 iter), loss = 0.118875, remaining 0 hours and 46 minutes
I0108 20:52:54.583775  2295 solver.cpp:291]     Train net output #0: loss = 0.118875 (* 1 = 0.118875 loss)
I0108 20:52:54.583782  2295 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0108 20:53:07.579010  2295 solver.cpp:270] Iteration 1250 (3.84771 iter/s, 12.9948s/50 iter), loss = 0.112302, remaining 0 hours and 46 minutes
I0108 20:53:07.579043  2295 solver.cpp:291]     Train net output #0: loss = 0.112302 (* 1 = 0.112302 loss)
I0108 20:53:07.579051  2295 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0108 20:53:20.599807  2295 solver.cpp:270] Iteration 1300 (3.84016 iter/s, 13.0203s/50 iter), loss = 0.110924, remaining 0 hours and 46 minutes
I0108 20:53:20.599856  2295 solver.cpp:291]     Train net output #0: loss = 0.110924 (* 1 = 0.110924 loss)
I0108 20:53:20.599880  2295 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0108 20:53:33.582535  2295 solver.cpp:270] Iteration 1350 (3.85143 iter/s, 12.9822s/50 iter), loss = 0.118745, remaining 0 hours and 45 minutes
I0108 20:53:33.582566  2295 solver.cpp:291]     Train net output #0: loss = 0.118745 (* 1 = 0.118745 loss)
I0108 20:53:33.582572  2295 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0108 20:53:46.565740  2295 solver.cpp:270] Iteration 1400 (3.85128 iter/s, 12.9827s/50 iter), loss = 0.165889, remaining 0 hours and 45 minutes
I0108 20:53:46.565773  2295 solver.cpp:291]     Train net output #0: loss = 0.165889 (* 1 = 0.165889 loss)
I0108 20:53:46.565779  2295 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0108 20:53:59.561985  2295 solver.cpp:270] Iteration 1450 (3.84742 iter/s, 12.9957s/50 iter), loss = 0.109801, remaining 0 hours and 45 minutes
I0108 20:53:59.562033  2295 solver.cpp:291]     Train net output #0: loss = 0.109801 (* 1 = 0.109801 loss)
I0108 20:53:59.562041  2295 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0108 20:54:12.542685  2295 solver.cpp:270] Iteration 1500 (3.85203 iter/s, 12.9802s/50 iter), loss = 0.082074, remaining 0 hours and 45 minutes
I0108 20:54:12.542716  2295 solver.cpp:291]     Train net output #0: loss = 0.082074 (* 1 = 0.082074 loss)
I0108 20:54:12.542722  2295 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0108 20:54:25.514847  2295 solver.cpp:270] Iteration 1550 (3.85456 iter/s, 12.9716s/50 iter), loss = 0.0898768, remaining 0 hours and 45 minutes
I0108 20:54:25.514881  2295 solver.cpp:291]     Train net output #0: loss = 0.0898768 (* 1 = 0.0898768 loss)
I0108 20:54:25.514887  2295 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0108 20:54:38.503104  2295 solver.cpp:270] Iteration 1600 (3.84978 iter/s, 12.9877s/50 iter), loss = 0.126923, remaining 0 hours and 44 minutes
I0108 20:54:38.503160  2295 solver.cpp:291]     Train net output #0: loss = 0.126923 (* 1 = 0.126923 loss)
I0108 20:54:38.503168  2295 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0108 20:54:51.496587  2295 solver.cpp:270] Iteration 1650 (3.84824 iter/s, 12.9929s/50 iter), loss = 0.141125, remaining 0 hours and 44 minutes
I0108 20:54:51.496619  2295 solver.cpp:291]     Train net output #0: loss = 0.141125 (* 1 = 0.141125 loss)
I0108 20:54:51.496626  2295 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0108 20:55:04.486654  2295 solver.cpp:270] Iteration 1700 (3.84925 iter/s, 12.9895s/50 iter), loss = 0.106056, remaining 0 hours and 44 minutes
I0108 20:55:04.486685  2295 solver.cpp:291]     Train net output #0: loss = 0.106056 (* 1 = 0.106056 loss)
I0108 20:55:04.486707  2295 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0108 20:55:17.469276  2295 solver.cpp:270] Iteration 1750 (3.85145 iter/s, 12.9821s/50 iter), loss = 0.0877338, remaining 0 hours and 44 minutes
I0108 20:55:17.469327  2295 solver.cpp:291]     Train net output #0: loss = 0.0877338 (* 1 = 0.0877338 loss)
I0108 20:55:17.469336  2295 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0108 20:55:30.449920  2295 solver.cpp:270] Iteration 1800 (3.85205 iter/s, 12.9801s/50 iter), loss = 0.129338, remaining 0 hours and 44 minutes
I0108 20:55:30.449950  2295 solver.cpp:291]     Train net output #0: loss = 0.129338 (* 1 = 0.129338 loss)
I0108 20:55:30.449972  2295 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0108 20:55:43.396715  2295 solver.cpp:270] Iteration 1850 (3.86211 iter/s, 12.9463s/50 iter), loss = 0.0616459, remaining 0 hours and 43 minutes
I0108 20:55:43.396747  2295 solver.cpp:291]     Train net output #0: loss = 0.0616459 (* 1 = 0.0616459 loss)
I0108 20:55:43.396754  2295 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0108 20:55:56.399658  2295 solver.cpp:270] Iteration 1900 (3.84544 iter/s, 13.0024s/50 iter), loss = 0.0761921, remaining 0 hours and 43 minutes
I0108 20:55:56.399705  2295 solver.cpp:291]     Train net output #0: loss = 0.0761921 (* 1 = 0.0761921 loss)
I0108 20:55:56.399711  2295 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0108 20:56:09.359143  2295 solver.cpp:270] Iteration 1950 (3.85834 iter/s, 12.959s/50 iter), loss = 0.0868228, remaining 0 hours and 43 minutes
I0108 20:56:09.359175  2295 solver.cpp:291]     Train net output #0: loss = 0.0868228 (* 1 = 0.0868228 loss)
I0108 20:56:09.359198  2295 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0108 20:56:22.104573  2295 solver.cpp:424] Iteration 2000, Testing net (#0)
I0108 20:56:23.641249  2295 solver.cpp:523]     Test net output #0: accuracy = 0.92375
I0108 20:56:23.641278  2295 solver.cpp:523]     Test net output #1: loss = 0.19195 (* 1 = 0.19195 loss)
I0108 20:56:23.641283  2295 solver.cpp:523]     Test net output #2: top-1 = 0.92375
I0108 20:56:23.890637  2295 solver.cpp:270] Iteration 2000 (3.44094 iter/s, 14.5309s/50 iter), loss = 0.0868094, remaining 0 hours and 48 minutes
I0108 20:56:23.890663  2295 solver.cpp:291]     Train net output #0: loss = 0.0868094 (* 1 = 0.0868094 loss)
I0108 20:56:23.890671  2295 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0108 20:56:36.877211  2295 solver.cpp:270] Iteration 2050 (3.85028 iter/s, 12.9861s/50 iter), loss = 0.0978556, remaining 0 hours and 42 minutes
I0108 20:56:36.877257  2295 solver.cpp:291]     Train net output #0: loss = 0.0978556 (* 1 = 0.0978556 loss)
I0108 20:56:36.877264  2295 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0108 20:56:49.815191  2295 solver.cpp:270] Iteration 2100 (3.86475 iter/s, 12.9374s/50 iter), loss = 0.115607, remaining 0 hours and 42 minutes
I0108 20:56:49.815222  2295 solver.cpp:291]     Train net output #0: loss = 0.115607 (* 1 = 0.115607 loss)
I0108 20:56:49.815227  2295 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0108 20:57:02.798328  2295 solver.cpp:270] Iteration 2150 (3.8513 iter/s, 12.9826s/50 iter), loss = 0.0763647, remaining 0 hours and 42 minutes
I0108 20:57:02.798360  2295 solver.cpp:291]     Train net output #0: loss = 0.0763647 (* 1 = 0.0763647 loss)
I0108 20:57:02.798367  2295 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0108 20:57:15.790920  2295 solver.cpp:270] Iteration 2200 (3.8485 iter/s, 12.9921s/50 iter), loss = 0.136038, remaining 0 hours and 42 minutes
I0108 20:57:15.790966  2295 solver.cpp:291]     Train net output #0: loss = 0.136038 (* 1 = 0.136038 loss)
I0108 20:57:15.790973  2295 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0108 20:57:28.775478  2295 solver.cpp:270] Iteration 2250 (3.85089 iter/s, 12.984s/50 iter), loss = 0.100553, remaining 0 hours and 42 minutes
I0108 20:57:28.775509  2295 solver.cpp:291]     Train net output #0: loss = 0.100553 (* 1 = 0.100553 loss)
I0108 20:57:28.775532  2295 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0108 20:57:41.754916  2295 solver.cpp:270] Iteration 2300 (3.8524 iter/s, 12.9789s/50 iter), loss = 0.185956, remaining 0 hours and 41 minutes
I0108 20:57:41.754948  2295 solver.cpp:291]     Train net output #0: loss = 0.185956 (* 1 = 0.185956 loss)
I0108 20:57:41.754956  2295 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0108 20:57:54.729691  2295 solver.cpp:270] Iteration 2350 (3.85379 iter/s, 12.9743s/50 iter), loss = 0.110027, remaining 0 hours and 41 minutes
I0108 20:57:54.729743  2295 solver.cpp:291]     Train net output #0: loss = 0.110027 (* 1 = 0.110027 loss)
I0108 20:57:54.729749  2295 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0108 20:58:07.730914  2295 solver.cpp:270] Iteration 2400 (3.84595 iter/s, 13.0007s/50 iter), loss = 0.111907, remaining 0 hours and 41 minutes
I0108 20:58:07.730947  2295 solver.cpp:291]     Train net output #0: loss = 0.111907 (* 1 = 0.111907 loss)
I0108 20:58:07.730953  2295 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0108 20:58:20.706516  2295 solver.cpp:270] Iteration 2450 (3.85354 iter/s, 12.9751s/50 iter), loss = 0.0986886, remaining 0 hours and 41 minutes
I0108 20:58:20.706550  2295 solver.cpp:291]     Train net output #0: loss = 0.0986886 (* 1 = 0.0986886 loss)
I0108 20:58:20.706557  2295 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0108 20:58:33.705122  2295 solver.cpp:270] Iteration 2500 (3.84672 iter/s, 12.9981s/50 iter), loss = 0.132702, remaining 0 hours and 41 minutes
I0108 20:58:33.705184  2295 solver.cpp:291]     Train net output #0: loss = 0.132702 (* 1 = 0.132702 loss)
I0108 20:58:33.705191  2295 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0108 20:58:46.680474  2295 solver.cpp:270] Iteration 2550 (3.85362 iter/s, 12.9748s/50 iter), loss = 0.0561866, remaining 0 hours and 40 minutes
I0108 20:58:46.680506  2295 solver.cpp:291]     Train net output #0: loss = 0.0561866 (* 1 = 0.0561866 loss)
I0108 20:58:46.680514  2295 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0108 20:58:59.684060  2295 solver.cpp:270] Iteration 2600 (3.84525 iter/s, 13.0031s/50 iter), loss = 0.0437934, remaining 0 hours and 40 minutes
I0108 20:58:59.684092  2295 solver.cpp:291]     Train net output #0: loss = 0.0437934 (* 1 = 0.0437934 loss)
I0108 20:58:59.684099  2295 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0108 20:59:12.668781  2295 solver.cpp:270] Iteration 2650 (3.85083 iter/s, 12.9842s/50 iter), loss = 0.0648092, remaining 0 hours and 40 minutes
I0108 20:59:12.668828  2295 solver.cpp:291]     Train net output #0: loss = 0.0648092 (* 1 = 0.0648092 loss)
I0108 20:59:12.668835  2295 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0108 20:59:25.660585  2295 solver.cpp:270] Iteration 2700 (3.84874 iter/s, 12.9913s/50 iter), loss = 0.0339221, remaining 0 hours and 40 minutes
I0108 20:59:25.660619  2295 solver.cpp:291]     Train net output #0: loss = 0.0339221 (* 1 = 0.0339221 loss)
I0108 20:59:25.660625  2295 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0108 20:59:38.624497  2295 solver.cpp:270] Iteration 2750 (3.85701 iter/s, 12.9634s/50 iter), loss = 0.0233026, remaining 0 hours and 39 minutes
I0108 20:59:38.624529  2295 solver.cpp:291]     Train net output #0: loss = 0.0233027 (* 1 = 0.0233027 loss)
I0108 20:59:38.624536  2295 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0108 20:59:51.611944  2295 solver.cpp:270] Iteration 2800 (3.85002 iter/s, 12.9869s/50 iter), loss = 0.0429548, remaining 0 hours and 39 minutes
I0108 20:59:51.611991  2295 solver.cpp:291]     Train net output #0: loss = 0.0429548 (* 1 = 0.0429548 loss)
I0108 20:59:51.611999  2295 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0108 21:00:04.616751  2295 solver.cpp:270] Iteration 2850 (3.84489 iter/s, 13.0043s/50 iter), loss = 0.0420546, remaining 0 hours and 39 minutes
I0108 21:00:04.616784  2295 solver.cpp:291]     Train net output #0: loss = 0.0420546 (* 1 = 0.0420546 loss)
I0108 21:00:04.616792  2295 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0108 21:00:17.583968  2295 solver.cpp:270] Iteration 2900 (3.85603 iter/s, 12.9667s/50 iter), loss = 0.0408823, remaining 0 hours and 39 minutes
I0108 21:00:17.584002  2295 solver.cpp:291]     Train net output #0: loss = 0.0408823 (* 1 = 0.0408823 loss)
I0108 21:00:17.584008  2295 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0108 21:00:30.585247  2295 solver.cpp:270] Iteration 2950 (3.84593 iter/s, 13.0008s/50 iter), loss = 0.0327996, remaining 0 hours and 39 minutes
I0108 21:00:30.585301  2295 solver.cpp:291]     Train net output #0: loss = 0.0327996 (* 1 = 0.0327996 loss)
I0108 21:00:30.585309  2295 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0108 21:00:43.290761  2295 solver.cpp:424] Iteration 3000, Testing net (#0)
I0108 21:00:44.829457  2295 solver.cpp:523]     Test net output #0: accuracy = 0.94225
I0108 21:00:44.829504  2295 solver.cpp:523]     Test net output #1: loss = 0.148753 (* 1 = 0.148753 loss)
I0108 21:00:44.829509  2295 solver.cpp:523]     Test net output #2: top-1 = 0.94225
I0108 21:00:45.080569  2295 solver.cpp:270] Iteration 3000 (3.44953 iter/s, 14.4947s/50 iter), loss = 0.0215867, remaining 0 hours and 43 minutes
I0108 21:00:45.080595  2295 solver.cpp:291]     Train net output #0: loss = 0.0215867 (* 1 = 0.0215867 loss)
I0108 21:00:45.080603  2295 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0108 21:00:58.067667  2295 solver.cpp:270] Iteration 3050 (3.85013 iter/s, 12.9866s/50 iter), loss = 0.0356157, remaining 0 hours and 38 minutes
I0108 21:00:58.067698  2295 solver.cpp:291]     Train net output #0: loss = 0.0356157 (* 1 = 0.0356157 loss)
I0108 21:00:58.067704  2295 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0108 21:01:11.046450  2295 solver.cpp:270] Iteration 3100 (3.85259 iter/s, 12.9783s/50 iter), loss = 0.00915801, remaining 0 hours and 38 minutes
I0108 21:01:11.046495  2295 solver.cpp:291]     Train net output #0: loss = 0.00915803 (* 1 = 0.00915803 loss)
I0108 21:01:11.046502  2295 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0108 21:01:24.037447  2295 solver.cpp:270] Iteration 3150 (3.84898 iter/s, 12.9905s/50 iter), loss = 0.0641338, remaining 0 hours and 38 minutes
I0108 21:01:24.037479  2295 solver.cpp:291]     Train net output #0: loss = 0.0641338 (* 1 = 0.0641338 loss)
I0108 21:01:24.037487  2295 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0108 21:01:37.030795  2295 solver.cpp:270] Iteration 3200 (3.84828 iter/s, 12.9928s/50 iter), loss = 0.0323239, remaining 0 hours and 37 minutes
I0108 21:01:37.030827  2295 solver.cpp:291]     Train net output #0: loss = 0.0323239 (* 1 = 0.0323239 loss)
I0108 21:01:37.030834  2295 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0108 21:01:50.005479  2295 solver.cpp:270] Iteration 3250 (3.85381 iter/s, 12.9742s/50 iter), loss = 0.0404883, remaining 0 hours and 37 minutes
I0108 21:01:50.005523  2295 solver.cpp:291]     Train net output #0: loss = 0.0404883 (* 1 = 0.0404883 loss)
I0108 21:01:50.005532  2295 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0108 21:02:03.005262  2295 solver.cpp:270] Iteration 3300 (3.84637 iter/s, 12.9993s/50 iter), loss = 0.0452346, remaining 0 hours and 37 minutes
I0108 21:02:03.005296  2295 solver.cpp:291]     Train net output #0: loss = 0.0452346 (* 1 = 0.0452346 loss)
I0108 21:02:03.005318  2295 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0108 21:02:15.985759  2295 solver.cpp:270] Iteration 3350 (3.85209 iter/s, 12.98s/50 iter), loss = 0.042626, remaining 0 hours and 37 minutes
I0108 21:02:15.985791  2295 solver.cpp:291]     Train net output #0: loss = 0.0426261 (* 1 = 0.0426261 loss)
I0108 21:02:15.985798  2295 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0108 21:02:28.993079  2295 solver.cpp:270] Iteration 3400 (3.84414 iter/s, 13.0068s/50 iter), loss = 0.0772641, remaining 0 hours and 37 minutes
I0108 21:02:28.993129  2295 solver.cpp:291]     Train net output #0: loss = 0.0772641 (* 1 = 0.0772641 loss)
I0108 21:02:28.993136  2295 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0108 21:02:41.972970  2295 solver.cpp:270] Iteration 3450 (3.85227 iter/s, 12.9794s/50 iter), loss = 0.0488064, remaining 0 hours and 36 minutes
I0108 21:02:41.973001  2295 solver.cpp:291]     Train net output #0: loss = 0.0488064 (* 1 = 0.0488064 loss)
I0108 21:02:41.973009  2295 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0108 21:02:54.953084  2295 solver.cpp:270] Iteration 3500 (3.8522 iter/s, 12.9796s/50 iter), loss = 0.0377879, remaining 0 hours and 36 minutes
I0108 21:02:54.953116  2295 solver.cpp:291]     Train net output #0: loss = 0.0377879 (* 1 = 0.0377879 loss)
I0108 21:02:54.953124  2295 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0108 21:03:07.933946  2295 solver.cpp:270] Iteration 3550 (3.85198 iter/s, 12.9803s/50 iter), loss = 0.0439396, remaining 0 hours and 36 minutes
I0108 21:03:07.933991  2295 solver.cpp:291]     Train net output #0: loss = 0.0439396 (* 1 = 0.0439396 loss)
I0108 21:03:07.933998  2295 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0108 21:03:20.922857  2295 solver.cpp:270] Iteration 3600 (3.84959 iter/s, 12.9884s/50 iter), loss = 0.0623381, remaining 0 hours and 36 minutes
I0108 21:03:20.922888  2295 solver.cpp:291]     Train net output #0: loss = 0.0623382 (* 1 = 0.0623382 loss)
I0108 21:03:20.922895  2295 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0108 21:03:33.921438  2295 solver.cpp:270] Iteration 3650 (3.84673 iter/s, 12.9981s/50 iter), loss = 0.0353108, remaining 0 hours and 36 minutes
I0108 21:03:33.921469  2295 solver.cpp:291]     Train net output #0: loss = 0.0353109 (* 1 = 0.0353109 loss)
I0108 21:03:33.921478  2295 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0108 21:03:46.936175  2295 solver.cpp:270] Iteration 3700 (3.84195 iter/s, 13.0142s/50 iter), loss = 0.0227299, remaining 0 hours and 35 minutes
I0108 21:03:46.936220  2295 solver.cpp:291]     Train net output #0: loss = 0.0227299 (* 1 = 0.0227299 loss)
I0108 21:03:46.936228  2295 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0108 21:03:59.929158  2295 solver.cpp:270] Iteration 3750 (3.84839 iter/s, 12.9925s/50 iter), loss = 0.0564367, remaining 0 hours and 35 minutes
I0108 21:03:59.929189  2295 solver.cpp:291]     Train net output #0: loss = 0.0564367 (* 1 = 0.0564367 loss)
I0108 21:03:59.929196  2295 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0108 21:04:12.888149  2295 solver.cpp:270] Iteration 3800 (3.85848 iter/s, 12.9585s/50 iter), loss = 0.0305138, remaining 0 hours and 35 minutes
I0108 21:04:12.888181  2295 solver.cpp:291]     Train net output #0: loss = 0.0305138 (* 1 = 0.0305138 loss)
I0108 21:04:12.888187  2295 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0108 21:04:25.839434  2295 solver.cpp:270] Iteration 3850 (3.86077 iter/s, 12.9508s/50 iter), loss = 0.0247187, remaining 0 hours and 34 minutes
I0108 21:04:25.839480  2295 solver.cpp:291]     Train net output #0: loss = 0.0247187 (* 1 = 0.0247187 loss)
I0108 21:04:25.839488  2295 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0108 21:04:38.820729  2295 solver.cpp:270] Iteration 3900 (3.85185 iter/s, 12.9808s/50 iter), loss = 0.0145736, remaining 0 hours and 35 minutes
I0108 21:04:38.820760  2295 solver.cpp:291]     Train net output #0: loss = 0.0145737 (* 1 = 0.0145737 loss)
I0108 21:04:38.820782  2295 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0108 21:04:51.798720  2295 solver.cpp:270] Iteration 3950 (3.85283 iter/s, 12.9775s/50 iter), loss = 0.0432973, remaining 0 hours and 34 minutes
I0108 21:04:51.798753  2295 solver.cpp:291]     Train net output #0: loss = 0.0432974 (* 1 = 0.0432974 loss)
I0108 21:04:51.798759  2295 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0108 21:05:04.504235  2295 solver.cpp:424] Iteration 4000, Testing net (#0)
I0108 21:05:06.045608  2295 solver.cpp:523]     Test net output #0: accuracy = 0.9435
I0108 21:05:06.045639  2295 solver.cpp:523]     Test net output #1: loss = 0.138916 (* 1 = 0.138916 loss)
I0108 21:05:06.045644  2295 solver.cpp:523]     Test net output #2: top-1 = 0.9435
I0108 21:05:06.297152  2295 solver.cpp:270] Iteration 4000 (3.44879 iter/s, 14.4979s/50 iter), loss = 0.0155282, remaining 0 hours and 38 minutes
I0108 21:05:06.297183  2295 solver.cpp:291]     Train net output #0: loss = 0.0155282 (* 1 = 0.0155282 loss)
I0108 21:05:06.297190  2295 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0108 21:05:19.290307  2295 solver.cpp:270] Iteration 4050 (3.84833 iter/s, 12.9926s/50 iter), loss = 0.0391874, remaining 0 hours and 34 minutes
I0108 21:05:19.290339  2295 solver.cpp:291]     Train net output #0: loss = 0.0391874 (* 1 = 0.0391874 loss)
I0108 21:05:19.290346  2295 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0108 21:05:32.263196  2295 solver.cpp:270] Iteration 4100 (3.85434 iter/s, 12.9724s/50 iter), loss = 0.0174386, remaining 0 hours and 33 minutes
I0108 21:05:32.263228  2295 solver.cpp:291]     Train net output #0: loss = 0.0174387 (* 1 = 0.0174387 loss)
I0108 21:05:32.263236  2295 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0108 21:05:45.236816  2295 solver.cpp:270] Iteration 4150 (3.85413 iter/s, 12.9731s/50 iter), loss = 0.0266644, remaining 0 hours and 33 minutes
I0108 21:05:45.236873  2295 solver.cpp:291]     Train net output #0: loss = 0.0266644 (* 1 = 0.0266644 loss)
I0108 21:05:45.236881  2295 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0108 21:05:58.228243  2295 solver.cpp:270] Iteration 4200 (3.84885 iter/s, 12.9909s/50 iter), loss = 0.0198999, remaining 0 hours and 33 minutes
I0108 21:05:58.228274  2295 solver.cpp:291]     Train net output #0: loss = 0.0199 (* 1 = 0.0199 loss)
I0108 21:05:58.228281  2295 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0108 21:06:11.214550  2295 solver.cpp:270] Iteration 4250 (3.85036 iter/s, 12.9858s/50 iter), loss = 0.0201988, remaining 0 hours and 33 minutes
I0108 21:06:11.214581  2295 solver.cpp:291]     Train net output #0: loss = 0.0201988 (* 1 = 0.0201988 loss)
I0108 21:06:11.214588  2295 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0108 21:06:24.170601  2295 solver.cpp:270] Iteration 4300 (3.85935 iter/s, 12.9555s/50 iter), loss = 0.0287971, remaining 0 hours and 33 minutes
I0108 21:06:24.170652  2295 solver.cpp:291]     Train net output #0: loss = 0.0287971 (* 1 = 0.0287971 loss)
I0108 21:06:24.170660  2295 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0108 21:06:37.124753  2295 solver.cpp:270] Iteration 4350 (3.85993 iter/s, 12.9536s/50 iter), loss = 0.0116825, remaining 0 hours and 32 minutes
I0108 21:06:37.124786  2295 solver.cpp:291]     Train net output #0: loss = 0.0116825 (* 1 = 0.0116825 loss)
I0108 21:06:37.124794  2295 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0108 21:06:50.109026  2295 solver.cpp:270] Iteration 4400 (3.85097 iter/s, 12.9838s/50 iter), loss = 0.0503994, remaining 0 hours and 32 minutes
I0108 21:06:50.109057  2295 solver.cpp:291]     Train net output #0: loss = 0.0503994 (* 1 = 0.0503994 loss)
I0108 21:06:50.109064  2295 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0108 21:07:03.076129  2295 solver.cpp:270] Iteration 4450 (3.85606 iter/s, 12.9666s/50 iter), loss = 0.0382675, remaining 0 hours and 32 minutes
I0108 21:07:03.076174  2295 solver.cpp:291]     Train net output #0: loss = 0.0382675 (* 1 = 0.0382675 loss)
I0108 21:07:03.076197  2295 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0108 21:07:16.068063  2295 solver.cpp:270] Iteration 4500 (3.8487 iter/s, 12.9914s/50 iter), loss = 0.0111872, remaining 0 hours and 32 minutes
I0108 21:07:16.068095  2295 solver.cpp:291]     Train net output #0: loss = 0.0111872 (* 1 = 0.0111872 loss)
I0108 21:07:16.068102  2295 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0108 21:07:29.034875  2295 solver.cpp:270] Iteration 4550 (3.85615 iter/s, 12.9663s/50 iter), loss = 0.0493292, remaining 0 hours and 32 minutes
I0108 21:07:29.034910  2295 solver.cpp:291]     Train net output #0: loss = 0.0493292 (* 1 = 0.0493292 loss)
I0108 21:07:29.034932  2295 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0108 21:07:42.040526  2295 solver.cpp:270] Iteration 4600 (3.84464 iter/s, 13.0051s/50 iter), loss = 0.0398111, remaining 0 hours and 31 minutes
I0108 21:07:42.040581  2295 solver.cpp:291]     Train net output #0: loss = 0.0398111 (* 1 = 0.0398111 loss)
I0108 21:07:42.040589  2295 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0108 21:07:55.019666  2295 solver.cpp:270] Iteration 4650 (3.8525 iter/s, 12.9786s/50 iter), loss = 0.0169153, remaining 0 hours and 31 minutes
I0108 21:07:55.019699  2295 solver.cpp:291]     Train net output #0: loss = 0.0169153 (* 1 = 0.0169153 loss)
I0108 21:07:55.019706  2295 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0108 21:08:07.978219  2295 solver.cpp:270] Iteration 4700 (3.85861 iter/s, 12.958s/50 iter), loss = 0.0269636, remaining 0 hours and 31 minutes
I0108 21:08:07.978255  2295 solver.cpp:291]     Train net output #0: loss = 0.0269636 (* 1 = 0.0269636 loss)
I0108 21:08:07.978277  2295 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0108 21:08:20.967746  2295 solver.cpp:270] Iteration 4750 (3.84941 iter/s, 12.989s/50 iter), loss = 0.0245621, remaining 0 hours and 31 minutes
I0108 21:08:20.967787  2295 solver.cpp:291]     Train net output #0: loss = 0.0245621 (* 1 = 0.0245621 loss)
I0108 21:08:20.967793  2295 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0108 21:08:33.971359  2295 solver.cpp:270] Iteration 4800 (3.84524 iter/s, 13.0031s/50 iter), loss = 0.0232929, remaining 0 hours and 31 minutes
I0108 21:08:33.971390  2295 solver.cpp:291]     Train net output #0: loss = 0.0232929 (* 1 = 0.0232929 loss)
I0108 21:08:33.971412  2295 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0108 21:08:46.951783  2295 solver.cpp:270] Iteration 4850 (3.85211 iter/s, 12.9799s/50 iter), loss = 0.0384392, remaining 0 hours and 30 minutes
I0108 21:08:46.951815  2295 solver.cpp:291]     Train net output #0: loss = 0.0384392 (* 1 = 0.0384392 loss)
I0108 21:08:46.951838  2295 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0108 21:08:59.932649  2295 solver.cpp:270] Iteration 4900 (3.85198 iter/s, 12.9803s/50 iter), loss = 0.0397109, remaining 0 hours and 30 minutes
I0108 21:08:59.932694  2295 solver.cpp:291]     Train net output #0: loss = 0.0397109 (* 1 = 0.0397109 loss)
I0108 21:08:59.932703  2295 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0108 21:09:12.935902  2295 solver.cpp:270] Iteration 4950 (3.84535 iter/s, 13.0027s/50 iter), loss = 0.010411, remaining 0 hours and 30 minutes
I0108 21:09:12.935933  2295 solver.cpp:291]     Train net output #0: loss = 0.010411 (* 1 = 0.010411 loss)
I0108 21:09:12.935956  2295 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0108 21:09:25.650787  2295 solver.cpp:424] Iteration 5000, Testing net (#0)
I0108 21:09:27.178928  2295 solver.cpp:523]     Test net output #0: accuracy = 0.93325
I0108 21:09:27.178957  2295 solver.cpp:523]     Test net output #1: loss = 0.183192 (* 1 = 0.183192 loss)
I0108 21:09:27.178961  2295 solver.cpp:523]     Test net output #2: top-1 = 0.93325
I0108 21:09:27.431999  2295 solver.cpp:270] Iteration 5000 (3.44934 iter/s, 14.4955s/50 iter), loss = 0.0276065, remaining 0 hours and 33 minutes
I0108 21:09:27.432025  2295 solver.cpp:291]     Train net output #0: loss = 0.0276065 (* 1 = 0.0276065 loss)
I0108 21:09:27.432032  2295 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0108 21:09:40.422529  2295 solver.cpp:270] Iteration 5050 (3.84911 iter/s, 12.99s/50 iter), loss = 0.01523, remaining 0 hours and 29 minutes
I0108 21:09:40.422574  2295 solver.cpp:291]     Train net output #0: loss = 0.0152299 (* 1 = 0.0152299 loss)
I0108 21:09:40.422580  2295 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0108 21:09:53.388500  2295 solver.cpp:270] Iteration 5100 (3.85641 iter/s, 12.9654s/50 iter), loss = 0.00674825, remaining 0 hours and 29 minutes
I0108 21:09:53.388532  2295 solver.cpp:291]     Train net output #0: loss = 0.00674821 (* 1 = 0.00674821 loss)
I0108 21:09:53.388540  2295 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0108 21:10:06.380069  2295 solver.cpp:270] Iteration 5150 (3.8488 iter/s, 12.9911s/50 iter), loss = 0.0138318, remaining 0 hours and 29 minutes
I0108 21:10:06.380098  2295 solver.cpp:291]     Train net output #0: loss = 0.0138318 (* 1 = 0.0138318 loss)
I0108 21:10:06.380105  2295 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0108 21:10:19.376736  2295 solver.cpp:270] Iteration 5200 (3.84729 iter/s, 12.9962s/50 iter), loss = 0.00889962, remaining 0 hours and 29 minutes
I0108 21:10:19.376791  2295 solver.cpp:291]     Train net output #0: loss = 0.00889957 (* 1 = 0.00889957 loss)
I0108 21:10:19.376798  2295 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0108 21:10:32.347316  2295 solver.cpp:270] Iteration 5250 (3.85504 iter/s, 12.97s/50 iter), loss = 0.00347766, remaining 0 hours and 29 minutes
I0108 21:10:32.347348  2295 solver.cpp:291]     Train net output #0: loss = 0.0034776 (* 1 = 0.0034776 loss)
I0108 21:10:32.347355  2295 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0108 21:10:45.315400  2295 solver.cpp:270] Iteration 5300 (3.85577 iter/s, 12.9676s/50 iter), loss = 0.0322145, remaining 0 hours and 28 minutes
I0108 21:10:45.315433  2295 solver.cpp:291]     Train net output #0: loss = 0.0322145 (* 1 = 0.0322145 loss)
I0108 21:10:45.315438  2295 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0108 21:10:58.315078  2295 solver.cpp:270] Iteration 5350 (3.8464 iter/s, 12.9992s/50 iter), loss = 0.0142626, remaining 0 hours and 28 minutes
I0108 21:10:58.315124  2295 solver.cpp:291]     Train net output #0: loss = 0.0142625 (* 1 = 0.0142625 loss)
I0108 21:10:58.315146  2295 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0108 21:11:11.297437  2295 solver.cpp:270] Iteration 5400 (3.85154 iter/s, 12.9818s/50 iter), loss = 0.0212067, remaining 0 hours and 28 minutes
I0108 21:11:11.297468  2295 solver.cpp:291]     Train net output #0: loss = 0.0212066 (* 1 = 0.0212066 loss)
I0108 21:11:11.297475  2295 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0108 21:11:24.279737  2295 solver.cpp:270] Iteration 5450 (3.85155 iter/s, 12.9818s/50 iter), loss = 0.0136934, remaining 0 hours and 28 minutes
I0108 21:11:24.279768  2295 solver.cpp:291]     Train net output #0: loss = 0.0136933 (* 1 = 0.0136933 loss)
I0108 21:11:24.279791  2295 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0108 21:11:37.266333  2295 solver.cpp:270] Iteration 5500 (3.85028 iter/s, 12.9861s/50 iter), loss = 0.00598788, remaining 0 hours and 28 minutes
I0108 21:11:37.266381  2295 solver.cpp:291]     Train net output #0: loss = 0.00598783 (* 1 = 0.00598783 loss)
I0108 21:11:37.266388  2295 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0108 21:11:50.264521  2295 solver.cpp:270] Iteration 5550 (3.84685 iter/s, 12.9977s/50 iter), loss = 0.00732565, remaining 0 hours and 27 minutes
I0108 21:11:50.264554  2295 solver.cpp:291]     Train net output #0: loss = 0.0073256 (* 1 = 0.0073256 loss)
I0108 21:11:50.264562  2295 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0108 21:12:03.259178  2295 solver.cpp:270] Iteration 5600 (3.84789 iter/s, 12.9941s/50 iter), loss = 0.00742761, remaining 0 hours and 27 minutes
I0108 21:12:03.259212  2295 solver.cpp:291]     Train net output #0: loss = 0.00742756 (* 1 = 0.00742756 loss)
I0108 21:12:03.259218  2295 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0108 21:12:16.245160  2295 solver.cpp:270] Iteration 5650 (3.85046 iter/s, 12.9855s/50 iter), loss = 0.00714188, remaining 0 hours and 27 minutes
I0108 21:12:16.245208  2295 solver.cpp:291]     Train net output #0: loss = 0.00714182 (* 1 = 0.00714182 loss)
I0108 21:12:16.245215  2295 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0108 21:12:29.219019  2295 solver.cpp:270] Iteration 5700 (3.85406 iter/s, 12.9733s/50 iter), loss = 0.00271524, remaining 0 hours and 27 minutes
I0108 21:12:29.219050  2295 solver.cpp:291]     Train net output #0: loss = 0.00271519 (* 1 = 0.00271519 loss)
I0108 21:12:29.219074  2295 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0108 21:12:42.189301  2295 solver.cpp:270] Iteration 5750 (3.85512 iter/s, 12.9698s/50 iter), loss = 0.00476921, remaining 0 hours and 26 minutes
I0108 21:12:42.189332  2295 solver.cpp:291]     Train net output #0: loss = 0.00476916 (* 1 = 0.00476916 loss)
I0108 21:12:42.189339  2295 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0108 21:12:55.176743  2295 solver.cpp:270] Iteration 5800 (3.85003 iter/s, 12.9869s/50 iter), loss = 0.00225747, remaining 0 hours and 26 minutes
I0108 21:12:55.176796  2295 solver.cpp:291]     Train net output #0: loss = 0.00225742 (* 1 = 0.00225742 loss)
I0108 21:12:55.176803  2295 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0108 21:13:08.165307  2295 solver.cpp:270] Iteration 5850 (3.8497 iter/s, 12.988s/50 iter), loss = 0.00937564, remaining 0 hours and 26 minutes
I0108 21:13:08.165339  2295 solver.cpp:291]     Train net output #0: loss = 0.00937558 (* 1 = 0.00937558 loss)
I0108 21:13:08.165346  2295 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0108 21:13:21.169276  2295 solver.cpp:270] Iteration 5900 (3.84513 iter/s, 13.0035s/50 iter), loss = 0.0267531, remaining 0 hours and 26 minutes
I0108 21:13:21.169308  2295 solver.cpp:291]     Train net output #0: loss = 0.0267531 (* 1 = 0.0267531 loss)
I0108 21:13:21.169332  2295 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0108 21:13:34.123387  2295 solver.cpp:270] Iteration 5950 (3.85993 iter/s, 12.9536s/50 iter), loss = 0.0190588, remaining 0 hours and 25 minutes
I0108 21:13:34.123431  2295 solver.cpp:291]     Train net output #0: loss = 0.0190587 (* 1 = 0.0190587 loss)
I0108 21:13:34.123438  2295 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0108 21:13:46.868247  2295 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.1/snapshots/_iter_6000.caffemodel
I0108 21:13:49.319561  2295 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.1/snapshots/_iter_6000.solverstate
I0108 21:13:49.542265  2295 solver.cpp:424] Iteration 6000, Testing net (#0)
I0108 21:13:51.018863  2295 solver.cpp:523]     Test net output #0: accuracy = 0.94875
I0108 21:13:51.018893  2295 solver.cpp:523]     Test net output #1: loss = 0.174305 (* 1 = 0.174305 loss)
I0108 21:13:51.018899  2295 solver.cpp:523]     Test net output #2: top-1 = 0.94875
I0108 21:13:51.266001  2295 solver.cpp:270] Iteration 6000 (2.91682 iter/s, 17.1419s/50 iter), loss = 0.00192461, remaining 0 hours and 34 minutes
I0108 21:13:51.266027  2295 solver.cpp:291]     Train net output #0: loss = 0.00192457 (* 1 = 0.00192457 loss)
I0108 21:13:51.266034  2295 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0108 21:14:04.206719  2295 solver.cpp:270] Iteration 6050 (3.86393 iter/s, 12.9402s/50 iter), loss = 0.01473, remaining 0 hours and 25 minutes
I0108 21:14:04.206763  2295 solver.cpp:291]     Train net output #0: loss = 0.0147299 (* 1 = 0.0147299 loss)
I0108 21:14:04.206770  2295 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0108 21:14:17.134600  2295 solver.cpp:270] Iteration 6100 (3.86777 iter/s, 12.9274s/50 iter), loss = 0.0273777, remaining 0 hours and 25 minutes
I0108 21:14:17.134634  2295 solver.cpp:291]     Train net output #0: loss = 0.0273777 (* 1 = 0.0273777 loss)
I0108 21:14:17.134641  2295 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0108 21:14:30.091050  2295 solver.cpp:270] Iteration 6150 (3.85924 iter/s, 12.9559s/50 iter), loss = 0.0133532, remaining 0 hours and 25 minutes
I0108 21:14:30.091084  2295 solver.cpp:291]     Train net output #0: loss = 0.0133531 (* 1 = 0.0133531 loss)
I0108 21:14:30.091091  2295 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0108 21:14:43.070827  2295 solver.cpp:270] Iteration 6200 (3.8523 iter/s, 12.9793s/50 iter), loss = 0.0155623, remaining 0 hours and 24 minutes
I0108 21:14:43.070875  2295 solver.cpp:291]     Train net output #0: loss = 0.0155623 (* 1 = 0.0155623 loss)
I0108 21:14:43.070883  2295 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0108 21:14:56.032035  2295 solver.cpp:270] Iteration 6250 (3.85782 iter/s, 12.9607s/50 iter), loss = 0.00542914, remaining 0 hours and 24 minutes
I0108 21:14:56.032065  2295 solver.cpp:291]     Train net output #0: loss = 0.00542909 (* 1 = 0.00542909 loss)
I0108 21:14:56.032073  2295 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0108 21:15:09.028970  2295 solver.cpp:270] Iteration 6300 (3.84721 iter/s, 12.9964s/50 iter), loss = 0.0140425, remaining 0 hours and 24 minutes
I0108 21:15:09.029001  2295 solver.cpp:291]     Train net output #0: loss = 0.0140424 (* 1 = 0.0140424 loss)
I0108 21:15:09.029024  2295 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0108 21:15:22.016275  2295 solver.cpp:270] Iteration 6350 (3.85007 iter/s, 12.9868s/50 iter), loss = 0.0014534, remaining 0 hours and 24 minutes
I0108 21:15:22.016330  2295 solver.cpp:291]     Train net output #0: loss = 0.00145336 (* 1 = 0.00145336 loss)
I0108 21:15:22.016338  2295 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0108 21:15:35.024312  2295 solver.cpp:270] Iteration 6400 (3.84394 iter/s, 13.0075s/50 iter), loss = 0.0040501, remaining 0 hours and 24 minutes
I0108 21:15:35.024344  2295 solver.cpp:291]     Train net output #0: loss = 0.00405006 (* 1 = 0.00405006 loss)
I0108 21:15:35.024366  2295 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0108 21:15:48.028645  2295 solver.cpp:270] Iteration 6450 (3.84503 iter/s, 13.0038s/50 iter), loss = 0.0120778, remaining 0 hours and 23 minutes
I0108 21:15:48.028677  2295 solver.cpp:291]     Train net output #0: loss = 0.0120778 (* 1 = 0.0120778 loss)
I0108 21:15:48.028684  2295 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0108 21:16:01.036880  2295 solver.cpp:270] Iteration 6500 (3.84387 iter/s, 13.0077s/50 iter), loss = 0.00346407, remaining 0 hours and 23 minutes
I0108 21:16:01.036923  2295 solver.cpp:291]     Train net output #0: loss = 0.00346403 (* 1 = 0.00346403 loss)
I0108 21:16:01.036931  2295 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0108 21:16:14.007081  2295 solver.cpp:270] Iteration 6550 (3.85515 iter/s, 12.9697s/50 iter), loss = 0.0073364, remaining 0 hours and 23 minutes
I0108 21:16:14.007113  2295 solver.cpp:291]     Train net output #0: loss = 0.00733637 (* 1 = 0.00733637 loss)
I0108 21:16:14.007135  2295 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0108 21:16:27.011698  2295 solver.cpp:270] Iteration 6600 (3.84494 iter/s, 13.0041s/50 iter), loss = 0.0192445, remaining 0 hours and 23 minutes
I0108 21:16:27.011731  2295 solver.cpp:291]     Train net output #0: loss = 0.0192445 (* 1 = 0.0192445 loss)
I0108 21:16:27.011754  2295 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0108 21:16:39.983528  2295 solver.cpp:270] Iteration 6650 (3.85466 iter/s, 12.9713s/50 iter), loss = 0.00651271, remaining 0 hours and 23 minutes
I0108 21:16:39.983589  2295 solver.cpp:291]     Train net output #0: loss = 0.00651267 (* 1 = 0.00651267 loss)
I0108 21:16:39.983597  2295 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0108 21:16:52.966701  2295 solver.cpp:270] Iteration 6700 (3.8513 iter/s, 12.9826s/50 iter), loss = 0.00581989, remaining 0 hours and 22 minutes
I0108 21:16:52.966732  2295 solver.cpp:291]     Train net output #0: loss = 0.00581985 (* 1 = 0.00581985 loss)
I0108 21:16:52.966739  2295 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0108 21:17:05.960589  2295 solver.cpp:270] Iteration 6750 (3.84812 iter/s, 12.9934s/50 iter), loss = 0.0149566, remaining 0 hours and 22 minutes
I0108 21:17:05.960621  2295 solver.cpp:291]     Train net output #0: loss = 0.0149566 (* 1 = 0.0149566 loss)
I0108 21:17:05.960628  2295 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0108 21:17:18.942538  2295 solver.cpp:270] Iteration 6800 (3.85166 iter/s, 12.9814s/50 iter), loss = 0.00878445, remaining 0 hours and 22 minutes
I0108 21:17:18.942582  2295 solver.cpp:291]     Train net output #0: loss = 0.00878441 (* 1 = 0.00878441 loss)
I0108 21:17:18.942590  2295 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0108 21:17:31.939481  2295 solver.cpp:270] Iteration 6850 (3.84722 iter/s, 12.9964s/50 iter), loss = 0.00820713, remaining 0 hours and 22 minutes
I0108 21:17:31.939512  2295 solver.cpp:291]     Train net output #0: loss = 0.00820709 (* 1 = 0.00820709 loss)
I0108 21:17:31.939536  2295 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0108 21:17:44.911748  2295 solver.cpp:270] Iteration 6900 (3.85453 iter/s, 12.9718s/50 iter), loss = 0.00712819, remaining 0 hours and 22 minutes
I0108 21:17:44.911780  2295 solver.cpp:291]     Train net output #0: loss = 0.00712815 (* 1 = 0.00712815 loss)
I0108 21:17:44.911787  2295 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0108 21:17:57.884202  2295 solver.cpp:270] Iteration 6950 (3.85447 iter/s, 12.9719s/50 iter), loss = 0.0199916, remaining 0 hours and 21 minutes
I0108 21:17:57.884254  2295 solver.cpp:291]     Train net output #0: loss = 0.0199916 (* 1 = 0.0199916 loss)
I0108 21:17:57.884277  2295 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0108 21:18:10.634768  2295 solver.cpp:424] Iteration 7000, Testing net (#0)
I0108 21:18:12.176304  2295 solver.cpp:523]     Test net output #0: accuracy = 0.94925
I0108 21:18:12.176333  2295 solver.cpp:523]     Test net output #1: loss = 0.201787 (* 1 = 0.201787 loss)
I0108 21:18:12.176338  2295 solver.cpp:523]     Test net output #2: top-1 = 0.94925
I0108 21:18:12.424518  2295 solver.cpp:270] Iteration 7000 (3.43885 iter/s, 14.5397s/50 iter), loss = 0.00606399, remaining 0 hours and 24 minutes
I0108 21:18:12.424543  2295 solver.cpp:291]     Train net output #0: loss = 0.00606395 (* 1 = 0.00606395 loss)
I0108 21:18:12.424551  2295 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0108 21:18:25.396641  2295 solver.cpp:270] Iteration 7050 (3.85457 iter/s, 12.9716s/50 iter), loss = 0.0227463, remaining 0 hours and 21 minutes
I0108 21:18:25.396672  2295 solver.cpp:291]     Train net output #0: loss = 0.0227462 (* 1 = 0.0227462 loss)
I0108 21:18:25.396680  2295 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0108 21:18:38.384196  2295 solver.cpp:270] Iteration 7100 (3.84999 iter/s, 12.987s/50 iter), loss = 0.0012237, remaining 0 hours and 21 minutes
I0108 21:18:38.384241  2295 solver.cpp:291]     Train net output #0: loss = 0.00122367 (* 1 = 0.00122367 loss)
I0108 21:18:38.384264  2295 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0108 21:18:51.354445  2295 solver.cpp:270] Iteration 7150 (3.85513 iter/s, 12.9697s/50 iter), loss = 0.0152437, remaining 0 hours and 20 minutes
I0108 21:18:51.354478  2295 solver.cpp:291]     Train net output #0: loss = 0.0152436 (* 1 = 0.0152436 loss)
I0108 21:18:51.354485  2295 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0108 21:19:04.350116  2295 solver.cpp:270] Iteration 7200 (3.84759 iter/s, 12.9952s/50 iter), loss = 0.0103186, remaining 0 hours and 20 minutes
I0108 21:19:04.350148  2295 solver.cpp:291]     Train net output #0: loss = 0.0103186 (* 1 = 0.0103186 loss)
I0108 21:19:04.350155  2295 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0108 21:19:17.343000  2295 solver.cpp:270] Iteration 7250 (3.84841 iter/s, 12.9924s/50 iter), loss = 0.03878, remaining 0 hours and 20 minutes
I0108 21:19:17.343045  2295 solver.cpp:291]     Train net output #0: loss = 0.03878 (* 1 = 0.03878 loss)
I0108 21:19:17.343053  2295 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0108 21:19:30.307060  2295 solver.cpp:270] Iteration 7300 (3.85697 iter/s, 12.9635s/50 iter), loss = 0.0113183, remaining 0 hours and 20 minutes
I0108 21:19:30.307094  2295 solver.cpp:291]     Train net output #0: loss = 0.0113183 (* 1 = 0.0113183 loss)
I0108 21:19:30.307102  2295 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0108 21:19:43.310699  2295 solver.cpp:270] Iteration 7350 (3.84523 iter/s, 13.0031s/50 iter), loss = 0.0314409, remaining 0 hours and 20 minutes
I0108 21:19:43.310731  2295 solver.cpp:291]     Train net output #0: loss = 0.0314409 (* 1 = 0.0314409 loss)
I0108 21:19:43.310739  2295 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0108 21:19:56.280869  2295 solver.cpp:270] Iteration 7400 (3.85515 iter/s, 12.9697s/50 iter), loss = 0.0137055, remaining 0 hours and 19 minutes
I0108 21:19:56.280915  2295 solver.cpp:291]     Train net output #0: loss = 0.0137055 (* 1 = 0.0137055 loss)
I0108 21:19:56.280937  2295 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0108 21:20:09.262763  2295 solver.cpp:270] Iteration 7450 (3.85168 iter/s, 12.9814s/50 iter), loss = 0.0257469, remaining 0 hours and 19 minutes
I0108 21:20:09.262796  2295 solver.cpp:291]     Train net output #0: loss = 0.0257469 (* 1 = 0.0257469 loss)
I0108 21:20:09.262804  2295 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0108 21:20:22.261376  2295 solver.cpp:270] Iteration 7500 (3.84672 iter/s, 12.9981s/50 iter), loss = 0.00471204, remaining 0 hours and 19 minutes
I0108 21:20:22.261409  2295 solver.cpp:291]     Train net output #0: loss = 0.00471203 (* 1 = 0.00471203 loss)
I0108 21:20:22.261416  2295 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0108 21:20:35.234458  2295 solver.cpp:270] Iteration 7550 (3.85429 iter/s, 12.9726s/50 iter), loss = 0.0256729, remaining 0 hours and 19 minutes
I0108 21:20:35.234508  2295 solver.cpp:291]     Train net output #0: loss = 0.0256729 (* 1 = 0.0256729 loss)
I0108 21:20:35.234534  2295 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0108 21:20:48.235743  2295 solver.cpp:270] Iteration 7600 (3.84593 iter/s, 13.0008s/50 iter), loss = 0.00272861, remaining 0 hours and 18 minutes
I0108 21:20:48.235774  2295 solver.cpp:291]     Train net output #0: loss = 0.00272861 (* 1 = 0.00272861 loss)
I0108 21:20:48.235780  2295 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0108 21:21:01.189455  2295 solver.cpp:270] Iteration 7650 (3.86005 iter/s, 12.9532s/50 iter), loss = 0.00311573, remaining 0 hours and 18 minutes
I0108 21:21:01.189486  2295 solver.cpp:291]     Train net output #0: loss = 0.00311572 (* 1 = 0.00311572 loss)
I0108 21:21:01.189493  2295 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0108 21:21:14.182765  2295 solver.cpp:270] Iteration 7700 (3.84829 iter/s, 12.9928s/50 iter), loss = 0.0160185, remaining 0 hours and 18 minutes
I0108 21:21:14.182809  2295 solver.cpp:291]     Train net output #0: loss = 0.0160185 (* 1 = 0.0160185 loss)
I0108 21:21:14.182834  2295 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0108 21:21:27.151137  2295 solver.cpp:270] Iteration 7750 (3.85569 iter/s, 12.9678s/50 iter), loss = 0.0098622, remaining 0 hours and 18 minutes
I0108 21:21:27.151170  2295 solver.cpp:291]     Train net output #0: loss = 0.00986219 (* 1 = 0.00986219 loss)
I0108 21:21:27.151176  2295 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0108 21:21:40.130264  2295 solver.cpp:270] Iteration 7800 (3.85249 iter/s, 12.9786s/50 iter), loss = 0.00819829, remaining 0 hours and 18 minutes
I0108 21:21:40.130295  2295 solver.cpp:291]     Train net output #0: loss = 0.00819828 (* 1 = 0.00819828 loss)
I0108 21:21:40.130301  2295 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0108 21:21:53.102612  2295 solver.cpp:270] Iteration 7850 (3.85451 iter/s, 12.9718s/50 iter), loss = 0.00175863, remaining 0 hours and 17 minutes
I0108 21:21:53.102656  2295 solver.cpp:291]     Train net output #0: loss = 0.00175862 (* 1 = 0.00175862 loss)
I0108 21:21:53.102663  2295 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0108 21:22:06.076185  2295 solver.cpp:270] Iteration 7900 (3.85414 iter/s, 12.973s/50 iter), loss = 0.0175859, remaining 0 hours and 17 minutes
I0108 21:22:06.076217  2295 solver.cpp:291]     Train net output #0: loss = 0.0175859 (* 1 = 0.0175859 loss)
I0108 21:22:06.076225  2295 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0108 21:22:19.047238  2295 solver.cpp:270] Iteration 7950 (3.85489 iter/s, 12.9705s/50 iter), loss = 0.0054047, remaining 0 hours and 17 minutes
I0108 21:22:19.047271  2295 solver.cpp:291]     Train net output #0: loss = 0.00540469 (* 1 = 0.00540469 loss)
I0108 21:22:19.047294  2295 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0108 21:22:31.771210  2295 solver.cpp:424] Iteration 8000, Testing net (#0)
I0108 21:22:33.331662  2295 solver.cpp:523]     Test net output #0: accuracy = 0.94975
I0108 21:22:33.331691  2295 solver.cpp:523]     Test net output #1: loss = 0.219078 (* 1 = 0.219078 loss)
I0108 21:22:33.331697  2295 solver.cpp:523]     Test net output #2: top-1 = 0.94975
I0108 21:22:33.582433  2295 solver.cpp:270] Iteration 8000 (3.44006 iter/s, 14.5346s/50 iter), loss = 0.00282, remaining 0 hours and 19 minutes
I0108 21:22:33.582460  2295 solver.cpp:291]     Train net output #0: loss = 0.00281999 (* 1 = 0.00281999 loss)
I0108 21:22:33.582468  2295 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0108 21:22:46.544534  2295 solver.cpp:270] Iteration 8050 (3.85755 iter/s, 12.9616s/50 iter), loss = 0.0220283, remaining 0 hours and 16 minutes
I0108 21:22:46.544567  2295 solver.cpp:291]     Train net output #0: loss = 0.0220283 (* 1 = 0.0220283 loss)
I0108 21:22:46.544574  2295 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0108 21:22:59.521536  2295 solver.cpp:270] Iteration 8100 (3.85312 iter/s, 12.9765s/50 iter), loss = 0.00441002, remaining 0 hours and 16 minutes
I0108 21:22:59.521569  2295 solver.cpp:291]     Train net output #0: loss = 0.00441002 (* 1 = 0.00441002 loss)
I0108 21:22:59.521575  2295 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0108 21:23:12.481451  2295 solver.cpp:270] Iteration 8150 (3.8582 iter/s, 12.9594s/50 iter), loss = 0.0108497, remaining 0 hours and 16 minutes
I0108 21:23:12.481505  2295 solver.cpp:291]     Train net output #0: loss = 0.0108497 (* 1 = 0.0108497 loss)
I0108 21:23:12.481513  2295 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0108 21:23:25.454485  2295 solver.cpp:270] Iteration 8200 (3.85431 iter/s, 12.9725s/50 iter), loss = 0.00405225, remaining 0 hours and 16 minutes
I0108 21:23:25.454517  2295 solver.cpp:291]     Train net output #0: loss = 0.00405225 (* 1 = 0.00405225 loss)
I0108 21:23:25.454524  2295 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0108 21:23:38.437456  2295 solver.cpp:270] Iteration 8250 (3.85135 iter/s, 12.9825s/50 iter), loss = 0.00123232, remaining 0 hours and 16 minutes
I0108 21:23:38.437489  2295 solver.cpp:291]     Train net output #0: loss = 0.00123232 (* 1 = 0.00123232 loss)
I0108 21:23:38.437496  2295 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0108 21:23:51.427007  2295 solver.cpp:270] Iteration 8300 (3.8494 iter/s, 12.989s/50 iter), loss = 0.0225861, remaining 0 hours and 15 minutes
I0108 21:23:51.427052  2295 solver.cpp:291]     Train net output #0: loss = 0.0225861 (* 1 = 0.0225861 loss)
I0108 21:23:51.427075  2295 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0108 21:24:04.411917  2295 solver.cpp:270] Iteration 8350 (3.85078 iter/s, 12.9844s/50 iter), loss = 0.0164771, remaining 0 hours and 15 minutes
I0108 21:24:04.411949  2295 solver.cpp:291]     Train net output #0: loss = 0.0164771 (* 1 = 0.0164771 loss)
I0108 21:24:04.411957  2295 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0108 21:24:17.361755  2295 solver.cpp:270] Iteration 8400 (3.86121 iter/s, 12.9493s/50 iter), loss = 0.0139528, remaining 0 hours and 15 minutes
I0108 21:24:17.361788  2295 solver.cpp:291]     Train net output #0: loss = 0.0139528 (* 1 = 0.0139528 loss)
I0108 21:24:17.361794  2295 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0108 21:24:30.360607  2295 solver.cpp:270] Iteration 8450 (3.84665 iter/s, 12.9983s/50 iter), loss = 0.0102966, remaining 0 hours and 15 minutes
I0108 21:24:30.360651  2295 solver.cpp:291]     Train net output #0: loss = 0.0102966 (* 1 = 0.0102966 loss)
I0108 21:24:30.360674  2295 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0108 21:24:43.349494  2295 solver.cpp:270] Iteration 8500 (3.8496 iter/s, 12.9884s/50 iter), loss = 0.013244, remaining 0 hours and 15 minutes
I0108 21:24:43.349526  2295 solver.cpp:291]     Train net output #0: loss = 0.013244 (* 1 = 0.013244 loss)
I0108 21:24:43.349550  2295 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0108 21:24:56.328446  2295 solver.cpp:270] Iteration 8550 (3.85254 iter/s, 12.9784s/50 iter), loss = 0.0203509, remaining 0 hours and 14 minutes
I0108 21:24:56.328477  2295 solver.cpp:291]     Train net output #0: loss = 0.0203509 (* 1 = 0.0203509 loss)
I0108 21:24:56.328500  2295 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0108 21:25:09.336809  2295 solver.cpp:270] Iteration 8600 (3.84383 iter/s, 13.0078s/50 iter), loss = 0.016845, remaining 0 hours and 14 minutes
I0108 21:25:09.336853  2295 solver.cpp:291]     Train net output #0: loss = 0.016845 (* 1 = 0.016845 loss)
I0108 21:25:09.336859  2295 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0108 21:25:22.304857  2295 solver.cpp:270] Iteration 8650 (3.85579 iter/s, 12.9675s/50 iter), loss = 0.00621068, remaining 0 hours and 14 minutes
I0108 21:25:22.304889  2295 solver.cpp:291]     Train net output #0: loss = 0.00621068 (* 1 = 0.00621068 loss)
I0108 21:25:22.304898  2295 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0108 21:25:35.286167  2295 solver.cpp:270] Iteration 8700 (3.85185 iter/s, 12.9808s/50 iter), loss = 0.0261454, remaining 0 hours and 14 minutes
I0108 21:25:35.286199  2295 solver.cpp:291]     Train net output #0: loss = 0.0261454 (* 1 = 0.0261454 loss)
I0108 21:25:35.286206  2295 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0108 21:25:48.257633  2295 solver.cpp:270] Iteration 8750 (3.85477 iter/s, 12.9709s/50 iter), loss = 0.00469064, remaining 0 hours and 14 minutes
I0108 21:25:48.257690  2295 solver.cpp:291]     Train net output #0: loss = 0.00469064 (* 1 = 0.00469064 loss)
I0108 21:25:48.257714  2295 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0108 21:26:01.250402  2295 solver.cpp:270] Iteration 8800 (3.84845 iter/s, 12.9922s/50 iter), loss = 0.0181279, remaining 0 hours and 13 minutes
I0108 21:26:01.250434  2295 solver.cpp:291]     Train net output #0: loss = 0.0181279 (* 1 = 0.0181279 loss)
I0108 21:26:01.250442  2295 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0108 21:26:14.228353  2295 solver.cpp:270] Iteration 8850 (3.85284 iter/s, 12.9774s/50 iter), loss = 0.00328093, remaining 0 hours and 13 minutes
I0108 21:26:14.228384  2295 solver.cpp:291]     Train net output #0: loss = 0.00328094 (* 1 = 0.00328094 loss)
I0108 21:26:14.228407  2295 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0108 21:26:27.208214  2295 solver.cpp:270] Iteration 8900 (3.85227 iter/s, 12.9793s/50 iter), loss = 0.0106084, remaining 0 hours and 13 minutes
I0108 21:26:27.208258  2295 solver.cpp:291]     Train net output #0: loss = 0.0106084 (* 1 = 0.0106084 loss)
I0108 21:26:27.208266  2295 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0108 21:26:40.176856  2295 solver.cpp:270] Iteration 8950 (3.85561 iter/s, 12.9681s/50 iter), loss = 0.0158309, remaining 0 hours and 12 minutes
I0108 21:26:40.176887  2295 solver.cpp:291]     Train net output #0: loss = 0.0158309 (* 1 = 0.0158309 loss)
I0108 21:26:40.176909  2295 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0108 21:26:52.906191  2295 solver.cpp:424] Iteration 9000, Testing net (#0)
I0108 21:26:54.441848  2295 solver.cpp:523]     Test net output #0: accuracy = 0.95
I0108 21:26:54.441874  2295 solver.cpp:523]     Test net output #1: loss = 0.240564 (* 1 = 0.240564 loss)
I0108 21:26:54.441879  2295 solver.cpp:523]     Test net output #2: top-1 = 0.95
I0108 21:26:54.691854  2295 solver.cpp:270] Iteration 9000 (3.44485 iter/s, 14.5144s/50 iter), loss = 0.00157132, remaining 0 hours and 14 minutes
I0108 21:26:54.691879  2295 solver.cpp:291]     Train net output #0: loss = 0.00157133 (* 1 = 0.00157133 loss)
I0108 21:26:54.691887  2295 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0108 21:27:07.675053  2295 solver.cpp:270] Iteration 9050 (3.85128 iter/s, 12.9827s/50 iter), loss = 0.0023682, remaining 0 hours and 12 minutes
I0108 21:27:07.675098  2295 solver.cpp:291]     Train net output #0: loss = 0.0023682 (* 1 = 0.0023682 loss)
I0108 21:27:07.675122  2295 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0108 21:27:20.683331  2295 solver.cpp:270] Iteration 9100 (3.84386 iter/s, 13.0077s/50 iter), loss = 0.0128852, remaining 0 hours and 12 minutes
I0108 21:27:20.683362  2295 solver.cpp:291]     Train net output #0: loss = 0.0128852 (* 1 = 0.0128852 loss)
I0108 21:27:20.683369  2295 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0108 21:27:33.648263  2295 solver.cpp:270] Iteration 9150 (3.85671 iter/s, 12.9644s/50 iter), loss = 0.00528137, remaining 0 hours and 12 minutes
I0108 21:27:33.648296  2295 solver.cpp:291]     Train net output #0: loss = 0.00528136 (* 1 = 0.00528136 loss)
I0108 21:27:33.648303  2295 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0108 21:27:46.648227  2295 solver.cpp:270] Iteration 9200 (3.84632 iter/s, 12.9994s/50 iter), loss = 0.00198244, remaining 0 hours and 11 minutes
I0108 21:27:46.648272  2295 solver.cpp:291]     Train net output #0: loss = 0.00198244 (* 1 = 0.00198244 loss)
I0108 21:27:46.648280  2295 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0108 21:27:59.619377  2295 solver.cpp:270] Iteration 9250 (3.85487 iter/s, 12.9706s/50 iter), loss = 0.000899252, remaining 0 hours and 11 minutes
I0108 21:27:59.619410  2295 solver.cpp:291]     Train net output #0: loss = 0.000899245 (* 1 = 0.000899245 loss)
I0108 21:27:59.619417  2295 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0108 21:28:12.574393  2295 solver.cpp:270] Iteration 9300 (3.85966 iter/s, 12.9545s/50 iter), loss = 0.0032958, remaining 0 hours and 11 minutes
I0108 21:28:12.574425  2295 solver.cpp:291]     Train net output #0: loss = 0.00329579 (* 1 = 0.00329579 loss)
I0108 21:28:12.574434  2295 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0108 21:28:25.560770  2295 solver.cpp:270] Iteration 9350 (3.85034 iter/s, 12.9859s/50 iter), loss = 0.0119467, remaining 0 hours and 11 minutes
I0108 21:28:25.560824  2295 solver.cpp:291]     Train net output #0: loss = 0.0119467 (* 1 = 0.0119467 loss)
I0108 21:28:25.560847  2295 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0108 21:28:38.546690  2295 solver.cpp:270] Iteration 9400 (3.85048 iter/s, 12.9854s/50 iter), loss = 0.00530015, remaining 0 hours and 11 minutes
I0108 21:28:38.546722  2295 solver.cpp:291]     Train net output #0: loss = 0.00530014 (* 1 = 0.00530014 loss)
I0108 21:28:38.546730  2295 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0108 21:28:51.532536  2295 solver.cpp:270] Iteration 9450 (3.8505 iter/s, 12.9853s/50 iter), loss = 0.00169709, remaining 0 hours and 10 minutes
I0108 21:28:51.532569  2295 solver.cpp:291]     Train net output #0: loss = 0.00169708 (* 1 = 0.00169708 loss)
I0108 21:28:51.532577  2295 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0108 21:29:04.496851  2295 solver.cpp:270] Iteration 9500 (3.85689 iter/s, 12.9638s/50 iter), loss = 0.00146963, remaining 0 hours and 10 minutes
I0108 21:29:04.496897  2295 solver.cpp:291]     Train net output #0: loss = 0.00146962 (* 1 = 0.00146962 loss)
I0108 21:29:04.496906  2295 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0108 21:29:17.479705  2295 solver.cpp:270] Iteration 9550 (3.85139 iter/s, 12.9823s/50 iter), loss = 0.00273764, remaining 0 hours and 10 minutes
I0108 21:29:17.479737  2295 solver.cpp:291]     Train net output #0: loss = 0.00273763 (* 1 = 0.00273763 loss)
I0108 21:29:17.479760  2295 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0108 21:29:30.453155  2295 solver.cpp:270] Iteration 9600 (3.85418 iter/s, 12.9729s/50 iter), loss = 0.00551351, remaining 0 hours and 10 minutes
I0108 21:29:30.453188  2295 solver.cpp:291]     Train net output #0: loss = 0.0055135 (* 1 = 0.0055135 loss)
I0108 21:29:30.453197  2295 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0108 21:29:43.442531  2295 solver.cpp:270] Iteration 9650 (3.84945 iter/s, 12.9889s/50 iter), loss = 0.0163267, remaining 0 hours and 10 minutes
I0108 21:29:43.442570  2295 solver.cpp:291]     Train net output #0: loss = 0.0163267 (* 1 = 0.0163267 loss)
I0108 21:29:43.442577  2295 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0108 21:29:56.437078  2295 solver.cpp:270] Iteration 9700 (3.84792 iter/s, 12.994s/50 iter), loss = 0.0106351, remaining 0 hours and 9 minutes
I0108 21:29:56.437110  2295 solver.cpp:291]     Train net output #0: loss = 0.0106351 (* 1 = 0.0106351 loss)
I0108 21:29:56.437117  2295 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0108 21:30:09.409317  2295 solver.cpp:270] Iteration 9750 (3.85454 iter/s, 12.9717s/50 iter), loss = 0.00308583, remaining 0 hours and 9 minutes
I0108 21:30:09.409349  2295 solver.cpp:291]     Train net output #0: loss = 0.00308582 (* 1 = 0.00308582 loss)
I0108 21:30:09.409358  2295 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0108 21:30:22.415669  2295 solver.cpp:270] Iteration 9800 (3.84443 iter/s, 13.0058s/50 iter), loss = 0.0207353, remaining 0 hours and 9 minutes
I0108 21:30:22.415715  2295 solver.cpp:291]     Train net output #0: loss = 0.0207353 (* 1 = 0.0207353 loss)
I0108 21:30:22.415724  2295 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0108 21:30:35.400177  2295 solver.cpp:270] Iteration 9850 (3.8509 iter/s, 12.984s/50 iter), loss = 0.0231634, remaining 0 hours and 9 minutes
I0108 21:30:35.400208  2295 solver.cpp:291]     Train net output #0: loss = 0.0231634 (* 1 = 0.0231634 loss)
I0108 21:30:35.400216  2295 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0108 21:30:48.397302  2295 solver.cpp:270] Iteration 9900 (3.84716 iter/s, 12.9966s/50 iter), loss = 0.00732661, remaining 0 hours and 9 minutes
I0108 21:30:48.397336  2295 solver.cpp:291]     Train net output #0: loss = 0.0073266 (* 1 = 0.0073266 loss)
I0108 21:30:48.397342  2295 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0108 21:31:01.367784  2295 solver.cpp:270] Iteration 9950 (3.85506 iter/s, 12.97s/50 iter), loss = 0.00993603, remaining 0 hours and 8 minutes
I0108 21:31:01.367835  2295 solver.cpp:291]     Train net output #0: loss = 0.00993602 (* 1 = 0.00993602 loss)
I0108 21:31:01.367842  2295 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0108 21:31:14.101080  2295 solver.cpp:424] Iteration 10000, Testing net (#0)
I0108 21:31:15.635848  2295 solver.cpp:523]     Test net output #0: accuracy = 0.9485
I0108 21:31:15.635876  2295 solver.cpp:523]     Test net output #1: loss = 0.253461 (* 1 = 0.253461 loss)
I0108 21:31:15.635883  2295 solver.cpp:523]     Test net output #2: top-1 = 0.9485
I0108 21:31:15.890277  2295 solver.cpp:270] Iteration 10000 (3.44307 iter/s, 14.5219s/50 iter), loss = 0.00782348, remaining 0 hours and 9 minutes
I0108 21:31:15.890309  2295 solver.cpp:291]     Train net output #0: loss = 0.00782346 (* 1 = 0.00782346 loss)
I0108 21:31:15.890318  2295 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0108 21:31:28.857513  2295 solver.cpp:270] Iteration 10050 (3.85603 iter/s, 12.9667s/50 iter), loss = 0.00289341, remaining 0 hours and 8 minutes
I0108 21:31:28.857549  2295 solver.cpp:291]     Train net output #0: loss = 0.00289339 (* 1 = 0.00289339 loss)
I0108 21:31:28.857558  2295 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0108 21:31:41.840827  2295 solver.cpp:270] Iteration 10100 (3.85125 iter/s, 12.9828s/50 iter), loss = 0.00220689, remaining 0 hours and 8 minutes
I0108 21:31:41.840873  2295 solver.cpp:291]     Train net output #0: loss = 0.00220687 (* 1 = 0.00220687 loss)
I0108 21:31:41.840880  2295 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0108 21:31:54.806732  2295 solver.cpp:270] Iteration 10150 (3.85642 iter/s, 12.9654s/50 iter), loss = 0.00556381, remaining 0 hours and 7 minutes
I0108 21:31:54.806763  2295 solver.cpp:291]     Train net output #0: loss = 0.0055638 (* 1 = 0.0055638 loss)
I0108 21:31:54.806771  2295 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0108 21:32:07.798085  2295 solver.cpp:270] Iteration 10200 (3.84887 iter/s, 12.9908s/50 iter), loss = 0.00550556, remaining 0 hours and 7 minutes
I0108 21:32:07.798116  2295 solver.cpp:291]     Train net output #0: loss = 0.00550555 (* 1 = 0.00550555 loss)
I0108 21:32:07.798125  2295 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0108 21:32:20.766492  2295 solver.cpp:270] Iteration 10250 (3.85568 iter/s, 12.9679s/50 iter), loss = 0.00166769, remaining 0 hours and 7 minutes
I0108 21:32:20.766538  2295 solver.cpp:291]     Train net output #0: loss = 0.00166767 (* 1 = 0.00166767 loss)
I0108 21:32:20.766546  2295 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0108 21:32:33.746544  2295 solver.cpp:270] Iteration 10300 (3.85222 iter/s, 12.9795s/50 iter), loss = 0.00615349, remaining 0 hours and 7 minutes
I0108 21:32:33.746578  2295 solver.cpp:291]     Train net output #0: loss = 0.00615348 (* 1 = 0.00615348 loss)
I0108 21:32:33.746585  2295 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0108 21:32:46.737295  2295 solver.cpp:270] Iteration 10350 (3.84905 iter/s, 12.9902s/50 iter), loss = 0.00568833, remaining 0 hours and 7 minutes
I0108 21:32:46.737327  2295 solver.cpp:291]     Train net output #0: loss = 0.00568831 (* 1 = 0.00568831 loss)
I0108 21:32:46.737350  2295 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0108 21:32:59.721690  2295 solver.cpp:270] Iteration 10400 (3.85093 iter/s, 12.9839s/50 iter), loss = 0.0102656, remaining 0 hours and 6 minutes
I0108 21:32:59.721742  2295 solver.cpp:291]     Train net output #0: loss = 0.0102655 (* 1 = 0.0102655 loss)
I0108 21:32:59.721750  2295 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0108 21:33:12.694813  2295 solver.cpp:270] Iteration 10450 (3.85428 iter/s, 12.9726s/50 iter), loss = 0.0294698, remaining 0 hours and 6 minutes
I0108 21:33:12.694844  2295 solver.cpp:291]     Train net output #0: loss = 0.0294698 (* 1 = 0.0294698 loss)
I0108 21:33:12.694852  2295 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0108 21:33:25.678063  2295 solver.cpp:270] Iteration 10500 (3.85127 iter/s, 12.9827s/50 iter), loss = 0.00493332, remaining 0 hours and 6 minutes
I0108 21:33:25.678094  2295 solver.cpp:291]     Train net output #0: loss = 0.00493331 (* 1 = 0.00493331 loss)
I0108 21:33:25.678102  2295 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0108 21:33:38.660198  2295 solver.cpp:270] Iteration 10550 (3.8516 iter/s, 12.9816s/50 iter), loss = 0.00590071, remaining 0 hours and 6 minutes
I0108 21:33:38.660260  2295 solver.cpp:291]     Train net output #0: loss = 0.0059007 (* 1 = 0.0059007 loss)
I0108 21:33:38.660267  2295 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0108 21:33:51.609874  2295 solver.cpp:270] Iteration 10600 (3.86126 iter/s, 12.9491s/50 iter), loss = 0.00129911, remaining 0 hours and 5 minutes
I0108 21:33:51.609907  2295 solver.cpp:291]     Train net output #0: loss = 0.00129909 (* 1 = 0.00129909 loss)
I0108 21:33:51.609915  2295 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0108 21:34:04.593425  2295 solver.cpp:270] Iteration 10650 (3.85118 iter/s, 12.983s/50 iter), loss = 0.00534045, remaining 0 hours and 5 minutes
I0108 21:34:04.593456  2295 solver.cpp:291]     Train net output #0: loss = 0.00534044 (* 1 = 0.00534044 loss)
I0108 21:34:04.593479  2295 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0108 21:34:17.578085  2295 solver.cpp:270] Iteration 10700 (3.85085 iter/s, 12.9841s/50 iter), loss = 0.00731551, remaining 0 hours and 5 minutes
I0108 21:34:17.578132  2295 solver.cpp:291]     Train net output #0: loss = 0.0073155 (* 1 = 0.0073155 loss)
I0108 21:34:17.578140  2295 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0108 21:34:30.568079  2295 solver.cpp:270] Iteration 10750 (3.84927 iter/s, 12.9895s/50 iter), loss = 0.00275626, remaining 0 hours and 5 minutes
I0108 21:34:30.568112  2295 solver.cpp:291]     Train net output #0: loss = 0.00275624 (* 1 = 0.00275624 loss)
I0108 21:34:30.568120  2295 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0108 21:34:43.538575  2295 solver.cpp:270] Iteration 10800 (3.85506 iter/s, 12.97s/50 iter), loss = 0.00721041, remaining 0 hours and 5 minutes
I0108 21:34:43.538607  2295 solver.cpp:291]     Train net output #0: loss = 0.00721039 (* 1 = 0.00721039 loss)
I0108 21:34:43.538615  2295 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0108 21:34:56.518910  2295 solver.cpp:270] Iteration 10850 (3.85213 iter/s, 12.9798s/50 iter), loss = 0.00313361, remaining 0 hours and 4 minutes
I0108 21:34:56.518955  2295 solver.cpp:291]     Train net output #0: loss = 0.0031336 (* 1 = 0.0031336 loss)
I0108 21:34:56.518962  2295 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0108 21:35:09.494043  2295 solver.cpp:270] Iteration 10900 (3.85368 iter/s, 12.9746s/50 iter), loss = 0.00227135, remaining 0 hours and 4 minutes
I0108 21:35:09.494076  2295 solver.cpp:291]     Train net output #0: loss = 0.00227134 (* 1 = 0.00227134 loss)
I0108 21:35:09.494098  2295 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0108 21:35:22.472157  2295 solver.cpp:270] Iteration 10950 (3.85279 iter/s, 12.9776s/50 iter), loss = 0.0187237, remaining 0 hours and 4 minutes
I0108 21:35:22.472189  2295 solver.cpp:291]     Train net output #0: loss = 0.0187237 (* 1 = 0.0187237 loss)
I0108 21:35:22.472196  2295 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0108 21:35:35.182530  2295 solver.cpp:424] Iteration 11000, Testing net (#0)
I0108 21:35:36.716424  2295 solver.cpp:523]     Test net output #0: accuracy = 0.9485
I0108 21:35:36.716451  2295 solver.cpp:523]     Test net output #1: loss = 0.260399 (* 1 = 0.260399 loss)
I0108 21:35:36.716456  2295 solver.cpp:523]     Test net output #2: top-1 = 0.9485
I0108 21:35:36.965456  2295 solver.cpp:270] Iteration 11000 (3.45001 iter/s, 14.4927s/50 iter), loss = 0.00536241, remaining 0 hours and 4 minutes
I0108 21:35:36.965481  2295 solver.cpp:291]     Train net output #0: loss = 0.0053624 (* 1 = 0.0053624 loss)
I0108 21:35:36.965489  2295 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0108 21:35:49.963060  2295 solver.cpp:270] Iteration 11050 (3.84701 iter/s, 12.9971s/50 iter), loss = 0.0136369, remaining 0 hours and 3 minutes
I0108 21:35:49.963091  2295 solver.cpp:291]     Train net output #0: loss = 0.0136369 (* 1 = 0.0136369 loss)
I0108 21:35:49.963099  2295 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0108 21:36:02.931277  2295 solver.cpp:270] Iteration 11100 (3.85573 iter/s, 12.9677s/50 iter), loss = 0.0280155, remaining 0 hours and 3 minutes
I0108 21:36:02.931310  2295 solver.cpp:291]     Train net output #0: loss = 0.0280155 (* 1 = 0.0280155 loss)
I0108 21:36:02.931334  2295 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0108 21:36:15.943699  2295 solver.cpp:270] Iteration 11150 (3.84264 iter/s, 13.0119s/50 iter), loss = 0.0038202, remaining 0 hours and 3 minutes
I0108 21:36:15.943756  2295 solver.cpp:291]     Train net output #0: loss = 0.00382019 (* 1 = 0.00382019 loss)
I0108 21:36:15.943763  2295 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0108 21:36:28.920192  2295 solver.cpp:270] Iteration 11200 (3.85328 iter/s, 12.976s/50 iter), loss = 0.015296, remaining 0 hours and 3 minutes
I0108 21:36:28.920223  2295 solver.cpp:291]     Train net output #0: loss = 0.015296 (* 1 = 0.015296 loss)
I0108 21:36:28.920230  2295 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0108 21:36:41.909534  2295 solver.cpp:270] Iteration 11250 (3.84946 iter/s, 12.9888s/50 iter), loss = 0.00868167, remaining 0 hours and 3 minutes
I0108 21:36:41.909569  2295 solver.cpp:291]     Train net output #0: loss = 0.00868167 (* 1 = 0.00868167 loss)
I0108 21:36:41.909575  2295 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0108 21:36:54.871409  2295 solver.cpp:270] Iteration 11300 (3.85762 iter/s, 12.9614s/50 iter), loss = 0.00844001, remaining 0 hours and 2 minutes
I0108 21:36:54.871456  2295 solver.cpp:291]     Train net output #0: loss = 0.00844001 (* 1 = 0.00844001 loss)
I0108 21:36:54.871464  2295 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0108 21:37:07.828941  2295 solver.cpp:270] Iteration 11350 (3.85892 iter/s, 12.957s/50 iter), loss = 0.00388257, remaining 0 hours and 2 minutes
I0108 21:37:07.828972  2295 solver.cpp:291]     Train net output #0: loss = 0.00388257 (* 1 = 0.00388257 loss)
I0108 21:37:07.828979  2295 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0108 21:37:20.816880  2295 solver.cpp:270] Iteration 11400 (3.84988 iter/s, 12.9874s/50 iter), loss = 0.00575328, remaining 0 hours and 2 minutes
I0108 21:37:20.816912  2295 solver.cpp:291]     Train net output #0: loss = 0.00575328 (* 1 = 0.00575328 loss)
I0108 21:37:20.816920  2295 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0108 21:37:33.804091  2295 solver.cpp:270] Iteration 11450 (3.85009 iter/s, 12.9867s/50 iter), loss = 0.00141529, remaining 0 hours and 2 minutes
I0108 21:37:33.804136  2295 solver.cpp:291]     Train net output #0: loss = 0.00141528 (* 1 = 0.00141528 loss)
I0108 21:37:33.804159  2295 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0108 21:37:46.767938  2295 solver.cpp:270] Iteration 11500 (3.85704 iter/s, 12.9633s/50 iter), loss = 0.00363845, remaining 0 hours and 2 minutes
I0108 21:37:46.767971  2295 solver.cpp:291]     Train net output #0: loss = 0.00363845 (* 1 = 0.00363845 loss)
I0108 21:37:46.767979  2295 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0108 21:37:59.758491  2295 solver.cpp:270] Iteration 11550 (3.84911 iter/s, 12.99s/50 iter), loss = 0.00507377, remaining 0 hours and 1 minutes
I0108 21:37:59.758523  2295 solver.cpp:291]     Train net output #0: loss = 0.00507377 (* 1 = 0.00507377 loss)
I0108 21:37:59.758531  2295 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0108 21:38:12.736908  2295 solver.cpp:270] Iteration 11600 (3.8527 iter/s, 12.9779s/50 iter), loss = 0.00234737, remaining 0 hours and 1 minutes
I0108 21:38:12.736964  2295 solver.cpp:291]     Train net output #0: loss = 0.00234737 (* 1 = 0.00234737 loss)
I0108 21:38:12.736972  2295 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0108 21:38:25.710458  2295 solver.cpp:270] Iteration 11650 (3.85416 iter/s, 12.973s/50 iter), loss = 0.00928401, remaining 0 hours and 1 minutes
I0108 21:38:25.710489  2295 solver.cpp:291]     Train net output #0: loss = 0.00928401 (* 1 = 0.00928401 loss)
I0108 21:38:25.710497  2295 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0108 21:38:38.674258  2295 solver.cpp:270] Iteration 11700 (3.85705 iter/s, 12.9633s/50 iter), loss = 0.00681787, remaining 0 hours and 1 minutes
I0108 21:38:38.674294  2295 solver.cpp:291]     Train net output #0: loss = 0.00681787 (* 1 = 0.00681787 loss)
I0108 21:38:38.674302  2295 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0108 21:38:51.676026  2295 solver.cpp:270] Iteration 11750 (3.84578 iter/s, 13.0012s/50 iter), loss = 0.0152735, remaining 0 hours and 1 minutes
I0108 21:38:51.676070  2295 solver.cpp:291]     Train net output #0: loss = 0.0152735 (* 1 = 0.0152735 loss)
I0108 21:38:51.676077  2295 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0108 21:39:04.661162  2295 solver.cpp:270] Iteration 11800 (3.85071 iter/s, 12.9846s/50 iter), loss = 0.00287741, remaining 0 hours and 0 minutes
I0108 21:39:04.661195  2295 solver.cpp:291]     Train net output #0: loss = 0.00287741 (* 1 = 0.00287741 loss)
I0108 21:39:04.661202  2295 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0108 21:39:17.654882  2295 solver.cpp:270] Iteration 11850 (3.84817 iter/s, 12.9932s/50 iter), loss = 0.000871354, remaining 0 hours and 0 minutes
I0108 21:39:17.654914  2295 solver.cpp:291]     Train net output #0: loss = 0.000871353 (* 1 = 0.000871353 loss)
I0108 21:39:17.654920  2295 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0108 21:39:30.649083  2295 solver.cpp:270] Iteration 11900 (3.84802 iter/s, 12.9937s/50 iter), loss = 0.00161817, remaining 0 hours and 0 minutes
I0108 21:39:30.649128  2295 solver.cpp:291]     Train net output #0: loss = 0.00161817 (* 1 = 0.00161817 loss)
I0108 21:39:30.649137  2295 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0108 21:39:43.644888  2295 solver.cpp:270] Iteration 11950 (3.84755 iter/s, 12.9953s/50 iter), loss = 0.00270582, remaining 0 hours and 0 minutes
I0108 21:39:43.644922  2295 solver.cpp:291]     Train net output #0: loss = 0.00270582 (* 1 = 0.00270582 loss)
I0108 21:39:43.644929  2295 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0108 21:39:56.338634  2295 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.1/snapshots/_iter_12000.caffemodel
I0108 21:39:58.735165  2295 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.1/snapshots/_iter_12000.solverstate
I0108 21:39:59.055079  2295 solver.cpp:384] Iteration 12000, loss = 0.00243039
I0108 21:39:59.055107  2295 solver.cpp:424] Iteration 12000, Testing net (#0)
I0108 21:40:00.517405  2295 solver.cpp:523]     Test net output #0: accuracy = 0.9485
I0108 21:40:00.517431  2295 solver.cpp:523]     Test net output #1: loss = 0.263775 (* 1 = 0.263775 loss)
I0108 21:40:00.517434  2295 solver.cpp:523]     Test net output #2: top-1 = 0.9485
I0108 21:40:00.517438  2295 solver.cpp:392] Optimization Done (3.8419 iter/s).
I0108 21:40:00.517442  2295 caffe_interface.cpp:546] Optimization Done.
(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

I0108 21:40:01.193459  2392 pruning_runner.cpp:206] Analysis info found.
I0108 21:40:02.718004  2392 pruning_runner.cpp:237] Start pruning, please wait...
I0108 21:40:09.295382  2392 pruning_runner.cpp:284] Compression complete 0.39923%
I0108 21:40:17.521865  2392 pruning_runner.cpp:337] pruning done, output model: pruning/alexnetBNnoLRN/regular_rate_0.2/sparse.caffemodel
I0108 21:40:17.521893  2392 pruning_runner.cpp:351] summary of REGULAR compression with rate 0.2:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.943749785    | 0.948499799    | 0.00475001335  |
+-------------------------------------------------------------------+
| Weights        | 3.7649951 M    | 1.037413 M     | -72.4458313%   |
+-------------------------------------------------------------------+
| Operations     | 2.1539185 G    | 1.23211837 G   | -42.7964211%   |
+-------------------------------------------------------------------+
To fine-tune the pruned model, please run:
vai_p_caffe finetune -config /workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/config2.prototxt
(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

W0108 21:40:17.677899  2637 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0108 21:40:17.678082  2637 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0108 21:40:17.678117  2637 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0108 21:40:17.682420  2637 vai_p_caffe.cpp:287] pruning/alexnetBNnoLRN/regular_rate_0.2/net_finetune.prototxt
I0108 21:40:17.841969  2637 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0108 21:40:17.841990  2637 gpu_memory.cpp:55] Total memory: 25620447232, Free: 25022103552, dev_info[0]: total=25620447232 free=25022103552
I0108 21:40:17.842779  2637 caffe_interface.cpp:509] Using GPUs 0
I0108 21:40:17.843030  2637 caffe_interface.cpp:514] GPU 0: Quadro P6000
I0108 21:40:18.698766  2637 solver.cpp:51] Initializing solver from parameters:
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 6000
snapshot_prefix: "pruning/alexnetBNnoLRN/regular_rate_0.2/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "pruning/alexnetBNnoLRN/regular_rate_0.2/net_finetune.prototxt"
type: "Adam"
I0108 21:40:18.698930  2637 solver.cpp:99] Creating training net from net file: pruning/alexnetBNnoLRN/regular_rate_0.2/net_finetune.prototxt
I0108 21:40:18.699227  2637 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0108 21:40:18.699241  2637 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0108 21:40:18.699245  2637 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0108 21:40:18.699250  2637 net.cpp:52] Initializing net from parameters:
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0108 21:40:18.699461  2637 layer_factory.hpp:77] Creating layer data
I0108 21:40:18.699594  2637 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 21:40:18.701488  2637 net.cpp:94] Creating Layer data
I0108 21:40:18.701508  2637 net.cpp:409] data -> data
I0108 21:40:18.701521  2637 net.cpp:409] data -> label
I0108 21:40:18.701793  2674 db_lmdb.cpp:35] Opened lmdb input/lmdb/train_lmdb
I0108 21:40:18.701802  2674 db_lmdb.cpp:38] Items count: 20000
I0108 21:40:18.701813  2674 data_reader.cpp:124] TRAIN: reading data using 1 channel(s)
I0108 21:40:18.701994  2637 data_layer.cpp:78] ReshapePrefetch 256, 3, 227, 227
I0108 21:40:18.702128  2637 data_layer.cpp:83] output data size: 256,3,227,227
I0108 21:40:19.207716  2637 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 21:40:19.207804  2637 net.cpp:144] Setting up data
I0108 21:40:19.207809  2637 net.cpp:151] Top shape: 256 3 227 227 (39574272)
I0108 21:40:19.207834  2637 net.cpp:151] Top shape: 256 (256)
I0108 21:40:19.207839  2637 net.cpp:159] Memory required for data: 158298112
I0108 21:40:19.207842  2637 layer_factory.hpp:77] Creating layer conv1
I0108 21:40:19.207857  2637 net.cpp:94] Creating Layer conv1
I0108 21:40:19.207866  2637 net.cpp:435] conv1 <- data
I0108 21:40:19.207875  2637 net.cpp:409] conv1 -> conv1
I0108 21:40:19.208531  2637 net.cpp:144] Setting up conv1
I0108 21:40:19.208539  2637 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0108 21:40:19.208545  2637 net.cpp:159] Memory required for data: 455667712
I0108 21:40:19.208556  2637 layer_factory.hpp:77] Creating layer bn1
I0108 21:40:19.208564  2637 net.cpp:94] Creating Layer bn1
I0108 21:40:19.208568  2637 net.cpp:435] bn1 <- conv1
I0108 21:40:19.208573  2637 net.cpp:409] bn1 -> bn1
I0108 21:40:19.209089  2637 net.cpp:144] Setting up bn1
I0108 21:40:19.209093  2637 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0108 21:40:19.209098  2637 net.cpp:159] Memory required for data: 753037312
I0108 21:40:19.209107  2637 layer_factory.hpp:77] Creating layer relu1
I0108 21:40:19.209112  2637 net.cpp:94] Creating Layer relu1
I0108 21:40:19.209116  2637 net.cpp:435] relu1 <- bn1
I0108 21:40:19.209120  2637 net.cpp:409] relu1 -> relu1
I0108 21:40:19.209136  2637 net.cpp:144] Setting up relu1
I0108 21:40:19.209139  2637 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0108 21:40:19.209143  2637 net.cpp:159] Memory required for data: 1050406912
I0108 21:40:19.209147  2637 layer_factory.hpp:77] Creating layer pool1
I0108 21:40:19.209152  2637 net.cpp:94] Creating Layer pool1
I0108 21:40:19.209156  2637 net.cpp:435] pool1 <- relu1
I0108 21:40:19.209161  2637 net.cpp:409] pool1 -> pool1
I0108 21:40:19.209182  2637 net.cpp:144] Setting up pool1
I0108 21:40:19.209184  2637 net.cpp:151] Top shape: 256 96 27 27 (17915904)
I0108 21:40:19.209189  2637 net.cpp:159] Memory required for data: 1122070528
I0108 21:40:19.209192  2637 layer_factory.hpp:77] Creating layer conv2
I0108 21:40:19.209199  2637 net.cpp:94] Creating Layer conv2
I0108 21:40:19.209203  2637 net.cpp:435] conv2 <- pool1
I0108 21:40:19.209208  2637 net.cpp:409] conv2 -> conv2
I0108 21:40:19.224761  2637 net.cpp:144] Setting up conv2
I0108 21:40:19.224781  2637 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0108 21:40:19.224789  2637 net.cpp:159] Memory required for data: 1313173504
I0108 21:40:19.224802  2637 layer_factory.hpp:77] Creating layer bn2
I0108 21:40:19.224812  2637 net.cpp:94] Creating Layer bn2
I0108 21:40:19.224817  2637 net.cpp:435] bn2 <- conv2
I0108 21:40:19.224825  2637 net.cpp:409] bn2 -> bn2
I0108 21:40:19.225390  2637 net.cpp:144] Setting up bn2
I0108 21:40:19.225401  2637 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0108 21:40:19.225409  2637 net.cpp:159] Memory required for data: 1504276480
I0108 21:40:19.225417  2637 layer_factory.hpp:77] Creating layer relu2
I0108 21:40:19.225423  2637 net.cpp:94] Creating Layer relu2
I0108 21:40:19.225430  2637 net.cpp:435] relu2 <- bn2
I0108 21:40:19.225438  2637 net.cpp:409] relu2 -> relu2
I0108 21:40:19.225461  2637 net.cpp:144] Setting up relu2
I0108 21:40:19.225468  2637 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0108 21:40:19.225476  2637 net.cpp:159] Memory required for data: 1695379456
I0108 21:40:19.225481  2637 layer_factory.hpp:77] Creating layer pool2
I0108 21:40:19.225489  2637 net.cpp:94] Creating Layer pool2
I0108 21:40:19.225494  2637 net.cpp:435] pool2 <- relu2
I0108 21:40:19.225500  2637 net.cpp:409] pool2 -> pool2
I0108 21:40:19.225533  2637 net.cpp:144] Setting up pool2
I0108 21:40:19.225539  2637 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0108 21:40:19.225546  2637 net.cpp:159] Memory required for data: 1739681792
I0108 21:40:19.225551  2637 layer_factory.hpp:77] Creating layer conv3
I0108 21:40:19.225579  2637 net.cpp:94] Creating Layer conv3
I0108 21:40:19.225585  2637 net.cpp:435] conv3 <- pool2
I0108 21:40:19.225591  2637 net.cpp:409] conv3 -> conv3
I0108 21:40:19.243144  2637 net.cpp:144] Setting up conv3
I0108 21:40:19.243163  2637 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 21:40:19.243171  2637 net.cpp:159] Memory required for data: 1806135296
I0108 21:40:19.243181  2637 layer_factory.hpp:77] Creating layer relu3
I0108 21:40:19.243188  2637 net.cpp:94] Creating Layer relu3
I0108 21:40:19.243193  2637 net.cpp:435] relu3 <- conv3
I0108 21:40:19.243199  2637 net.cpp:409] relu3 -> relu3
I0108 21:40:19.243222  2637 net.cpp:144] Setting up relu3
I0108 21:40:19.243227  2637 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 21:40:19.243232  2637 net.cpp:159] Memory required for data: 1872588800
I0108 21:40:19.243237  2637 layer_factory.hpp:77] Creating layer conv4
I0108 21:40:19.243245  2637 net.cpp:94] Creating Layer conv4
I0108 21:40:19.243250  2637 net.cpp:435] conv4 <- relu3
I0108 21:40:19.243255  2637 net.cpp:409] conv4 -> conv4
I0108 21:40:19.271551  2637 net.cpp:144] Setting up conv4
I0108 21:40:19.271679  2637 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 21:40:19.271744  2637 net.cpp:159] Memory required for data: 1939042304
I0108 21:40:19.271816  2637 layer_factory.hpp:77] Creating layer relu4
I0108 21:40:19.271879  2637 net.cpp:94] Creating Layer relu4
I0108 21:40:19.271934  2637 net.cpp:435] relu4 <- conv4
I0108 21:40:19.271991  2637 net.cpp:409] relu4 -> relu4
I0108 21:40:19.272105  2637 net.cpp:144] Setting up relu4
I0108 21:40:19.272161  2637 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 21:40:19.272219  2637 net.cpp:159] Memory required for data: 2005495808
I0108 21:40:19.272274  2637 layer_factory.hpp:77] Creating layer conv5
I0108 21:40:19.272336  2637 net.cpp:94] Creating Layer conv5
I0108 21:40:19.272399  2637 net.cpp:435] conv5 <- relu4
I0108 21:40:19.272459  2637 net.cpp:409] conv5 -> conv5
I0108 21:40:19.290016  2637 net.cpp:144] Setting up conv5
I0108 21:40:19.290035  2637 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0108 21:40:19.290042  2637 net.cpp:159] Memory required for data: 2049798144
I0108 21:40:19.290066  2637 layer_factory.hpp:77] Creating layer relu5
I0108 21:40:19.290072  2637 net.cpp:94] Creating Layer relu5
I0108 21:40:19.290076  2637 net.cpp:435] relu5 <- conv5
I0108 21:40:19.290081  2637 net.cpp:409] relu5 -> relu5
I0108 21:40:19.290104  2637 net.cpp:144] Setting up relu5
I0108 21:40:19.290107  2637 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0108 21:40:19.290112  2637 net.cpp:159] Memory required for data: 2094100480
I0108 21:40:19.290114  2637 layer_factory.hpp:77] Creating layer pool5
I0108 21:40:19.290119  2637 net.cpp:94] Creating Layer pool5
I0108 21:40:19.290122  2637 net.cpp:435] pool5 <- relu5
I0108 21:40:19.290127  2637 net.cpp:409] pool5 -> pool5
I0108 21:40:19.290148  2637 net.cpp:144] Setting up pool5
I0108 21:40:19.290153  2637 net.cpp:151] Top shape: 256 256 6 6 (2359296)
I0108 21:40:19.290158  2637 net.cpp:159] Memory required for data: 2103537664
I0108 21:40:19.290160  2637 layer_factory.hpp:77] Creating layer fc6
I0108 21:40:19.290166  2637 net.cpp:94] Creating Layer fc6
I0108 21:40:19.290169  2637 net.cpp:435] fc6 <- pool5
I0108 21:40:19.290174  2637 net.cpp:409] fc6 -> fc6
I0108 21:40:19.659476  2637 net.cpp:144] Setting up fc6
I0108 21:40:19.659499  2637 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 21:40:19.659507  2637 net.cpp:159] Memory required for data: 2107731968
I0108 21:40:19.659518  2637 layer_factory.hpp:77] Creating layer relu6
I0108 21:40:19.659523  2637 net.cpp:94] Creating Layer relu6
I0108 21:40:19.659528  2637 net.cpp:435] relu6 <- fc6
I0108 21:40:19.659533  2637 net.cpp:409] relu6 -> relu6
I0108 21:40:19.659564  2637 net.cpp:144] Setting up relu6
I0108 21:40:19.659570  2637 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 21:40:19.659574  2637 net.cpp:159] Memory required for data: 2111926272
I0108 21:40:19.659579  2637 layer_factory.hpp:77] Creating layer drop6
I0108 21:40:19.659588  2637 net.cpp:94] Creating Layer drop6
I0108 21:40:19.659613  2637 net.cpp:435] drop6 <- relu6
I0108 21:40:19.659618  2637 net.cpp:409] drop6 -> drop6
I0108 21:40:19.659641  2637 net.cpp:144] Setting up drop6
I0108 21:40:19.659646  2637 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 21:40:19.659651  2637 net.cpp:159] Memory required for data: 2116120576
I0108 21:40:19.659653  2637 layer_factory.hpp:77] Creating layer fc7
I0108 21:40:19.659659  2637 net.cpp:94] Creating Layer fc7
I0108 21:40:19.659663  2637 net.cpp:435] fc7 <- drop6
I0108 21:40:19.659668  2637 net.cpp:409] fc7 -> fc7
I0108 21:40:19.813354  2637 net.cpp:144] Setting up fc7
I0108 21:40:19.813378  2637 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 21:40:19.813386  2637 net.cpp:159] Memory required for data: 2120314880
I0108 21:40:19.813395  2637 layer_factory.hpp:77] Creating layer bn7
I0108 21:40:19.813405  2637 net.cpp:94] Creating Layer bn7
I0108 21:40:19.813410  2637 net.cpp:435] bn7 <- fc7
I0108 21:40:19.813414  2637 net.cpp:409] bn7 -> bn7
I0108 21:40:19.813844  2637 net.cpp:144] Setting up bn7
I0108 21:40:19.813850  2637 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 21:40:19.813855  2637 net.cpp:159] Memory required for data: 2124509184
I0108 21:40:19.813863  2637 layer_factory.hpp:77] Creating layer relu7
I0108 21:40:19.813868  2637 net.cpp:94] Creating Layer relu7
I0108 21:40:19.813871  2637 net.cpp:435] relu7 <- bn7
I0108 21:40:19.813875  2637 net.cpp:409] relu7 -> relu7
I0108 21:40:19.813891  2637 net.cpp:144] Setting up relu7
I0108 21:40:19.813896  2637 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 21:40:19.813917  2637 net.cpp:159] Memory required for data: 2128703488
I0108 21:40:19.813921  2637 layer_factory.hpp:77] Creating layer drop7
I0108 21:40:19.813927  2637 net.cpp:94] Creating Layer drop7
I0108 21:40:19.813931  2637 net.cpp:435] drop7 <- relu7
I0108 21:40:19.813936  2637 net.cpp:409] drop7 -> drop7
I0108 21:40:19.813958  2637 net.cpp:144] Setting up drop7
I0108 21:40:19.813963  2637 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 21:40:19.813967  2637 net.cpp:159] Memory required for data: 2132897792
I0108 21:40:19.813971  2637 layer_factory.hpp:77] Creating layer fc8
I0108 21:40:19.813977  2637 net.cpp:94] Creating Layer fc8
I0108 21:40:19.813982  2637 net.cpp:435] fc8 <- drop7
I0108 21:40:19.813987  2637 net.cpp:409] fc8 -> fc8
I0108 21:40:19.814141  2637 net.cpp:144] Setting up fc8
I0108 21:40:19.814146  2637 net.cpp:151] Top shape: 256 2 (512)
I0108 21:40:19.814152  2637 net.cpp:159] Memory required for data: 2132899840
I0108 21:40:19.814157  2637 layer_factory.hpp:77] Creating layer loss
I0108 21:40:19.814162  2637 net.cpp:94] Creating Layer loss
I0108 21:40:19.814165  2637 net.cpp:435] loss <- fc8
I0108 21:40:19.814169  2637 net.cpp:435] loss <- label
I0108 21:40:19.814174  2637 net.cpp:409] loss -> loss
I0108 21:40:19.814182  2637 layer_factory.hpp:77] Creating layer loss
I0108 21:40:19.814244  2637 net.cpp:144] Setting up loss
I0108 21:40:19.814255  2637 net.cpp:151] Top shape: (1)
I0108 21:40:19.814260  2637 net.cpp:154]     with loss weight 1
I0108 21:40:19.814273  2637 net.cpp:159] Memory required for data: 2132899844
I0108 21:40:19.814276  2637 net.cpp:220] loss needs backward computation.
I0108 21:40:19.814280  2637 net.cpp:220] fc8 needs backward computation.
I0108 21:40:19.814285  2637 net.cpp:220] drop7 needs backward computation.
I0108 21:40:19.814288  2637 net.cpp:220] relu7 needs backward computation.
I0108 21:40:19.814291  2637 net.cpp:220] bn7 needs backward computation.
I0108 21:40:19.814296  2637 net.cpp:220] fc7 needs backward computation.
I0108 21:40:19.814299  2637 net.cpp:220] drop6 needs backward computation.
I0108 21:40:19.814303  2637 net.cpp:220] relu6 needs backward computation.
I0108 21:40:19.814307  2637 net.cpp:220] fc6 needs backward computation.
I0108 21:40:19.814311  2637 net.cpp:220] pool5 needs backward computation.
I0108 21:40:19.814316  2637 net.cpp:220] relu5 needs backward computation.
I0108 21:40:19.814319  2637 net.cpp:220] conv5 needs backward computation.
I0108 21:40:19.814323  2637 net.cpp:220] relu4 needs backward computation.
I0108 21:40:19.814342  2637 net.cpp:220] conv4 needs backward computation.
I0108 21:40:19.814347  2637 net.cpp:220] relu3 needs backward computation.
I0108 21:40:19.814350  2637 net.cpp:220] conv3 needs backward computation.
I0108 21:40:19.814354  2637 net.cpp:220] pool2 needs backward computation.
I0108 21:40:19.814358  2637 net.cpp:220] relu2 needs backward computation.
I0108 21:40:19.814363  2637 net.cpp:220] bn2 needs backward computation.
I0108 21:40:19.814366  2637 net.cpp:220] conv2 needs backward computation.
I0108 21:40:19.814370  2637 net.cpp:220] pool1 needs backward computation.
I0108 21:40:19.814374  2637 net.cpp:220] relu1 needs backward computation.
I0108 21:40:19.814378  2637 net.cpp:220] bn1 needs backward computation.
I0108 21:40:19.814383  2637 net.cpp:220] conv1 needs backward computation.
I0108 21:40:19.814386  2637 net.cpp:222] data does not need backward computation.
I0108 21:40:19.814390  2637 net.cpp:264] This network produces output loss
I0108 21:40:19.814410  2637 net.cpp:284] Network initialization done.
I0108 21:40:19.814783  2637 solver.cpp:189] Creating test net (#0) specified by net file: pruning/alexnetBNnoLRN/regular_rate_0.2/net_finetune.prototxt
I0108 21:40:19.814817  2637 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0108 21:40:19.814833  2637 net.cpp:52] Initializing net from parameters:
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0108 21:40:19.815083  2637 layer_factory.hpp:77] Creating layer data
I0108 21:40:19.815124  2637 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 21:40:19.818086  2637 net.cpp:94] Creating Layer data
I0108 21:40:19.818114  2637 net.cpp:409] data -> data
I0108 21:40:19.818133  2637 net.cpp:409] data -> label
I0108 21:40:19.818524  2704 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0108 21:40:19.818545  2704 db_lmdb.cpp:38] Items count: 4000
I0108 21:40:19.818565  2704 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0108 21:40:19.818881  2637 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0108 21:40:19.819133  2637 data_layer.cpp:83] output data size: 50,3,227,227
I0108 21:40:19.928268  2637 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 21:40:19.928370  2637 net.cpp:144] Setting up data
I0108 21:40:19.928377  2637 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0108 21:40:19.928385  2637 net.cpp:151] Top shape: 50 (50)
I0108 21:40:19.928390  2637 net.cpp:159] Memory required for data: 30917600
I0108 21:40:19.928395  2637 layer_factory.hpp:77] Creating layer label_data_1_split
I0108 21:40:19.928402  2637 net.cpp:94] Creating Layer label_data_1_split
I0108 21:40:19.928406  2637 net.cpp:435] label_data_1_split <- label
I0108 21:40:19.928412  2637 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0108 21:40:19.928421  2637 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0108 21:40:19.928426  2637 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0108 21:40:19.928493  2637 net.cpp:144] Setting up label_data_1_split
I0108 21:40:19.928498  2637 net.cpp:151] Top shape: 50 (50)
I0108 21:40:19.928501  2637 net.cpp:151] Top shape: 50 (50)
I0108 21:40:19.928505  2637 net.cpp:151] Top shape: 50 (50)
I0108 21:40:19.928510  2637 net.cpp:159] Memory required for data: 30918200
I0108 21:40:19.928514  2637 layer_factory.hpp:77] Creating layer conv1
I0108 21:40:19.928524  2637 net.cpp:94] Creating Layer conv1
I0108 21:40:19.928527  2637 net.cpp:435] conv1 <- data
I0108 21:40:19.928531  2637 net.cpp:409] conv1 -> conv1
I0108 21:40:19.929129  2637 net.cpp:144] Setting up conv1
I0108 21:40:19.929136  2637 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0108 21:40:19.929141  2637 net.cpp:159] Memory required for data: 88998200
I0108 21:40:19.929152  2637 layer_factory.hpp:77] Creating layer bn1
I0108 21:40:19.929159  2637 net.cpp:94] Creating Layer bn1
I0108 21:40:19.929167  2637 net.cpp:435] bn1 <- conv1
I0108 21:40:19.929172  2637 net.cpp:409] bn1 -> bn1
I0108 21:40:19.929698  2637 net.cpp:144] Setting up bn1
I0108 21:40:19.929704  2637 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0108 21:40:19.929710  2637 net.cpp:159] Memory required for data: 147078200
I0108 21:40:19.929719  2637 layer_factory.hpp:77] Creating layer relu1
I0108 21:40:19.929726  2637 net.cpp:94] Creating Layer relu1
I0108 21:40:19.929729  2637 net.cpp:435] relu1 <- bn1
I0108 21:40:19.929734  2637 net.cpp:409] relu1 -> relu1
I0108 21:40:19.929750  2637 net.cpp:144] Setting up relu1
I0108 21:40:19.929755  2637 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0108 21:40:19.929761  2637 net.cpp:159] Memory required for data: 205158200
I0108 21:40:19.929764  2637 layer_factory.hpp:77] Creating layer pool1
I0108 21:40:19.929769  2637 net.cpp:94] Creating Layer pool1
I0108 21:40:19.929774  2637 net.cpp:435] pool1 <- relu1
I0108 21:40:19.929778  2637 net.cpp:409] pool1 -> pool1
I0108 21:40:19.929801  2637 net.cpp:144] Setting up pool1
I0108 21:40:19.929807  2637 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0108 21:40:19.929812  2637 net.cpp:159] Memory required for data: 219155000
I0108 21:40:19.929816  2637 layer_factory.hpp:77] Creating layer conv2
I0108 21:40:19.929822  2637 net.cpp:94] Creating Layer conv2
I0108 21:40:19.929826  2637 net.cpp:435] conv2 <- pool1
I0108 21:40:19.929831  2637 net.cpp:409] conv2 -> conv2
I0108 21:40:19.936952  2637 net.cpp:144] Setting up conv2
I0108 21:40:19.936971  2637 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0108 21:40:19.936980  2637 net.cpp:159] Memory required for data: 256479800
I0108 21:40:19.936990  2637 layer_factory.hpp:77] Creating layer bn2
I0108 21:40:19.937000  2637 net.cpp:94] Creating Layer bn2
I0108 21:40:19.937005  2637 net.cpp:435] bn2 <- conv2
I0108 21:40:19.937011  2637 net.cpp:409] bn2 -> bn2
I0108 21:40:19.937471  2637 net.cpp:144] Setting up bn2
I0108 21:40:19.937480  2637 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0108 21:40:19.937485  2637 net.cpp:159] Memory required for data: 293804600
I0108 21:40:19.937494  2637 layer_factory.hpp:77] Creating layer relu2
I0108 21:40:19.937500  2637 net.cpp:94] Creating Layer relu2
I0108 21:40:19.937503  2637 net.cpp:435] relu2 <- bn2
I0108 21:40:19.937508  2637 net.cpp:409] relu2 -> relu2
I0108 21:40:19.937525  2637 net.cpp:144] Setting up relu2
I0108 21:40:19.937541  2637 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0108 21:40:19.937546  2637 net.cpp:159] Memory required for data: 331129400
I0108 21:40:19.937549  2637 layer_factory.hpp:77] Creating layer pool2
I0108 21:40:19.937554  2637 net.cpp:94] Creating Layer pool2
I0108 21:40:19.937559  2637 net.cpp:435] pool2 <- relu2
I0108 21:40:19.937563  2637 net.cpp:409] pool2 -> pool2
I0108 21:40:19.937588  2637 net.cpp:144] Setting up pool2
I0108 21:40:19.937595  2637 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0108 21:40:19.937600  2637 net.cpp:159] Memory required for data: 339782200
I0108 21:40:19.937604  2637 layer_factory.hpp:77] Creating layer conv3
I0108 21:40:19.937613  2637 net.cpp:94] Creating Layer conv3
I0108 21:40:19.937618  2637 net.cpp:435] conv3 <- pool2
I0108 21:40:19.937623  2637 net.cpp:409] conv3 -> conv3
I0108 21:40:19.949326  2637 net.cpp:144] Setting up conv3
I0108 21:40:19.949348  2637 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 21:40:19.949359  2637 net.cpp:159] Memory required for data: 352761400
I0108 21:40:19.949369  2637 layer_factory.hpp:77] Creating layer relu3
I0108 21:40:19.949376  2637 net.cpp:94] Creating Layer relu3
I0108 21:40:19.949381  2637 net.cpp:435] relu3 <- conv3
I0108 21:40:19.949388  2637 net.cpp:409] relu3 -> relu3
I0108 21:40:19.949411  2637 net.cpp:144] Setting up relu3
I0108 21:40:19.949417  2637 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 21:40:19.949422  2637 net.cpp:159] Memory required for data: 365740600
I0108 21:40:19.949426  2637 layer_factory.hpp:77] Creating layer conv4
I0108 21:40:19.949434  2637 net.cpp:94] Creating Layer conv4
I0108 21:40:19.949438  2637 net.cpp:435] conv4 <- relu3
I0108 21:40:19.949443  2637 net.cpp:409] conv4 -> conv4
I0108 21:40:19.965710  2637 net.cpp:144] Setting up conv4
I0108 21:40:19.965730  2637 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 21:40:19.965739  2637 net.cpp:159] Memory required for data: 378719800
I0108 21:40:19.965767  2637 layer_factory.hpp:77] Creating layer relu4
I0108 21:40:19.965775  2637 net.cpp:94] Creating Layer relu4
I0108 21:40:19.965781  2637 net.cpp:435] relu4 <- conv4
I0108 21:40:19.965788  2637 net.cpp:409] relu4 -> relu4
I0108 21:40:19.965816  2637 net.cpp:144] Setting up relu4
I0108 21:40:19.965819  2637 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 21:40:19.965824  2637 net.cpp:159] Memory required for data: 391699000
I0108 21:40:19.965828  2637 layer_factory.hpp:77] Creating layer conv5
I0108 21:40:19.965839  2637 net.cpp:94] Creating Layer conv5
I0108 21:40:19.965843  2637 net.cpp:435] conv5 <- relu4
I0108 21:40:19.965848  2637 net.cpp:409] conv5 -> conv5
I0108 21:40:19.976357  2637 net.cpp:144] Setting up conv5
I0108 21:40:19.976380  2637 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0108 21:40:19.976392  2637 net.cpp:159] Memory required for data: 400351800
I0108 21:40:19.976402  2637 layer_factory.hpp:77] Creating layer relu5
I0108 21:40:19.976408  2637 net.cpp:94] Creating Layer relu5
I0108 21:40:19.976414  2637 net.cpp:435] relu5 <- conv5
I0108 21:40:19.976421  2637 net.cpp:409] relu5 -> relu5
I0108 21:40:19.976446  2637 net.cpp:144] Setting up relu5
I0108 21:40:19.976452  2637 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0108 21:40:19.976457  2637 net.cpp:159] Memory required for data: 409004600
I0108 21:40:19.976461  2637 layer_factory.hpp:77] Creating layer pool5
I0108 21:40:19.976473  2637 net.cpp:94] Creating Layer pool5
I0108 21:40:19.976477  2637 net.cpp:435] pool5 <- relu5
I0108 21:40:19.976481  2637 net.cpp:409] pool5 -> pool5
I0108 21:40:19.976506  2637 net.cpp:144] Setting up pool5
I0108 21:40:19.976516  2637 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0108 21:40:19.976521  2637 net.cpp:159] Memory required for data: 410847800
I0108 21:40:19.976524  2637 layer_factory.hpp:77] Creating layer fc6
I0108 21:40:19.976531  2637 net.cpp:94] Creating Layer fc6
I0108 21:40:19.976536  2637 net.cpp:435] fc6 <- pool5
I0108 21:40:19.976541  2637 net.cpp:409] fc6 -> fc6
I0108 21:40:20.316632  2637 net.cpp:144] Setting up fc6
I0108 21:40:20.316655  2637 net.cpp:151] Top shape: 50 4096 (204800)
I0108 21:40:20.316680  2637 net.cpp:159] Memory required for data: 411667000
I0108 21:40:20.316690  2637 layer_factory.hpp:77] Creating layer relu6
I0108 21:40:20.316697  2637 net.cpp:94] Creating Layer relu6
I0108 21:40:20.316716  2637 net.cpp:435] relu6 <- fc6
I0108 21:40:20.316725  2637 net.cpp:409] relu6 -> relu6
I0108 21:40:20.316751  2637 net.cpp:144] Setting up relu6
I0108 21:40:20.316757  2637 net.cpp:151] Top shape: 50 4096 (204800)
I0108 21:40:20.316761  2637 net.cpp:159] Memory required for data: 412486200
I0108 21:40:20.316764  2637 layer_factory.hpp:77] Creating layer drop6
I0108 21:40:20.316771  2637 net.cpp:94] Creating Layer drop6
I0108 21:40:20.316773  2637 net.cpp:435] drop6 <- relu6
I0108 21:40:20.316777  2637 net.cpp:409] drop6 -> drop6
I0108 21:40:20.316797  2637 net.cpp:144] Setting up drop6
I0108 21:40:20.316799  2637 net.cpp:151] Top shape: 50 4096 (204800)
I0108 21:40:20.316802  2637 net.cpp:159] Memory required for data: 413305400
I0108 21:40:20.316805  2637 layer_factory.hpp:77] Creating layer fc7
I0108 21:40:20.316812  2637 net.cpp:94] Creating Layer fc7
I0108 21:40:20.316814  2637 net.cpp:435] fc7 <- drop6
I0108 21:40:20.316818  2637 net.cpp:409] fc7 -> fc7
I0108 21:40:20.461604  2637 net.cpp:144] Setting up fc7
I0108 21:40:20.461629  2637 net.cpp:151] Top shape: 50 4096 (204800)
I0108 21:40:20.461637  2637 net.cpp:159] Memory required for data: 414124600
I0108 21:40:20.461645  2637 layer_factory.hpp:77] Creating layer bn7
I0108 21:40:20.461655  2637 net.cpp:94] Creating Layer bn7
I0108 21:40:20.461659  2637 net.cpp:435] bn7 <- fc7
I0108 21:40:20.461664  2637 net.cpp:409] bn7 -> bn7
I0108 21:40:20.462111  2637 net.cpp:144] Setting up bn7
I0108 21:40:20.462118  2637 net.cpp:151] Top shape: 50 4096 (204800)
I0108 21:40:20.462122  2637 net.cpp:159] Memory required for data: 414943800
I0108 21:40:20.462129  2637 layer_factory.hpp:77] Creating layer relu7
I0108 21:40:20.462133  2637 net.cpp:94] Creating Layer relu7
I0108 21:40:20.462137  2637 net.cpp:435] relu7 <- bn7
I0108 21:40:20.462141  2637 net.cpp:409] relu7 -> relu7
I0108 21:40:20.462172  2637 net.cpp:144] Setting up relu7
I0108 21:40:20.462177  2637 net.cpp:151] Top shape: 50 4096 (204800)
I0108 21:40:20.462182  2637 net.cpp:159] Memory required for data: 415763000
I0108 21:40:20.462185  2637 layer_factory.hpp:77] Creating layer drop7
I0108 21:40:20.462191  2637 net.cpp:94] Creating Layer drop7
I0108 21:40:20.462194  2637 net.cpp:435] drop7 <- relu7
I0108 21:40:20.462199  2637 net.cpp:409] drop7 -> drop7
I0108 21:40:20.462220  2637 net.cpp:144] Setting up drop7
I0108 21:40:20.462225  2637 net.cpp:151] Top shape: 50 4096 (204800)
I0108 21:40:20.462230  2637 net.cpp:159] Memory required for data: 416582200
I0108 21:40:20.462234  2637 layer_factory.hpp:77] Creating layer fc8
I0108 21:40:20.462239  2637 net.cpp:94] Creating Layer fc8
I0108 21:40:20.462244  2637 net.cpp:435] fc8 <- drop7
I0108 21:40:20.462270  2637 net.cpp:409] fc8 -> fc8
I0108 21:40:20.462431  2637 net.cpp:144] Setting up fc8
I0108 21:40:20.462436  2637 net.cpp:151] Top shape: 50 2 (100)
I0108 21:40:20.462441  2637 net.cpp:159] Memory required for data: 416582600
I0108 21:40:20.462446  2637 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0108 21:40:20.462452  2637 net.cpp:94] Creating Layer fc8_fc8_0_split
I0108 21:40:20.462456  2637 net.cpp:435] fc8_fc8_0_split <- fc8
I0108 21:40:20.462460  2637 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0108 21:40:20.462467  2637 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0108 21:40:20.462472  2637 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0108 21:40:20.462504  2637 net.cpp:144] Setting up fc8_fc8_0_split
I0108 21:40:20.462510  2637 net.cpp:151] Top shape: 50 2 (100)
I0108 21:40:20.462515  2637 net.cpp:151] Top shape: 50 2 (100)
I0108 21:40:20.462519  2637 net.cpp:151] Top shape: 50 2 (100)
I0108 21:40:20.462523  2637 net.cpp:159] Memory required for data: 416583800
I0108 21:40:20.462527  2637 layer_factory.hpp:77] Creating layer accuracy
I0108 21:40:20.462533  2637 net.cpp:94] Creating Layer accuracy
I0108 21:40:20.462548  2637 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0108 21:40:20.462553  2637 net.cpp:435] accuracy <- label_data_1_split_0
I0108 21:40:20.462558  2637 net.cpp:409] accuracy -> accuracy
I0108 21:40:20.462565  2637 net.cpp:144] Setting up accuracy
I0108 21:40:20.462568  2637 net.cpp:151] Top shape: (1)
I0108 21:40:20.462572  2637 net.cpp:159] Memory required for data: 416583804
I0108 21:40:20.462576  2637 layer_factory.hpp:77] Creating layer loss
I0108 21:40:20.462581  2637 net.cpp:94] Creating Layer loss
I0108 21:40:20.462585  2637 net.cpp:435] loss <- fc8_fc8_0_split_1
I0108 21:40:20.462589  2637 net.cpp:435] loss <- label_data_1_split_1
I0108 21:40:20.462594  2637 net.cpp:409] loss -> loss
I0108 21:40:20.462608  2637 layer_factory.hpp:77] Creating layer loss
I0108 21:40:20.462680  2637 net.cpp:144] Setting up loss
I0108 21:40:20.462687  2637 net.cpp:151] Top shape: (1)
I0108 21:40:20.462690  2637 net.cpp:154]     with loss weight 1
I0108 21:40:20.462702  2637 net.cpp:159] Memory required for data: 416583808
I0108 21:40:20.462707  2637 layer_factory.hpp:77] Creating layer accuracy-top1
I0108 21:40:20.462711  2637 net.cpp:94] Creating Layer accuracy-top1
I0108 21:40:20.462715  2637 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0108 21:40:20.462719  2637 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0108 21:40:20.462724  2637 net.cpp:409] accuracy-top1 -> top-1
I0108 21:40:20.462730  2637 net.cpp:144] Setting up accuracy-top1
I0108 21:40:20.462733  2637 net.cpp:151] Top shape: (1)
I0108 21:40:20.462738  2637 net.cpp:159] Memory required for data: 416583812
I0108 21:40:20.462741  2637 net.cpp:222] accuracy-top1 does not need backward computation.
I0108 21:40:20.462745  2637 net.cpp:220] loss needs backward computation.
I0108 21:40:20.462749  2637 net.cpp:222] accuracy does not need backward computation.
I0108 21:40:20.462754  2637 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0108 21:40:20.462757  2637 net.cpp:220] fc8 needs backward computation.
I0108 21:40:20.462761  2637 net.cpp:220] drop7 needs backward computation.
I0108 21:40:20.462765  2637 net.cpp:220] relu7 needs backward computation.
I0108 21:40:20.462769  2637 net.cpp:220] bn7 needs backward computation.
I0108 21:40:20.462772  2637 net.cpp:220] fc7 needs backward computation.
I0108 21:40:20.462776  2637 net.cpp:220] drop6 needs backward computation.
I0108 21:40:20.462780  2637 net.cpp:220] relu6 needs backward computation.
I0108 21:40:20.462785  2637 net.cpp:220] fc6 needs backward computation.
I0108 21:40:20.462788  2637 net.cpp:220] pool5 needs backward computation.
I0108 21:40:20.462792  2637 net.cpp:220] relu5 needs backward computation.
I0108 21:40:20.462796  2637 net.cpp:220] conv5 needs backward computation.
I0108 21:40:20.462800  2637 net.cpp:220] relu4 needs backward computation.
I0108 21:40:20.462805  2637 net.cpp:220] conv4 needs backward computation.
I0108 21:40:20.462808  2637 net.cpp:220] relu3 needs backward computation.
I0108 21:40:20.462813  2637 net.cpp:220] conv3 needs backward computation.
I0108 21:40:20.462817  2637 net.cpp:220] pool2 needs backward computation.
I0108 21:40:20.462821  2637 net.cpp:220] relu2 needs backward computation.
I0108 21:40:20.462826  2637 net.cpp:220] bn2 needs backward computation.
I0108 21:40:20.462829  2637 net.cpp:220] conv2 needs backward computation.
I0108 21:40:20.462833  2637 net.cpp:220] pool1 needs backward computation.
I0108 21:40:20.462837  2637 net.cpp:220] relu1 needs backward computation.
I0108 21:40:20.462841  2637 net.cpp:220] bn1 needs backward computation.
I0108 21:40:20.462844  2637 net.cpp:220] conv1 needs backward computation.
I0108 21:40:20.462849  2637 net.cpp:222] label_data_1_split does not need backward computation.
I0108 21:40:20.462854  2637 net.cpp:222] data does not need backward computation.
I0108 21:40:20.462857  2637 net.cpp:264] This network produces output accuracy
I0108 21:40:20.462862  2637 net.cpp:264] This network produces output loss
I0108 21:40:20.462867  2637 net.cpp:264] This network produces output top-1
I0108 21:40:20.462896  2637 net.cpp:284] Network initialization done.
I0108 21:40:20.462966  2637 solver.cpp:63] Solver scaffolding done.
I0108 21:40:20.463985  2637 caffe_interface.cpp:109] Finetuning from pruning/alexnetBNnoLRN/regular_rate_0.2/sparse.caffemodel
I0108 21:40:22.839702  2637 caffe_interface.cpp:543] Starting Optimization
I0108 21:40:22.839727  2637 solver.cpp:341] Solving
I0108 21:40:22.839730  2637 solver.cpp:342] Learning Rate Policy: step
I0108 21:40:22.841135  2637 solver.cpp:424] Iteration 0, Testing net (#0)
I0108 21:40:24.353587  2637 solver.cpp:523]     Test net output #0: accuracy = 0.9485
I0108 21:40:24.353621  2637 solver.cpp:523]     Test net output #1: loss = 0.263775 (* 1 = 0.263775 loss)
I0108 21:40:24.353626  2637 solver.cpp:523]     Test net output #2: top-1 = 0.9485
I0108 21:40:24.623975  2637 solver.cpp:270] Iteration 0 (0 iter/s, 1.78413s/50 iter), loss = 0.00444525, remaining 333333 hours and 20 minutes
I0108 21:40:24.624006  2637 solver.cpp:291]     Train net output #0: loss = 0.00444525 (* 1 = 0.00444525 loss)
I0108 21:40:24.624014  2637 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0108 21:40:37.381489  2637 solver.cpp:270] Iteration 50 (3.91941 iter/s, 12.757s/50 iter), loss = 0.0517896, remaining 0 hours and 50 minutes
I0108 21:40:37.381525  2637 solver.cpp:291]     Train net output #0: loss = 0.0517895 (* 1 = 0.0517895 loss)
I0108 21:40:37.381533  2637 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0108 21:40:50.185220  2637 solver.cpp:270] Iteration 100 (3.90527 iter/s, 12.8032s/50 iter), loss = 0.0934946, remaining 0 hours and 50 minutes
I0108 21:40:50.185266  2637 solver.cpp:291]     Train net output #0: loss = 0.0934945 (* 1 = 0.0934945 loss)
I0108 21:40:50.185273  2637 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0108 21:41:03.013777  2637 solver.cpp:270] Iteration 150 (3.89771 iter/s, 12.828s/50 iter), loss = 0.0658561, remaining 0 hours and 50 minutes
I0108 21:41:03.013810  2637 solver.cpp:291]     Train net output #0: loss = 0.0658561 (* 1 = 0.0658561 loss)
I0108 21:41:03.013818  2637 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0108 21:41:15.869777  2637 solver.cpp:270] Iteration 200 (3.88939 iter/s, 12.8555s/50 iter), loss = 0.110377, remaining 0 hours and 50 minutes
I0108 21:41:15.869812  2637 solver.cpp:291]     Train net output #0: loss = 0.110377 (* 1 = 0.110377 loss)
I0108 21:41:15.869818  2637 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0108 21:41:28.755632  2637 solver.cpp:270] Iteration 250 (3.88038 iter/s, 12.8853s/50 iter), loss = 0.0725859, remaining 0 hours and 50 minutes
I0108 21:41:28.755679  2637 solver.cpp:291]     Train net output #0: loss = 0.0725859 (* 1 = 0.0725859 loss)
I0108 21:41:28.755687  2637 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0108 21:41:41.711091  2637 solver.cpp:270] Iteration 300 (3.85953 iter/s, 12.9549s/50 iter), loss = 0.0861784, remaining 0 hours and 50 minutes
I0108 21:41:41.711123  2637 solver.cpp:291]     Train net output #0: loss = 0.0861783 (* 1 = 0.0861783 loss)
I0108 21:41:41.711130  2637 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0108 21:41:54.695622  2637 solver.cpp:270] Iteration 350 (3.85089 iter/s, 12.984s/50 iter), loss = 0.104604, remaining 0 hours and 50 minutes
I0108 21:41:54.695654  2637 solver.cpp:291]     Train net output #0: loss = 0.104604 (* 1 = 0.104604 loss)
I0108 21:41:54.695662  2637 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0108 21:42:07.685904  2637 solver.cpp:270] Iteration 400 (3.84918 iter/s, 12.9898s/50 iter), loss = 0.0847116, remaining 0 hours and 50 minutes
I0108 21:42:07.685950  2637 solver.cpp:291]     Train net output #0: loss = 0.0847116 (* 1 = 0.0847116 loss)
I0108 21:42:07.685958  2637 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0108 21:42:20.685698  2637 solver.cpp:270] Iteration 450 (3.84637 iter/s, 12.9993s/50 iter), loss = 0.117495, remaining 0 hours and 49 minutes
I0108 21:42:20.685732  2637 solver.cpp:291]     Train net output #0: loss = 0.117495 (* 1 = 0.117495 loss)
I0108 21:42:20.685739  2637 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0108 21:42:33.681255  2637 solver.cpp:270] Iteration 500 (3.84762 iter/s, 12.995s/50 iter), loss = 0.0580602, remaining 0 hours and 49 minutes
I0108 21:42:33.681288  2637 solver.cpp:291]     Train net output #0: loss = 0.0580602 (* 1 = 0.0580602 loss)
I0108 21:42:33.681294  2637 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0108 21:42:46.704962  2637 solver.cpp:270] Iteration 550 (3.83931 iter/s, 13.0232s/50 iter), loss = 0.109043, remaining 0 hours and 49 minutes
I0108 21:42:46.705015  2637 solver.cpp:291]     Train net output #0: loss = 0.109043 (* 1 = 0.109043 loss)
I0108 21:42:46.705024  2637 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0108 21:42:59.705847  2637 solver.cpp:270] Iteration 600 (3.84605 iter/s, 13.0003s/50 iter), loss = 0.066289, remaining 0 hours and 49 minutes
I0108 21:42:59.705883  2637 solver.cpp:291]     Train net output #0: loss = 0.066289 (* 1 = 0.066289 loss)
I0108 21:42:59.705890  2637 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0108 21:43:12.716356  2637 solver.cpp:270] Iteration 650 (3.8432 iter/s, 13.01s/50 iter), loss = 0.0880898, remaining 0 hours and 49 minutes
I0108 21:43:12.716388  2637 solver.cpp:291]     Train net output #0: loss = 0.0880898 (* 1 = 0.0880898 loss)
I0108 21:43:12.716411  2637 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0108 21:43:25.711974  2637 solver.cpp:270] Iteration 700 (3.8476 iter/s, 12.9951s/50 iter), loss = 0.129968, remaining 0 hours and 48 minutes
I0108 21:43:25.712024  2637 solver.cpp:291]     Train net output #0: loss = 0.129968 (* 1 = 0.129968 loss)
I0108 21:43:25.712031  2637 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0108 21:43:38.721204  2637 solver.cpp:270] Iteration 750 (3.84358 iter/s, 13.0087s/50 iter), loss = 0.105559, remaining 0 hours and 48 minutes
I0108 21:43:38.721237  2637 solver.cpp:291]     Train net output #0: loss = 0.105559 (* 1 = 0.105559 loss)
I0108 21:43:38.721244  2637 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0108 21:43:51.714537  2637 solver.cpp:270] Iteration 800 (3.84828 iter/s, 12.9928s/50 iter), loss = 0.0904742, remaining 0 hours and 48 minutes
I0108 21:43:51.714570  2637 solver.cpp:291]     Train net output #0: loss = 0.0904742 (* 1 = 0.0904742 loss)
I0108 21:43:51.714577  2637 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0108 21:44:04.721302  2637 solver.cpp:270] Iteration 850 (3.84431 iter/s, 13.0062s/50 iter), loss = 0.0583356, remaining 0 hours and 48 minutes
I0108 21:44:04.721349  2637 solver.cpp:291]     Train net output #0: loss = 0.0583356 (* 1 = 0.0583356 loss)
I0108 21:44:04.721371  2637 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0108 21:44:17.711578  2637 solver.cpp:270] Iteration 900 (3.84919 iter/s, 12.9897s/50 iter), loss = 0.10198, remaining 0 hours and 48 minutes
I0108 21:44:17.711609  2637 solver.cpp:291]     Train net output #0: loss = 0.10198 (* 1 = 0.10198 loss)
I0108 21:44:17.711616  2637 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0108 21:44:30.709434  2637 solver.cpp:270] Iteration 950 (3.84694 iter/s, 12.9973s/50 iter), loss = 0.0770028, remaining 0 hours and 47 minutes
I0108 21:44:30.709466  2637 solver.cpp:291]     Train net output #0: loss = 0.0770028 (* 1 = 0.0770028 loss)
I0108 21:44:30.709473  2637 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0108 21:44:43.449632  2637 solver.cpp:424] Iteration 1000, Testing net (#0)
I0108 21:44:44.996038  2637 solver.cpp:523]     Test net output #0: accuracy = 0.89675
I0108 21:44:44.996068  2637 solver.cpp:523]     Test net output #1: loss = 0.275236 (* 1 = 0.275236 loss)
I0108 21:44:44.996073  2637 solver.cpp:523]     Test net output #2: top-1 = 0.89675
I0108 21:44:45.250968  2637 solver.cpp:270] Iteration 1000 (3.43856 iter/s, 14.541s/50 iter), loss = 0.096268, remaining 0 hours and 53 minutes
I0108 21:44:45.250993  2637 solver.cpp:291]     Train net output #0: loss = 0.096268 (* 1 = 0.096268 loss)
I0108 21:44:45.250999  2637 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0108 21:44:58.246294  2637 solver.cpp:270] Iteration 1050 (3.84769 iter/s, 12.9948s/50 iter), loss = 0.0960399, remaining 0 hours and 47 minutes
I0108 21:44:58.246325  2637 solver.cpp:291]     Train net output #0: loss = 0.0960399 (* 1 = 0.0960399 loss)
I0108 21:44:58.246333  2637 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0108 21:45:11.265894  2637 solver.cpp:270] Iteration 1100 (3.84052 iter/s, 13.0191s/50 iter), loss = 0.0987557, remaining 0 hours and 47 minutes
I0108 21:45:11.265928  2637 solver.cpp:291]     Train net output #0: loss = 0.0987557 (* 1 = 0.0987557 loss)
I0108 21:45:11.265934  2637 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0108 21:45:24.255486  2637 solver.cpp:270] Iteration 1150 (3.84939 iter/s, 12.9891s/50 iter), loss = 0.1321, remaining 0 hours and 46 minutes
I0108 21:45:24.255540  2637 solver.cpp:291]     Train net output #0: loss = 0.1321 (* 1 = 0.1321 loss)
I0108 21:45:24.255564  2637 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0108 21:45:37.256809  2637 solver.cpp:270] Iteration 1200 (3.84592 iter/s, 13.0008s/50 iter), loss = 0.0612359, remaining 0 hours and 46 minutes
I0108 21:45:37.256844  2637 solver.cpp:291]     Train net output #0: loss = 0.0612358 (* 1 = 0.0612358 loss)
I0108 21:45:37.256851  2637 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0108 21:45:50.240427  2637 solver.cpp:270] Iteration 1250 (3.85116 iter/s, 12.9831s/50 iter), loss = 0.168743, remaining 0 hours and 46 minutes
I0108 21:45:50.240459  2637 solver.cpp:291]     Train net output #0: loss = 0.168743 (* 1 = 0.168743 loss)
I0108 21:45:50.240466  2637 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0108 21:46:03.239984  2637 solver.cpp:270] Iteration 1300 (3.84644 iter/s, 12.999s/50 iter), loss = 0.0985277, remaining 0 hours and 46 minutes
I0108 21:46:03.240034  2637 solver.cpp:291]     Train net output #0: loss = 0.0985277 (* 1 = 0.0985277 loss)
I0108 21:46:03.240042  2637 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0108 21:46:16.246423  2637 solver.cpp:270] Iteration 1350 (3.84441 iter/s, 13.0059s/50 iter), loss = 0.181011, remaining 0 hours and 46 minutes
I0108 21:46:16.246454  2637 solver.cpp:291]     Train net output #0: loss = 0.181011 (* 1 = 0.181011 loss)
I0108 21:46:16.246461  2637 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0108 21:46:29.244946  2637 solver.cpp:270] Iteration 1400 (3.84674 iter/s, 12.998s/50 iter), loss = 0.134701, remaining 0 hours and 45 minutes
I0108 21:46:29.244976  2637 solver.cpp:291]     Train net output #0: loss = 0.134701 (* 1 = 0.134701 loss)
I0108 21:46:29.244998  2637 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0108 21:46:42.235836  2637 solver.cpp:270] Iteration 1450 (3.849 iter/s, 12.9904s/50 iter), loss = 0.0964963, remaining 0 hours and 45 minutes
I0108 21:46:42.235883  2637 solver.cpp:291]     Train net output #0: loss = 0.0964962 (* 1 = 0.0964962 loss)
I0108 21:46:42.235891  2637 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0108 21:46:55.220567  2637 solver.cpp:270] Iteration 1500 (3.85083 iter/s, 12.9842s/50 iter), loss = 0.0569873, remaining 0 hours and 45 minutes
I0108 21:46:55.220599  2637 solver.cpp:291]     Train net output #0: loss = 0.0569873 (* 1 = 0.0569873 loss)
I0108 21:46:55.220607  2637 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0108 21:47:08.208638  2637 solver.cpp:270] Iteration 1550 (3.84984 iter/s, 12.9876s/50 iter), loss = 0.121484, remaining 0 hours and 45 minutes
I0108 21:47:08.208674  2637 solver.cpp:291]     Train net output #0: loss = 0.121484 (* 1 = 0.121484 loss)
I0108 21:47:08.208683  2637 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0108 21:47:21.179342  2637 solver.cpp:270] Iteration 1600 (3.855 iter/s, 12.9702s/50 iter), loss = 0.0937738, remaining 0 hours and 44 minutes
I0108 21:47:21.179390  2637 solver.cpp:291]     Train net output #0: loss = 0.0937738 (* 1 = 0.0937738 loss)
I0108 21:47:21.179397  2637 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0108 21:47:34.181294  2637 solver.cpp:270] Iteration 1650 (3.84573 iter/s, 13.0014s/50 iter), loss = 0.147636, remaining 0 hours and 44 minutes
I0108 21:47:34.181326  2637 solver.cpp:291]     Train net output #0: loss = 0.147636 (* 1 = 0.147636 loss)
I0108 21:47:34.181334  2637 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0108 21:47:47.144134  2637 solver.cpp:270] Iteration 1700 (3.85733 iter/s, 12.9623s/50 iter), loss = 0.0936866, remaining 0 hours and 44 minutes
I0108 21:47:47.144166  2637 solver.cpp:291]     Train net output #0: loss = 0.0936866 (* 1 = 0.0936866 loss)
I0108 21:47:47.144189  2637 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0108 21:48:00.143011  2637 solver.cpp:270] Iteration 1750 (3.84664 iter/s, 12.9984s/50 iter), loss = 0.0835823, remaining 0 hours and 44 minutes
I0108 21:48:00.143065  2637 solver.cpp:291]     Train net output #0: loss = 0.0835823 (* 1 = 0.0835823 loss)
I0108 21:48:00.143074  2637 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0108 21:48:13.142719  2637 solver.cpp:270] Iteration 1800 (3.8464 iter/s, 12.9992s/50 iter), loss = 0.0545079, remaining 0 hours and 44 minutes
I0108 21:48:13.142753  2637 solver.cpp:291]     Train net output #0: loss = 0.0545079 (* 1 = 0.0545079 loss)
I0108 21:48:13.142776  2637 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0108 21:48:26.127599  2637 solver.cpp:270] Iteration 1850 (3.85079 iter/s, 12.9844s/50 iter), loss = 0.0768188, remaining 0 hours and 43 minutes
I0108 21:48:26.127631  2637 solver.cpp:291]     Train net output #0: loss = 0.0768188 (* 1 = 0.0768188 loss)
I0108 21:48:26.127640  2637 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0108 21:48:39.119532  2637 solver.cpp:270] Iteration 1900 (3.8487 iter/s, 12.9914s/50 iter), loss = 0.0754202, remaining 0 hours and 43 minutes
I0108 21:48:39.119578  2637 solver.cpp:291]     Train net output #0: loss = 0.0754202 (* 1 = 0.0754202 loss)
I0108 21:48:39.119585  2637 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0108 21:48:52.072106  2637 solver.cpp:270] Iteration 1950 (3.86039 iter/s, 12.952s/50 iter), loss = 0.0779742, remaining 0 hours and 43 minutes
I0108 21:48:52.072139  2637 solver.cpp:291]     Train net output #0: loss = 0.0779742 (* 1 = 0.0779742 loss)
I0108 21:48:52.072146  2637 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0108 21:49:04.802711  2637 solver.cpp:424] Iteration 2000, Testing net (#0)
I0108 21:49:06.334919  2637 solver.cpp:523]     Test net output #0: accuracy = 0.89875
I0108 21:49:06.334949  2637 solver.cpp:523]     Test net output #1: loss = 0.413641 (* 1 = 0.413641 loss)
I0108 21:49:06.334954  2637 solver.cpp:523]     Test net output #2: top-1 = 0.89875
I0108 21:49:06.591580  2637 solver.cpp:270] Iteration 2000 (3.44379 iter/s, 14.5189s/50 iter), loss = 0.122951, remaining 0 hours and 48 minutes
I0108 21:49:06.591606  2637 solver.cpp:291]     Train net output #0: loss = 0.122951 (* 1 = 0.122951 loss)
I0108 21:49:06.591630  2637 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0108 21:49:19.553288  2637 solver.cpp:270] Iteration 2050 (3.85767 iter/s, 12.9612s/50 iter), loss = 0.102183, remaining 0 hours and 42 minutes
I0108 21:49:19.553336  2637 solver.cpp:291]     Train net output #0: loss = 0.102183 (* 1 = 0.102183 loss)
I0108 21:49:19.553344  2637 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0108 21:49:32.557307  2637 solver.cpp:270] Iteration 2100 (3.84512 iter/s, 13.0035s/50 iter), loss = 0.0454144, remaining 0 hours and 42 minutes
I0108 21:49:32.557339  2637 solver.cpp:291]     Train net output #0: loss = 0.0454144 (* 1 = 0.0454144 loss)
I0108 21:49:32.557345  2637 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0108 21:49:45.515210  2637 solver.cpp:270] Iteration 2150 (3.8588 iter/s, 12.9574s/50 iter), loss = 0.080189, remaining 0 hours and 42 minutes
I0108 21:49:45.515244  2637 solver.cpp:291]     Train net output #0: loss = 0.080189 (* 1 = 0.080189 loss)
I0108 21:49:45.515250  2637 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0108 21:49:58.457523  2637 solver.cpp:270] Iteration 2200 (3.86345 iter/s, 12.9418s/50 iter), loss = 0.0784071, remaining 0 hours and 42 minutes
I0108 21:49:58.457569  2637 solver.cpp:291]     Train net output #0: loss = 0.0784071 (* 1 = 0.0784071 loss)
I0108 21:49:58.457576  2637 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0108 21:50:11.465190  2637 solver.cpp:270] Iteration 2250 (3.84404 iter/s, 13.0071s/50 iter), loss = 0.0510434, remaining 0 hours and 42 minutes
I0108 21:50:11.465224  2637 solver.cpp:291]     Train net output #0: loss = 0.0510434 (* 1 = 0.0510434 loss)
I0108 21:50:11.465246  2637 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0108 21:50:24.422987  2637 solver.cpp:270] Iteration 2300 (3.85883 iter/s, 12.9573s/50 iter), loss = 0.113779, remaining 0 hours and 41 minutes
I0108 21:50:24.423019  2637 solver.cpp:291]     Train net output #0: loss = 0.113779 (* 1 = 0.113779 loss)
I0108 21:50:24.423027  2637 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0108 21:50:37.380887  2637 solver.cpp:270] Iteration 2350 (3.8588 iter/s, 12.9574s/50 iter), loss = 0.129377, remaining 0 hours and 41 minutes
I0108 21:50:37.380939  2637 solver.cpp:291]     Train net output #0: loss = 0.129377 (* 1 = 0.129377 loss)
I0108 21:50:37.380946  2637 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0108 21:50:50.377837  2637 solver.cpp:270] Iteration 2400 (3.84722 iter/s, 12.9964s/50 iter), loss = 0.126291, remaining 0 hours and 41 minutes
I0108 21:50:50.377871  2637 solver.cpp:291]     Train net output #0: loss = 0.126291 (* 1 = 0.126291 loss)
I0108 21:50:50.377877  2637 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0108 21:51:03.362077  2637 solver.cpp:270] Iteration 2450 (3.85098 iter/s, 12.9837s/50 iter), loss = 0.0769171, remaining 0 hours and 41 minutes
I0108 21:51:03.362109  2637 solver.cpp:291]     Train net output #0: loss = 0.0769171 (* 1 = 0.0769171 loss)
I0108 21:51:03.362118  2637 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0108 21:51:16.336221  2637 solver.cpp:270] Iteration 2500 (3.85397 iter/s, 12.9736s/50 iter), loss = 0.103293, remaining 0 hours and 40 minutes
I0108 21:51:16.336268  2637 solver.cpp:291]     Train net output #0: loss = 0.103293 (* 1 = 0.103293 loss)
I0108 21:51:16.336292  2637 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0108 21:51:29.325371  2637 solver.cpp:270] Iteration 2550 (3.84952 iter/s, 12.9886s/50 iter), loss = 0.056896, remaining 0 hours and 40 minutes
I0108 21:51:29.325403  2637 solver.cpp:291]     Train net output #0: loss = 0.056896 (* 1 = 0.056896 loss)
I0108 21:51:29.325410  2637 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0108 21:51:42.296422  2637 solver.cpp:270] Iteration 2600 (3.85489 iter/s, 12.9705s/50 iter), loss = 0.0316747, remaining 0 hours and 40 minutes
I0108 21:51:42.296453  2637 solver.cpp:291]     Train net output #0: loss = 0.0316747 (* 1 = 0.0316747 loss)
I0108 21:51:42.296461  2637 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0108 21:51:55.280230  2637 solver.cpp:270] Iteration 2650 (3.8511 iter/s, 12.9833s/50 iter), loss = 0.0427205, remaining 0 hours and 40 minutes
I0108 21:51:55.280277  2637 solver.cpp:291]     Train net output #0: loss = 0.0427205 (* 1 = 0.0427205 loss)
I0108 21:51:55.280300  2637 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0108 21:52:08.258800  2637 solver.cpp:270] Iteration 2700 (3.85266 iter/s, 12.978s/50 iter), loss = 0.0183393, remaining 0 hours and 40 minutes
I0108 21:52:08.258833  2637 solver.cpp:291]     Train net output #0: loss = 0.0183393 (* 1 = 0.0183393 loss)
I0108 21:52:08.258841  2637 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0108 21:52:21.238590  2637 solver.cpp:270] Iteration 2750 (3.8523 iter/s, 12.9793s/50 iter), loss = 0.0301754, remaining 0 hours and 39 minutes
I0108 21:52:21.238622  2637 solver.cpp:291]     Train net output #0: loss = 0.0301754 (* 1 = 0.0301754 loss)
I0108 21:52:21.238629  2637 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0108 21:52:34.202828  2637 solver.cpp:270] Iteration 2800 (3.85692 iter/s, 12.9637s/50 iter), loss = 0.0252105, remaining 0 hours and 39 minutes
I0108 21:52:34.202874  2637 solver.cpp:291]     Train net output #0: loss = 0.0252105 (* 1 = 0.0252105 loss)
I0108 21:52:34.202881  2637 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0108 21:52:47.194319  2637 solver.cpp:270] Iteration 2850 (3.84883 iter/s, 12.991s/50 iter), loss = 0.0564951, remaining 0 hours and 39 minutes
I0108 21:52:47.194350  2637 solver.cpp:291]     Train net output #0: loss = 0.0564951 (* 1 = 0.0564951 loss)
I0108 21:52:47.194356  2637 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0108 21:53:00.185573  2637 solver.cpp:270] Iteration 2900 (3.8489 iter/s, 12.9907s/50 iter), loss = 0.0375341, remaining 0 hours and 39 minutes
I0108 21:53:00.185606  2637 solver.cpp:291]     Train net output #0: loss = 0.0375341 (* 1 = 0.0375341 loss)
I0108 21:53:00.185612  2637 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0108 21:53:13.148450  2637 solver.cpp:270] Iteration 2950 (3.85732 iter/s, 12.9624s/50 iter), loss = 0.0192972, remaining 0 hours and 38 minutes
I0108 21:53:13.148506  2637 solver.cpp:291]     Train net output #0: loss = 0.0192972 (* 1 = 0.0192972 loss)
I0108 21:53:13.148530  2637 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0108 21:53:25.892783  2637 solver.cpp:424] Iteration 3000, Testing net (#0)
I0108 21:53:27.428052  2637 solver.cpp:523]     Test net output #0: accuracy = 0.94475
I0108 21:53:27.428081  2637 solver.cpp:523]     Test net output #1: loss = 0.137594 (* 1 = 0.137594 loss)
I0108 21:53:27.428086  2637 solver.cpp:523]     Test net output #2: top-1 = 0.94475
I0108 21:53:27.678539  2637 solver.cpp:270] Iteration 3000 (3.44128 iter/s, 14.5295s/50 iter), loss = 0.024572, remaining 0 hours and 43 minutes
I0108 21:53:27.678565  2637 solver.cpp:291]     Train net output #0: loss = 0.024572 (* 1 = 0.024572 loss)
I0108 21:53:27.678571  2637 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0108 21:53:40.629940  2637 solver.cpp:270] Iteration 3050 (3.86074 iter/s, 12.9509s/50 iter), loss = 0.0178607, remaining 0 hours and 38 minutes
I0108 21:53:40.629971  2637 solver.cpp:291]     Train net output #0: loss = 0.0178608 (* 1 = 0.0178608 loss)
I0108 21:53:40.629993  2637 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0108 21:53:53.617000  2637 solver.cpp:270] Iteration 3100 (3.85014 iter/s, 12.9865s/50 iter), loss = 0.00748783, remaining 0 hours and 38 minutes
I0108 21:53:53.617048  2637 solver.cpp:291]     Train net output #0: loss = 0.00748785 (* 1 = 0.00748785 loss)
I0108 21:53:53.617056  2637 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0108 21:54:06.606761  2637 solver.cpp:270] Iteration 3150 (3.84934 iter/s, 12.9892s/50 iter), loss = 0.0407517, remaining 0 hours and 38 minutes
I0108 21:54:06.606793  2637 solver.cpp:291]     Train net output #0: loss = 0.0407517 (* 1 = 0.0407517 loss)
I0108 21:54:06.606801  2637 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0108 21:54:19.582717  2637 solver.cpp:270] Iteration 3200 (3.85343 iter/s, 12.9754s/50 iter), loss = 0.0380599, remaining 0 hours and 37 minutes
I0108 21:54:19.582751  2637 solver.cpp:291]     Train net output #0: loss = 0.0380599 (* 1 = 0.0380599 loss)
I0108 21:54:19.582757  2637 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0108 21:54:32.587314  2637 solver.cpp:270] Iteration 3250 (3.84495 iter/s, 13.0041s/50 iter), loss = 0.0221431, remaining 0 hours and 37 minutes
I0108 21:54:32.587361  2637 solver.cpp:291]     Train net output #0: loss = 0.0221431 (* 1 = 0.0221431 loss)
I0108 21:54:32.587368  2637 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0108 21:54:45.543088  2637 solver.cpp:270] Iteration 3300 (3.85944 iter/s, 12.9552s/50 iter), loss = 0.0370978, remaining 0 hours and 37 minutes
I0108 21:54:45.543121  2637 solver.cpp:291]     Train net output #0: loss = 0.0370978 (* 1 = 0.0370978 loss)
I0108 21:54:45.543129  2637 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0108 21:54:58.538017  2637 solver.cpp:270] Iteration 3350 (3.84781 iter/s, 12.9944s/50 iter), loss = 0.0389477, remaining 0 hours and 37 minutes
I0108 21:54:58.538049  2637 solver.cpp:291]     Train net output #0: loss = 0.0389478 (* 1 = 0.0389478 loss)
I0108 21:54:58.538058  2637 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0108 21:55:11.521891  2637 solver.cpp:270] Iteration 3400 (3.85108 iter/s, 12.9834s/50 iter), loss = 0.0372344, remaining 0 hours and 37 minutes
I0108 21:55:11.521944  2637 solver.cpp:291]     Train net output #0: loss = 0.0372344 (* 1 = 0.0372344 loss)
I0108 21:55:11.521951  2637 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0108 21:55:24.522636  2637 solver.cpp:270] Iteration 3450 (3.84609 iter/s, 13.0002s/50 iter), loss = 0.0481111, remaining 0 hours and 36 minutes
I0108 21:55:24.522667  2637 solver.cpp:291]     Train net output #0: loss = 0.0481111 (* 1 = 0.0481111 loss)
I0108 21:55:24.522675  2637 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0108 21:55:37.495529  2637 solver.cpp:270] Iteration 3500 (3.85434 iter/s, 12.9724s/50 iter), loss = 0.0329879, remaining 0 hours and 36 minutes
I0108 21:55:37.495561  2637 solver.cpp:291]     Train net output #0: loss = 0.0329879 (* 1 = 0.0329879 loss)
I0108 21:55:37.495569  2637 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0108 21:55:50.457152  2637 solver.cpp:270] Iteration 3550 (3.8577 iter/s, 12.9611s/50 iter), loss = 0.0390648, remaining 0 hours and 36 minutes
I0108 21:55:50.457199  2637 solver.cpp:291]     Train net output #0: loss = 0.0390648 (* 1 = 0.0390648 loss)
I0108 21:55:50.457207  2637 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0108 21:56:03.458112  2637 solver.cpp:270] Iteration 3600 (3.84603 iter/s, 13.0004s/50 iter), loss = 0.033785, remaining 0 hours and 36 minutes
I0108 21:56:03.458148  2637 solver.cpp:291]     Train net output #0: loss = 0.033785 (* 1 = 0.033785 loss)
I0108 21:56:03.458154  2637 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0108 21:56:16.430517  2637 solver.cpp:270] Iteration 3650 (3.85449 iter/s, 12.9719s/50 iter), loss = 0.0281468, remaining 0 hours and 36 minutes
I0108 21:56:16.430550  2637 solver.cpp:291]     Train net output #0: loss = 0.0281468 (* 1 = 0.0281468 loss)
I0108 21:56:16.430557  2637 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0108 21:56:29.406960  2637 solver.cpp:270] Iteration 3700 (3.85329 iter/s, 12.9759s/50 iter), loss = 0.028347, remaining 0 hours and 35 minutes
I0108 21:56:29.407006  2637 solver.cpp:291]     Train net output #0: loss = 0.028347 (* 1 = 0.028347 loss)
I0108 21:56:29.407013  2637 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0108 21:56:42.364344  2637 solver.cpp:270] Iteration 3750 (3.85896 iter/s, 12.9569s/50 iter), loss = 0.0289773, remaining 0 hours and 35 minutes
I0108 21:56:42.364377  2637 solver.cpp:291]     Train net output #0: loss = 0.0289773 (* 1 = 0.0289773 loss)
I0108 21:56:42.364384  2637 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0108 21:56:55.338516  2637 solver.cpp:270] Iteration 3800 (3.85396 iter/s, 12.9737s/50 iter), loss = 0.0304814, remaining 0 hours and 35 minutes
I0108 21:56:55.338549  2637 solver.cpp:291]     Train net output #0: loss = 0.0304814 (* 1 = 0.0304814 loss)
I0108 21:56:55.338557  2637 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0108 21:57:08.297825  2637 solver.cpp:270] Iteration 3850 (3.85838 iter/s, 12.9588s/50 iter), loss = 0.0225156, remaining 0 hours and 34 minutes
I0108 21:57:08.297871  2637 solver.cpp:291]     Train net output #0: loss = 0.0225157 (* 1 = 0.0225157 loss)
I0108 21:57:08.297878  2637 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0108 21:57:21.238293  2637 solver.cpp:270] Iteration 3900 (3.86401 iter/s, 12.9399s/50 iter), loss = 0.00737944, remaining 0 hours and 34 minutes
I0108 21:57:21.238324  2637 solver.cpp:291]     Train net output #0: loss = 0.00737947 (* 1 = 0.00737947 loss)
I0108 21:57:21.238348  2637 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0108 21:57:34.225456  2637 solver.cpp:270] Iteration 3950 (3.85011 iter/s, 12.9866s/50 iter), loss = 0.0417715, remaining 0 hours and 34 minutes
I0108 21:57:34.225489  2637 solver.cpp:291]     Train net output #0: loss = 0.0417716 (* 1 = 0.0417716 loss)
I0108 21:57:34.225497  2637 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0108 21:57:46.949589  2637 solver.cpp:424] Iteration 4000, Testing net (#0)
I0108 21:57:48.468974  2637 solver.cpp:523]     Test net output #0: accuracy = 0.9445
I0108 21:57:48.469002  2637 solver.cpp:523]     Test net output #1: loss = 0.135875 (* 1 = 0.135875 loss)
I0108 21:57:48.469007  2637 solver.cpp:523]     Test net output #2: top-1 = 0.9445
I0108 21:57:48.725436  2637 solver.cpp:270] Iteration 4000 (3.44842 iter/s, 14.4994s/50 iter), loss = 0.0130087, remaining 0 hours and 38 minutes
I0108 21:57:48.725462  2637 solver.cpp:291]     Train net output #0: loss = 0.0130088 (* 1 = 0.0130088 loss)
I0108 21:57:48.725471  2637 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0108 21:58:01.681771  2637 solver.cpp:270] Iteration 4050 (3.85927 iter/s, 12.9558s/50 iter), loss = 0.037512, remaining 0 hours and 34 minutes
I0108 21:58:01.681804  2637 solver.cpp:291]     Train net output #0: loss = 0.037512 (* 1 = 0.037512 loss)
I0108 21:58:01.681811  2637 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0108 21:58:14.670328  2637 solver.cpp:270] Iteration 4100 (3.8497 iter/s, 12.988s/50 iter), loss = 0.0177404, remaining 0 hours and 34 minutes
I0108 21:58:14.670361  2637 solver.cpp:291]     Train net output #0: loss = 0.0177404 (* 1 = 0.0177404 loss)
I0108 21:58:14.670384  2637 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0108 21:58:27.669512  2637 solver.cpp:270] Iteration 4150 (3.84655 iter/s, 12.9987s/50 iter), loss = 0.0364532, remaining 0 hours and 33 minutes
I0108 21:58:27.669565  2637 solver.cpp:291]     Train net output #0: loss = 0.0364532 (* 1 = 0.0364532 loss)
I0108 21:58:27.669572  2637 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0108 21:58:40.608371  2637 solver.cpp:270] Iteration 4200 (3.86449 iter/s, 12.9383s/50 iter), loss = 0.0377161, remaining 0 hours and 33 minutes
I0108 21:58:40.608405  2637 solver.cpp:291]     Train net output #0: loss = 0.0377161 (* 1 = 0.0377161 loss)
I0108 21:58:40.608428  2637 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0108 21:58:53.607861  2637 solver.cpp:270] Iteration 4250 (3.84646 iter/s, 12.999s/50 iter), loss = 0.00788422, remaining 0 hours and 33 minutes
I0108 21:58:53.607893  2637 solver.cpp:291]     Train net output #0: loss = 0.00788424 (* 1 = 0.00788424 loss)
I0108 21:58:53.607901  2637 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0108 21:59:06.567775  2637 solver.cpp:270] Iteration 4300 (3.8582 iter/s, 12.9594s/50 iter), loss = 0.0204114, remaining 0 hours and 33 minutes
I0108 21:59:06.567821  2637 solver.cpp:291]     Train net output #0: loss = 0.0204114 (* 1 = 0.0204114 loss)
I0108 21:59:06.567843  2637 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0108 21:59:19.562152  2637 solver.cpp:270] Iteration 4350 (3.84797 iter/s, 12.9938s/50 iter), loss = 0.0112988, remaining 0 hours and 33 minutes
I0108 21:59:19.562187  2637 solver.cpp:291]     Train net output #0: loss = 0.0112988 (* 1 = 0.0112988 loss)
I0108 21:59:19.562194  2637 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0108 21:59:32.523355  2637 solver.cpp:270] Iteration 4400 (3.85782 iter/s, 12.9607s/50 iter), loss = 0.0160039, remaining 0 hours and 32 minutes
I0108 21:59:32.523386  2637 solver.cpp:291]     Train net output #0: loss = 0.016004 (* 1 = 0.016004 loss)
I0108 21:59:32.523393  2637 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0108 21:59:45.498379  2637 solver.cpp:270] Iteration 4450 (3.85371 iter/s, 12.9745s/50 iter), loss = 0.0437431, remaining 0 hours and 32 minutes
I0108 21:59:45.498426  2637 solver.cpp:291]     Train net output #0: loss = 0.0437431 (* 1 = 0.0437431 loss)
I0108 21:59:45.498433  2637 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0108 21:59:58.473428  2637 solver.cpp:270] Iteration 4500 (3.85371 iter/s, 12.9745s/50 iter), loss = 0.00632755, remaining 0 hours and 32 minutes
I0108 21:59:58.473460  2637 solver.cpp:291]     Train net output #0: loss = 0.00632757 (* 1 = 0.00632757 loss)
I0108 21:59:58.473467  2637 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0108 22:00:11.426342  2637 solver.cpp:270] Iteration 4550 (3.86029 iter/s, 12.9524s/50 iter), loss = 0.0444684, remaining 0 hours and 32 minutes
I0108 22:00:11.426373  2637 solver.cpp:291]     Train net output #0: loss = 0.0444684 (* 1 = 0.0444684 loss)
I0108 22:00:11.426380  2637 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0108 22:00:24.406270  2637 solver.cpp:270] Iteration 4600 (3.85225 iter/s, 12.9794s/50 iter), loss = 0.0198022, remaining 0 hours and 31 minutes
I0108 22:00:24.406322  2637 solver.cpp:291]     Train net output #0: loss = 0.0198022 (* 1 = 0.0198022 loss)
I0108 22:00:24.406329  2637 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0108 22:00:37.373554  2637 solver.cpp:270] Iteration 4650 (3.85602 iter/s, 12.9667s/50 iter), loss = 0.0137549, remaining 0 hours and 31 minutes
I0108 22:00:37.373589  2637 solver.cpp:291]     Train net output #0: loss = 0.0137549 (* 1 = 0.0137549 loss)
I0108 22:00:37.373594  2637 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0108 22:00:50.349339  2637 solver.cpp:270] Iteration 4700 (3.85349 iter/s, 12.9753s/50 iter), loss = 0.0663866, remaining 0 hours and 31 minutes
I0108 22:00:50.349371  2637 solver.cpp:291]     Train net output #0: loss = 0.0663866 (* 1 = 0.0663866 loss)
I0108 22:00:50.349377  2637 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0108 22:01:03.344354  2637 solver.cpp:270] Iteration 4750 (3.84778 iter/s, 12.9945s/50 iter), loss = 0.0178331, remaining 0 hours and 31 minutes
I0108 22:01:03.344403  2637 solver.cpp:291]     Train net output #0: loss = 0.0178331 (* 1 = 0.0178331 loss)
I0108 22:01:03.344410  2637 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0108 22:01:16.351112  2637 solver.cpp:270] Iteration 4800 (3.84431 iter/s, 13.0062s/50 iter), loss = 0.027967, remaining 0 hours and 31 minutes
I0108 22:01:16.351145  2637 solver.cpp:291]     Train net output #0: loss = 0.027967 (* 1 = 0.027967 loss)
I0108 22:01:16.351168  2637 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0108 22:01:29.333802  2637 solver.cpp:270] Iteration 4850 (3.85144 iter/s, 12.9822s/50 iter), loss = 0.0506803, remaining 0 hours and 30 minutes
I0108 22:01:29.333834  2637 solver.cpp:291]     Train net output #0: loss = 0.0506803 (* 1 = 0.0506803 loss)
I0108 22:01:29.333858  2637 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0108 22:01:42.290753  2637 solver.cpp:270] Iteration 4900 (3.85909 iter/s, 12.9564s/50 iter), loss = 0.0329336, remaining 0 hours and 30 minutes
I0108 22:01:42.290800  2637 solver.cpp:291]     Train net output #0: loss = 0.0329337 (* 1 = 0.0329337 loss)
I0108 22:01:42.290823  2637 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0108 22:01:55.257918  2637 solver.cpp:270] Iteration 4950 (3.85605 iter/s, 12.9666s/50 iter), loss = 0.0130208, remaining 0 hours and 30 minutes
I0108 22:01:55.257951  2637 solver.cpp:291]     Train net output #0: loss = 0.0130208 (* 1 = 0.0130208 loss)
I0108 22:01:55.257958  2637 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0108 22:02:07.985889  2637 solver.cpp:424] Iteration 5000, Testing net (#0)
I0108 22:02:09.518563  2637 solver.cpp:523]     Test net output #0: accuracy = 0.94925
I0108 22:02:09.518590  2637 solver.cpp:523]     Test net output #1: loss = 0.150981 (* 1 = 0.150981 loss)
I0108 22:02:09.518595  2637 solver.cpp:523]     Test net output #2: top-1 = 0.94925
I0108 22:02:09.770885  2637 solver.cpp:270] Iteration 5000 (3.44533 iter/s, 14.5124s/50 iter), loss = 0.0206898, remaining 0 hours and 33 minutes
I0108 22:02:09.770911  2637 solver.cpp:291]     Train net output #0: loss = 0.0206899 (* 1 = 0.0206899 loss)
I0108 22:02:09.770920  2637 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0108 22:02:22.723371  2637 solver.cpp:270] Iteration 5050 (3.86041 iter/s, 12.952s/50 iter), loss = 0.00746134, remaining 0 hours and 29 minutes
I0108 22:02:22.723419  2637 solver.cpp:291]     Train net output #0: loss = 0.00746135 (* 1 = 0.00746135 loss)
I0108 22:02:22.723426  2637 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0108 22:02:35.712771  2637 solver.cpp:270] Iteration 5100 (3.84945 iter/s, 12.9889s/50 iter), loss = 0.00274682, remaining 0 hours and 29 minutes
I0108 22:02:35.712803  2637 solver.cpp:291]     Train net output #0: loss = 0.00274684 (* 1 = 0.00274684 loss)
I0108 22:02:35.712810  2637 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0108 22:02:48.687142  2637 solver.cpp:270] Iteration 5150 (3.8539 iter/s, 12.9739s/50 iter), loss = 0.00456205, remaining 0 hours and 29 minutes
I0108 22:02:48.687175  2637 solver.cpp:291]     Train net output #0: loss = 0.00456206 (* 1 = 0.00456206 loss)
I0108 22:02:48.687183  2637 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0108 22:03:01.657807  2637 solver.cpp:270] Iteration 5200 (3.85501 iter/s, 12.9701s/50 iter), loss = 0.00274707, remaining 0 hours and 29 minutes
I0108 22:03:01.657861  2637 solver.cpp:291]     Train net output #0: loss = 0.00274709 (* 1 = 0.00274709 loss)
I0108 22:03:01.657869  2637 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0108 22:03:14.648116  2637 solver.cpp:270] Iteration 5250 (3.84918 iter/s, 12.9898s/50 iter), loss = 0.00862456, remaining 0 hours and 29 minutes
I0108 22:03:14.648149  2637 solver.cpp:291]     Train net output #0: loss = 0.00862457 (* 1 = 0.00862457 loss)
I0108 22:03:14.648156  2637 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0108 22:03:27.600785  2637 solver.cpp:270] Iteration 5300 (3.86036 iter/s, 12.9522s/50 iter), loss = 0.0388492, remaining 0 hours and 28 minutes
I0108 22:03:27.600817  2637 solver.cpp:291]     Train net output #0: loss = 0.0388492 (* 1 = 0.0388492 loss)
I0108 22:03:27.600824  2637 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0108 22:03:40.557301  2637 solver.cpp:270] Iteration 5350 (3.85922 iter/s, 12.956s/50 iter), loss = 0.00674449, remaining 0 hours and 28 minutes
I0108 22:03:40.557346  2637 solver.cpp:291]     Train net output #0: loss = 0.00674449 (* 1 = 0.00674449 loss)
I0108 22:03:40.557353  2637 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0108 22:03:53.530676  2637 solver.cpp:270] Iteration 5400 (3.8542 iter/s, 12.9728s/50 iter), loss = 0.0169259, remaining 0 hours and 28 minutes
I0108 22:03:53.530709  2637 solver.cpp:291]     Train net output #0: loss = 0.0169259 (* 1 = 0.0169259 loss)
I0108 22:03:53.530716  2637 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0108 22:04:06.495875  2637 solver.cpp:270] Iteration 5450 (3.85663 iter/s, 12.9647s/50 iter), loss = 0.00237984, remaining 0 hours and 28 minutes
I0108 22:04:06.495908  2637 solver.cpp:291]     Train net output #0: loss = 0.00237985 (* 1 = 0.00237985 loss)
I0108 22:04:06.495914  2637 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0108 22:04:19.497227  2637 solver.cpp:270] Iteration 5500 (3.84591 iter/s, 13.0008s/50 iter), loss = 0.00172933, remaining 0 hours and 28 minutes
I0108 22:04:19.497272  2637 solver.cpp:291]     Train net output #0: loss = 0.00172934 (* 1 = 0.00172934 loss)
I0108 22:04:19.497294  2637 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0108 22:04:32.473006  2637 solver.cpp:270] Iteration 5550 (3.85349 iter/s, 12.9753s/50 iter), loss = 0.0266248, remaining 0 hours and 27 minutes
I0108 22:04:32.473038  2637 solver.cpp:291]     Train net output #0: loss = 0.0266248 (* 1 = 0.0266248 loss)
I0108 22:04:32.473062  2637 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0108 22:04:45.457257  2637 solver.cpp:270] Iteration 5600 (3.85097 iter/s, 12.9837s/50 iter), loss = 0.00677486, remaining 0 hours and 27 minutes
I0108 22:04:45.457290  2637 solver.cpp:291]     Train net output #0: loss = 0.00677487 (* 1 = 0.00677487 loss)
I0108 22:04:45.457298  2637 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0108 22:04:58.439877  2637 solver.cpp:270] Iteration 5650 (3.85146 iter/s, 12.9821s/50 iter), loss = 0.00308907, remaining 0 hours and 27 minutes
I0108 22:04:58.439922  2637 solver.cpp:291]     Train net output #0: loss = 0.00308908 (* 1 = 0.00308908 loss)
I0108 22:04:58.439929  2637 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0108 22:05:11.426524  2637 solver.cpp:270] Iteration 5700 (3.85027 iter/s, 12.9861s/50 iter), loss = 0.00227836, remaining 0 hours and 27 minutes
I0108 22:05:11.426556  2637 solver.cpp:291]     Train net output #0: loss = 0.00227837 (* 1 = 0.00227837 loss)
I0108 22:05:11.426563  2637 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0108 22:05:24.380854  2637 solver.cpp:270] Iteration 5750 (3.85987 iter/s, 12.9538s/50 iter), loss = 0.00928853, remaining 0 hours and 26 minutes
I0108 22:05:24.380887  2637 solver.cpp:291]     Train net output #0: loss = 0.00928855 (* 1 = 0.00928855 loss)
I0108 22:05:24.380893  2637 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0108 22:05:37.363983  2637 solver.cpp:270] Iteration 5800 (3.85131 iter/s, 12.9826s/50 iter), loss = 0.000603577, remaining 0 hours and 26 minutes
I0108 22:05:37.364039  2637 solver.cpp:291]     Train net output #0: loss = 0.000603592 (* 1 = 0.000603592 loss)
I0108 22:05:37.364048  2637 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0108 22:05:50.326879  2637 solver.cpp:270] Iteration 5850 (3.85732 iter/s, 12.9624s/50 iter), loss = 0.00927611, remaining 0 hours and 26 minutes
I0108 22:05:50.326913  2637 solver.cpp:291]     Train net output #0: loss = 0.00927613 (* 1 = 0.00927613 loss)
I0108 22:05:50.326936  2637 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0108 22:06:03.315629  2637 solver.cpp:270] Iteration 5900 (3.84964 iter/s, 12.9882s/50 iter), loss = 0.0121373, remaining 0 hours and 26 minutes
I0108 22:06:03.315663  2637 solver.cpp:291]     Train net output #0: loss = 0.0121374 (* 1 = 0.0121374 loss)
I0108 22:06:03.315670  2637 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0108 22:06:16.267338  2637 solver.cpp:270] Iteration 5950 (3.86065 iter/s, 12.9512s/50 iter), loss = 0.0105721, remaining 0 hours and 25 minutes
I0108 22:06:16.267385  2637 solver.cpp:291]     Train net output #0: loss = 0.0105722 (* 1 = 0.0105722 loss)
I0108 22:06:16.267408  2637 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0108 22:06:29.008365  2637 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.2/snapshots/_iter_6000.caffemodel
I0108 22:06:31.493338  2637 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.2/snapshots/_iter_6000.solverstate
I0108 22:06:31.717799  2637 solver.cpp:424] Iteration 6000, Testing net (#0)
I0108 22:06:33.183259  2637 solver.cpp:523]     Test net output #0: accuracy = 0.9515
I0108 22:06:33.183288  2637 solver.cpp:523]     Test net output #1: loss = 0.179617 (* 1 = 0.179617 loss)
I0108 22:06:33.183293  2637 solver.cpp:523]     Test net output #2: top-1 = 0.9515
I0108 22:06:33.432304  2637 solver.cpp:270] Iteration 6000 (2.91303 iter/s, 17.1643s/50 iter), loss = 0.0146811, remaining 0 hours and 34 minutes
I0108 22:06:33.432329  2637 solver.cpp:291]     Train net output #0: loss = 0.0146811 (* 1 = 0.0146811 loss)
I0108 22:06:33.432337  2637 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0108 22:06:46.346722  2637 solver.cpp:270] Iteration 6050 (3.87179 iter/s, 12.9139s/50 iter), loss = 0.0165987, remaining 0 hours and 25 minutes
I0108 22:06:46.346767  2637 solver.cpp:291]     Train net output #0: loss = 0.0165987 (* 1 = 0.0165987 loss)
I0108 22:06:46.346774  2637 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0108 22:06:59.253646  2637 solver.cpp:270] Iteration 6100 (3.87405 iter/s, 12.9064s/50 iter), loss = 0.0030692, remaining 0 hours and 25 minutes
I0108 22:06:59.253679  2637 solver.cpp:291]     Train net output #0: loss = 0.00306923 (* 1 = 0.00306923 loss)
I0108 22:06:59.253685  2637 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0108 22:07:12.203982  2637 solver.cpp:270] Iteration 6150 (3.86106 iter/s, 12.9498s/50 iter), loss = 0.0122857, remaining 0 hours and 25 minutes
I0108 22:07:12.204015  2637 solver.cpp:291]     Train net output #0: loss = 0.0122857 (* 1 = 0.0122857 loss)
I0108 22:07:12.204022  2637 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0108 22:07:25.174579  2637 solver.cpp:270] Iteration 6200 (3.85503 iter/s, 12.9701s/50 iter), loss = 0.00809099, remaining 0 hours and 24 minutes
I0108 22:07:25.174625  2637 solver.cpp:291]     Train net output #0: loss = 0.00809102 (* 1 = 0.00809102 loss)
I0108 22:07:25.174633  2637 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0108 22:07:38.158620  2637 solver.cpp:270] Iteration 6250 (3.85104 iter/s, 12.9835s/50 iter), loss = 0.00841482, remaining 0 hours and 24 minutes
I0108 22:07:38.158653  2637 solver.cpp:291]     Train net output #0: loss = 0.00841486 (* 1 = 0.00841486 loss)
I0108 22:07:38.158661  2637 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0108 22:07:51.110374  2637 solver.cpp:270] Iteration 6300 (3.86063 iter/s, 12.9512s/50 iter), loss = 0.0110727, remaining 0 hours and 24 minutes
I0108 22:07:51.110407  2637 solver.cpp:291]     Train net output #0: loss = 0.0110727 (* 1 = 0.0110727 loss)
I0108 22:07:51.110414  2637 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0108 22:08:04.116168  2637 solver.cpp:270] Iteration 6350 (3.84459 iter/s, 13.0053s/50 iter), loss = 0.00169653, remaining 0 hours and 24 minutes
I0108 22:08:04.116217  2637 solver.cpp:291]     Train net output #0: loss = 0.00169657 (* 1 = 0.00169657 loss)
I0108 22:08:04.116240  2637 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0108 22:08:17.110905  2637 solver.cpp:270] Iteration 6400 (3.84787 iter/s, 12.9942s/50 iter), loss = 0.00220545, remaining 0 hours and 24 minutes
I0108 22:08:17.110939  2637 solver.cpp:291]     Train net output #0: loss = 0.00220549 (* 1 = 0.00220549 loss)
I0108 22:08:17.110945  2637 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0108 22:08:30.094496  2637 solver.cpp:270] Iteration 6450 (3.85117 iter/s, 12.9831s/50 iter), loss = 0.0016967, remaining 0 hours and 23 minutes
I0108 22:08:30.094532  2637 solver.cpp:291]     Train net output #0: loss = 0.00169674 (* 1 = 0.00169674 loss)
I0108 22:08:30.094540  2637 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0108 22:08:43.058027  2637 solver.cpp:270] Iteration 6500 (3.85713 iter/s, 12.963s/50 iter), loss = 0.00130175, remaining 0 hours and 23 minutes
I0108 22:08:43.058073  2637 solver.cpp:291]     Train net output #0: loss = 0.00130179 (* 1 = 0.00130179 loss)
I0108 22:08:43.058095  2637 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0108 22:08:56.032867  2637 solver.cpp:270] Iteration 6550 (3.85377 iter/s, 12.9743s/50 iter), loss = 0.0117493, remaining 0 hours and 23 minutes
I0108 22:08:56.032902  2637 solver.cpp:291]     Train net output #0: loss = 0.0117493 (* 1 = 0.0117493 loss)
I0108 22:08:56.032909  2637 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0108 22:09:09.027527  2637 solver.cpp:270] Iteration 6600 (3.84789 iter/s, 12.9941s/50 iter), loss = 0.0165328, remaining 0 hours and 23 minutes
I0108 22:09:09.027560  2637 solver.cpp:291]     Train net output #0: loss = 0.0165328 (* 1 = 0.0165328 loss)
I0108 22:09:09.027567  2637 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0108 22:09:22.016927  2637 solver.cpp:270] Iteration 6650 (3.84945 iter/s, 12.9889s/50 iter), loss = 0.00136944, remaining 0 hours and 23 minutes
I0108 22:09:22.016973  2637 solver.cpp:291]     Train net output #0: loss = 0.00136947 (* 1 = 0.00136947 loss)
I0108 22:09:22.016980  2637 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0108 22:09:35.007725  2637 solver.cpp:270] Iteration 6700 (3.84904 iter/s, 12.9903s/50 iter), loss = 0.00500919, remaining 0 hours and 22 minutes
I0108 22:09:35.007755  2637 solver.cpp:291]     Train net output #0: loss = 0.00500922 (* 1 = 0.00500922 loss)
I0108 22:09:35.007762  2637 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0108 22:09:47.969400  2637 solver.cpp:270] Iteration 6750 (3.85768 iter/s, 12.9612s/50 iter), loss = 0.00818831, remaining 0 hours and 22 minutes
I0108 22:09:47.969431  2637 solver.cpp:291]     Train net output #0: loss = 0.00818834 (* 1 = 0.00818834 loss)
I0108 22:09:47.969439  2637 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0108 22:10:00.967851  2637 solver.cpp:270] Iteration 6800 (3.84677 iter/s, 12.9979s/50 iter), loss = 0.0117846, remaining 0 hours and 22 minutes
I0108 22:10:00.967898  2637 solver.cpp:291]     Train net output #0: loss = 0.0117846 (* 1 = 0.0117846 loss)
I0108 22:10:00.967905  2637 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0108 22:10:13.974056  2637 solver.cpp:270] Iteration 6850 (3.84448 iter/s, 13.0057s/50 iter), loss = 0.01414, remaining 0 hours and 22 minutes
I0108 22:10:13.974089  2637 solver.cpp:291]     Train net output #0: loss = 0.0141401 (* 1 = 0.0141401 loss)
I0108 22:10:13.974097  2637 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0108 22:10:26.922089  2637 solver.cpp:270] Iteration 6900 (3.86174 iter/s, 12.9475s/50 iter), loss = 0.00268496, remaining 0 hours and 22 minutes
I0108 22:10:26.922122  2637 solver.cpp:291]     Train net output #0: loss = 0.002685 (* 1 = 0.002685 loss)
I0108 22:10:26.922129  2637 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0108 22:10:39.908092  2637 solver.cpp:270] Iteration 6950 (3.85045 iter/s, 12.9855s/50 iter), loss = 0.0119821, remaining 0 hours and 21 minutes
I0108 22:10:39.908159  2637 solver.cpp:291]     Train net output #0: loss = 0.0119821 (* 1 = 0.0119821 loss)
I0108 22:10:39.908172  2637 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0108 22:10:52.631192  2637 solver.cpp:424] Iteration 7000, Testing net (#0)
I0108 22:10:54.190363  2637 solver.cpp:523]     Test net output #0: accuracy = 0.9515
I0108 22:10:54.190392  2637 solver.cpp:523]     Test net output #1: loss = 0.205509 (* 1 = 0.205509 loss)
I0108 22:10:54.190397  2637 solver.cpp:523]     Test net output #2: top-1 = 0.9515
I0108 22:10:54.440368  2637 solver.cpp:270] Iteration 7000 (3.44076 iter/s, 14.5317s/50 iter), loss = 0.0121832, remaining 0 hours and 24 minutes
I0108 22:10:54.440394  2637 solver.cpp:291]     Train net output #0: loss = 0.0121833 (* 1 = 0.0121833 loss)
I0108 22:10:54.440402  2637 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0108 22:11:07.389199  2637 solver.cpp:270] Iteration 7050 (3.8615 iter/s, 12.9483s/50 iter), loss = 0.00988512, remaining 0 hours and 21 minutes
I0108 22:11:07.389232  2637 solver.cpp:291]     Train net output #0: loss = 0.00988515 (* 1 = 0.00988515 loss)
I0108 22:11:07.389240  2637 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0108 22:11:20.375706  2637 solver.cpp:270] Iteration 7100 (3.8503 iter/s, 12.986s/50 iter), loss = 0.00223075, remaining 0 hours and 21 minutes
I0108 22:11:20.375753  2637 solver.cpp:291]     Train net output #0: loss = 0.00223078 (* 1 = 0.00223078 loss)
I0108 22:11:20.375761  2637 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0108 22:11:33.332746  2637 solver.cpp:270] Iteration 7150 (3.85906 iter/s, 12.9565s/50 iter), loss = 0.0152938, remaining 0 hours and 20 minutes
I0108 22:11:33.332780  2637 solver.cpp:291]     Train net output #0: loss = 0.0152939 (* 1 = 0.0152939 loss)
I0108 22:11:33.332787  2637 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0108 22:11:46.294167  2637 solver.cpp:270] Iteration 7200 (3.85776 iter/s, 12.9609s/50 iter), loss = 0.0059736, remaining 0 hours and 20 minutes
I0108 22:11:46.294198  2637 solver.cpp:291]     Train net output #0: loss = 0.00597364 (* 1 = 0.00597364 loss)
I0108 22:11:46.294206  2637 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0108 22:11:59.285660  2637 solver.cpp:270] Iteration 7250 (3.84883 iter/s, 12.991s/50 iter), loss = 0.027895, remaining 0 hours and 20 minutes
I0108 22:11:59.285706  2637 solver.cpp:291]     Train net output #0: loss = 0.027895 (* 1 = 0.027895 loss)
I0108 22:11:59.285712  2637 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0108 22:12:12.245169  2637 solver.cpp:270] Iteration 7300 (3.85833 iter/s, 12.959s/50 iter), loss = 0.0264517, remaining 0 hours and 20 minutes
I0108 22:12:12.245200  2637 solver.cpp:291]     Train net output #0: loss = 0.0264517 (* 1 = 0.0264517 loss)
I0108 22:12:12.245208  2637 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0108 22:12:25.232776  2637 solver.cpp:270] Iteration 7350 (3.84998 iter/s, 12.9871s/50 iter), loss = 0.0101264, remaining 0 hours and 20 minutes
I0108 22:12:25.232808  2637 solver.cpp:291]     Train net output #0: loss = 0.0101264 (* 1 = 0.0101264 loss)
I0108 22:12:25.232831  2637 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0108 22:12:38.219930  2637 solver.cpp:270] Iteration 7400 (3.85011 iter/s, 12.9866s/50 iter), loss = 0.0124326, remaining 0 hours and 19 minutes
I0108 22:12:38.219978  2637 solver.cpp:291]     Train net output #0: loss = 0.0124327 (* 1 = 0.0124327 loss)
I0108 22:12:38.220001  2637 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0108 22:12:51.161444  2637 solver.cpp:270] Iteration 7450 (3.86369 iter/s, 12.941s/50 iter), loss = 0.0226492, remaining 0 hours and 19 minutes
I0108 22:12:51.161475  2637 solver.cpp:291]     Train net output #0: loss = 0.0226492 (* 1 = 0.0226492 loss)
I0108 22:12:51.161482  2637 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0108 22:13:04.143673  2637 solver.cpp:270] Iteration 7500 (3.85157 iter/s, 12.9817s/50 iter), loss = 0.00244587, remaining 0 hours and 19 minutes
I0108 22:13:04.143707  2637 solver.cpp:291]     Train net output #0: loss = 0.0024459 (* 1 = 0.0024459 loss)
I0108 22:13:04.143713  2637 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0108 22:13:17.101723  2637 solver.cpp:270] Iteration 7550 (3.85876 iter/s, 12.9575s/50 iter), loss = 0.0139819, remaining 0 hours and 19 minutes
I0108 22:13:17.101780  2637 solver.cpp:291]     Train net output #0: loss = 0.0139819 (* 1 = 0.0139819 loss)
I0108 22:13:17.101788  2637 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0108 22:13:30.104023  2637 solver.cpp:270] Iteration 7600 (3.84563 iter/s, 13.0018s/50 iter), loss = 0.00049709, remaining 0 hours and 18 minutes
I0108 22:13:30.104056  2637 solver.cpp:291]     Train net output #0: loss = 0.000497121 (* 1 = 0.000497121 loss)
I0108 22:13:30.104079  2637 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0108 22:13:43.083273  2637 solver.cpp:270] Iteration 7650 (3.85246 iter/s, 12.9787s/50 iter), loss = 0.00158309, remaining 0 hours and 18 minutes
I0108 22:13:43.083307  2637 solver.cpp:291]     Train net output #0: loss = 0.00158312 (* 1 = 0.00158312 loss)
I0108 22:13:43.083313  2637 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0108 22:13:56.028837  2637 solver.cpp:270] Iteration 7700 (3.86248 iter/s, 12.945s/50 iter), loss = 0.00803755, remaining 0 hours and 18 minutes
I0108 22:13:56.028883  2637 solver.cpp:291]     Train net output #0: loss = 0.00803758 (* 1 = 0.00803758 loss)
I0108 22:13:56.028892  2637 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0108 22:14:09.024031  2637 solver.cpp:270] Iteration 7750 (3.84773 iter/s, 12.9947s/50 iter), loss = 0.00467071, remaining 0 hours and 18 minutes
I0108 22:14:09.024065  2637 solver.cpp:291]     Train net output #0: loss = 0.00467074 (* 1 = 0.00467074 loss)
I0108 22:14:09.024072  2637 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0108 22:14:21.988894  2637 solver.cpp:270] Iteration 7800 (3.85673 iter/s, 12.9643s/50 iter), loss = 0.00945037, remaining 0 hours and 18 minutes
I0108 22:14:21.988927  2637 solver.cpp:291]     Train net output #0: loss = 0.00945041 (* 1 = 0.00945041 loss)
I0108 22:14:21.988935  2637 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0108 22:14:34.998219  2637 solver.cpp:270] Iteration 7850 (3.84355 iter/s, 13.0088s/50 iter), loss = 0.00715389, remaining 0 hours and 17 minutes
I0108 22:14:34.998267  2637 solver.cpp:291]     Train net output #0: loss = 0.00715392 (* 1 = 0.00715392 loss)
I0108 22:14:34.998275  2637 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0108 22:14:47.955047  2637 solver.cpp:270] Iteration 7900 (3.85913 iter/s, 12.9563s/50 iter), loss = 0.00554528, remaining 0 hours and 17 minutes
I0108 22:14:47.955078  2637 solver.cpp:291]     Train net output #0: loss = 0.00554531 (* 1 = 0.00554531 loss)
I0108 22:14:47.955086  2637 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0108 22:15:00.936573  2637 solver.cpp:270] Iteration 7950 (3.85178 iter/s, 12.981s/50 iter), loss = 0.00819459, remaining 0 hours and 17 minutes
I0108 22:15:00.936605  2637 solver.cpp:291]     Train net output #0: loss = 0.00819463 (* 1 = 0.00819463 loss)
I0108 22:15:00.936612  2637 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0108 22:15:13.666466  2637 solver.cpp:424] Iteration 8000, Testing net (#0)
I0108 22:15:15.193832  2637 solver.cpp:523]     Test net output #0: accuracy = 0.95025
I0108 22:15:15.193861  2637 solver.cpp:523]     Test net output #1: loss = 0.228762 (* 1 = 0.228762 loss)
I0108 22:15:15.193866  2637 solver.cpp:523]     Test net output #2: top-1 = 0.95025
I0108 22:15:15.444705  2637 solver.cpp:270] Iteration 8000 (3.44648 iter/s, 14.5076s/50 iter), loss = 0.00180151, remaining 0 hours and 19 minutes
I0108 22:15:15.444732  2637 solver.cpp:291]     Train net output #0: loss = 0.00180155 (* 1 = 0.00180155 loss)
I0108 22:15:15.444741  2637 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0108 22:15:28.401355  2637 solver.cpp:270] Iteration 8050 (3.85918 iter/s, 12.9561s/50 iter), loss = 0.0113506, remaining 0 hours and 16 minutes
I0108 22:15:28.401386  2637 solver.cpp:291]     Train net output #0: loss = 0.0113507 (* 1 = 0.0113507 loss)
I0108 22:15:28.401408  2637 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0108 22:15:41.369849  2637 solver.cpp:270] Iteration 8100 (3.85565 iter/s, 12.968s/50 iter), loss = 0.0107598, remaining 0 hours and 16 minutes
I0108 22:15:41.369882  2637 solver.cpp:291]     Train net output #0: loss = 0.0107598 (* 1 = 0.0107598 loss)
I0108 22:15:41.369890  2637 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0108 22:15:54.343940  2637 solver.cpp:270] Iteration 8150 (3.85399 iter/s, 12.9736s/50 iter), loss = 0.0112883, remaining 0 hours and 16 minutes
I0108 22:15:54.343991  2637 solver.cpp:291]     Train net output #0: loss = 0.0112883 (* 1 = 0.0112883 loss)
I0108 22:15:54.344014  2637 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0108 22:16:07.313040  2637 solver.cpp:270] Iteration 8200 (3.85548 iter/s, 12.9686s/50 iter), loss = 0.00296572, remaining 0 hours and 16 minutes
I0108 22:16:07.313073  2637 solver.cpp:291]     Train net output #0: loss = 0.00296575 (* 1 = 0.00296575 loss)
I0108 22:16:07.313081  2637 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0108 22:16:20.296092  2637 solver.cpp:270] Iteration 8250 (3.85133 iter/s, 12.9825s/50 iter), loss = 0.00169637, remaining 0 hours and 16 minutes
I0108 22:16:20.296123  2637 solver.cpp:291]     Train net output #0: loss = 0.0016964 (* 1 = 0.0016964 loss)
I0108 22:16:20.296131  2637 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0108 22:16:33.265559  2637 solver.cpp:270] Iteration 8300 (3.85536 iter/s, 12.969s/50 iter), loss = 0.0140155, remaining 0 hours and 15 minutes
I0108 22:16:33.265606  2637 solver.cpp:291]     Train net output #0: loss = 0.0140155 (* 1 = 0.0140155 loss)
I0108 22:16:33.265630  2637 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0108 22:16:46.262140  2637 solver.cpp:270] Iteration 8350 (3.84732 iter/s, 12.996s/50 iter), loss = 0.00332173, remaining 0 hours and 15 minutes
I0108 22:16:46.262171  2637 solver.cpp:291]     Train net output #0: loss = 0.00332177 (* 1 = 0.00332177 loss)
I0108 22:16:46.262178  2637 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0108 22:16:59.235224  2637 solver.cpp:270] Iteration 8400 (3.85429 iter/s, 12.9726s/50 iter), loss = 0.00333784, remaining 0 hours and 15 minutes
I0108 22:16:59.235257  2637 solver.cpp:291]     Train net output #0: loss = 0.00333787 (* 1 = 0.00333787 loss)
I0108 22:16:59.235280  2637 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0108 22:17:12.216603  2637 solver.cpp:270] Iteration 8450 (3.85182 iter/s, 12.9809s/50 iter), loss = 0.00284684, remaining 0 hours and 15 minutes
I0108 22:17:12.216650  2637 solver.cpp:291]     Train net output #0: loss = 0.00284687 (* 1 = 0.00284687 loss)
I0108 22:17:12.216657  2637 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0108 22:17:25.194617  2637 solver.cpp:270] Iteration 8500 (3.85283 iter/s, 12.9775s/50 iter), loss = 0.00367768, remaining 0 hours and 15 minutes
I0108 22:17:25.194648  2637 solver.cpp:291]     Train net output #0: loss = 0.00367771 (* 1 = 0.00367771 loss)
I0108 22:17:25.194672  2637 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0108 22:17:38.160487  2637 solver.cpp:270] Iteration 8550 (3.85643 iter/s, 12.9654s/50 iter), loss = 0.0199316, remaining 0 hours and 14 minutes
I0108 22:17:38.160519  2637 solver.cpp:291]     Train net output #0: loss = 0.0199317 (* 1 = 0.0199317 loss)
I0108 22:17:38.160526  2637 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0108 22:17:51.144276  2637 solver.cpp:270] Iteration 8600 (3.85111 iter/s, 12.9833s/50 iter), loss = 0.0059534, remaining 0 hours and 14 minutes
I0108 22:17:51.144322  2637 solver.cpp:291]     Train net output #0: loss = 0.00595344 (* 1 = 0.00595344 loss)
I0108 22:17:51.144330  2637 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0108 22:18:04.115203  2637 solver.cpp:270] Iteration 8650 (3.85493 iter/s, 12.9704s/50 iter), loss = 0.00846198, remaining 0 hours and 14 minutes
I0108 22:18:04.115236  2637 solver.cpp:291]     Train net output #0: loss = 0.00846202 (* 1 = 0.00846202 loss)
I0108 22:18:04.115244  2637 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0108 22:18:17.107169  2637 solver.cpp:270] Iteration 8700 (3.84869 iter/s, 12.9914s/50 iter), loss = 0.0170404, remaining 0 hours and 14 minutes
I0108 22:18:17.107203  2637 solver.cpp:291]     Train net output #0: loss = 0.0170404 (* 1 = 0.0170404 loss)
I0108 22:18:17.107210  2637 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0108 22:18:30.059311  2637 solver.cpp:270] Iteration 8750 (3.86052 iter/s, 12.9516s/50 iter), loss = 0.00120233, remaining 0 hours and 13 minutes
I0108 22:18:30.059362  2637 solver.cpp:291]     Train net output #0: loss = 0.00120238 (* 1 = 0.00120238 loss)
I0108 22:18:30.059386  2637 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0108 22:18:43.061019  2637 solver.cpp:270] Iteration 8800 (3.84581 iter/s, 13.0012s/50 iter), loss = 0.0367902, remaining 0 hours and 13 minutes
I0108 22:18:43.061053  2637 solver.cpp:291]     Train net output #0: loss = 0.0367903 (* 1 = 0.0367903 loss)
I0108 22:18:43.061060  2637 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0108 22:18:56.036737  2637 solver.cpp:270] Iteration 8850 (3.85351 iter/s, 12.9752s/50 iter), loss = 0.00541019, remaining 0 hours and 13 minutes
I0108 22:18:56.036769  2637 solver.cpp:291]     Train net output #0: loss = 0.00541023 (* 1 = 0.00541023 loss)
I0108 22:18:56.036777  2637 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0108 22:19:09.034072  2637 solver.cpp:270] Iteration 8900 (3.8471 iter/s, 12.9968s/50 iter), loss = 0.0139834, remaining 0 hours and 13 minutes
I0108 22:19:09.034119  2637 solver.cpp:291]     Train net output #0: loss = 0.0139834 (* 1 = 0.0139834 loss)
I0108 22:19:09.034126  2637 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0108 22:19:21.989809  2637 solver.cpp:270] Iteration 8950 (3.85945 iter/s, 12.9552s/50 iter), loss = 0.0135499, remaining 0 hours and 12 minutes
I0108 22:19:21.989841  2637 solver.cpp:291]     Train net output #0: loss = 0.0135499 (* 1 = 0.0135499 loss)
I0108 22:19:21.989848  2637 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0108 22:19:34.752256  2637 solver.cpp:424] Iteration 9000, Testing net (#0)
I0108 22:19:36.280720  2637 solver.cpp:523]     Test net output #0: accuracy = 0.95
I0108 22:19:36.280750  2637 solver.cpp:523]     Test net output #1: loss = 0.250088 (* 1 = 0.250088 loss)
I0108 22:19:36.280755  2637 solver.cpp:523]     Test net output #2: top-1 = 0.95
I0108 22:19:36.528959  2637 solver.cpp:270] Iteration 9000 (3.43913 iter/s, 14.5386s/50 iter), loss = 0.000682177, remaining 0 hours and 14 minutes
I0108 22:19:36.528985  2637 solver.cpp:291]     Train net output #0: loss = 0.000682223 (* 1 = 0.000682223 loss)
I0108 22:19:36.528995  2637 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0108 22:19:49.518800  2637 solver.cpp:270] Iteration 9050 (3.84931 iter/s, 12.9893s/50 iter), loss = 0.000358215, remaining 0 hours and 12 minutes
I0108 22:19:49.518847  2637 solver.cpp:291]     Train net output #0: loss = 0.000358263 (* 1 = 0.000358263 loss)
I0108 22:19:49.518855  2637 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0108 22:20:02.494236  2637 solver.cpp:270] Iteration 9100 (3.85359 iter/s, 12.9749s/50 iter), loss = 0.0157275, remaining 0 hours and 12 minutes
I0108 22:20:02.494271  2637 solver.cpp:291]     Train net output #0: loss = 0.0157276 (* 1 = 0.0157276 loss)
I0108 22:20:02.494278  2637 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0108 22:20:15.468972  2637 solver.cpp:270] Iteration 9150 (3.8538 iter/s, 12.9742s/50 iter), loss = 0.00219354, remaining 0 hours and 12 minutes
I0108 22:20:15.469007  2637 solver.cpp:291]     Train net output #0: loss = 0.00219359 (* 1 = 0.00219359 loss)
I0108 22:20:15.469013  2637 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0108 22:20:28.459818  2637 solver.cpp:270] Iteration 9200 (3.84902 iter/s, 12.9903s/50 iter), loss = 0.000879856, remaining 0 hours and 11 minutes
I0108 22:20:28.459863  2637 solver.cpp:291]     Train net output #0: loss = 0.000879906 (* 1 = 0.000879906 loss)
I0108 22:20:28.459887  2637 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0108 22:20:41.443449  2637 solver.cpp:270] Iteration 9250 (3.85116 iter/s, 12.9831s/50 iter), loss = 0.00148815, remaining 0 hours and 11 minutes
I0108 22:20:41.443481  2637 solver.cpp:291]     Train net output #0: loss = 0.0014882 (* 1 = 0.0014882 loss)
I0108 22:20:41.443488  2637 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0108 22:20:54.390306  2637 solver.cpp:270] Iteration 9300 (3.86209 iter/s, 12.9463s/50 iter), loss = 0.00586228, remaining 0 hours and 11 minutes
I0108 22:20:54.390339  2637 solver.cpp:291]     Train net output #0: loss = 0.00586233 (* 1 = 0.00586233 loss)
I0108 22:20:54.390347  2637 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0108 22:21:07.372902  2637 solver.cpp:270] Iteration 9350 (3.85146 iter/s, 12.9821s/50 iter), loss = 0.00553053, remaining 0 hours and 11 minutes
I0108 22:21:07.372954  2637 solver.cpp:291]     Train net output #0: loss = 0.00553058 (* 1 = 0.00553058 loss)
I0108 22:21:07.372962  2637 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0108 22:21:20.354030  2637 solver.cpp:270] Iteration 9400 (3.8519 iter/s, 12.9806s/50 iter), loss = 0.00437804, remaining 0 hours and 11 minutes
I0108 22:21:20.354061  2637 solver.cpp:291]     Train net output #0: loss = 0.0043781 (* 1 = 0.0043781 loss)
I0108 22:21:20.354068  2637 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0108 22:21:33.308871  2637 solver.cpp:270] Iteration 9450 (3.85971 iter/s, 12.9543s/50 iter), loss = 0.00565845, remaining 0 hours and 10 minutes
I0108 22:21:33.308902  2637 solver.cpp:291]     Train net output #0: loss = 0.0056585 (* 1 = 0.0056585 loss)
I0108 22:21:33.308910  2637 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0108 22:21:46.321992  2637 solver.cpp:270] Iteration 9500 (3.84243 iter/s, 13.0126s/50 iter), loss = 0.00952549, remaining 0 hours and 10 minutes
I0108 22:21:46.322041  2637 solver.cpp:291]     Train net output #0: loss = 0.00952554 (* 1 = 0.00952554 loss)
I0108 22:21:46.322049  2637 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0108 22:21:59.264315  2637 solver.cpp:270] Iteration 9550 (3.86345 iter/s, 12.9418s/50 iter), loss = 0.000355338, remaining 0 hours and 10 minutes
I0108 22:21:59.264346  2637 solver.cpp:291]     Train net output #0: loss = 0.000355389 (* 1 = 0.000355389 loss)
I0108 22:21:59.264369  2637 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0108 22:22:12.229001  2637 solver.cpp:270] Iteration 9600 (3.85678 iter/s, 12.9642s/50 iter), loss = 0.00246073, remaining 0 hours and 10 minutes
I0108 22:22:12.229033  2637 solver.cpp:291]     Train net output #0: loss = 0.00246079 (* 1 = 0.00246079 loss)
I0108 22:22:12.229040  2637 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0108 22:22:25.226586  2637 solver.cpp:270] Iteration 9650 (3.84702 iter/s, 12.9971s/50 iter), loss = 0.0130036, remaining 0 hours and 10 minutes
I0108 22:22:25.226632  2637 solver.cpp:291]     Train net output #0: loss = 0.0130037 (* 1 = 0.0130037 loss)
I0108 22:22:25.226639  2637 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0108 22:22:38.201489  2637 solver.cpp:270] Iteration 9700 (3.85375 iter/s, 12.9744s/50 iter), loss = 0.0143356, remaining 0 hours and 9 minutes
I0108 22:22:38.201520  2637 solver.cpp:291]     Train net output #0: loss = 0.0143357 (* 1 = 0.0143357 loss)
I0108 22:22:38.201527  2637 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0108 22:22:51.206276  2637 solver.cpp:270] Iteration 9750 (3.84489 iter/s, 13.0043s/50 iter), loss = 0.0069621, remaining 0 hours and 9 minutes
I0108 22:22:51.206310  2637 solver.cpp:291]     Train net output #0: loss = 0.00696216 (* 1 = 0.00696216 loss)
I0108 22:22:51.206317  2637 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0108 22:23:04.174913  2637 solver.cpp:270] Iteration 9800 (3.85561 iter/s, 12.9681s/50 iter), loss = 0.00846025, remaining 0 hours and 9 minutes
I0108 22:23:04.174962  2637 solver.cpp:291]     Train net output #0: loss = 0.00846031 (* 1 = 0.00846031 loss)
I0108 22:23:04.174968  2637 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0108 22:23:17.180887  2637 solver.cpp:270] Iteration 9850 (3.84454 iter/s, 13.0054s/50 iter), loss = 0.00681808, remaining 0 hours and 9 minutes
I0108 22:23:17.180920  2637 solver.cpp:291]     Train net output #0: loss = 0.00681814 (* 1 = 0.00681814 loss)
I0108 22:23:17.180928  2637 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0108 22:23:30.148033  2637 solver.cpp:270] Iteration 9900 (3.85605 iter/s, 12.9666s/50 iter), loss = 0.00974062, remaining 0 hours and 9 minutes
I0108 22:23:30.148066  2637 solver.cpp:291]     Train net output #0: loss = 0.00974069 (* 1 = 0.00974069 loss)
I0108 22:23:30.148088  2637 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0108 22:23:43.124110  2637 solver.cpp:270] Iteration 9950 (3.8534 iter/s, 12.9756s/50 iter), loss = 0.00705835, remaining 0 hours and 8 minutes
I0108 22:23:43.124162  2637 solver.cpp:291]     Train net output #0: loss = 0.00705841 (* 1 = 0.00705841 loss)
I0108 22:23:43.124171  2637 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0108 22:23:55.844251  2637 solver.cpp:424] Iteration 10000, Testing net (#0)
I0108 22:23:57.376857  2637 solver.cpp:523]     Test net output #0: accuracy = 0.9485
I0108 22:23:57.376885  2637 solver.cpp:523]     Test net output #1: loss = 0.26133 (* 1 = 0.26133 loss)
I0108 22:23:57.376890  2637 solver.cpp:523]     Test net output #2: top-1 = 0.9485
I0108 22:23:57.628608  2637 solver.cpp:270] Iteration 10000 (3.44735 iter/s, 14.5039s/50 iter), loss = 0.0104402, remaining 0 hours and 9 minutes
I0108 22:23:57.628635  2637 solver.cpp:291]     Train net output #0: loss = 0.0104403 (* 1 = 0.0104403 loss)
I0108 22:23:57.628643  2637 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0108 22:24:10.586258  2637 solver.cpp:270] Iteration 10050 (3.85888 iter/s, 12.9571s/50 iter), loss = 0.0055856, remaining 0 hours and 8 minutes
I0108 22:24:10.586292  2637 solver.cpp:291]     Train net output #0: loss = 0.00558567 (* 1 = 0.00558567 loss)
I0108 22:24:10.586299  2637 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0108 22:24:23.573714  2637 solver.cpp:270] Iteration 10100 (3.85002 iter/s, 12.9869s/50 iter), loss = 0.00113714, remaining 0 hours and 8 minutes
I0108 22:24:23.573763  2637 solver.cpp:291]     Train net output #0: loss = 0.0011372 (* 1 = 0.0011372 loss)
I0108 22:24:23.573771  2637 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0108 22:24:36.558539  2637 solver.cpp:270] Iteration 10150 (3.85081 iter/s, 12.9843s/50 iter), loss = 0.00210909, remaining 0 hours and 7 minutes
I0108 22:24:36.558573  2637 solver.cpp:291]     Train net output #0: loss = 0.00210916 (* 1 = 0.00210916 loss)
I0108 22:24:36.558581  2637 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0108 22:24:49.576575  2637 solver.cpp:270] Iteration 10200 (3.84098 iter/s, 13.0175s/50 iter), loss = 0.00157376, remaining 0 hours and 7 minutes
I0108 22:24:49.576607  2637 solver.cpp:291]     Train net output #0: loss = 0.00157383 (* 1 = 0.00157383 loss)
I0108 22:24:49.576615  2637 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0108 22:25:02.561045  2637 solver.cpp:270] Iteration 10250 (3.85091 iter/s, 12.984s/50 iter), loss = 0.00172507, remaining 0 hours and 7 minutes
I0108 22:25:02.561092  2637 solver.cpp:291]     Train net output #0: loss = 0.00172514 (* 1 = 0.00172514 loss)
I0108 22:25:02.561115  2637 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0108 22:25:15.513087  2637 solver.cpp:270] Iteration 10300 (3.86055 iter/s, 12.9515s/50 iter), loss = 0.00314773, remaining 0 hours and 7 minutes
I0108 22:25:15.513119  2637 solver.cpp:291]     Train net output #0: loss = 0.0031478 (* 1 = 0.0031478 loss)
I0108 22:25:15.513126  2637 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0108 22:25:28.517520  2637 solver.cpp:270] Iteration 10350 (3.845 iter/s, 13.0039s/50 iter), loss = 0.00657228, remaining 0 hours and 7 minutes
I0108 22:25:28.517552  2637 solver.cpp:291]     Train net output #0: loss = 0.00657236 (* 1 = 0.00657236 loss)
I0108 22:25:28.517560  2637 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0108 22:25:41.479140  2637 solver.cpp:270] Iteration 10400 (3.8577 iter/s, 12.9611s/50 iter), loss = 0.0265025, remaining 0 hours and 6 minutes
I0108 22:25:41.479210  2637 solver.cpp:291]     Train net output #0: loss = 0.0265026 (* 1 = 0.0265026 loss)
I0108 22:25:41.479218  2637 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0108 22:25:54.466312  2637 solver.cpp:270] Iteration 10450 (3.85012 iter/s, 12.9866s/50 iter), loss = 0.00306765, remaining 0 hours and 6 minutes
I0108 22:25:54.466346  2637 solver.cpp:291]     Train net output #0: loss = 0.00306773 (* 1 = 0.00306773 loss)
I0108 22:25:54.466369  2637 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0108 22:26:07.450122  2637 solver.cpp:270] Iteration 10500 (3.8511 iter/s, 12.9833s/50 iter), loss = 0.00200672, remaining 0 hours and 6 minutes
I0108 22:26:07.450153  2637 solver.cpp:291]     Train net output #0: loss = 0.0020068 (* 1 = 0.0020068 loss)
I0108 22:26:07.450160  2637 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0108 22:26:20.410404  2637 solver.cpp:270] Iteration 10550 (3.85809 iter/s, 12.9598s/50 iter), loss = 0.0108644, remaining 0 hours and 6 minutes
I0108 22:26:20.410449  2637 solver.cpp:291]     Train net output #0: loss = 0.0108645 (* 1 = 0.0108645 loss)
I0108 22:26:20.410472  2637 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0108 22:26:33.400123  2637 solver.cpp:270] Iteration 10600 (3.84935 iter/s, 12.9892s/50 iter), loss = 0.00193046, remaining 0 hours and 5 minutes
I0108 22:26:33.400156  2637 solver.cpp:291]     Train net output #0: loss = 0.00193053 (* 1 = 0.00193053 loss)
I0108 22:26:33.400164  2637 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0108 22:26:46.376181  2637 solver.cpp:270] Iteration 10650 (3.8534 iter/s, 12.9755s/50 iter), loss = 0.000956411, remaining 0 hours and 5 minutes
I0108 22:26:46.376214  2637 solver.cpp:291]     Train net output #0: loss = 0.000956493 (* 1 = 0.000956493 loss)
I0108 22:26:46.376220  2637 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0108 22:26:59.349814  2637 solver.cpp:270] Iteration 10700 (3.85412 iter/s, 12.9731s/50 iter), loss = 0.00176797, remaining 0 hours and 5 minutes
I0108 22:26:59.349859  2637 solver.cpp:291]     Train net output #0: loss = 0.00176805 (* 1 = 0.00176805 loss)
I0108 22:26:59.349882  2637 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0108 22:27:12.333745  2637 solver.cpp:270] Iteration 10750 (3.85107 iter/s, 12.9834s/50 iter), loss = 0.00250089, remaining 0 hours and 5 minutes
I0108 22:27:12.333777  2637 solver.cpp:291]     Train net output #0: loss = 0.00250097 (* 1 = 0.00250097 loss)
I0108 22:27:12.333801  2637 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0108 22:27:25.339850  2637 solver.cpp:270] Iteration 10800 (3.8445 iter/s, 13.0056s/50 iter), loss = 0.00196334, remaining 0 hours and 5 minutes
I0108 22:27:25.339882  2637 solver.cpp:291]     Train net output #0: loss = 0.00196342 (* 1 = 0.00196342 loss)
I0108 22:27:25.339890  2637 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0108 22:27:38.296030  2637 solver.cpp:270] Iteration 10850 (3.85932 iter/s, 12.9557s/50 iter), loss = 0.0182303, remaining 0 hours and 4 minutes
I0108 22:27:38.296075  2637 solver.cpp:291]     Train net output #0: loss = 0.0182304 (* 1 = 0.0182304 loss)
I0108 22:27:38.296083  2637 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0108 22:27:51.266801  2637 solver.cpp:270] Iteration 10900 (3.85498 iter/s, 12.9702s/50 iter), loss = 0.00246779, remaining 0 hours and 4 minutes
I0108 22:27:51.266834  2637 solver.cpp:291]     Train net output #0: loss = 0.00246786 (* 1 = 0.00246786 loss)
I0108 22:27:51.266841  2637 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0108 22:28:04.242671  2637 solver.cpp:270] Iteration 10950 (3.85346 iter/s, 12.9754s/50 iter), loss = 0.00231194, remaining 0 hours and 4 minutes
I0108 22:28:04.242703  2637 solver.cpp:291]     Train net output #0: loss = 0.00231202 (* 1 = 0.00231202 loss)
I0108 22:28:04.242710  2637 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0108 22:28:16.958389  2637 solver.cpp:424] Iteration 11000, Testing net (#0)
I0108 22:28:18.508769  2637 solver.cpp:523]     Test net output #0: accuracy = 0.94925
I0108 22:28:18.508797  2637 solver.cpp:523]     Test net output #1: loss = 0.269483 (* 1 = 0.269483 loss)
I0108 22:28:18.508802  2637 solver.cpp:523]     Test net output #2: top-1 = 0.94925
I0108 22:28:18.755892  2637 solver.cpp:270] Iteration 11000 (3.44527 iter/s, 14.5127s/50 iter), loss = 0.0115071, remaining 0 hours and 4 minutes
I0108 22:28:18.755916  2637 solver.cpp:291]     Train net output #0: loss = 0.0115072 (* 1 = 0.0115072 loss)
I0108 22:28:18.755925  2637 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0108 22:28:31.730441  2637 solver.cpp:270] Iteration 11050 (3.85385 iter/s, 12.974s/50 iter), loss = 0.0113718, remaining 0 hours and 3 minutes
I0108 22:28:31.730476  2637 solver.cpp:291]     Train net output #0: loss = 0.0113718 (* 1 = 0.0113718 loss)
I0108 22:28:31.730484  2637 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0108 22:28:44.697377  2637 solver.cpp:270] Iteration 11100 (3.85611 iter/s, 12.9664s/50 iter), loss = 0.0108384, remaining 0 hours and 3 minutes
I0108 22:28:44.697408  2637 solver.cpp:291]     Train net output #0: loss = 0.0108385 (* 1 = 0.0108385 loss)
I0108 22:28:44.697432  2637 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0108 22:28:57.663038  2637 solver.cpp:270] Iteration 11150 (3.85649 iter/s, 12.9651s/50 iter), loss = 0.00127162, remaining 0 hours and 3 minutes
I0108 22:28:57.663094  2637 solver.cpp:291]     Train net output #0: loss = 0.0012717 (* 1 = 0.0012717 loss)
I0108 22:28:57.663101  2637 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0108 22:29:10.655503  2637 solver.cpp:270] Iteration 11200 (3.84854 iter/s, 12.9919s/50 iter), loss = 0.00708181, remaining 0 hours and 3 minutes
I0108 22:29:10.655534  2637 solver.cpp:291]     Train net output #0: loss = 0.00708189 (* 1 = 0.00708189 loss)
I0108 22:29:10.655542  2637 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0108 22:29:23.627166  2637 solver.cpp:270] Iteration 11250 (3.85471 iter/s, 12.9711s/50 iter), loss = 0.0158359, remaining 0 hours and 3 minutes
I0108 22:29:23.627197  2637 solver.cpp:291]     Train net output #0: loss = 0.015836 (* 1 = 0.015836 loss)
I0108 22:29:23.627204  2637 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0108 22:29:36.616482  2637 solver.cpp:270] Iteration 11300 (3.84947 iter/s, 12.9888s/50 iter), loss = 0.0110201, remaining 0 hours and 2 minutes
I0108 22:29:36.616529  2637 solver.cpp:291]     Train net output #0: loss = 0.0110201 (* 1 = 0.0110201 loss)
I0108 22:29:36.616537  2637 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0108 22:29:49.601342  2637 solver.cpp:270] Iteration 11350 (3.8508 iter/s, 12.9843s/50 iter), loss = 0.00117152, remaining 0 hours and 2 minutes
I0108 22:29:49.601375  2637 solver.cpp:291]     Train net output #0: loss = 0.00117161 (* 1 = 0.00117161 loss)
I0108 22:29:49.601382  2637 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0108 22:30:02.559684  2637 solver.cpp:270] Iteration 11400 (3.85867 iter/s, 12.9578s/50 iter), loss = 0.00704294, remaining 0 hours and 2 minutes
I0108 22:30:02.559717  2637 solver.cpp:291]     Train net output #0: loss = 0.00704302 (* 1 = 0.00704302 loss)
I0108 22:30:02.559725  2637 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0108 22:30:15.531630  2637 solver.cpp:270] Iteration 11450 (3.85463 iter/s, 12.9714s/50 iter), loss = 0.00544357, remaining 0 hours and 2 minutes
I0108 22:30:15.531677  2637 solver.cpp:291]     Train net output #0: loss = 0.00544365 (* 1 = 0.00544365 loss)
I0108 22:30:15.531687  2637 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0108 22:30:28.530211  2637 solver.cpp:270] Iteration 11500 (3.84673 iter/s, 12.998s/50 iter), loss = 0.000297932, remaining 0 hours and 2 minutes
I0108 22:30:28.530244  2637 solver.cpp:291]     Train net output #0: loss = 0.000298026 (* 1 = 0.000298026 loss)
I0108 22:30:28.530253  2637 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0108 22:30:41.489714  2637 solver.cpp:270] Iteration 11550 (3.85833 iter/s, 12.959s/50 iter), loss = 0.00562075, remaining 0 hours and 1 minutes
I0108 22:30:41.489748  2637 solver.cpp:291]     Train net output #0: loss = 0.00562085 (* 1 = 0.00562085 loss)
I0108 22:30:41.489755  2637 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0108 22:30:54.473202  2637 solver.cpp:270] Iteration 11600 (3.8512 iter/s, 12.983s/50 iter), loss = 0.00474831, remaining 0 hours and 1 minutes
I0108 22:30:54.473259  2637 solver.cpp:291]     Train net output #0: loss = 0.00474841 (* 1 = 0.00474841 loss)
I0108 22:30:54.473284  2637 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0108 22:31:07.438144  2637 solver.cpp:270] Iteration 11650 (3.85671 iter/s, 12.9644s/50 iter), loss = 0.0363443, remaining 0 hours and 1 minutes
I0108 22:31:07.438175  2637 solver.cpp:291]     Train net output #0: loss = 0.0363444 (* 1 = 0.0363444 loss)
I0108 22:31:07.438182  2637 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0108 22:31:20.393445  2637 solver.cpp:270] Iteration 11700 (3.85958 iter/s, 12.9548s/50 iter), loss = 0.000549642, remaining 0 hours and 1 minutes
I0108 22:31:20.393476  2637 solver.cpp:291]     Train net output #0: loss = 0.000549743 (* 1 = 0.000549743 loss)
I0108 22:31:20.393482  2637 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0108 22:31:33.358795  2637 solver.cpp:270] Iteration 11750 (3.85659 iter/s, 12.9648s/50 iter), loss = 0.00479677, remaining 0 hours and 1 minutes
I0108 22:31:33.358841  2637 solver.cpp:291]     Train net output #0: loss = 0.00479688 (* 1 = 0.00479688 loss)
I0108 22:31:33.358848  2637 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0108 22:31:46.317927  2637 solver.cpp:270] Iteration 11800 (3.85844 iter/s, 12.9586s/50 iter), loss = 0.00263172, remaining 0 hours and 0 minutes
I0108 22:31:46.317960  2637 solver.cpp:291]     Train net output #0: loss = 0.00263183 (* 1 = 0.00263183 loss)
I0108 22:31:46.317967  2637 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0108 22:31:59.298391  2637 solver.cpp:270] Iteration 11850 (3.8521 iter/s, 12.9799s/50 iter), loss = 0.00338484, remaining 0 hours and 0 minutes
I0108 22:31:59.298426  2637 solver.cpp:291]     Train net output #0: loss = 0.00338494 (* 1 = 0.00338494 loss)
I0108 22:31:59.298434  2637 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0108 22:32:12.265662  2637 solver.cpp:270] Iteration 11900 (3.85602 iter/s, 12.9668s/50 iter), loss = 0.00497602, remaining 0 hours and 0 minutes
I0108 22:32:12.265709  2637 solver.cpp:291]     Train net output #0: loss = 0.00497613 (* 1 = 0.00497613 loss)
I0108 22:32:12.265717  2637 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0108 22:32:25.229844  2637 solver.cpp:270] Iteration 11950 (3.85694 iter/s, 12.9637s/50 iter), loss = 0.00246797, remaining 0 hours and 0 minutes
I0108 22:32:25.229877  2637 solver.cpp:291]     Train net output #0: loss = 0.00246808 (* 1 = 0.00246808 loss)
I0108 22:32:25.229885  2637 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0108 22:32:37.938118  2637 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.2/snapshots/_iter_12000.caffemodel
I0108 22:32:40.357761  2637 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.2/snapshots/_iter_12000.solverstate
I0108 22:32:40.673842  2637 solver.cpp:384] Iteration 12000, loss = 0.0017036
I0108 22:32:40.673871  2637 solver.cpp:424] Iteration 12000, Testing net (#0)
I0108 22:32:42.141280  2637 solver.cpp:523]     Test net output #0: accuracy = 0.94975
I0108 22:32:42.141309  2637 solver.cpp:523]     Test net output #1: loss = 0.273009 (* 1 = 0.273009 loss)
I0108 22:32:42.141314  2637 solver.cpp:523]     Test net output #2: top-1 = 0.94975
I0108 22:32:42.141335  2637 solver.cpp:392] Optimization Done (3.84336 iter/s).
I0108 22:32:42.141338  2637 caffe_interface.cpp:546] Optimization Done.
(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

I0108 22:32:42.818069  2734 pruning_runner.cpp:206] Analysis info found.
I0108 22:32:44.371654  2734 pruning_runner.cpp:237] Start pruning, please wait...
I0108 22:32:50.960489  2734 pruning_runner.cpp:284] Compression complete 0.39923%
I0108 22:32:59.268187  2734 pruning_runner.cpp:337] pruning done, output model: pruning/alexnetBNnoLRN/regular_rate_0.3/sparse.caffemodel
I0108 22:32:59.268213  2734 pruning_runner.cpp:351] summary of REGULAR compression with rate 0.3:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.943749785    | 0.949749649    | 0.00599986315  |
+-------------------------------------------------------------------+
| Weights        | 3.7649951 M    | 1.037413 M     | -72.4458313%   |
+-------------------------------------------------------------------+
| Operations     | 2.1539185 G    | 1.23211837 G   | -42.7964211%   |
+-------------------------------------------------------------------+
To fine-tune the pruned model, please run:
vai_p_caffe finetune -config /workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/config3.prototxt
(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

W0108 22:32:59.435771  2979 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0108 22:32:59.436043  2979 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0108 22:32:59.436069  2979 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0108 22:32:59.439792  2979 vai_p_caffe.cpp:287] pruning/alexnetBNnoLRN/regular_rate_0.3/net_finetune.prototxt
I0108 22:32:59.601678  2979 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0108 22:32:59.601698  2979 gpu_memory.cpp:55] Total memory: 25620447232, Free: 25022103552, dev_info[0]: total=25620447232 free=25022103552
I0108 22:32:59.602502  2979 caffe_interface.cpp:509] Using GPUs 0
I0108 22:32:59.602754  2979 caffe_interface.cpp:514] GPU 0: Quadro P6000
I0108 22:33:00.495098  2979 solver.cpp:51] Initializing solver from parameters:
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 6000
snapshot_prefix: "pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "pruning/alexnetBNnoLRN/regular_rate_0.3/net_finetune.prototxt"
type: "Adam"
I0108 22:33:00.495249  2979 solver.cpp:99] Creating training net from net file: pruning/alexnetBNnoLRN/regular_rate_0.3/net_finetune.prototxt
I0108 22:33:00.495559  2979 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0108 22:33:00.495573  2979 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0108 22:33:00.495576  2979 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0108 22:33:00.495581  2979 net.cpp:52] Initializing net from parameters:
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0108 22:33:00.495787  2979 layer_factory.hpp:77] Creating layer data
I0108 22:33:00.495937  2979 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 22:33:00.497553  2979 net.cpp:94] Creating Layer data
I0108 22:33:00.497565  2979 net.cpp:409] data -> data
I0108 22:33:00.497575  2979 net.cpp:409] data -> label
I0108 22:33:00.498796  3016 db_lmdb.cpp:35] Opened lmdb input/lmdb/train_lmdb
I0108 22:33:00.498818  3016 db_lmdb.cpp:38] Items count: 20000
I0108 22:33:00.498840  3016 data_reader.cpp:124] TRAIN: reading data using 1 channel(s)
I0108 22:33:00.499157  2979 data_layer.cpp:78] ReshapePrefetch 256, 3, 227, 227
I0108 22:33:00.499250  2979 data_layer.cpp:83] output data size: 256,3,227,227
I0108 22:33:00.969857  2979 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 22:33:00.969945  2979 net.cpp:144] Setting up data
I0108 22:33:00.969950  2979 net.cpp:151] Top shape: 256 3 227 227 (39574272)
I0108 22:33:00.969975  2979 net.cpp:151] Top shape: 256 (256)
I0108 22:33:00.969980  2979 net.cpp:159] Memory required for data: 158298112
I0108 22:33:00.969985  2979 layer_factory.hpp:77] Creating layer conv1
I0108 22:33:00.969996  2979 net.cpp:94] Creating Layer conv1
I0108 22:33:00.970010  2979 net.cpp:435] conv1 <- data
I0108 22:33:00.970016  2979 net.cpp:409] conv1 -> conv1
I0108 22:33:00.970582  2979 net.cpp:144] Setting up conv1
I0108 22:33:00.970588  2979 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0108 22:33:00.970593  2979 net.cpp:159] Memory required for data: 455667712
I0108 22:33:00.970604  2979 layer_factory.hpp:77] Creating layer bn1
I0108 22:33:00.970611  2979 net.cpp:94] Creating Layer bn1
I0108 22:33:00.970615  2979 net.cpp:435] bn1 <- conv1
I0108 22:33:00.970620  2979 net.cpp:409] bn1 -> bn1
I0108 22:33:00.971099  2979 net.cpp:144] Setting up bn1
I0108 22:33:00.971105  2979 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0108 22:33:00.971110  2979 net.cpp:159] Memory required for data: 753037312
I0108 22:33:00.971119  2979 layer_factory.hpp:77] Creating layer relu1
I0108 22:33:00.971125  2979 net.cpp:94] Creating Layer relu1
I0108 22:33:00.971128  2979 net.cpp:435] relu1 <- bn1
I0108 22:33:00.971132  2979 net.cpp:409] relu1 -> relu1
I0108 22:33:00.971148  2979 net.cpp:144] Setting up relu1
I0108 22:33:00.971153  2979 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0108 22:33:00.971158  2979 net.cpp:159] Memory required for data: 1050406912
I0108 22:33:00.971160  2979 layer_factory.hpp:77] Creating layer pool1
I0108 22:33:00.971168  2979 net.cpp:94] Creating Layer pool1
I0108 22:33:00.971170  2979 net.cpp:435] pool1 <- relu1
I0108 22:33:00.971174  2979 net.cpp:409] pool1 -> pool1
I0108 22:33:00.971200  2979 net.cpp:144] Setting up pool1
I0108 22:33:00.971205  2979 net.cpp:151] Top shape: 256 96 27 27 (17915904)
I0108 22:33:00.971210  2979 net.cpp:159] Memory required for data: 1122070528
I0108 22:33:00.971213  2979 layer_factory.hpp:77] Creating layer conv2
I0108 22:33:00.971221  2979 net.cpp:94] Creating Layer conv2
I0108 22:33:00.971225  2979 net.cpp:435] conv2 <- pool1
I0108 22:33:00.971230  2979 net.cpp:409] conv2 -> conv2
I0108 22:33:00.986534  2979 net.cpp:144] Setting up conv2
I0108 22:33:00.986552  2979 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0108 22:33:00.986560  2979 net.cpp:159] Memory required for data: 1313173504
I0108 22:33:00.986572  2979 layer_factory.hpp:77] Creating layer bn2
I0108 22:33:00.986580  2979 net.cpp:94] Creating Layer bn2
I0108 22:33:00.986585  2979 net.cpp:435] bn2 <- conv2
I0108 22:33:00.986624  2979 net.cpp:409] bn2 -> bn2
I0108 22:33:00.987434  2979 net.cpp:144] Setting up bn2
I0108 22:33:00.987443  2979 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0108 22:33:00.987449  2979 net.cpp:159] Memory required for data: 1504276480
I0108 22:33:00.987458  2979 layer_factory.hpp:77] Creating layer relu2
I0108 22:33:00.987463  2979 net.cpp:94] Creating Layer relu2
I0108 22:33:00.987468  2979 net.cpp:435] relu2 <- bn2
I0108 22:33:00.987473  2979 net.cpp:409] relu2 -> relu2
I0108 22:33:00.987490  2979 net.cpp:144] Setting up relu2
I0108 22:33:00.987496  2979 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0108 22:33:00.987502  2979 net.cpp:159] Memory required for data: 1695379456
I0108 22:33:00.987506  2979 layer_factory.hpp:77] Creating layer pool2
I0108 22:33:00.987514  2979 net.cpp:94] Creating Layer pool2
I0108 22:33:00.987517  2979 net.cpp:435] pool2 <- relu2
I0108 22:33:00.987524  2979 net.cpp:409] pool2 -> pool2
I0108 22:33:00.987567  2979 net.cpp:144] Setting up pool2
I0108 22:33:00.987574  2979 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0108 22:33:00.987581  2979 net.cpp:159] Memory required for data: 1739681792
I0108 22:33:00.987584  2979 layer_factory.hpp:77] Creating layer conv3
I0108 22:33:00.987605  2979 net.cpp:94] Creating Layer conv3
I0108 22:33:00.987609  2979 net.cpp:435] conv3 <- pool2
I0108 22:33:00.987615  2979 net.cpp:409] conv3 -> conv3
I0108 22:33:00.999938  2979 net.cpp:144] Setting up conv3
I0108 22:33:00.999961  2979 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 22:33:00.999974  2979 net.cpp:159] Memory required for data: 1806135296
I0108 22:33:00.999986  2979 layer_factory.hpp:77] Creating layer relu3
I0108 22:33:01.000020  2979 net.cpp:94] Creating Layer relu3
I0108 22:33:01.000047  2979 net.cpp:435] relu3 <- conv3
I0108 22:33:01.000075  2979 net.cpp:409] relu3 -> relu3
I0108 22:33:01.000134  2979 net.cpp:144] Setting up relu3
I0108 22:33:01.000157  2979 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 22:33:01.000181  2979 net.cpp:159] Memory required for data: 1872588800
I0108 22:33:01.000203  2979 layer_factory.hpp:77] Creating layer conv4
I0108 22:33:01.000231  2979 net.cpp:94] Creating Layer conv4
I0108 22:33:01.000254  2979 net.cpp:435] conv4 <- relu3
I0108 22:33:01.000284  2979 net.cpp:409] conv4 -> conv4
I0108 22:33:01.020426  2979 net.cpp:144] Setting up conv4
I0108 22:33:01.020447  2979 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 22:33:01.020454  2979 net.cpp:159] Memory required for data: 1939042304
I0108 22:33:01.020467  2979 layer_factory.hpp:77] Creating layer relu4
I0108 22:33:01.020473  2979 net.cpp:94] Creating Layer relu4
I0108 22:33:01.020478  2979 net.cpp:435] relu4 <- conv4
I0108 22:33:01.020484  2979 net.cpp:409] relu4 -> relu4
I0108 22:33:01.020506  2979 net.cpp:144] Setting up relu4
I0108 22:33:01.020509  2979 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 22:33:01.020517  2979 net.cpp:159] Memory required for data: 2005495808
I0108 22:33:01.020524  2979 layer_factory.hpp:77] Creating layer conv5
I0108 22:33:01.020534  2979 net.cpp:94] Creating Layer conv5
I0108 22:33:01.020545  2979 net.cpp:435] conv5 <- relu4
I0108 22:33:01.020567  2979 net.cpp:409] conv5 -> conv5
I0108 22:33:01.036116  2979 net.cpp:144] Setting up conv5
I0108 22:33:01.036178  2979 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0108 22:33:01.036216  2979 net.cpp:159] Memory required for data: 2049798144
I0108 22:33:01.036259  2979 layer_factory.hpp:77] Creating layer relu5
I0108 22:33:01.036303  2979 net.cpp:94] Creating Layer relu5
I0108 22:33:01.036329  2979 net.cpp:435] relu5 <- conv5
I0108 22:33:01.036360  2979 net.cpp:409] relu5 -> relu5
I0108 22:33:01.036443  2979 net.cpp:144] Setting up relu5
I0108 22:33:01.036473  2979 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0108 22:33:01.036501  2979 net.cpp:159] Memory required for data: 2094100480
I0108 22:33:01.036526  2979 layer_factory.hpp:77] Creating layer pool5
I0108 22:33:01.036557  2979 net.cpp:94] Creating Layer pool5
I0108 22:33:01.036582  2979 net.cpp:435] pool5 <- relu5
I0108 22:33:01.036612  2979 net.cpp:409] pool5 -> pool5
I0108 22:33:01.036702  2979 net.cpp:144] Setting up pool5
I0108 22:33:01.036731  2979 net.cpp:151] Top shape: 256 256 6 6 (2359296)
I0108 22:33:01.036758  2979 net.cpp:159] Memory required for data: 2103537664
I0108 22:33:01.036787  2979 layer_factory.hpp:77] Creating layer fc6
I0108 22:33:01.036832  2979 net.cpp:94] Creating Layer fc6
I0108 22:33:01.036861  2979 net.cpp:435] fc6 <- pool5
I0108 22:33:01.036898  2979 net.cpp:409] fc6 -> fc6
I0108 22:33:01.400882  2979 net.cpp:144] Setting up fc6
I0108 22:33:01.400925  2979 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 22:33:01.400936  2979 net.cpp:159] Memory required for data: 2107731968
I0108 22:33:01.400952  2979 layer_factory.hpp:77] Creating layer relu6
I0108 22:33:01.400964  2979 net.cpp:94] Creating Layer relu6
I0108 22:33:01.400977  2979 net.cpp:435] relu6 <- fc6
I0108 22:33:01.400988  2979 net.cpp:409] relu6 -> relu6
I0108 22:33:01.401024  2979 net.cpp:144] Setting up relu6
I0108 22:33:01.401033  2979 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 22:33:01.401038  2979 net.cpp:159] Memory required for data: 2111926272
I0108 22:33:01.401043  2979 layer_factory.hpp:77] Creating layer drop6
I0108 22:33:01.401057  2979 net.cpp:94] Creating Layer drop6
I0108 22:33:01.401078  2979 net.cpp:435] drop6 <- relu6
I0108 22:33:01.401084  2979 net.cpp:409] drop6 -> drop6
I0108 22:33:01.401124  2979 net.cpp:144] Setting up drop6
I0108 22:33:01.401134  2979 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 22:33:01.401141  2979 net.cpp:159] Memory required for data: 2116120576
I0108 22:33:01.401146  2979 layer_factory.hpp:77] Creating layer fc7
I0108 22:33:01.401155  2979 net.cpp:94] Creating Layer fc7
I0108 22:33:01.401161  2979 net.cpp:435] fc7 <- drop6
I0108 22:33:01.401171  2979 net.cpp:409] fc7 -> fc7
I0108 22:33:01.555299  2979 net.cpp:144] Setting up fc7
I0108 22:33:01.555321  2979 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 22:33:01.555330  2979 net.cpp:159] Memory required for data: 2120314880
I0108 22:33:01.555339  2979 layer_factory.hpp:77] Creating layer bn7
I0108 22:33:01.555348  2979 net.cpp:94] Creating Layer bn7
I0108 22:33:01.555352  2979 net.cpp:435] bn7 <- fc7
I0108 22:33:01.555361  2979 net.cpp:409] bn7 -> bn7
I0108 22:33:01.555814  2979 net.cpp:144] Setting up bn7
I0108 22:33:01.555824  2979 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 22:33:01.555830  2979 net.cpp:159] Memory required for data: 2124509184
I0108 22:33:01.555840  2979 layer_factory.hpp:77] Creating layer relu7
I0108 22:33:01.555850  2979 net.cpp:94] Creating Layer relu7
I0108 22:33:01.555857  2979 net.cpp:435] relu7 <- bn7
I0108 22:33:01.555866  2979 net.cpp:409] relu7 -> relu7
I0108 22:33:01.555891  2979 net.cpp:144] Setting up relu7
I0108 22:33:01.555896  2979 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 22:33:01.555902  2979 net.cpp:159] Memory required for data: 2128703488
I0108 22:33:01.555905  2979 layer_factory.hpp:77] Creating layer drop7
I0108 22:33:01.555912  2979 net.cpp:94] Creating Layer drop7
I0108 22:33:01.555917  2979 net.cpp:435] drop7 <- relu7
I0108 22:33:01.555927  2979 net.cpp:409] drop7 -> drop7
I0108 22:33:01.555965  2979 net.cpp:144] Setting up drop7
I0108 22:33:01.555971  2979 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 22:33:01.555975  2979 net.cpp:159] Memory required for data: 2132897792
I0108 22:33:01.555979  2979 layer_factory.hpp:77] Creating layer fc8
I0108 22:33:01.555990  2979 net.cpp:94] Creating Layer fc8
I0108 22:33:01.556002  2979 net.cpp:435] fc8 <- drop7
I0108 22:33:01.556008  2979 net.cpp:409] fc8 -> fc8
I0108 22:33:01.556211  2979 net.cpp:144] Setting up fc8
I0108 22:33:01.556219  2979 net.cpp:151] Top shape: 256 2 (512)
I0108 22:33:01.556224  2979 net.cpp:159] Memory required for data: 2132899840
I0108 22:33:01.556231  2979 layer_factory.hpp:77] Creating layer loss
I0108 22:33:01.556236  2979 net.cpp:94] Creating Layer loss
I0108 22:33:01.556239  2979 net.cpp:435] loss <- fc8
I0108 22:33:01.556243  2979 net.cpp:435] loss <- label
I0108 22:33:01.556248  2979 net.cpp:409] loss -> loss
I0108 22:33:01.556267  2979 layer_factory.hpp:77] Creating layer loss
I0108 22:33:01.556334  2979 net.cpp:144] Setting up loss
I0108 22:33:01.556339  2979 net.cpp:151] Top shape: (1)
I0108 22:33:01.556344  2979 net.cpp:154]     with loss weight 1
I0108 22:33:01.556357  2979 net.cpp:159] Memory required for data: 2132899844
I0108 22:33:01.556365  2979 net.cpp:220] loss needs backward computation.
I0108 22:33:01.556368  2979 net.cpp:220] fc8 needs backward computation.
I0108 22:33:01.556372  2979 net.cpp:220] drop7 needs backward computation.
I0108 22:33:01.556376  2979 net.cpp:220] relu7 needs backward computation.
I0108 22:33:01.556380  2979 net.cpp:220] bn7 needs backward computation.
I0108 22:33:01.556383  2979 net.cpp:220] fc7 needs backward computation.
I0108 22:33:01.556388  2979 net.cpp:220] drop6 needs backward computation.
I0108 22:33:01.556393  2979 net.cpp:220] relu6 needs backward computation.
I0108 22:33:01.556397  2979 net.cpp:220] fc6 needs backward computation.
I0108 22:33:01.556401  2979 net.cpp:220] pool5 needs backward computation.
I0108 22:33:01.556406  2979 net.cpp:220] relu5 needs backward computation.
I0108 22:33:01.556409  2979 net.cpp:220] conv5 needs backward computation.
I0108 22:33:01.556412  2979 net.cpp:220] relu4 needs backward computation.
I0108 22:33:01.556425  2979 net.cpp:220] conv4 needs backward computation.
I0108 22:33:01.556429  2979 net.cpp:220] relu3 needs backward computation.
I0108 22:33:01.556433  2979 net.cpp:220] conv3 needs backward computation.
I0108 22:33:01.556437  2979 net.cpp:220] pool2 needs backward computation.
I0108 22:33:01.556442  2979 net.cpp:220] relu2 needs backward computation.
I0108 22:33:01.556445  2979 net.cpp:220] bn2 needs backward computation.
I0108 22:33:01.556449  2979 net.cpp:220] conv2 needs backward computation.
I0108 22:33:01.556453  2979 net.cpp:220] pool1 needs backward computation.
I0108 22:33:01.556458  2979 net.cpp:220] relu1 needs backward computation.
I0108 22:33:01.556463  2979 net.cpp:220] bn1 needs backward computation.
I0108 22:33:01.556468  2979 net.cpp:220] conv1 needs backward computation.
I0108 22:33:01.556473  2979 net.cpp:222] data does not need backward computation.
I0108 22:33:01.556478  2979 net.cpp:264] This network produces output loss
I0108 22:33:01.556507  2979 net.cpp:284] Network initialization done.
I0108 22:33:01.556923  2979 solver.cpp:189] Creating test net (#0) specified by net file: pruning/alexnetBNnoLRN/regular_rate_0.3/net_finetune.prototxt
I0108 22:33:01.556959  2979 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0108 22:33:01.556975  2979 net.cpp:52] Initializing net from parameters:
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0108 22:33:01.557248  2979 layer_factory.hpp:77] Creating layer data
I0108 22:33:01.557319  2979 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 22:33:01.560987  2979 net.cpp:94] Creating Layer data
I0108 22:33:01.561025  2979 net.cpp:409] data -> data
I0108 22:33:01.561058  2979 net.cpp:409] data -> label
I0108 22:33:01.561782  3046 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0108 22:33:01.561800  3046 db_lmdb.cpp:38] Items count: 4000
I0108 22:33:01.561820  3046 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0108 22:33:01.562351  2979 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0108 22:33:01.562666  2979 data_layer.cpp:83] output data size: 50,3,227,227
I0108 22:33:01.672775  2979 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 22:33:01.672894  2979 net.cpp:144] Setting up data
I0108 22:33:01.672901  2979 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0108 22:33:01.672910  2979 net.cpp:151] Top shape: 50 (50)
I0108 22:33:01.672914  2979 net.cpp:159] Memory required for data: 30917600
I0108 22:33:01.672919  2979 layer_factory.hpp:77] Creating layer label_data_1_split
I0108 22:33:01.672927  2979 net.cpp:94] Creating Layer label_data_1_split
I0108 22:33:01.672931  2979 net.cpp:435] label_data_1_split <- label
I0108 22:33:01.672936  2979 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0108 22:33:01.672945  2979 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0108 22:33:01.672950  2979 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0108 22:33:01.672999  2979 net.cpp:144] Setting up label_data_1_split
I0108 22:33:01.673004  2979 net.cpp:151] Top shape: 50 (50)
I0108 22:33:01.673007  2979 net.cpp:151] Top shape: 50 (50)
I0108 22:33:01.673012  2979 net.cpp:151] Top shape: 50 (50)
I0108 22:33:01.673014  2979 net.cpp:159] Memory required for data: 30918200
I0108 22:33:01.673017  2979 layer_factory.hpp:77] Creating layer conv1
I0108 22:33:01.673027  2979 net.cpp:94] Creating Layer conv1
I0108 22:33:01.673032  2979 net.cpp:435] conv1 <- data
I0108 22:33:01.673036  2979 net.cpp:409] conv1 -> conv1
I0108 22:33:01.673652  2979 net.cpp:144] Setting up conv1
I0108 22:33:01.673660  2979 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0108 22:33:01.673664  2979 net.cpp:159] Memory required for data: 88998200
I0108 22:33:01.673676  2979 layer_factory.hpp:77] Creating layer bn1
I0108 22:33:01.673681  2979 net.cpp:94] Creating Layer bn1
I0108 22:33:01.673686  2979 net.cpp:435] bn1 <- conv1
I0108 22:33:01.673691  2979 net.cpp:409] bn1 -> bn1
I0108 22:33:01.674223  2979 net.cpp:144] Setting up bn1
I0108 22:33:01.674229  2979 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0108 22:33:01.674235  2979 net.cpp:159] Memory required for data: 147078200
I0108 22:33:01.674244  2979 layer_factory.hpp:77] Creating layer relu1
I0108 22:33:01.674257  2979 net.cpp:94] Creating Layer relu1
I0108 22:33:01.674260  2979 net.cpp:435] relu1 <- bn1
I0108 22:33:01.674264  2979 net.cpp:409] relu1 -> relu1
I0108 22:33:01.674281  2979 net.cpp:144] Setting up relu1
I0108 22:33:01.674288  2979 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0108 22:33:01.674293  2979 net.cpp:159] Memory required for data: 205158200
I0108 22:33:01.674296  2979 layer_factory.hpp:77] Creating layer pool1
I0108 22:33:01.674302  2979 net.cpp:94] Creating Layer pool1
I0108 22:33:01.674305  2979 net.cpp:435] pool1 <- relu1
I0108 22:33:01.674311  2979 net.cpp:409] pool1 -> pool1
I0108 22:33:01.674335  2979 net.cpp:144] Setting up pool1
I0108 22:33:01.674340  2979 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0108 22:33:01.674345  2979 net.cpp:159] Memory required for data: 219155000
I0108 22:33:01.674350  2979 layer_factory.hpp:77] Creating layer conv2
I0108 22:33:01.674357  2979 net.cpp:94] Creating Layer conv2
I0108 22:33:01.674363  2979 net.cpp:435] conv2 <- pool1
I0108 22:33:01.674368  2979 net.cpp:409] conv2 -> conv2
I0108 22:33:01.681278  2979 net.cpp:144] Setting up conv2
I0108 22:33:01.681298  2979 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0108 22:33:01.681305  2979 net.cpp:159] Memory required for data: 256479800
I0108 22:33:01.681318  2979 layer_factory.hpp:77] Creating layer bn2
I0108 22:33:01.681332  2979 net.cpp:94] Creating Layer bn2
I0108 22:33:01.681339  2979 net.cpp:435] bn2 <- conv2
I0108 22:33:01.681346  2979 net.cpp:409] bn2 -> bn2
I0108 22:33:01.682006  2979 net.cpp:144] Setting up bn2
I0108 22:33:01.682018  2979 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0108 22:33:01.682024  2979 net.cpp:159] Memory required for data: 293804600
I0108 22:33:01.682034  2979 layer_factory.hpp:77] Creating layer relu2
I0108 22:33:01.682041  2979 net.cpp:94] Creating Layer relu2
I0108 22:33:01.682045  2979 net.cpp:435] relu2 <- bn2
I0108 22:33:01.682052  2979 net.cpp:409] relu2 -> relu2
I0108 22:33:01.682070  2979 net.cpp:144] Setting up relu2
I0108 22:33:01.682085  2979 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0108 22:33:01.682090  2979 net.cpp:159] Memory required for data: 331129400
I0108 22:33:01.682093  2979 layer_factory.hpp:77] Creating layer pool2
I0108 22:33:01.682098  2979 net.cpp:94] Creating Layer pool2
I0108 22:33:01.682102  2979 net.cpp:435] pool2 <- relu2
I0108 22:33:01.682108  2979 net.cpp:409] pool2 -> pool2
I0108 22:33:01.682132  2979 net.cpp:144] Setting up pool2
I0108 22:33:01.682138  2979 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0108 22:33:01.682143  2979 net.cpp:159] Memory required for data: 339782200
I0108 22:33:01.682147  2979 layer_factory.hpp:77] Creating layer conv3
I0108 22:33:01.682154  2979 net.cpp:94] Creating Layer conv3
I0108 22:33:01.682158  2979 net.cpp:435] conv3 <- pool2
I0108 22:33:01.682163  2979 net.cpp:409] conv3 -> conv3
I0108 22:33:01.693305  2979 net.cpp:144] Setting up conv3
I0108 22:33:01.693322  2979 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 22:33:01.693329  2979 net.cpp:159] Memory required for data: 352761400
I0108 22:33:01.693338  2979 layer_factory.hpp:77] Creating layer relu3
I0108 22:33:01.693346  2979 net.cpp:94] Creating Layer relu3
I0108 22:33:01.693351  2979 net.cpp:435] relu3 <- conv3
I0108 22:33:01.693356  2979 net.cpp:409] relu3 -> relu3
I0108 22:33:01.693378  2979 net.cpp:144] Setting up relu3
I0108 22:33:01.693384  2979 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 22:33:01.693389  2979 net.cpp:159] Memory required for data: 365740600
I0108 22:33:01.693392  2979 layer_factory.hpp:77] Creating layer conv4
I0108 22:33:01.693403  2979 net.cpp:94] Creating Layer conv4
I0108 22:33:01.693408  2979 net.cpp:435] conv4 <- relu3
I0108 22:33:01.693413  2979 net.cpp:409] conv4 -> conv4
I0108 22:33:01.711194  2979 net.cpp:144] Setting up conv4
I0108 22:33:01.711236  2979 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 22:33:01.711249  2979 net.cpp:159] Memory required for data: 378719800
I0108 22:33:01.711266  2979 layer_factory.hpp:77] Creating layer relu4
I0108 22:33:01.711277  2979 net.cpp:94] Creating Layer relu4
I0108 22:33:01.711284  2979 net.cpp:435] relu4 <- conv4
I0108 22:33:01.711297  2979 net.cpp:409] relu4 -> relu4
I0108 22:33:01.711359  2979 net.cpp:144] Setting up relu4
I0108 22:33:01.711405  2979 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 22:33:01.711438  2979 net.cpp:159] Memory required for data: 391699000
I0108 22:33:01.711465  2979 layer_factory.hpp:77] Creating layer conv5
I0108 22:33:01.711516  2979 net.cpp:94] Creating Layer conv5
I0108 22:33:01.711541  2979 net.cpp:435] conv5 <- relu4
I0108 22:33:01.711570  2979 net.cpp:409] conv5 -> conv5
I0108 22:33:01.722818  2979 net.cpp:144] Setting up conv5
I0108 22:33:01.722887  2979 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0108 22:33:01.722923  2979 net.cpp:159] Memory required for data: 400351800
I0108 22:33:01.722959  2979 layer_factory.hpp:77] Creating layer relu5
I0108 22:33:01.722990  2979 net.cpp:94] Creating Layer relu5
I0108 22:33:01.723016  2979 net.cpp:435] relu5 <- conv5
I0108 22:33:01.723043  2979 net.cpp:409] relu5 -> relu5
I0108 22:33:01.723124  2979 net.cpp:144] Setting up relu5
I0108 22:33:01.723151  2979 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0108 22:33:01.723181  2979 net.cpp:159] Memory required for data: 409004600
I0108 22:33:01.723203  2979 layer_factory.hpp:77] Creating layer pool5
I0108 22:33:01.723234  2979 net.cpp:94] Creating Layer pool5
I0108 22:33:01.723258  2979 net.cpp:435] pool5 <- relu5
I0108 22:33:01.723282  2979 net.cpp:409] pool5 -> pool5
I0108 22:33:01.723358  2979 net.cpp:144] Setting up pool5
I0108 22:33:01.723382  2979 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0108 22:33:01.723417  2979 net.cpp:159] Memory required for data: 410847800
I0108 22:33:01.723448  2979 layer_factory.hpp:77] Creating layer fc6
I0108 22:33:01.723486  2979 net.cpp:94] Creating Layer fc6
I0108 22:33:01.723522  2979 net.cpp:435] fc6 <- pool5
I0108 22:33:01.723556  2979 net.cpp:409] fc6 -> fc6
I0108 22:33:02.069051  2979 net.cpp:144] Setting up fc6
I0108 22:33:02.069075  2979 net.cpp:151] Top shape: 50 4096 (204800)
I0108 22:33:02.069116  2979 net.cpp:159] Memory required for data: 411667000
I0108 22:33:02.069126  2979 layer_factory.hpp:77] Creating layer relu6
I0108 22:33:02.069134  2979 net.cpp:94] Creating Layer relu6
I0108 22:33:02.069139  2979 net.cpp:435] relu6 <- fc6
I0108 22:33:02.069144  2979 net.cpp:409] relu6 -> relu6
I0108 22:33:02.069177  2979 net.cpp:144] Setting up relu6
I0108 22:33:02.069186  2979 net.cpp:151] Top shape: 50 4096 (204800)
I0108 22:33:02.069192  2979 net.cpp:159] Memory required for data: 412486200
I0108 22:33:02.069195  2979 layer_factory.hpp:77] Creating layer drop6
I0108 22:33:02.069203  2979 net.cpp:94] Creating Layer drop6
I0108 22:33:02.069208  2979 net.cpp:435] drop6 <- relu6
I0108 22:33:02.069214  2979 net.cpp:409] drop6 -> drop6
I0108 22:33:02.069242  2979 net.cpp:144] Setting up drop6
I0108 22:33:02.069247  2979 net.cpp:151] Top shape: 50 4096 (204800)
I0108 22:33:02.069252  2979 net.cpp:159] Memory required for data: 413305400
I0108 22:33:02.069254  2979 layer_factory.hpp:77] Creating layer fc7
I0108 22:33:02.069262  2979 net.cpp:94] Creating Layer fc7
I0108 22:33:02.069267  2979 net.cpp:435] fc7 <- drop6
I0108 22:33:02.069273  2979 net.cpp:409] fc7 -> fc7
I0108 22:33:02.214046  2979 net.cpp:144] Setting up fc7
I0108 22:33:02.214071  2979 net.cpp:151] Top shape: 50 4096 (204800)
I0108 22:33:02.214078  2979 net.cpp:159] Memory required for data: 414124600
I0108 22:33:02.214103  2979 layer_factory.hpp:77] Creating layer bn7
I0108 22:33:02.214112  2979 net.cpp:94] Creating Layer bn7
I0108 22:33:02.214116  2979 net.cpp:435] bn7 <- fc7
I0108 22:33:02.214123  2979 net.cpp:409] bn7 -> bn7
I0108 22:33:02.214653  2979 net.cpp:144] Setting up bn7
I0108 22:33:02.214661  2979 net.cpp:151] Top shape: 50 4096 (204800)
I0108 22:33:02.214666  2979 net.cpp:159] Memory required for data: 414943800
I0108 22:33:02.214675  2979 layer_factory.hpp:77] Creating layer relu7
I0108 22:33:02.214682  2979 net.cpp:94] Creating Layer relu7
I0108 22:33:02.214687  2979 net.cpp:435] relu7 <- bn7
I0108 22:33:02.214695  2979 net.cpp:409] relu7 -> relu7
I0108 22:33:02.214720  2979 net.cpp:144] Setting up relu7
I0108 22:33:02.214725  2979 net.cpp:151] Top shape: 50 4096 (204800)
I0108 22:33:02.214730  2979 net.cpp:159] Memory required for data: 415763000
I0108 22:33:02.214733  2979 layer_factory.hpp:77] Creating layer drop7
I0108 22:33:02.214741  2979 net.cpp:94] Creating Layer drop7
I0108 22:33:02.214751  2979 net.cpp:435] drop7 <- relu7
I0108 22:33:02.214757  2979 net.cpp:409] drop7 -> drop7
I0108 22:33:02.214802  2979 net.cpp:144] Setting up drop7
I0108 22:33:02.214808  2979 net.cpp:151] Top shape: 50 4096 (204800)
I0108 22:33:02.214812  2979 net.cpp:159] Memory required for data: 416582200
I0108 22:33:02.214816  2979 layer_factory.hpp:77] Creating layer fc8
I0108 22:33:02.214826  2979 net.cpp:94] Creating Layer fc8
I0108 22:33:02.214833  2979 net.cpp:435] fc8 <- drop7
I0108 22:33:02.214839  2979 net.cpp:409] fc8 -> fc8
I0108 22:33:02.215009  2979 net.cpp:144] Setting up fc8
I0108 22:33:02.215016  2979 net.cpp:151] Top shape: 50 2 (100)
I0108 22:33:02.215020  2979 net.cpp:159] Memory required for data: 416582600
I0108 22:33:02.215027  2979 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0108 22:33:02.215034  2979 net.cpp:94] Creating Layer fc8_fc8_0_split
I0108 22:33:02.215039  2979 net.cpp:435] fc8_fc8_0_split <- fc8
I0108 22:33:02.215046  2979 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0108 22:33:02.215055  2979 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0108 22:33:02.215065  2979 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0108 22:33:02.215109  2979 net.cpp:144] Setting up fc8_fc8_0_split
I0108 22:33:02.215116  2979 net.cpp:151] Top shape: 50 2 (100)
I0108 22:33:02.215121  2979 net.cpp:151] Top shape: 50 2 (100)
I0108 22:33:02.215126  2979 net.cpp:151] Top shape: 50 2 (100)
I0108 22:33:02.215131  2979 net.cpp:159] Memory required for data: 416583800
I0108 22:33:02.215137  2979 layer_factory.hpp:77] Creating layer accuracy
I0108 22:33:02.215145  2979 net.cpp:94] Creating Layer accuracy
I0108 22:33:02.215164  2979 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0108 22:33:02.215170  2979 net.cpp:435] accuracy <- label_data_1_split_0
I0108 22:33:02.215178  2979 net.cpp:409] accuracy -> accuracy
I0108 22:33:02.215188  2979 net.cpp:144] Setting up accuracy
I0108 22:33:02.215194  2979 net.cpp:151] Top shape: (1)
I0108 22:33:02.215198  2979 net.cpp:159] Memory required for data: 416583804
I0108 22:33:02.215202  2979 layer_factory.hpp:77] Creating layer loss
I0108 22:33:02.215210  2979 net.cpp:94] Creating Layer loss
I0108 22:33:02.215216  2979 net.cpp:435] loss <- fc8_fc8_0_split_1
I0108 22:33:02.215224  2979 net.cpp:435] loss <- label_data_1_split_1
I0108 22:33:02.215232  2979 net.cpp:409] loss -> loss
I0108 22:33:02.215246  2979 layer_factory.hpp:77] Creating layer loss
I0108 22:33:02.215328  2979 net.cpp:144] Setting up loss
I0108 22:33:02.215335  2979 net.cpp:151] Top shape: (1)
I0108 22:33:02.215339  2979 net.cpp:154]     with loss weight 1
I0108 22:33:02.215356  2979 net.cpp:159] Memory required for data: 416583808
I0108 22:33:02.215361  2979 layer_factory.hpp:77] Creating layer accuracy-top1
I0108 22:33:02.215368  2979 net.cpp:94] Creating Layer accuracy-top1
I0108 22:33:02.215373  2979 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0108 22:33:02.215379  2979 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0108 22:33:02.215389  2979 net.cpp:409] accuracy-top1 -> top-1
I0108 22:33:02.215399  2979 net.cpp:144] Setting up accuracy-top1
I0108 22:33:02.215407  2979 net.cpp:151] Top shape: (1)
I0108 22:33:02.215411  2979 net.cpp:159] Memory required for data: 416583812
I0108 22:33:02.215415  2979 net.cpp:222] accuracy-top1 does not need backward computation.
I0108 22:33:02.215422  2979 net.cpp:220] loss needs backward computation.
I0108 22:33:02.215428  2979 net.cpp:222] accuracy does not need backward computation.
I0108 22:33:02.215435  2979 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0108 22:33:02.215441  2979 net.cpp:220] fc8 needs backward computation.
I0108 22:33:02.215446  2979 net.cpp:220] drop7 needs backward computation.
I0108 22:33:02.215452  2979 net.cpp:220] relu7 needs backward computation.
I0108 22:33:02.215458  2979 net.cpp:220] bn7 needs backward computation.
I0108 22:33:02.215464  2979 net.cpp:220] fc7 needs backward computation.
I0108 22:33:02.215471  2979 net.cpp:220] drop6 needs backward computation.
I0108 22:33:02.215476  2979 net.cpp:220] relu6 needs backward computation.
I0108 22:33:02.215481  2979 net.cpp:220] fc6 needs backward computation.
I0108 22:33:02.215487  2979 net.cpp:220] pool5 needs backward computation.
I0108 22:33:02.215493  2979 net.cpp:220] relu5 needs backward computation.
I0108 22:33:02.215499  2979 net.cpp:220] conv5 needs backward computation.
I0108 22:33:02.215505  2979 net.cpp:220] relu4 needs backward computation.
I0108 22:33:02.215512  2979 net.cpp:220] conv4 needs backward computation.
I0108 22:33:02.215517  2979 net.cpp:220] relu3 needs backward computation.
I0108 22:33:02.215524  2979 net.cpp:220] conv3 needs backward computation.
I0108 22:33:02.215530  2979 net.cpp:220] pool2 needs backward computation.
I0108 22:33:02.215536  2979 net.cpp:220] relu2 needs backward computation.
I0108 22:33:02.215543  2979 net.cpp:220] bn2 needs backward computation.
I0108 22:33:02.215548  2979 net.cpp:220] conv2 needs backward computation.
I0108 22:33:02.215554  2979 net.cpp:220] pool1 needs backward computation.
I0108 22:33:02.215560  2979 net.cpp:220] relu1 needs backward computation.
I0108 22:33:02.215565  2979 net.cpp:220] bn1 needs backward computation.
I0108 22:33:02.215572  2979 net.cpp:220] conv1 needs backward computation.
I0108 22:33:02.215579  2979 net.cpp:222] label_data_1_split does not need backward computation.
I0108 22:33:02.215586  2979 net.cpp:222] data does not need backward computation.
I0108 22:33:02.215592  2979 net.cpp:264] This network produces output accuracy
I0108 22:33:02.215598  2979 net.cpp:264] This network produces output loss
I0108 22:33:02.215605  2979 net.cpp:264] This network produces output top-1
I0108 22:33:02.215643  2979 net.cpp:284] Network initialization done.
I0108 22:33:02.215724  2979 solver.cpp:63] Solver scaffolding done.
I0108 22:33:02.216840  2979 caffe_interface.cpp:109] Finetuning from pruning/alexnetBNnoLRN/regular_rate_0.3/sparse.caffemodel
I0108 22:33:04.537354  2979 caffe_interface.cpp:543] Starting Optimization
I0108 22:33:04.537376  2979 solver.cpp:341] Solving
I0108 22:33:04.537380  2979 solver.cpp:342] Learning Rate Policy: step
I0108 22:33:04.538818  2979 solver.cpp:424] Iteration 0, Testing net (#0)
I0108 22:33:06.053503  2979 solver.cpp:523]     Test net output #0: accuracy = 0.94975
I0108 22:33:06.053535  2979 solver.cpp:523]     Test net output #1: loss = 0.273009 (* 1 = 0.273009 loss)
I0108 22:33:06.053540  2979 solver.cpp:523]     Test net output #2: top-1 = 0.94975
I0108 22:33:06.314606  2979 solver.cpp:270] Iteration 0 (0 iter/s, 1.77713s/50 iter), loss = 0.00805193, remaining 333333 hours and 20 minutes
I0108 22:33:06.314637  2979 solver.cpp:291]     Train net output #0: loss = 0.00805193 (* 1 = 0.00805193 loss)
I0108 22:33:06.314646  2979 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0108 22:33:19.062784  2979 solver.cpp:270] Iteration 50 (3.92228 iter/s, 12.7477s/50 iter), loss = 0.0800471, remaining 0 hours and 50 minutes
I0108 22:33:19.062815  2979 solver.cpp:291]     Train net output #0: loss = 0.0800471 (* 1 = 0.0800471 loss)
I0108 22:33:19.062822  2979 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0108 22:33:31.879015  2979 solver.cpp:270] Iteration 100 (3.90146 iter/s, 12.8157s/50 iter), loss = 0.0642453, remaining 0 hours and 50 minutes
I0108 22:33:31.879060  2979 solver.cpp:291]     Train net output #0: loss = 0.0642453 (* 1 = 0.0642453 loss)
I0108 22:33:31.879082  2979 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0108 22:33:44.725306  2979 solver.cpp:270] Iteration 150 (3.89233 iter/s, 12.8458s/50 iter), loss = 0.0733468, remaining 0 hours and 50 minutes
I0108 22:33:44.725337  2979 solver.cpp:291]     Train net output #0: loss = 0.0733468 (* 1 = 0.0733468 loss)
I0108 22:33:44.725344  2979 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0108 22:33:57.578353  2979 solver.cpp:270] Iteration 200 (3.89028 iter/s, 12.8525s/50 iter), loss = 0.0613066, remaining 0 hours and 50 minutes
I0108 22:33:57.578387  2979 solver.cpp:291]     Train net output #0: loss = 0.0613066 (* 1 = 0.0613066 loss)
I0108 22:33:57.578393  2979 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0108 22:34:10.450487  2979 solver.cpp:270] Iteration 250 (3.88451 iter/s, 12.8716s/50 iter), loss = 0.0856965, remaining 0 hours and 50 minutes
I0108 22:34:10.450533  2979 solver.cpp:291]     Train net output #0: loss = 0.0856965 (* 1 = 0.0856965 loss)
I0108 22:34:10.450557  2979 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0108 22:34:23.397284  2979 solver.cpp:270] Iteration 300 (3.86212 iter/s, 12.9463s/50 iter), loss = 0.0635226, remaining 0 hours and 50 minutes
I0108 22:34:23.397315  2979 solver.cpp:291]     Train net output #0: loss = 0.0635226 (* 1 = 0.0635226 loss)
I0108 22:34:23.397321  2979 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0108 22:34:36.409340  2979 solver.cpp:270] Iteration 350 (3.84274 iter/s, 13.0115s/50 iter), loss = 0.0875663, remaining 0 hours and 50 minutes
I0108 22:34:36.409371  2979 solver.cpp:291]     Train net output #0: loss = 0.0875663 (* 1 = 0.0875663 loss)
I0108 22:34:36.409394  2979 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0108 22:34:49.406116  2979 solver.cpp:270] Iteration 400 (3.84726 iter/s, 12.9963s/50 iter), loss = 0.0841334, remaining 0 hours and 50 minutes
I0108 22:34:49.406162  2979 solver.cpp:291]     Train net output #0: loss = 0.0841334 (* 1 = 0.0841334 loss)
I0108 22:34:49.406169  2979 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0108 22:35:02.418247  2979 solver.cpp:270] Iteration 450 (3.84273 iter/s, 13.0116s/50 iter), loss = 0.148276, remaining 0 hours and 49 minutes
I0108 22:35:02.418278  2979 solver.cpp:291]     Train net output #0: loss = 0.148276 (* 1 = 0.148276 loss)
I0108 22:35:02.418285  2979 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0108 22:35:15.411135  2979 solver.cpp:270] Iteration 500 (3.84841 iter/s, 12.9924s/50 iter), loss = 0.0773662, remaining 0 hours and 49 minutes
I0108 22:35:15.411166  2979 solver.cpp:291]     Train net output #0: loss = 0.0773662 (* 1 = 0.0773662 loss)
I0108 22:35:15.411173  2979 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0108 22:35:28.406980  2979 solver.cpp:270] Iteration 550 (3.84754 iter/s, 12.9953s/50 iter), loss = 0.116844, remaining 0 hours and 49 minutes
I0108 22:35:28.407032  2979 solver.cpp:291]     Train net output #0: loss = 0.116844 (* 1 = 0.116844 loss)
I0108 22:35:28.407039  2979 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0108 22:35:41.385008  2979 solver.cpp:270] Iteration 600 (3.85282 iter/s, 12.9775s/50 iter), loss = 0.0500592, remaining 0 hours and 49 minutes
I0108 22:35:41.385041  2979 solver.cpp:291]     Train net output #0: loss = 0.0500592 (* 1 = 0.0500592 loss)
I0108 22:35:41.385047  2979 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0108 22:35:54.409261  2979 solver.cpp:270] Iteration 650 (3.83914 iter/s, 13.0237s/50 iter), loss = 0.125126, remaining 0 hours and 49 minutes
I0108 22:35:54.409291  2979 solver.cpp:291]     Train net output #0: loss = 0.125126 (* 1 = 0.125126 loss)
I0108 22:35:54.409314  2979 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0108 22:36:07.435043  2979 solver.cpp:270] Iteration 700 (3.83869 iter/s, 13.0253s/50 iter), loss = 0.0819764, remaining 0 hours and 48 minutes
I0108 22:36:07.435087  2979 solver.cpp:291]     Train net output #0: loss = 0.0819764 (* 1 = 0.0819764 loss)
I0108 22:36:07.435096  2979 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0108 22:36:20.441473  2979 solver.cpp:270] Iteration 750 (3.84441 iter/s, 13.0059s/50 iter), loss = 0.0583859, remaining 0 hours and 48 minutes
I0108 22:36:20.441504  2979 solver.cpp:291]     Train net output #0: loss = 0.0583859 (* 1 = 0.0583859 loss)
I0108 22:36:20.441512  2979 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0108 22:36:33.440039  2979 solver.cpp:270] Iteration 800 (3.84673 iter/s, 12.998s/50 iter), loss = 0.0741122, remaining 0 hours and 48 minutes
I0108 22:36:33.440071  2979 solver.cpp:291]     Train net output #0: loss = 0.0741122 (* 1 = 0.0741122 loss)
I0108 22:36:33.440078  2979 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0108 22:36:46.452050  2979 solver.cpp:270] Iteration 850 (3.84276 iter/s, 13.0115s/50 iter), loss = 0.0691788, remaining 0 hours and 48 minutes
I0108 22:36:46.452100  2979 solver.cpp:291]     Train net output #0: loss = 0.0691788 (* 1 = 0.0691788 loss)
I0108 22:36:46.452123  2979 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0108 22:36:59.447484  2979 solver.cpp:270] Iteration 900 (3.84766 iter/s, 12.9949s/50 iter), loss = 0.0686133, remaining 0 hours and 48 minutes
I0108 22:36:59.447515  2979 solver.cpp:291]     Train net output #0: loss = 0.0686133 (* 1 = 0.0686133 loss)
I0108 22:36:59.447521  2979 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0108 22:37:12.474756  2979 solver.cpp:270] Iteration 950 (3.83825 iter/s, 13.0268s/50 iter), loss = 0.0941134, remaining 0 hours and 47 minutes
I0108 22:37:12.474787  2979 solver.cpp:291]     Train net output #0: loss = 0.0941134 (* 1 = 0.0941134 loss)
I0108 22:37:12.474795  2979 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0108 22:37:25.209100  2979 solver.cpp:424] Iteration 1000, Testing net (#0)
I0108 22:37:26.775641  2979 solver.cpp:523]     Test net output #0: accuracy = 0.91275
I0108 22:37:26.775669  2979 solver.cpp:523]     Test net output #1: loss = 0.28204 (* 1 = 0.28204 loss)
I0108 22:37:26.775673  2979 solver.cpp:523]     Test net output #2: top-1 = 0.91275
I0108 22:37:27.032356  2979 solver.cpp:270] Iteration 1000 (3.43477 iter/s, 14.557s/50 iter), loss = 0.084969, remaining 0 hours and 53 minutes
I0108 22:37:27.032382  2979 solver.cpp:291]     Train net output #0: loss = 0.084969 (* 1 = 0.084969 loss)
I0108 22:37:27.032389  2979 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0108 22:37:40.044906  2979 solver.cpp:270] Iteration 1050 (3.8426 iter/s, 13.012s/50 iter), loss = 0.123071, remaining 0 hours and 47 minutes
I0108 22:37:40.044936  2979 solver.cpp:291]     Train net output #0: loss = 0.123071 (* 1 = 0.123071 loss)
I0108 22:37:40.044943  2979 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0108 22:37:53.029852  2979 solver.cpp:270] Iteration 1100 (3.85077 iter/s, 12.9844s/50 iter), loss = 0.121664, remaining 0 hours and 47 minutes
I0108 22:37:53.029886  2979 solver.cpp:291]     Train net output #0: loss = 0.121664 (* 1 = 0.121664 loss)
I0108 22:37:53.029892  2979 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0108 22:38:06.028453  2979 solver.cpp:270] Iteration 1150 (3.84672 iter/s, 12.9981s/50 iter), loss = 0.126006, remaining 0 hours and 46 minutes
I0108 22:38:06.028510  2979 solver.cpp:291]     Train net output #0: loss = 0.126006 (* 1 = 0.126006 loss)
I0108 22:38:06.028518  2979 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0108 22:38:19.017666  2979 solver.cpp:270] Iteration 1200 (3.84951 iter/s, 12.9887s/50 iter), loss = 0.0868856, remaining 0 hours and 46 minutes
I0108 22:38:19.017699  2979 solver.cpp:291]     Train net output #0: loss = 0.0868856 (* 1 = 0.0868856 loss)
I0108 22:38:19.017705  2979 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0108 22:38:32.001049  2979 solver.cpp:270] Iteration 1250 (3.85123 iter/s, 12.9829s/50 iter), loss = 0.144618, remaining 0 hours and 46 minutes
I0108 22:38:32.001080  2979 solver.cpp:291]     Train net output #0: loss = 0.144618 (* 1 = 0.144618 loss)
I0108 22:38:32.001086  2979 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0108 22:38:45.013329  2979 solver.cpp:270] Iteration 1300 (3.84268 iter/s, 13.0118s/50 iter), loss = 0.0766533, remaining 0 hours and 46 minutes
I0108 22:38:45.013372  2979 solver.cpp:291]     Train net output #0: loss = 0.0766533 (* 1 = 0.0766533 loss)
I0108 22:38:45.013381  2979 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0108 22:38:58.024610  2979 solver.cpp:270] Iteration 1350 (3.84298 iter/s, 13.0108s/50 iter), loss = 0.151277, remaining 0 hours and 46 minutes
I0108 22:38:58.024639  2979 solver.cpp:291]     Train net output #0: loss = 0.151277 (* 1 = 0.151277 loss)
I0108 22:38:58.024662  2979 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0108 22:39:11.047348  2979 solver.cpp:270] Iteration 1400 (3.83959 iter/s, 13.0222s/50 iter), loss = 0.0944365, remaining 0 hours and 45 minutes
I0108 22:39:11.047379  2979 solver.cpp:291]     Train net output #0: loss = 0.0944365 (* 1 = 0.0944365 loss)
I0108 22:39:11.047402  2979 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0108 22:39:24.041810  2979 solver.cpp:270] Iteration 1450 (3.84795 iter/s, 12.9939s/50 iter), loss = 0.110806, remaining 0 hours and 45 minutes
I0108 22:39:24.041872  2979 solver.cpp:291]     Train net output #0: loss = 0.110806 (* 1 = 0.110806 loss)
I0108 22:39:24.041879  2979 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0108 22:39:37.054627  2979 solver.cpp:270] Iteration 1500 (3.84252 iter/s, 13.0123s/50 iter), loss = 0.0941252, remaining 0 hours and 45 minutes
I0108 22:39:37.054658  2979 solver.cpp:291]     Train net output #0: loss = 0.0941252 (* 1 = 0.0941252 loss)
I0108 22:39:37.054666  2979 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0108 22:39:50.037741  2979 solver.cpp:270] Iteration 1550 (3.85131 iter/s, 12.9826s/50 iter), loss = 0.0749469, remaining 0 hours and 45 minutes
I0108 22:39:50.037772  2979 solver.cpp:291]     Train net output #0: loss = 0.0749469 (* 1 = 0.0749469 loss)
I0108 22:39:50.037779  2979 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0108 22:40:03.054518  2979 solver.cpp:270] Iteration 1600 (3.84135 iter/s, 13.0163s/50 iter), loss = 0.0958829, remaining 0 hours and 45 minutes
I0108 22:40:03.054565  2979 solver.cpp:291]     Train net output #0: loss = 0.0958829 (* 1 = 0.0958829 loss)
I0108 22:40:03.054574  2979 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0108 22:40:16.048557  2979 solver.cpp:270] Iteration 1650 (3.84808 iter/s, 12.9935s/50 iter), loss = 0.0770986, remaining 0 hours and 44 minutes
I0108 22:40:16.048588  2979 solver.cpp:291]     Train net output #0: loss = 0.0770986 (* 1 = 0.0770986 loss)
I0108 22:40:16.048594  2979 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0108 22:40:29.033350  2979 solver.cpp:270] Iteration 1700 (3.85081 iter/s, 12.9843s/50 iter), loss = 0.0986104, remaining 0 hours and 44 minutes
I0108 22:40:29.033382  2979 solver.cpp:291]     Train net output #0: loss = 0.0986104 (* 1 = 0.0986104 loss)
I0108 22:40:29.033406  2979 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0108 22:40:42.011179  2979 solver.cpp:270] Iteration 1750 (3.85288 iter/s, 12.9773s/50 iter), loss = 0.0625804, remaining 0 hours and 44 minutes
I0108 22:40:42.011234  2979 solver.cpp:291]     Train net output #0: loss = 0.0625804 (* 1 = 0.0625804 loss)
I0108 22:40:42.011240  2979 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0108 22:40:55.007015  2979 solver.cpp:270] Iteration 1800 (3.84755 iter/s, 12.9953s/50 iter), loss = 0.120604, remaining 0 hours and 44 minutes
I0108 22:40:55.007046  2979 solver.cpp:291]     Train net output #0: loss = 0.120604 (* 1 = 0.120604 loss)
I0108 22:40:55.007053  2979 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0108 22:41:07.990574  2979 solver.cpp:270] Iteration 1850 (3.85118 iter/s, 12.983s/50 iter), loss = 0.0436238, remaining 0 hours and 43 minutes
I0108 22:41:07.990605  2979 solver.cpp:291]     Train net output #0: loss = 0.0436238 (* 1 = 0.0436238 loss)
I0108 22:41:07.990628  2979 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0108 22:41:20.952527  2979 solver.cpp:270] Iteration 1900 (3.8576 iter/s, 12.9614s/50 iter), loss = 0.0830623, remaining 0 hours and 43 minutes
I0108 22:41:20.952572  2979 solver.cpp:291]     Train net output #0: loss = 0.0830623 (* 1 = 0.0830623 loss)
I0108 22:41:20.952595  2979 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0108 22:41:33.957461  2979 solver.cpp:270] Iteration 1950 (3.84485 iter/s, 13.0044s/50 iter), loss = 0.0687427, remaining 0 hours and 43 minutes
I0108 22:41:33.957491  2979 solver.cpp:291]     Train net output #0: loss = 0.0687427 (* 1 = 0.0687427 loss)
I0108 22:41:33.957499  2979 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0108 22:41:46.684190  2979 solver.cpp:424] Iteration 2000, Testing net (#0)
I0108 22:41:48.192773  2979 solver.cpp:523]     Test net output #0: accuracy = 0.86375
I0108 22:41:48.192802  2979 solver.cpp:523]     Test net output #1: loss = 0.291792 (* 1 = 0.291792 loss)
I0108 22:41:48.192806  2979 solver.cpp:523]     Test net output #2: top-1 = 0.86375
I0108 22:41:48.444447  2979 solver.cpp:270] Iteration 2000 (3.45151 iter/s, 14.4864s/50 iter), loss = 0.0964354, remaining 0 hours and 48 minutes
I0108 22:41:48.444473  2979 solver.cpp:291]     Train net output #0: loss = 0.0964354 (* 1 = 0.0964354 loss)
I0108 22:41:48.444480  2979 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0108 22:42:01.439199  2979 solver.cpp:270] Iteration 2050 (3.84786 iter/s, 12.9942s/50 iter), loss = 0.0663464, remaining 0 hours and 42 minutes
I0108 22:42:01.439244  2979 solver.cpp:291]     Train net output #0: loss = 0.0663464 (* 1 = 0.0663464 loss)
I0108 22:42:01.439251  2979 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0108 22:42:14.420527  2979 solver.cpp:270] Iteration 2100 (3.85184 iter/s, 12.9808s/50 iter), loss = 0.0728842, remaining 0 hours and 42 minutes
I0108 22:42:14.420560  2979 solver.cpp:291]     Train net output #0: loss = 0.0728842 (* 1 = 0.0728842 loss)
I0108 22:42:14.420567  2979 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0108 22:42:27.411293  2979 solver.cpp:270] Iteration 2150 (3.84904 iter/s, 12.9902s/50 iter), loss = 0.0946731, remaining 0 hours and 42 minutes
I0108 22:42:27.411324  2979 solver.cpp:291]     Train net output #0: loss = 0.0946731 (* 1 = 0.0946731 loss)
I0108 22:42:27.411331  2979 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0108 22:42:40.372134  2979 solver.cpp:270] Iteration 2200 (3.85793 iter/s, 12.9603s/50 iter), loss = 0.0871694, remaining 0 hours and 42 minutes
I0108 22:42:40.372189  2979 solver.cpp:291]     Train net output #0: loss = 0.0871694 (* 1 = 0.0871694 loss)
I0108 22:42:40.372195  2979 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0108 22:42:53.333561  2979 solver.cpp:270] Iteration 2250 (3.85776 iter/s, 12.9609s/50 iter), loss = 0.0468182, remaining 0 hours and 41 minutes
I0108 22:42:53.333593  2979 solver.cpp:291]     Train net output #0: loss = 0.0468183 (* 1 = 0.0468183 loss)
I0108 22:42:53.333616  2979 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0108 22:43:06.304164  2979 solver.cpp:270] Iteration 2300 (3.85502 iter/s, 12.9701s/50 iter), loss = 0.0922114, remaining 0 hours and 41 minutes
I0108 22:43:06.304195  2979 solver.cpp:291]     Train net output #0: loss = 0.0922114 (* 1 = 0.0922114 loss)
I0108 22:43:06.304203  2979 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0108 22:43:19.271283  2979 solver.cpp:270] Iteration 2350 (3.85606 iter/s, 12.9666s/50 iter), loss = 0.0997449, remaining 0 hours and 41 minutes
I0108 22:43:19.271327  2979 solver.cpp:291]     Train net output #0: loss = 0.0997449 (* 1 = 0.0997449 loss)
I0108 22:43:19.271334  2979 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0108 22:43:32.285933  2979 solver.cpp:270] Iteration 2400 (3.84198 iter/s, 13.0141s/50 iter), loss = 0.0930863, remaining 0 hours and 41 minutes
I0108 22:43:32.285964  2979 solver.cpp:291]     Train net output #0: loss = 0.0930864 (* 1 = 0.0930864 loss)
I0108 22:43:32.285971  2979 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0108 22:43:45.248555  2979 solver.cpp:270] Iteration 2450 (3.8574 iter/s, 12.9621s/50 iter), loss = 0.0742004, remaining 0 hours and 41 minutes
I0108 22:43:45.248589  2979 solver.cpp:291]     Train net output #0: loss = 0.0742005 (* 1 = 0.0742005 loss)
I0108 22:43:45.248596  2979 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0108 22:43:58.230219  2979 solver.cpp:270] Iteration 2500 (3.85174 iter/s, 12.9811s/50 iter), loss = 0.127104, remaining 0 hours and 41 minutes
I0108 22:43:58.230266  2979 solver.cpp:291]     Train net output #0: loss = 0.127104 (* 1 = 0.127104 loss)
I0108 22:43:58.230273  2979 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0108 22:44:11.215057  2979 solver.cpp:270] Iteration 2550 (3.8508 iter/s, 12.9843s/50 iter), loss = 0.0521071, remaining 0 hours and 40 minutes
I0108 22:44:11.215088  2979 solver.cpp:291]     Train net output #0: loss = 0.0521071 (* 1 = 0.0521071 loss)
I0108 22:44:11.215095  2979 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0108 22:44:24.201166  2979 solver.cpp:270] Iteration 2600 (3.85042 iter/s, 12.9856s/50 iter), loss = 0.0370335, remaining 0 hours and 40 minutes
I0108 22:44:24.201198  2979 solver.cpp:291]     Train net output #0: loss = 0.0370335 (* 1 = 0.0370335 loss)
I0108 22:44:24.201205  2979 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0108 22:44:37.182788  2979 solver.cpp:270] Iteration 2650 (3.85175 iter/s, 12.9811s/50 iter), loss = 0.0497423, remaining 0 hours and 40 minutes
I0108 22:44:37.182834  2979 solver.cpp:291]     Train net output #0: loss = 0.0497423 (* 1 = 0.0497423 loss)
I0108 22:44:37.182842  2979 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0108 22:44:50.136250  2979 solver.cpp:270] Iteration 2700 (3.86013 iter/s, 12.9529s/50 iter), loss = 0.0294597, remaining 0 hours and 40 minutes
I0108 22:44:50.136282  2979 solver.cpp:291]     Train net output #0: loss = 0.0294597 (* 1 = 0.0294597 loss)
I0108 22:44:50.136305  2979 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0108 22:45:03.138011  2979 solver.cpp:270] Iteration 2750 (3.84579 iter/s, 13.0012s/50 iter), loss = 0.0235967, remaining 0 hours and 40 minutes
I0108 22:45:03.138042  2979 solver.cpp:291]     Train net output #0: loss = 0.0235967 (* 1 = 0.0235967 loss)
I0108 22:45:03.138049  2979 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0108 22:45:16.130304  2979 solver.cpp:270] Iteration 2800 (3.84859 iter/s, 12.9918s/50 iter), loss = 0.049041, remaining 0 hours and 39 minutes
I0108 22:45:16.130349  2979 solver.cpp:291]     Train net output #0: loss = 0.049041 (* 1 = 0.049041 loss)
I0108 22:45:16.130357  2979 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0108 22:45:29.119697  2979 solver.cpp:270] Iteration 2850 (3.84945 iter/s, 12.9889s/50 iter), loss = 0.0486632, remaining 0 hours and 39 minutes
I0108 22:45:29.119729  2979 solver.cpp:291]     Train net output #0: loss = 0.0486632 (* 1 = 0.0486632 loss)
I0108 22:45:29.119735  2979 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0108 22:45:42.094588  2979 solver.cpp:270] Iteration 2900 (3.85375 iter/s, 12.9744s/50 iter), loss = 0.0268478, remaining 0 hours and 39 minutes
I0108 22:45:42.094619  2979 solver.cpp:291]     Train net output #0: loss = 0.0268478 (* 1 = 0.0268478 loss)
I0108 22:45:42.094626  2979 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0108 22:45:55.074126  2979 solver.cpp:270] Iteration 2950 (3.85237 iter/s, 12.979s/50 iter), loss = 0.0255875, remaining 0 hours and 38 minutes
I0108 22:45:55.074177  2979 solver.cpp:291]     Train net output #0: loss = 0.0255875 (* 1 = 0.0255875 loss)
I0108 22:45:55.074184  2979 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0108 22:46:07.801265  2979 solver.cpp:424] Iteration 3000, Testing net (#0)
I0108 22:46:09.348726  2979 solver.cpp:523]     Test net output #0: accuracy = 0.94675
I0108 22:46:09.348753  2979 solver.cpp:523]     Test net output #1: loss = 0.140212 (* 1 = 0.140212 loss)
I0108 22:46:09.348758  2979 solver.cpp:523]     Test net output #2: top-1 = 0.94675
I0108 22:46:09.599342  2979 solver.cpp:270] Iteration 3000 (3.44243 iter/s, 14.5246s/50 iter), loss = 0.00747509, remaining 0 hours and 43 minutes
I0108 22:46:09.599366  2979 solver.cpp:291]     Train net output #0: loss = 0.00747509 (* 1 = 0.00747509 loss)
I0108 22:46:09.599375  2979 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0108 22:46:22.603276  2979 solver.cpp:270] Iteration 3050 (3.84514 iter/s, 13.0034s/50 iter), loss = 0.00751348, remaining 0 hours and 38 minutes
I0108 22:46:22.603307  2979 solver.cpp:291]     Train net output #0: loss = 0.0075135 (* 1 = 0.0075135 loss)
I0108 22:46:22.603313  2979 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0108 22:46:35.581223  2979 solver.cpp:270] Iteration 3100 (3.85284 iter/s, 12.9774s/50 iter), loss = 0.00437364, remaining 0 hours and 38 minutes
I0108 22:46:35.581269  2979 solver.cpp:291]     Train net output #0: loss = 0.00437366 (* 1 = 0.00437366 loss)
I0108 22:46:35.581291  2979 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0108 22:46:48.563155  2979 solver.cpp:270] Iteration 3150 (3.85166 iter/s, 12.9814s/50 iter), loss = 0.0495607, remaining 0 hours and 38 minutes
I0108 22:46:48.563185  2979 solver.cpp:291]     Train net output #0: loss = 0.0495608 (* 1 = 0.0495608 loss)
I0108 22:46:48.563192  2979 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0108 22:47:01.557577  2979 solver.cpp:270] Iteration 3200 (3.84796 iter/s, 12.9939s/50 iter), loss = 0.0197309, remaining 0 hours and 37 minutes
I0108 22:47:01.557610  2979 solver.cpp:291]     Train net output #0: loss = 0.0197309 (* 1 = 0.0197309 loss)
I0108 22:47:01.557617  2979 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0108 22:47:14.548235  2979 solver.cpp:270] Iteration 3250 (3.84907 iter/s, 12.9901s/50 iter), loss = 0.0219387, remaining 0 hours and 37 minutes
I0108 22:47:14.548281  2979 solver.cpp:291]     Train net output #0: loss = 0.0219387 (* 1 = 0.0219387 loss)
I0108 22:47:14.548288  2979 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0108 22:47:27.523823  2979 solver.cpp:270] Iteration 3300 (3.85355 iter/s, 12.9751s/50 iter), loss = 0.0351269, remaining 0 hours and 37 minutes
I0108 22:47:27.523856  2979 solver.cpp:291]     Train net output #0: loss = 0.0351269 (* 1 = 0.0351269 loss)
I0108 22:47:27.523864  2979 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0108 22:47:40.505793  2979 solver.cpp:270] Iteration 3350 (3.85165 iter/s, 12.9815s/50 iter), loss = 0.0486179, remaining 0 hours and 37 minutes
I0108 22:47:40.505825  2979 solver.cpp:291]     Train net output #0: loss = 0.0486179 (* 1 = 0.0486179 loss)
I0108 22:47:40.505832  2979 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0108 22:47:53.495141  2979 solver.cpp:270] Iteration 3400 (3.84946 iter/s, 12.9888s/50 iter), loss = 0.0583291, remaining 0 hours and 37 minutes
I0108 22:47:53.495196  2979 solver.cpp:291]     Train net output #0: loss = 0.0583291 (* 1 = 0.0583291 loss)
I0108 22:47:53.495204  2979 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0108 22:48:06.482249  2979 solver.cpp:270] Iteration 3450 (3.85013 iter/s, 12.9866s/50 iter), loss = 0.0224273, remaining 0 hours and 36 minutes
I0108 22:48:06.482282  2979 solver.cpp:291]     Train net output #0: loss = 0.0224273 (* 1 = 0.0224273 loss)
I0108 22:48:06.482290  2979 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0108 22:48:19.464264  2979 solver.cpp:270] Iteration 3500 (3.85164 iter/s, 12.9815s/50 iter), loss = 0.0413132, remaining 0 hours and 36 minutes
I0108 22:48:19.464296  2979 solver.cpp:291]     Train net output #0: loss = 0.0413132 (* 1 = 0.0413132 loss)
I0108 22:48:19.464303  2979 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0108 22:48:32.456975  2979 solver.cpp:270] Iteration 3550 (3.84846 iter/s, 12.9922s/50 iter), loss = 0.0189266, remaining 0 hours and 36 minutes
I0108 22:48:32.457021  2979 solver.cpp:291]     Train net output #0: loss = 0.0189267 (* 1 = 0.0189267 loss)
I0108 22:48:32.457029  2979 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0108 22:48:45.415247  2979 solver.cpp:270] Iteration 3600 (3.8587 iter/s, 12.9577s/50 iter), loss = 0.0295908, remaining 0 hours and 36 minutes
I0108 22:48:45.415289  2979 solver.cpp:291]     Train net output #0: loss = 0.0295908 (* 1 = 0.0295908 loss)
I0108 22:48:45.415311  2979 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0108 22:48:58.408321  2979 solver.cpp:270] Iteration 3650 (3.84836 iter/s, 12.9925s/50 iter), loss = 0.032853, remaining 0 hours and 36 minutes
I0108 22:48:58.408351  2979 solver.cpp:291]     Train net output #0: loss = 0.032853 (* 1 = 0.032853 loss)
I0108 22:48:58.408358  2979 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0108 22:49:11.408399  2979 solver.cpp:270] Iteration 3700 (3.84628 iter/s, 12.9996s/50 iter), loss = 0.0176983, remaining 0 hours and 35 minutes
I0108 22:49:11.408445  2979 solver.cpp:291]     Train net output #0: loss = 0.0176983 (* 1 = 0.0176983 loss)
I0108 22:49:11.408452  2979 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0108 22:49:24.385655  2979 solver.cpp:270] Iteration 3750 (3.85305 iter/s, 12.9767s/50 iter), loss = 0.0346821, remaining 0 hours and 35 minutes
I0108 22:49:24.385687  2979 solver.cpp:291]     Train net output #0: loss = 0.0346821 (* 1 = 0.0346821 loss)
I0108 22:49:24.385694  2979 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0108 22:49:37.354984  2979 solver.cpp:270] Iteration 3800 (3.8554 iter/s, 12.9688s/50 iter), loss = 0.0245348, remaining 0 hours and 35 minutes
I0108 22:49:37.355015  2979 solver.cpp:291]     Train net output #0: loss = 0.0245348 (* 1 = 0.0245348 loss)
I0108 22:49:37.355021  2979 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0108 22:49:50.327955  2979 solver.cpp:270] Iteration 3850 (3.85432 iter/s, 12.9725s/50 iter), loss = 0.0245127, remaining 0 hours and 35 minutes
I0108 22:49:50.328004  2979 solver.cpp:291]     Train net output #0: loss = 0.0245127 (* 1 = 0.0245127 loss)
I0108 22:49:50.328012  2979 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0108 22:50:03.321700  2979 solver.cpp:270] Iteration 3900 (3.84816 iter/s, 12.9932s/50 iter), loss = 0.00938412, remaining 0 hours and 35 minutes
I0108 22:50:03.321732  2979 solver.cpp:291]     Train net output #0: loss = 0.00938412 (* 1 = 0.00938412 loss)
I0108 22:50:03.321739  2979 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0108 22:50:16.293900  2979 solver.cpp:270] Iteration 3950 (3.85455 iter/s, 12.9717s/50 iter), loss = 0.020064, remaining 0 hours and 34 minutes
I0108 22:50:16.293932  2979 solver.cpp:291]     Train net output #0: loss = 0.020064 (* 1 = 0.020064 loss)
I0108 22:50:16.293938  2979 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0108 22:50:28.976984  2979 solver.cpp:424] Iteration 4000, Testing net (#0)
I0108 22:50:30.521484  2979 solver.cpp:523]     Test net output #0: accuracy = 0.944
I0108 22:50:30.521512  2979 solver.cpp:523]     Test net output #1: loss = 0.143077 (* 1 = 0.143077 loss)
I0108 22:50:30.521518  2979 solver.cpp:523]     Test net output #2: top-1 = 0.944
I0108 22:50:30.772578  2979 solver.cpp:270] Iteration 4000 (3.45349 iter/s, 14.4781s/50 iter), loss = 0.0289139, remaining 0 hours and 38 minutes
I0108 22:50:30.772604  2979 solver.cpp:291]     Train net output #0: loss = 0.0289139 (* 1 = 0.0289139 loss)
I0108 22:50:30.772612  2979 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0108 22:50:43.741498  2979 solver.cpp:270] Iteration 4050 (3.85552 iter/s, 12.9684s/50 iter), loss = 0.0228917, remaining 0 hours and 34 minutes
I0108 22:50:43.741529  2979 solver.cpp:291]     Train net output #0: loss = 0.0228917 (* 1 = 0.0228917 loss)
I0108 22:50:43.741535  2979 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0108 22:50:56.698230  2979 solver.cpp:270] Iteration 4100 (3.85915 iter/s, 12.9562s/50 iter), loss = 0.0168744, remaining 0 hours and 33 minutes
I0108 22:50:56.698263  2979 solver.cpp:291]     Train net output #0: loss = 0.0168744 (* 1 = 0.0168744 loss)
I0108 22:50:56.698271  2979 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0108 22:51:09.679533  2979 solver.cpp:270] Iteration 4150 (3.85185 iter/s, 12.9808s/50 iter), loss = 0.0212505, remaining 0 hours and 33 minutes
I0108 22:51:09.679587  2979 solver.cpp:291]     Train net output #0: loss = 0.0212505 (* 1 = 0.0212505 loss)
I0108 22:51:09.679594  2979 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0108 22:51:22.639043  2979 solver.cpp:270] Iteration 4200 (3.85833 iter/s, 12.959s/50 iter), loss = 0.00842631, remaining 0 hours and 33 minutes
I0108 22:51:22.639075  2979 solver.cpp:291]     Train net output #0: loss = 0.00842631 (* 1 = 0.00842631 loss)
I0108 22:51:22.639082  2979 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0108 22:51:35.611104  2979 solver.cpp:270] Iteration 4250 (3.85459 iter/s, 12.9715s/50 iter), loss = 0.0140968, remaining 0 hours and 33 minutes
I0108 22:51:35.611136  2979 solver.cpp:291]     Train net output #0: loss = 0.0140968 (* 1 = 0.0140968 loss)
I0108 22:51:35.611143  2979 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0108 22:51:48.609619  2979 solver.cpp:270] Iteration 4300 (3.84675 iter/s, 12.998s/50 iter), loss = 0.0254801, remaining 0 hours and 33 minutes
I0108 22:51:48.609666  2979 solver.cpp:291]     Train net output #0: loss = 0.0254801 (* 1 = 0.0254801 loss)
I0108 22:51:48.609674  2979 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0108 22:52:01.587975  2979 solver.cpp:270] Iteration 4350 (3.85273 iter/s, 12.9778s/50 iter), loss = 0.00768111, remaining 0 hours and 32 minutes
I0108 22:52:01.588008  2979 solver.cpp:291]     Train net output #0: loss = 0.00768111 (* 1 = 0.00768111 loss)
I0108 22:52:01.588016  2979 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0108 22:52:14.562486  2979 solver.cpp:270] Iteration 4400 (3.85386 iter/s, 12.974s/50 iter), loss = 0.0305306, remaining 0 hours and 32 minutes
I0108 22:52:14.562518  2979 solver.cpp:291]     Train net output #0: loss = 0.0305306 (* 1 = 0.0305306 loss)
I0108 22:52:14.562525  2979 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0108 22:52:27.525056  2979 solver.cpp:270] Iteration 4450 (3.85741 iter/s, 12.9621s/50 iter), loss = 0.0189104, remaining 0 hours and 32 minutes
I0108 22:52:27.525104  2979 solver.cpp:291]     Train net output #0: loss = 0.0189104 (* 1 = 0.0189104 loss)
I0108 22:52:27.525112  2979 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0108 22:52:40.509835  2979 solver.cpp:270] Iteration 4500 (3.85082 iter/s, 12.9842s/50 iter), loss = 0.0089722, remaining 0 hours and 32 minutes
I0108 22:52:40.509865  2979 solver.cpp:291]     Train net output #0: loss = 0.00897221 (* 1 = 0.00897221 loss)
I0108 22:52:40.509872  2979 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0108 22:52:53.445390  2979 solver.cpp:270] Iteration 4550 (3.86547 iter/s, 12.935s/50 iter), loss = 0.0137559, remaining 0 hours and 32 minutes
I0108 22:52:53.445421  2979 solver.cpp:291]     Train net output #0: loss = 0.0137559 (* 1 = 0.0137559 loss)
I0108 22:52:53.445427  2979 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0108 22:53:06.427958  2979 solver.cpp:270] Iteration 4600 (3.85147 iter/s, 12.9821s/50 iter), loss = 0.0104718, remaining 0 hours and 31 minutes
I0108 22:53:06.428011  2979 solver.cpp:291]     Train net output #0: loss = 0.0104718 (* 1 = 0.0104718 loss)
I0108 22:53:06.428020  2979 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0108 22:53:19.401402  2979 solver.cpp:270] Iteration 4650 (3.85419 iter/s, 12.9729s/50 iter), loss = 0.0148604, remaining 0 hours and 31 minutes
I0108 22:53:19.401432  2979 solver.cpp:291]     Train net output #0: loss = 0.0148604 (* 1 = 0.0148604 loss)
I0108 22:53:19.401439  2979 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0108 22:53:32.369098  2979 solver.cpp:270] Iteration 4700 (3.85589 iter/s, 12.9672s/50 iter), loss = 0.0115792, remaining 0 hours and 31 minutes
I0108 22:53:32.369128  2979 solver.cpp:291]     Train net output #0: loss = 0.0115792 (* 1 = 0.0115792 loss)
I0108 22:53:32.369151  2979 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0108 22:53:45.360234  2979 solver.cpp:270] Iteration 4750 (3.84893 iter/s, 12.9906s/50 iter), loss = 0.0126766, remaining 0 hours and 31 minutes
I0108 22:53:45.360277  2979 solver.cpp:291]     Train net output #0: loss = 0.0126766 (* 1 = 0.0126766 loss)
I0108 22:53:45.360285  2979 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0108 22:53:58.319856  2979 solver.cpp:270] Iteration 4800 (3.85829 iter/s, 12.9591s/50 iter), loss = 0.0198505, remaining 0 hours and 31 minutes
I0108 22:53:58.319887  2979 solver.cpp:291]     Train net output #0: loss = 0.0198505 (* 1 = 0.0198505 loss)
I0108 22:53:58.319895  2979 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0108 22:54:11.279580  2979 solver.cpp:270] Iteration 4850 (3.85826 iter/s, 12.9592s/50 iter), loss = 0.0407643, remaining 0 hours and 30 minutes
I0108 22:54:11.279613  2979 solver.cpp:291]     Train net output #0: loss = 0.0407643 (* 1 = 0.0407643 loss)
I0108 22:54:11.279620  2979 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0108 22:54:24.278422  2979 solver.cpp:270] Iteration 4900 (3.84665 iter/s, 12.9983s/50 iter), loss = 0.00998476, remaining 0 hours and 30 minutes
I0108 22:54:24.278466  2979 solver.cpp:291]     Train net output #0: loss = 0.00998476 (* 1 = 0.00998476 loss)
I0108 22:54:24.278491  2979 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0108 22:54:37.249006  2979 solver.cpp:270] Iteration 4950 (3.85503 iter/s, 12.9701s/50 iter), loss = 0.0102831, remaining 0 hours and 30 minutes
I0108 22:54:37.249038  2979 solver.cpp:291]     Train net output #0: loss = 0.0102831 (* 1 = 0.0102831 loss)
I0108 22:54:37.249061  2979 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0108 22:54:49.993595  2979 solver.cpp:424] Iteration 5000, Testing net (#0)
I0108 22:54:51.516222  2979 solver.cpp:523]     Test net output #0: accuracy = 0.93475
I0108 22:54:51.516249  2979 solver.cpp:523]     Test net output #1: loss = 0.196594 (* 1 = 0.196594 loss)
I0108 22:54:51.516253  2979 solver.cpp:523]     Test net output #2: top-1 = 0.93475
I0108 22:54:51.768362  2979 solver.cpp:270] Iteration 5000 (3.44381 iter/s, 14.5188s/50 iter), loss = 0.0194235, remaining 0 hours and 33 minutes
I0108 22:54:51.768384  2979 solver.cpp:291]     Train net output #0: loss = 0.0194235 (* 1 = 0.0194235 loss)
I0108 22:54:51.768391  2979 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0108 22:55:04.744618  2979 solver.cpp:270] Iteration 5050 (3.85334 iter/s, 12.9757s/50 iter), loss = 0.0242553, remaining 0 hours and 29 minutes
I0108 22:55:04.744664  2979 solver.cpp:291]     Train net output #0: loss = 0.0242553 (* 1 = 0.0242553 loss)
I0108 22:55:04.744673  2979 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0108 22:55:17.670852  2979 solver.cpp:270] Iteration 5100 (3.86826 iter/s, 12.9257s/50 iter), loss = 0.00477913, remaining 0 hours and 29 minutes
I0108 22:55:17.670882  2979 solver.cpp:291]     Train net output #0: loss = 0.00477914 (* 1 = 0.00477914 loss)
I0108 22:55:17.670890  2979 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0108 22:55:30.661682  2979 solver.cpp:270] Iteration 5150 (3.84902 iter/s, 12.9903s/50 iter), loss = 0.0170422, remaining 0 hours and 29 minutes
I0108 22:55:30.661713  2979 solver.cpp:291]     Train net output #0: loss = 0.0170422 (* 1 = 0.0170422 loss)
I0108 22:55:30.661720  2979 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0108 22:55:43.629927  2979 solver.cpp:270] Iteration 5200 (3.85572 iter/s, 12.9677s/50 iter), loss = 0.00447019, remaining 0 hours and 29 minutes
I0108 22:55:43.629981  2979 solver.cpp:291]     Train net output #0: loss = 0.00447019 (* 1 = 0.00447019 loss)
I0108 22:55:43.629989  2979 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0108 22:55:56.589568  2979 solver.cpp:270] Iteration 5250 (3.85829 iter/s, 12.9591s/50 iter), loss = 0.00413257, remaining 0 hours and 29 minutes
I0108 22:55:56.589599  2979 solver.cpp:291]     Train net output #0: loss = 0.00413257 (* 1 = 0.00413257 loss)
I0108 22:55:56.589607  2979 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0108 22:56:09.553099  2979 solver.cpp:270] Iteration 5300 (3.85713 iter/s, 12.963s/50 iter), loss = 0.0151188, remaining 0 hours and 28 minutes
I0108 22:56:09.553131  2979 solver.cpp:291]     Train net output #0: loss = 0.0151188 (* 1 = 0.0151188 loss)
I0108 22:56:09.553138  2979 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0108 22:56:22.528918  2979 solver.cpp:270] Iteration 5350 (3.85348 iter/s, 12.9753s/50 iter), loss = 0.0106001, remaining 0 hours and 28 minutes
I0108 22:56:22.528961  2979 solver.cpp:291]     Train net output #0: loss = 0.0106001 (* 1 = 0.0106001 loss)
I0108 22:56:22.528985  2979 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0108 22:56:35.527230  2979 solver.cpp:270] Iteration 5400 (3.84681 iter/s, 12.9978s/50 iter), loss = 0.00867882, remaining 0 hours and 28 minutes
I0108 22:56:35.527261  2979 solver.cpp:291]     Train net output #0: loss = 0.00867883 (* 1 = 0.00867883 loss)
I0108 22:56:35.527267  2979 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0108 22:56:48.490463  2979 solver.cpp:270] Iteration 5450 (3.85722 iter/s, 12.9627s/50 iter), loss = 0.00523632, remaining 0 hours and 28 minutes
I0108 22:56:48.490496  2979 solver.cpp:291]     Train net output #0: loss = 0.00523632 (* 1 = 0.00523632 loss)
I0108 22:56:48.490504  2979 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0108 22:57:01.508450  2979 solver.cpp:270] Iteration 5500 (3.84099 iter/s, 13.0175s/50 iter), loss = 0.00303008, remaining 0 hours and 28 minutes
I0108 22:57:01.508497  2979 solver.cpp:291]     Train net output #0: loss = 0.00303009 (* 1 = 0.00303009 loss)
I0108 22:57:01.508503  2979 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0108 22:57:14.477067  2979 solver.cpp:270] Iteration 5550 (3.85562 iter/s, 12.9681s/50 iter), loss = 0.00191536, remaining 0 hours and 27 minutes
I0108 22:57:14.477099  2979 solver.cpp:291]     Train net output #0: loss = 0.00191537 (* 1 = 0.00191537 loss)
I0108 22:57:14.477106  2979 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0108 22:57:27.460852  2979 solver.cpp:270] Iteration 5600 (3.85111 iter/s, 12.9833s/50 iter), loss = 0.00237568, remaining 0 hours and 27 minutes
I0108 22:57:27.460886  2979 solver.cpp:291]     Train net output #0: loss = 0.00237568 (* 1 = 0.00237568 loss)
I0108 22:57:27.460893  2979 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0108 22:57:40.446317  2979 solver.cpp:270] Iteration 5650 (3.85061 iter/s, 12.9849s/50 iter), loss = 0.00225214, remaining 0 hours and 27 minutes
I0108 22:57:40.446364  2979 solver.cpp:291]     Train net output #0: loss = 0.00225214 (* 1 = 0.00225214 loss)
I0108 22:57:40.446372  2979 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0108 22:57:53.405885  2979 solver.cpp:270] Iteration 5700 (3.85831 iter/s, 12.959s/50 iter), loss = 0.00136555, remaining 0 hours and 27 minutes
I0108 22:57:53.405916  2979 solver.cpp:291]     Train net output #0: loss = 0.00136555 (* 1 = 0.00136555 loss)
I0108 22:57:53.405925  2979 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0108 22:58:06.409426  2979 solver.cpp:270] Iteration 5750 (3.84526 iter/s, 13.003s/50 iter), loss = 0.00758606, remaining 0 hours and 27 minutes
I0108 22:58:06.409458  2979 solver.cpp:291]     Train net output #0: loss = 0.00758606 (* 1 = 0.00758606 loss)
I0108 22:58:06.409466  2979 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0108 22:58:19.376699  2979 solver.cpp:270] Iteration 5800 (3.85601 iter/s, 12.9668s/50 iter), loss = 0.000685291, remaining 0 hours and 26 minutes
I0108 22:58:19.376752  2979 solver.cpp:291]     Train net output #0: loss = 0.000685291 (* 1 = 0.000685291 loss)
I0108 22:58:19.376760  2979 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0108 22:58:32.354022  2979 solver.cpp:270] Iteration 5850 (3.85303 iter/s, 12.9768s/50 iter), loss = 0.0159892, remaining 0 hours and 26 minutes
I0108 22:58:32.354053  2979 solver.cpp:291]     Train net output #0: loss = 0.0159892 (* 1 = 0.0159892 loss)
I0108 22:58:32.354059  2979 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0108 22:58:45.322017  2979 solver.cpp:270] Iteration 5900 (3.8558 iter/s, 12.9675s/50 iter), loss = 0.023261, remaining 0 hours and 26 minutes
I0108 22:58:45.322049  2979 solver.cpp:291]     Train net output #0: loss = 0.023261 (* 1 = 0.023261 loss)
I0108 22:58:45.322072  2979 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0108 22:58:58.322796  2979 solver.cpp:270] Iteration 5950 (3.84608 iter/s, 13.0003s/50 iter), loss = 0.00862855, remaining 0 hours and 26 minutes
I0108 22:58:58.322844  2979 solver.cpp:291]     Train net output #0: loss = 0.00862855 (* 1 = 0.00862855 loss)
I0108 22:58:58.322866  2979 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0108 22:59:11.037469  2979 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_6000.caffemodel
I0108 22:59:13.530458  2979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_6000.solverstate
I0108 22:59:13.754124  2979 solver.cpp:424] Iteration 6000, Testing net (#0)
I0108 22:59:15.227798  2979 solver.cpp:523]     Test net output #0: accuracy = 0.951
I0108 22:59:15.227825  2979 solver.cpp:523]     Test net output #1: loss = 0.19267 (* 1 = 0.19267 loss)
I0108 22:59:15.227830  2979 solver.cpp:523]     Test net output #2: top-1 = 0.951
I0108 22:59:15.477104  2979 solver.cpp:270] Iteration 6000 (2.91484 iter/s, 17.1536s/50 iter), loss = 0.00388887, remaining 0 hours and 34 minutes
I0108 22:59:15.477129  2979 solver.cpp:291]     Train net output #0: loss = 0.00388888 (* 1 = 0.00388888 loss)
I0108 22:59:15.477152  2979 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0108 22:59:28.400436  2979 solver.cpp:270] Iteration 6050 (3.86912 iter/s, 12.9228s/50 iter), loss = 0.00983843, remaining 0 hours and 25 minutes
I0108 22:59:28.400477  2979 solver.cpp:291]     Train net output #0: loss = 0.00983844 (* 1 = 0.00983844 loss)
I0108 22:59:28.400485  2979 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0108 22:59:41.338723  2979 solver.cpp:270] Iteration 6100 (3.86466 iter/s, 12.9378s/50 iter), loss = 0.00187248, remaining 0 hours and 25 minutes
I0108 22:59:41.338757  2979 solver.cpp:291]     Train net output #0: loss = 0.00187249 (* 1 = 0.00187249 loss)
I0108 22:59:41.338763  2979 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0108 22:59:54.294029  2979 solver.cpp:270] Iteration 6150 (3.85958 iter/s, 12.9548s/50 iter), loss = 0.0254728, remaining 0 hours and 25 minutes
I0108 22:59:54.294060  2979 solver.cpp:291]     Train net output #0: loss = 0.0254728 (* 1 = 0.0254728 loss)
I0108 22:59:54.294068  2979 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0108 23:00:07.281014  2979 solver.cpp:270] Iteration 6200 (3.85016 iter/s, 12.9865s/50 iter), loss = 0.0187591, remaining 0 hours and 24 minutes
I0108 23:00:07.281059  2979 solver.cpp:291]     Train net output #0: loss = 0.0187591 (* 1 = 0.0187591 loss)
I0108 23:00:07.281066  2979 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0108 23:00:20.253057  2979 solver.cpp:270] Iteration 6250 (3.8546 iter/s, 12.9715s/50 iter), loss = 0.00345631, remaining 0 hours and 24 minutes
I0108 23:00:20.253088  2979 solver.cpp:291]     Train net output #0: loss = 0.00345632 (* 1 = 0.00345632 loss)
I0108 23:00:20.253096  2979 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0108 23:00:33.240301  2979 solver.cpp:270] Iteration 6300 (3.85008 iter/s, 12.9867s/50 iter), loss = 0.00499548, remaining 0 hours and 24 minutes
I0108 23:00:33.240332  2979 solver.cpp:291]     Train net output #0: loss = 0.00499548 (* 1 = 0.00499548 loss)
I0108 23:00:33.240339  2979 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0108 23:00:46.225354  2979 solver.cpp:270] Iteration 6350 (3.85073 iter/s, 12.9845s/50 iter), loss = 0.00146894, remaining 0 hours and 24 minutes
I0108 23:00:46.225405  2979 solver.cpp:291]     Train net output #0: loss = 0.00146895 (* 1 = 0.00146895 loss)
I0108 23:00:46.225414  2979 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0108 23:00:59.202491  2979 solver.cpp:270] Iteration 6400 (3.85309 iter/s, 12.9766s/50 iter), loss = 0.00258902, remaining 0 hours and 24 minutes
I0108 23:00:59.202523  2979 solver.cpp:291]     Train net output #0: loss = 0.00258903 (* 1 = 0.00258903 loss)
I0108 23:00:59.202530  2979 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0108 23:01:12.210628  2979 solver.cpp:270] Iteration 6450 (3.8439 iter/s, 13.0076s/50 iter), loss = 0.00174923, remaining 0 hours and 23 minutes
I0108 23:01:12.210657  2979 solver.cpp:291]     Train net output #0: loss = 0.00174924 (* 1 = 0.00174924 loss)
I0108 23:01:12.210680  2979 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0108 23:01:25.194764  2979 solver.cpp:270] Iteration 6500 (3.85101 iter/s, 12.9836s/50 iter), loss = 0.00374599, remaining 0 hours and 23 minutes
I0108 23:01:25.194811  2979 solver.cpp:291]     Train net output #0: loss = 0.00374599 (* 1 = 0.00374599 loss)
I0108 23:01:25.194818  2979 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0108 23:01:38.200943  2979 solver.cpp:270] Iteration 6550 (3.84448 iter/s, 13.0056s/50 iter), loss = 0.00228582, remaining 0 hours and 23 minutes
I0108 23:01:38.200975  2979 solver.cpp:291]     Train net output #0: loss = 0.00228582 (* 1 = 0.00228582 loss)
I0108 23:01:38.200999  2979 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0108 23:01:51.177105  2979 solver.cpp:270] Iteration 6600 (3.85337 iter/s, 12.9756s/50 iter), loss = 0.0137257, remaining 0 hours and 23 minutes
I0108 23:01:51.177137  2979 solver.cpp:291]     Train net output #0: loss = 0.0137257 (* 1 = 0.0137257 loss)
I0108 23:01:51.177145  2979 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0108 23:02:04.157714  2979 solver.cpp:270] Iteration 6650 (3.85205 iter/s, 12.9801s/50 iter), loss = 0.00203224, remaining 0 hours and 23 minutes
I0108 23:02:04.157763  2979 solver.cpp:291]     Train net output #0: loss = 0.00203224 (* 1 = 0.00203224 loss)
I0108 23:02:04.157770  2979 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0108 23:02:17.149562  2979 solver.cpp:270] Iteration 6700 (3.84873 iter/s, 12.9913s/50 iter), loss = 0.00705564, remaining 0 hours and 22 minutes
I0108 23:02:17.149592  2979 solver.cpp:291]     Train net output #0: loss = 0.00705564 (* 1 = 0.00705564 loss)
I0108 23:02:17.149600  2979 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0108 23:02:30.114071  2979 solver.cpp:270] Iteration 6750 (3.85684 iter/s, 12.964s/50 iter), loss = 0.00942659, remaining 0 hours and 22 minutes
I0108 23:02:30.114104  2979 solver.cpp:291]     Train net output #0: loss = 0.0094266 (* 1 = 0.0094266 loss)
I0108 23:02:30.114127  2979 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0108 23:02:43.121279  2979 solver.cpp:270] Iteration 6800 (3.84418 iter/s, 13.0067s/50 iter), loss = 0.00709593, remaining 0 hours and 22 minutes
I0108 23:02:43.121340  2979 solver.cpp:291]     Train net output #0: loss = 0.00709594 (* 1 = 0.00709594 loss)
I0108 23:02:43.121347  2979 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0108 23:02:56.074153  2979 solver.cpp:270] Iteration 6850 (3.8603 iter/s, 12.9523s/50 iter), loss = 0.00069109, remaining 0 hours and 22 minutes
I0108 23:02:56.074187  2979 solver.cpp:291]     Train net output #0: loss = 0.000691098 (* 1 = 0.000691098 loss)
I0108 23:02:56.074193  2979 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0108 23:03:09.075675  2979 solver.cpp:270] Iteration 6900 (3.84586 iter/s, 13.001s/50 iter), loss = 0.00613693, remaining 0 hours and 22 minutes
I0108 23:03:09.075706  2979 solver.cpp:291]     Train net output #0: loss = 0.00613694 (* 1 = 0.00613694 loss)
I0108 23:03:09.075728  2979 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0108 23:03:22.053771  2979 solver.cpp:270] Iteration 6950 (3.8528 iter/s, 12.9776s/50 iter), loss = 0.00641841, remaining 0 hours and 21 minutes
I0108 23:03:22.053822  2979 solver.cpp:291]     Train net output #0: loss = 0.00641843 (* 1 = 0.00641843 loss)
I0108 23:03:22.053830  2979 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0108 23:03:34.784590  2979 solver.cpp:424] Iteration 7000, Testing net (#0)
I0108 23:03:36.287650  2979 solver.cpp:523]     Test net output #0: accuracy = 0.95225
I0108 23:03:36.287675  2979 solver.cpp:523]     Test net output #1: loss = 0.210966 (* 1 = 0.210966 loss)
I0108 23:03:36.287680  2979 solver.cpp:523]     Test net output #2: top-1 = 0.95225
I0108 23:03:36.540017  2979 solver.cpp:270] Iteration 7000 (3.45169 iter/s, 14.4857s/50 iter), loss = 0.00362205, remaining 0 hours and 24 minutes
I0108 23:03:36.540043  2979 solver.cpp:291]     Train net output #0: loss = 0.00362206 (* 1 = 0.00362206 loss)
I0108 23:03:36.540068  2979 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0108 23:03:49.580361  2979 solver.cpp:270] Iteration 7050 (3.83441 iter/s, 13.0398s/50 iter), loss = 0.0112464, remaining 0 hours and 21 minutes
I0108 23:03:49.580394  2979 solver.cpp:291]     Train net output #0: loss = 0.0112464 (* 1 = 0.0112464 loss)
I0108 23:03:49.580400  2979 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0108 23:04:02.556843  2979 solver.cpp:270] Iteration 7100 (3.85328 iter/s, 12.976s/50 iter), loss = 0.00325128, remaining 0 hours and 21 minutes
I0108 23:04:02.556887  2979 solver.cpp:291]     Train net output #0: loss = 0.00325129 (* 1 = 0.00325129 loss)
I0108 23:04:02.556893  2979 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0108 23:04:15.525612  2979 solver.cpp:270] Iteration 7150 (3.85557 iter/s, 12.9682s/50 iter), loss = 0.00826248, remaining 0 hours and 20 minutes
I0108 23:04:15.525645  2979 solver.cpp:291]     Train net output #0: loss = 0.00826249 (* 1 = 0.00826249 loss)
I0108 23:04:15.525651  2979 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0108 23:04:28.477916  2979 solver.cpp:270] Iteration 7200 (3.86047 iter/s, 12.9518s/50 iter), loss = 0.00395483, remaining 0 hours and 20 minutes
I0108 23:04:28.477946  2979 solver.cpp:291]     Train net output #0: loss = 0.00395483 (* 1 = 0.00395483 loss)
I0108 23:04:28.477953  2979 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0108 23:04:41.436116  2979 solver.cpp:270] Iteration 7250 (3.85871 iter/s, 12.9577s/50 iter), loss = 0.0212139, remaining 0 hours and 20 minutes
I0108 23:04:41.436161  2979 solver.cpp:291]     Train net output #0: loss = 0.021214 (* 1 = 0.021214 loss)
I0108 23:04:41.436168  2979 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0108 23:04:54.435366  2979 solver.cpp:270] Iteration 7300 (3.84653 iter/s, 12.9987s/50 iter), loss = 0.0325429, remaining 0 hours and 20 minutes
I0108 23:04:54.435397  2979 solver.cpp:291]     Train net output #0: loss = 0.0325429 (* 1 = 0.0325429 loss)
I0108 23:04:54.435420  2979 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0108 23:05:07.409822  2979 solver.cpp:270] Iteration 7350 (3.85388 iter/s, 12.9739s/50 iter), loss = 0.00778216, remaining 0 hours and 19 minutes
I0108 23:05:07.409853  2979 solver.cpp:291]     Train net output #0: loss = 0.00778217 (* 1 = 0.00778217 loss)
I0108 23:05:07.409860  2979 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0108 23:05:20.406817  2979 solver.cpp:270] Iteration 7400 (3.8472 iter/s, 12.9965s/50 iter), loss = 0.0108113, remaining 0 hours and 19 minutes
I0108 23:05:20.406862  2979 solver.cpp:291]     Train net output #0: loss = 0.0108113 (* 1 = 0.0108113 loss)
I0108 23:05:20.406869  2979 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0108 23:05:33.374608  2979 solver.cpp:270] Iteration 7450 (3.85586 iter/s, 12.9673s/50 iter), loss = 0.0163663, remaining 0 hours and 19 minutes
I0108 23:05:33.374640  2979 solver.cpp:291]     Train net output #0: loss = 0.0163663 (* 1 = 0.0163663 loss)
I0108 23:05:33.374663  2979 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0108 23:05:46.321760  2979 solver.cpp:270] Iteration 7500 (3.86201 iter/s, 12.9466s/50 iter), loss = 0.00600355, remaining 0 hours and 19 minutes
I0108 23:05:46.321794  2979 solver.cpp:291]     Train net output #0: loss = 0.00600355 (* 1 = 0.00600355 loss)
I0108 23:05:46.321801  2979 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0108 23:05:59.321926  2979 solver.cpp:270] Iteration 7550 (3.84626 iter/s, 12.9996s/50 iter), loss = 0.00312548, remaining 0 hours and 19 minutes
I0108 23:05:59.321980  2979 solver.cpp:291]     Train net output #0: loss = 0.00312548 (* 1 = 0.00312548 loss)
I0108 23:05:59.322005  2979 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0108 23:06:12.282969  2979 solver.cpp:270] Iteration 7600 (3.85787 iter/s, 12.9605s/50 iter), loss = 0.00318175, remaining 0 hours and 18 minutes
I0108 23:06:12.283001  2979 solver.cpp:291]     Train net output #0: loss = 0.00318175 (* 1 = 0.00318175 loss)
I0108 23:06:12.283008  2979 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0108 23:06:25.257225  2979 solver.cpp:270] Iteration 7650 (3.85394 iter/s, 12.9737s/50 iter), loss = 0.00210317, remaining 0 hours and 18 minutes
I0108 23:06:25.257256  2979 solver.cpp:291]     Train net output #0: loss = 0.00210318 (* 1 = 0.00210318 loss)
I0108 23:06:25.257263  2979 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0108 23:06:38.212818  2979 solver.cpp:270] Iteration 7700 (3.85949 iter/s, 12.9551s/50 iter), loss = 0.00224001, remaining 0 hours and 18 minutes
I0108 23:06:38.212863  2979 solver.cpp:291]     Train net output #0: loss = 0.00224001 (* 1 = 0.00224001 loss)
I0108 23:06:38.212870  2979 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0108 23:06:51.187878  2979 solver.cpp:270] Iteration 7750 (3.8537 iter/s, 12.9745s/50 iter), loss = 0.00690222, remaining 0 hours and 18 minutes
I0108 23:06:51.187911  2979 solver.cpp:291]     Train net output #0: loss = 0.00690223 (* 1 = 0.00690223 loss)
I0108 23:06:51.187918  2979 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0108 23:07:04.167105  2979 solver.cpp:270] Iteration 7800 (3.85246 iter/s, 12.9787s/50 iter), loss = 0.0130553, remaining 0 hours and 18 minutes
I0108 23:07:04.167136  2979 solver.cpp:291]     Train net output #0: loss = 0.0130553 (* 1 = 0.0130553 loss)
I0108 23:07:04.167145  2979 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0108 23:07:17.138067  2979 solver.cpp:270] Iteration 7850 (3.85492 iter/s, 12.9704s/50 iter), loss = 0.00564894, remaining 0 hours and 17 minutes
I0108 23:07:17.138114  2979 solver.cpp:291]     Train net output #0: loss = 0.00564895 (* 1 = 0.00564895 loss)
I0108 23:07:17.138123  2979 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0108 23:07:30.100383  2979 solver.cpp:270] Iteration 7900 (3.85749 iter/s, 12.9618s/50 iter), loss = 0.0115688, remaining 0 hours and 17 minutes
I0108 23:07:30.100414  2979 solver.cpp:291]     Train net output #0: loss = 0.0115688 (* 1 = 0.0115688 loss)
I0108 23:07:30.100421  2979 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0108 23:07:43.076285  2979 solver.cpp:270] Iteration 7950 (3.85345 iter/s, 12.9754s/50 iter), loss = 0.00626833, remaining 0 hours and 17 minutes
I0108 23:07:43.076316  2979 solver.cpp:291]     Train net output #0: loss = 0.00626834 (* 1 = 0.00626834 loss)
I0108 23:07:43.076324  2979 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0108 23:07:55.772547  2979 solver.cpp:424] Iteration 8000, Testing net (#0)
I0108 23:07:57.330248  2979 solver.cpp:523]     Test net output #0: accuracy = 0.9515
I0108 23:07:57.330274  2979 solver.cpp:523]     Test net output #1: loss = 0.24176 (* 1 = 0.24176 loss)
I0108 23:07:57.330278  2979 solver.cpp:523]     Test net output #2: top-1 = 0.9515
I0108 23:07:57.580225  2979 solver.cpp:270] Iteration 8000 (3.44747 iter/s, 14.5034s/50 iter), loss = 0.00114751, remaining 0 hours and 19 minutes
I0108 23:07:57.580253  2979 solver.cpp:291]     Train net output #0: loss = 0.00114752 (* 1 = 0.00114752 loss)
I0108 23:07:57.580262  2979 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0108 23:08:10.569509  2979 solver.cpp:270] Iteration 8050 (3.84948 iter/s, 12.9888s/50 iter), loss = 0.00849724, remaining 0 hours and 16 minutes
I0108 23:08:10.569538  2979 solver.cpp:291]     Train net output #0: loss = 0.00849725 (* 1 = 0.00849725 loss)
I0108 23:08:10.569546  2979 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0108 23:08:23.545303  2979 solver.cpp:270] Iteration 8100 (3.85348 iter/s, 12.9753s/50 iter), loss = 0.00243467, remaining 0 hours and 16 minutes
I0108 23:08:23.545336  2979 solver.cpp:291]     Train net output #0: loss = 0.00243467 (* 1 = 0.00243467 loss)
I0108 23:08:23.545359  2979 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0108 23:08:36.509109  2979 solver.cpp:270] Iteration 8150 (3.85705 iter/s, 12.9633s/50 iter), loss = 0.0040948, remaining 0 hours and 16 minutes
I0108 23:08:36.509160  2979 solver.cpp:291]     Train net output #0: loss = 0.00409481 (* 1 = 0.00409481 loss)
I0108 23:08:36.509169  2979 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0108 23:08:49.492652  2979 solver.cpp:270] Iteration 8200 (3.85119 iter/s, 12.983s/50 iter), loss = 0.00292251, remaining 0 hours and 16 minutes
I0108 23:08:49.492683  2979 solver.cpp:291]     Train net output #0: loss = 0.00292252 (* 1 = 0.00292252 loss)
I0108 23:08:49.492691  2979 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0108 23:09:02.476089  2979 solver.cpp:270] Iteration 8250 (3.85121 iter/s, 12.9829s/50 iter), loss = 0.00176552, remaining 0 hours and 16 minutes
I0108 23:09:02.476120  2979 solver.cpp:291]     Train net output #0: loss = 0.00176553 (* 1 = 0.00176553 loss)
I0108 23:09:02.476127  2979 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0108 23:09:15.441022  2979 solver.cpp:270] Iteration 8300 (3.85671 iter/s, 12.9644s/50 iter), loss = 0.00568389, remaining 0 hours and 15 minutes
I0108 23:09:15.441067  2979 solver.cpp:291]     Train net output #0: loss = 0.0056839 (* 1 = 0.0056839 loss)
I0108 23:09:15.441074  2979 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0108 23:09:28.409477  2979 solver.cpp:270] Iteration 8350 (3.85567 iter/s, 12.9679s/50 iter), loss = 0.00439041, remaining 0 hours and 15 minutes
I0108 23:09:28.409509  2979 solver.cpp:291]     Train net output #0: loss = 0.00439042 (* 1 = 0.00439042 loss)
I0108 23:09:28.409516  2979 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0108 23:09:41.374747  2979 solver.cpp:270] Iteration 8400 (3.85661 iter/s, 12.9648s/50 iter), loss = 0.00323329, remaining 0 hours and 15 minutes
I0108 23:09:41.374776  2979 solver.cpp:291]     Train net output #0: loss = 0.00323329 (* 1 = 0.00323329 loss)
I0108 23:09:41.374799  2979 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0108 23:09:54.356926  2979 solver.cpp:270] Iteration 8450 (3.85159 iter/s, 12.9817s/50 iter), loss = 0.00654564, remaining 0 hours and 15 minutes
I0108 23:09:54.356973  2979 solver.cpp:291]     Train net output #0: loss = 0.00654564 (* 1 = 0.00654564 loss)
I0108 23:09:54.356981  2979 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0108 23:10:07.336083  2979 solver.cpp:270] Iteration 8500 (3.85249 iter/s, 12.9786s/50 iter), loss = 0.0119356, remaining 0 hours and 15 minutes
I0108 23:10:07.336114  2979 solver.cpp:291]     Train net output #0: loss = 0.0119356 (* 1 = 0.0119356 loss)
I0108 23:10:07.336122  2979 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0108 23:10:20.323109  2979 solver.cpp:270] Iteration 8550 (3.85015 iter/s, 12.9865s/50 iter), loss = 0.0225739, remaining 0 hours and 14 minutes
I0108 23:10:20.323141  2979 solver.cpp:291]     Train net output #0: loss = 0.0225739 (* 1 = 0.0225739 loss)
I0108 23:10:20.323165  2979 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0108 23:10:33.295261  2979 solver.cpp:270] Iteration 8600 (3.85456 iter/s, 12.9716s/50 iter), loss = 0.00580634, remaining 0 hours and 14 minutes
I0108 23:10:33.295308  2979 solver.cpp:291]     Train net output #0: loss = 0.00580634 (* 1 = 0.00580634 loss)
I0108 23:10:33.295316  2979 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0108 23:10:46.244767  2979 solver.cpp:270] Iteration 8650 (3.86131 iter/s, 12.949s/50 iter), loss = 0.00117508, remaining 0 hours and 14 minutes
I0108 23:10:46.244798  2979 solver.cpp:291]     Train net output #0: loss = 0.00117508 (* 1 = 0.00117508 loss)
I0108 23:10:46.244822  2979 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0108 23:10:59.219743  2979 solver.cpp:270] Iteration 8700 (3.85372 iter/s, 12.9745s/50 iter), loss = 0.00691035, remaining 0 hours and 14 minutes
I0108 23:10:59.219774  2979 solver.cpp:291]     Train net output #0: loss = 0.00691036 (* 1 = 0.00691036 loss)
I0108 23:10:59.219797  2979 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0108 23:11:12.206924  2979 solver.cpp:270] Iteration 8750 (3.8501 iter/s, 12.9867s/50 iter), loss = 0.00194088, remaining 0 hours and 14 minutes
I0108 23:11:12.206977  2979 solver.cpp:291]     Train net output #0: loss = 0.00194088 (* 1 = 0.00194088 loss)
I0108 23:11:12.207001  2979 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0108 23:11:25.190182  2979 solver.cpp:270] Iteration 8800 (3.85127 iter/s, 12.9827s/50 iter), loss = 0.00877874, remaining 0 hours and 13 minutes
I0108 23:11:25.190213  2979 solver.cpp:291]     Train net output #0: loss = 0.00877874 (* 1 = 0.00877874 loss)
I0108 23:11:25.190222  2979 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0108 23:11:38.158193  2979 solver.cpp:270] Iteration 8850 (3.85579 iter/s, 12.9675s/50 iter), loss = 0.0023237, remaining 0 hours and 13 minutes
I0108 23:11:38.158224  2979 solver.cpp:291]     Train net output #0: loss = 0.00232369 (* 1 = 0.00232369 loss)
I0108 23:11:38.158250  2979 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0108 23:11:51.145608  2979 solver.cpp:270] Iteration 8900 (3.85003 iter/s, 12.9869s/50 iter), loss = 0.00809017, remaining 0 hours and 13 minutes
I0108 23:11:51.145653  2979 solver.cpp:291]     Train net output #0: loss = 0.00809017 (* 1 = 0.00809017 loss)
I0108 23:11:51.145676  2979 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0108 23:12:04.109514  2979 solver.cpp:270] Iteration 8950 (3.85702 iter/s, 12.9634s/50 iter), loss = 0.0100503, remaining 0 hours and 12 minutes
I0108 23:12:04.109544  2979 solver.cpp:291]     Train net output #0: loss = 0.0100503 (* 1 = 0.0100503 loss)
I0108 23:12:04.109552  2979 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0108 23:12:16.829196  2979 solver.cpp:424] Iteration 9000, Testing net (#0)
I0108 23:12:18.364485  2979 solver.cpp:523]     Test net output #0: accuracy = 0.95175
I0108 23:12:18.364511  2979 solver.cpp:523]     Test net output #1: loss = 0.266118 (* 1 = 0.266118 loss)
I0108 23:12:18.364516  2979 solver.cpp:523]     Test net output #2: top-1 = 0.95175
I0108 23:12:18.613560  2979 solver.cpp:270] Iteration 9000 (3.44745 iter/s, 14.5035s/50 iter), loss = 0.00233154, remaining 0 hours and 14 minutes
I0108 23:12:18.613586  2979 solver.cpp:291]     Train net output #0: loss = 0.00233154 (* 1 = 0.00233154 loss)
I0108 23:12:18.613595  2979 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0108 23:12:31.600805  2979 solver.cpp:270] Iteration 9050 (3.85008 iter/s, 12.9867s/50 iter), loss = 0.000394034, remaining 0 hours and 12 minutes
I0108 23:12:31.600850  2979 solver.cpp:291]     Train net output #0: loss = 0.000394031 (* 1 = 0.000394031 loss)
I0108 23:12:31.600857  2979 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0108 23:12:44.579684  2979 solver.cpp:270] Iteration 9100 (3.85257 iter/s, 12.9783s/50 iter), loss = 0.00370203, remaining 0 hours and 12 minutes
I0108 23:12:44.579715  2979 solver.cpp:291]     Train net output #0: loss = 0.00370203 (* 1 = 0.00370203 loss)
I0108 23:12:44.579721  2979 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0108 23:12:57.555757  2979 solver.cpp:270] Iteration 9150 (3.8534 iter/s, 12.9756s/50 iter), loss = 0.00124947, remaining 0 hours and 12 minutes
I0108 23:12:57.555789  2979 solver.cpp:291]     Train net output #0: loss = 0.00124947 (* 1 = 0.00124947 loss)
I0108 23:12:57.555814  2979 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0108 23:13:10.537304  2979 solver.cpp:270] Iteration 9200 (3.85177 iter/s, 12.981s/50 iter), loss = 0.00188592, remaining 0 hours and 11 minutes
I0108 23:13:10.537367  2979 solver.cpp:291]     Train net output #0: loss = 0.00188592 (* 1 = 0.00188592 loss)
I0108 23:13:10.537391  2979 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0108 23:13:23.504056  2979 solver.cpp:270] Iteration 9250 (3.85618 iter/s, 12.9662s/50 iter), loss = 0.000535355, remaining 0 hours and 11 minutes
I0108 23:13:23.504087  2979 solver.cpp:291]     Train net output #0: loss = 0.000535351 (* 1 = 0.000535351 loss)
I0108 23:13:23.504096  2979 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0108 23:13:36.499157  2979 solver.cpp:270] Iteration 9300 (3.84776 iter/s, 12.9946s/50 iter), loss = 0.000692633, remaining 0 hours and 11 minutes
I0108 23:13:36.499187  2979 solver.cpp:291]     Train net output #0: loss = 0.000692629 (* 1 = 0.000692629 loss)
I0108 23:13:36.499195  2979 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0108 23:13:49.475579  2979 solver.cpp:270] Iteration 9350 (3.85329 iter/s, 12.9759s/50 iter), loss = 0.00508018, remaining 0 hours and 11 minutes
I0108 23:13:49.475626  2979 solver.cpp:291]     Train net output #0: loss = 0.00508018 (* 1 = 0.00508018 loss)
I0108 23:13:49.475634  2979 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0108 23:14:02.424862  2979 solver.cpp:270] Iteration 9400 (3.86138 iter/s, 12.9488s/50 iter), loss = 0.00649504, remaining 0 hours and 11 minutes
I0108 23:14:02.424893  2979 solver.cpp:291]     Train net output #0: loss = 0.00649504 (* 1 = 0.00649504 loss)
I0108 23:14:02.424901  2979 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0108 23:14:15.394834  2979 solver.cpp:270] Iteration 9450 (3.85521 iter/s, 12.9695s/50 iter), loss = 0.000859726, remaining 0 hours and 10 minutes
I0108 23:14:15.394868  2979 solver.cpp:291]     Train net output #0: loss = 0.000859723 (* 1 = 0.000859723 loss)
I0108 23:14:15.394876  2979 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0108 23:14:28.359269  2979 solver.cpp:270] Iteration 9500 (3.85686 iter/s, 12.9639s/50 iter), loss = 0.00630526, remaining 0 hours and 10 minutes
I0108 23:14:28.359313  2979 solver.cpp:291]     Train net output #0: loss = 0.00630526 (* 1 = 0.00630526 loss)
I0108 23:14:28.359320  2979 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0108 23:14:41.356321  2979 solver.cpp:270] Iteration 9550 (3.84718 iter/s, 12.9965s/50 iter), loss = 0.000673519, remaining 0 hours and 10 minutes
I0108 23:14:41.356355  2979 solver.cpp:291]     Train net output #0: loss = 0.00067351 (* 1 = 0.00067351 loss)
I0108 23:14:41.356362  2979 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0108 23:14:54.317744  2979 solver.cpp:270] Iteration 9600 (3.85776 iter/s, 12.9609s/50 iter), loss = 0.000465828, remaining 0 hours and 10 minutes
I0108 23:14:54.317775  2979 solver.cpp:291]     Train net output #0: loss = 0.000465821 (* 1 = 0.000465821 loss)
I0108 23:14:54.317782  2979 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0108 23:15:07.302636  2979 solver.cpp:270] Iteration 9650 (3.85078 iter/s, 12.9844s/50 iter), loss = 0.0103353, remaining 0 hours and 10 minutes
I0108 23:15:07.302681  2979 solver.cpp:291]     Train net output #0: loss = 0.0103353 (* 1 = 0.0103353 loss)
I0108 23:15:07.302690  2979 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0108 23:15:20.287864  2979 solver.cpp:270] Iteration 9700 (3.85069 iter/s, 12.9847s/50 iter), loss = 0.0185721, remaining 0 hours and 9 minutes
I0108 23:15:20.287896  2979 solver.cpp:291]     Train net output #0: loss = 0.0185721 (* 1 = 0.0185721 loss)
I0108 23:15:20.287904  2979 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0108 23:15:33.265239  2979 solver.cpp:270] Iteration 9750 (3.85301 iter/s, 12.9769s/50 iter), loss = 0.00295205, remaining 0 hours and 9 minutes
I0108 23:15:33.265269  2979 solver.cpp:291]     Train net output #0: loss = 0.00295204 (* 1 = 0.00295204 loss)
I0108 23:15:33.265292  2979 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0108 23:15:46.217141  2979 solver.cpp:270] Iteration 9800 (3.86059 iter/s, 12.9514s/50 iter), loss = 0.0129038, remaining 0 hours and 9 minutes
I0108 23:15:46.217187  2979 solver.cpp:291]     Train net output #0: loss = 0.0129038 (* 1 = 0.0129038 loss)
I0108 23:15:46.217195  2979 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0108 23:15:59.184489  2979 solver.cpp:270] Iteration 9850 (3.856 iter/s, 12.9668s/50 iter), loss = 0.0217783, remaining 0 hours and 9 minutes
I0108 23:15:59.184520  2979 solver.cpp:291]     Train net output #0: loss = 0.0217783 (* 1 = 0.0217783 loss)
I0108 23:15:59.184525  2979 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0108 23:16:12.134692  2979 solver.cpp:270] Iteration 9900 (3.8611 iter/s, 12.9497s/50 iter), loss = 0.00629543, remaining 0 hours and 9 minutes
I0108 23:16:12.134723  2979 solver.cpp:291]     Train net output #0: loss = 0.00629543 (* 1 = 0.00629543 loss)
I0108 23:16:12.134730  2979 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0108 23:16:25.120344  2979 solver.cpp:270] Iteration 9950 (3.85056 iter/s, 12.9851s/50 iter), loss = 0.0107314, remaining 0 hours and 8 minutes
I0108 23:16:25.120398  2979 solver.cpp:291]     Train net output #0: loss = 0.0107314 (* 1 = 0.0107314 loss)
I0108 23:16:25.120406  2979 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0108 23:16:37.812755  2979 solver.cpp:424] Iteration 10000, Testing net (#0)
I0108 23:16:39.375978  2979 solver.cpp:523]     Test net output #0: accuracy = 0.9505
I0108 23:16:39.376003  2979 solver.cpp:523]     Test net output #1: loss = 0.280358 (* 1 = 0.280358 loss)
I0108 23:16:39.376006  2979 solver.cpp:523]     Test net output #2: top-1 = 0.9505
I0108 23:16:39.627600  2979 solver.cpp:270] Iteration 10000 (3.44669 iter/s, 14.5067s/50 iter), loss = 0.00256994, remaining 0 hours and 9 minutes
I0108 23:16:39.627624  2979 solver.cpp:291]     Train net output #0: loss = 0.00256993 (* 1 = 0.00256993 loss)
I0108 23:16:39.627632  2979 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0108 23:16:52.573134  2979 solver.cpp:270] Iteration 10050 (3.86249 iter/s, 12.945s/50 iter), loss = 0.00347192, remaining 0 hours and 8 minutes
I0108 23:16:52.573164  2979 solver.cpp:291]     Train net output #0: loss = 0.0034719 (* 1 = 0.0034719 loss)
I0108 23:16:52.573189  2979 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0108 23:17:05.559208  2979 solver.cpp:270] Iteration 10100 (3.85043 iter/s, 12.9856s/50 iter), loss = 0.00481644, remaining 0 hours and 8 minutes
I0108 23:17:05.559254  2979 solver.cpp:291]     Train net output #0: loss = 0.00481642 (* 1 = 0.00481642 loss)
I0108 23:17:05.559262  2979 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0108 23:17:18.518633  2979 solver.cpp:270] Iteration 10150 (3.85835 iter/s, 12.9589s/50 iter), loss = 0.00373448, remaining 0 hours and 7 minutes
I0108 23:17:18.518667  2979 solver.cpp:291]     Train net output #0: loss = 0.00373446 (* 1 = 0.00373446 loss)
I0108 23:17:18.518674  2979 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0108 23:17:31.480913  2979 solver.cpp:270] Iteration 10200 (3.8575 iter/s, 12.9618s/50 iter), loss = 0.00216869, remaining 0 hours and 7 minutes
I0108 23:17:31.480945  2979 solver.cpp:291]     Train net output #0: loss = 0.00216867 (* 1 = 0.00216867 loss)
I0108 23:17:31.480953  2979 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0108 23:17:44.451676  2979 solver.cpp:270] Iteration 10250 (3.85498 iter/s, 12.9702s/50 iter), loss = 0.002914, remaining 0 hours and 7 minutes
I0108 23:17:44.451721  2979 solver.cpp:291]     Train net output #0: loss = 0.00291398 (* 1 = 0.00291398 loss)
I0108 23:17:44.451728  2979 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0108 23:17:57.446331  2979 solver.cpp:270] Iteration 10300 (3.84789 iter/s, 12.9941s/50 iter), loss = 0.00257241, remaining 0 hours and 7 minutes
I0108 23:17:57.446362  2979 solver.cpp:291]     Train net output #0: loss = 0.00257239 (* 1 = 0.00257239 loss)
I0108 23:17:57.446385  2979 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0108 23:18:10.412842  2979 solver.cpp:270] Iteration 10350 (3.85624 iter/s, 12.966s/50 iter), loss = 0.00191889, remaining 0 hours and 7 minutes
I0108 23:18:10.412873  2979 solver.cpp:291]     Train net output #0: loss = 0.00191888 (* 1 = 0.00191888 loss)
I0108 23:18:10.412881  2979 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0108 23:18:23.359330  2979 solver.cpp:270] Iteration 10400 (3.86221 iter/s, 12.946s/50 iter), loss = 0.0240677, remaining 0 hours and 6 minutes
I0108 23:18:23.359381  2979 solver.cpp:291]     Train net output #0: loss = 0.0240676 (* 1 = 0.0240676 loss)
I0108 23:18:23.359390  2979 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0108 23:18:36.345623  2979 solver.cpp:270] Iteration 10450 (3.85037 iter/s, 12.9858s/50 iter), loss = 0.00660753, remaining 0 hours and 6 minutes
I0108 23:18:36.345654  2979 solver.cpp:291]     Train net output #0: loss = 0.00660751 (* 1 = 0.00660751 loss)
I0108 23:18:36.345662  2979 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0108 23:18:49.335960  2979 solver.cpp:270] Iteration 10500 (3.84917 iter/s, 12.9898s/50 iter), loss = 0.00110749, remaining 0 hours and 6 minutes
I0108 23:18:49.335991  2979 solver.cpp:291]     Train net output #0: loss = 0.00110748 (* 1 = 0.00110748 loss)
I0108 23:18:49.335999  2979 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0108 23:19:02.311785  2979 solver.cpp:270] Iteration 10550 (3.85347 iter/s, 12.9753s/50 iter), loss = 0.00407913, remaining 0 hours and 6 minutes
I0108 23:19:02.311832  2979 solver.cpp:291]     Train net output #0: loss = 0.00407911 (* 1 = 0.00407911 loss)
I0108 23:19:02.311839  2979 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0108 23:19:15.291102  2979 solver.cpp:270] Iteration 10600 (3.85244 iter/s, 12.9788s/50 iter), loss = 0.000623382, remaining 0 hours and 5 minutes
I0108 23:19:15.291133  2979 solver.cpp:291]     Train net output #0: loss = 0.000623362 (* 1 = 0.000623362 loss)
I0108 23:19:15.291141  2979 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0108 23:19:28.239641  2979 solver.cpp:270] Iteration 10650 (3.86159 iter/s, 12.948s/50 iter), loss = 0.00040919, remaining 0 hours and 5 minutes
I0108 23:19:28.239673  2979 solver.cpp:291]     Train net output #0: loss = 0.000409167 (* 1 = 0.000409167 loss)
I0108 23:19:28.239681  2979 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0108 23:19:41.222431  2979 solver.cpp:270] Iteration 10700 (3.85141 iter/s, 12.9823s/50 iter), loss = 0.00108682, remaining 0 hours and 5 minutes
I0108 23:19:41.222476  2979 solver.cpp:291]     Train net output #0: loss = 0.00108679 (* 1 = 0.00108679 loss)
I0108 23:19:41.222498  2979 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0108 23:19:54.174863  2979 solver.cpp:270] Iteration 10750 (3.86044 iter/s, 12.9519s/50 iter), loss = 0.000908096, remaining 0 hours and 5 minutes
I0108 23:19:54.174897  2979 solver.cpp:291]     Train net output #0: loss = 0.000908067 (* 1 = 0.000908067 loss)
I0108 23:19:54.174906  2979 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0108 23:20:07.143541  2979 solver.cpp:270] Iteration 10800 (3.8556 iter/s, 12.9682s/50 iter), loss = 0.00116298, remaining 0 hours and 5 minutes
I0108 23:20:07.143573  2979 solver.cpp:291]     Train net output #0: loss = 0.00116296 (* 1 = 0.00116296 loss)
I0108 23:20:07.143580  2979 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0108 23:20:20.145838  2979 solver.cpp:270] Iteration 10850 (3.84563 iter/s, 13.0018s/50 iter), loss = 0.00741709, remaining 0 hours and 4 minutes
I0108 23:20:20.145884  2979 solver.cpp:291]     Train net output #0: loss = 0.00741707 (* 1 = 0.00741707 loss)
I0108 23:20:20.145891  2979 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0108 23:20:33.105170  2979 solver.cpp:270] Iteration 10900 (3.85838 iter/s, 12.9588s/50 iter), loss = 0.00159175, remaining 0 hours and 4 minutes
I0108 23:20:33.105201  2979 solver.cpp:291]     Train net output #0: loss = 0.00159173 (* 1 = 0.00159173 loss)
I0108 23:20:33.105208  2979 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0108 23:20:46.058007  2979 solver.cpp:270] Iteration 10950 (3.86031 iter/s, 12.9523s/50 iter), loss = 0.00553728, remaining 0 hours and 4 minutes
I0108 23:20:46.058039  2979 solver.cpp:291]     Train net output #0: loss = 0.00553725 (* 1 = 0.00553725 loss)
I0108 23:20:46.058046  2979 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0108 23:20:58.793556  2979 solver.cpp:424] Iteration 11000, Testing net (#0)
I0108 23:21:00.335166  2979 solver.cpp:523]     Test net output #0: accuracy = 0.951
I0108 23:21:00.335194  2979 solver.cpp:523]     Test net output #1: loss = 0.288338 (* 1 = 0.288338 loss)
I0108 23:21:00.335199  2979 solver.cpp:523]     Test net output #2: top-1 = 0.951
I0108 23:21:00.586418  2979 solver.cpp:270] Iteration 11000 (3.44167 iter/s, 14.5278s/50 iter), loss = 0.00830327, remaining 0 hours and 4 minutes
I0108 23:21:00.586443  2979 solver.cpp:291]     Train net output #0: loss = 0.00830324 (* 1 = 0.00830324 loss)
I0108 23:21:00.586467  2979 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0108 23:21:13.540122  2979 solver.cpp:270] Iteration 11050 (3.86005 iter/s, 12.9532s/50 iter), loss = 0.00624886, remaining 0 hours and 3 minutes
I0108 23:21:13.540154  2979 solver.cpp:291]     Train net output #0: loss = 0.00624883 (* 1 = 0.00624883 loss)
I0108 23:21:13.540163  2979 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0108 23:21:26.503480  2979 solver.cpp:270] Iteration 11100 (3.85718 iter/s, 12.9628s/50 iter), loss = 0.00171544, remaining 0 hours and 3 minutes
I0108 23:21:26.503510  2979 solver.cpp:291]     Train net output #0: loss = 0.00171542 (* 1 = 0.00171542 loss)
I0108 23:21:26.503517  2979 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0108 23:21:39.461656  2979 solver.cpp:270] Iteration 11150 (3.85872 iter/s, 12.9577s/50 iter), loss = 0.0021299, remaining 0 hours and 3 minutes
I0108 23:21:39.461702  2979 solver.cpp:291]     Train net output #0: loss = 0.00212988 (* 1 = 0.00212988 loss)
I0108 23:21:39.461710  2979 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0108 23:21:52.424197  2979 solver.cpp:270] Iteration 11200 (3.85743 iter/s, 12.962s/50 iter), loss = 0.00798868, remaining 0 hours and 3 minutes
I0108 23:21:52.424227  2979 solver.cpp:291]     Train net output #0: loss = 0.00798866 (* 1 = 0.00798866 loss)
I0108 23:21:52.424250  2979 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0108 23:22:05.414235  2979 solver.cpp:270] Iteration 11250 (3.84926 iter/s, 12.9895s/50 iter), loss = 0.00435412, remaining 0 hours and 3 minutes
I0108 23:22:05.414268  2979 solver.cpp:291]     Train net output #0: loss = 0.0043541 (* 1 = 0.0043541 loss)
I0108 23:22:05.414291  2979 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0108 23:22:18.393529  2979 solver.cpp:270] Iteration 11300 (3.85244 iter/s, 12.9788s/50 iter), loss = 0.00345587, remaining 0 hours and 2 minutes
I0108 23:22:18.393575  2979 solver.cpp:291]     Train net output #0: loss = 0.00345585 (* 1 = 0.00345585 loss)
I0108 23:22:18.393584  2979 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0108 23:22:31.367956  2979 solver.cpp:270] Iteration 11350 (3.85389 iter/s, 12.9739s/50 iter), loss = 0.0021334, remaining 0 hours and 2 minutes
I0108 23:22:31.367988  2979 solver.cpp:291]     Train net output #0: loss = 0.00213337 (* 1 = 0.00213337 loss)
I0108 23:22:31.367995  2979 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0108 23:22:44.331095  2979 solver.cpp:270] Iteration 11400 (3.85724 iter/s, 12.9626s/50 iter), loss = 0.00337218, remaining 0 hours and 2 minutes
I0108 23:22:44.331127  2979 solver.cpp:291]     Train net output #0: loss = 0.00337216 (* 1 = 0.00337216 loss)
I0108 23:22:44.331135  2979 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0108 23:22:57.298264  2979 solver.cpp:270] Iteration 11450 (3.85605 iter/s, 12.9667s/50 iter), loss = 0.00221912, remaining 0 hours and 2 minutes
I0108 23:22:57.298310  2979 solver.cpp:291]     Train net output #0: loss = 0.0022191 (* 1 = 0.0022191 loss)
I0108 23:22:57.298318  2979 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0108 23:23:10.280931  2979 solver.cpp:270] Iteration 11500 (3.85145 iter/s, 12.9821s/50 iter), loss = 0.00175284, remaining 0 hours and 2 minutes
I0108 23:23:10.280964  2979 solver.cpp:291]     Train net output #0: loss = 0.00175283 (* 1 = 0.00175283 loss)
I0108 23:23:10.280972  2979 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0108 23:23:23.237779  2979 solver.cpp:270] Iteration 11550 (3.85912 iter/s, 12.9563s/50 iter), loss = 0.00486914, remaining 0 hours and 1 minutes
I0108 23:23:23.237812  2979 solver.cpp:291]     Train net output #0: loss = 0.00486913 (* 1 = 0.00486913 loss)
I0108 23:23:23.237835  2979 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0108 23:23:36.229219  2979 solver.cpp:270] Iteration 11600 (3.84884 iter/s, 12.9909s/50 iter), loss = 0.00761095, remaining 0 hours and 1 minutes
I0108 23:23:36.229274  2979 solver.cpp:291]     Train net output #0: loss = 0.00761094 (* 1 = 0.00761094 loss)
I0108 23:23:36.229298  2979 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0108 23:23:49.196503  2979 solver.cpp:270] Iteration 11650 (3.85602 iter/s, 12.9667s/50 iter), loss = 0.0187083, remaining 0 hours and 1 minutes
I0108 23:23:49.196537  2979 solver.cpp:291]     Train net output #0: loss = 0.0187083 (* 1 = 0.0187083 loss)
I0108 23:23:49.196544  2979 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0108 23:24:02.163892  2979 solver.cpp:270] Iteration 11700 (3.85598 iter/s, 12.9669s/50 iter), loss = 0.00143418, remaining 0 hours and 1 minutes
I0108 23:24:02.163921  2979 solver.cpp:291]     Train net output #0: loss = 0.00143418 (* 1 = 0.00143418 loss)
I0108 23:24:02.163944  2979 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0108 23:24:15.153766  2979 solver.cpp:270] Iteration 11750 (3.8493 iter/s, 12.9894s/50 iter), loss = 0.00301789, remaining 0 hours and 1 minutes
I0108 23:24:15.153815  2979 solver.cpp:291]     Train net output #0: loss = 0.00301788 (* 1 = 0.00301788 loss)
I0108 23:24:15.153825  2979 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0108 23:24:28.103096  2979 solver.cpp:270] Iteration 11800 (3.86136 iter/s, 12.9488s/50 iter), loss = 0.00673658, remaining 0 hours and 0 minutes
I0108 23:24:28.103128  2979 solver.cpp:291]     Train net output #0: loss = 0.00673657 (* 1 = 0.00673657 loss)
I0108 23:24:28.103137  2979 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0108 23:24:41.089139  2979 solver.cpp:270] Iteration 11850 (3.85044 iter/s, 12.9855s/50 iter), loss = 0.00692929, remaining 0 hours and 0 minutes
I0108 23:24:41.089169  2979 solver.cpp:291]     Train net output #0: loss = 0.00692928 (* 1 = 0.00692928 loss)
I0108 23:24:41.089177  2979 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0108 23:24:54.057901  2979 solver.cpp:270] Iteration 11900 (3.85557 iter/s, 12.9682s/50 iter), loss = 0.0015423, remaining 0 hours and 0 minutes
I0108 23:24:54.057947  2979 solver.cpp:291]     Train net output #0: loss = 0.00154229 (* 1 = 0.00154229 loss)
I0108 23:24:54.057955  2979 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0108 23:25:07.019448  2979 solver.cpp:270] Iteration 11950 (3.85772 iter/s, 12.961s/50 iter), loss = 0.00274875, remaining 0 hours and 0 minutes
I0108 23:25:07.019480  2979 solver.cpp:291]     Train net output #0: loss = 0.00274874 (* 1 = 0.00274874 loss)
I0108 23:25:07.019490  2979 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0108 23:25:19.721349  2979 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_12000.caffemodel
I0108 23:25:22.118947  2979 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.3/snapshots/_iter_12000.solverstate
I0108 23:25:22.440806  2979 solver.cpp:384] Iteration 12000, loss = 0.00150008
I0108 23:25:22.440834  2979 solver.cpp:424] Iteration 12000, Testing net (#0)
I0108 23:25:23.904067  2979 solver.cpp:523]     Test net output #0: accuracy = 0.951
I0108 23:25:23.904093  2979 solver.cpp:523]     Test net output #1: loss = 0.291424 (* 1 = 0.291424 loss)
I0108 23:25:23.904098  2979 solver.cpp:523]     Test net output #2: top-1 = 0.951
I0108 23:25:23.904101  2979 solver.cpp:392] Optimization Done (3.84325 iter/s).
I0108 23:25:23.904104  2979 caffe_interface.cpp:546] Optimization Done.
(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

I0108 23:25:24.572687  3076 pruning_runner.cpp:206] Analysis info found.
I0108 23:25:26.092195  3076 pruning_runner.cpp:237] Start pruning, please wait...
I0108 23:25:31.820199  3076 pruning_runner.cpp:284] Compression complete 0%
I0108 23:25:37.800817  3076 pruning_runner.cpp:284] Compression complete 0%
I0108 23:25:43.841737  3076 pruning_runner.cpp:284] Compression complete 0%
I0108 23:25:50.118355  3076 pruning_runner.cpp:284] Compression complete 0%
I0108 23:25:56.123037  3076 pruning_runner.cpp:284] Compression complete 0%
I0108 23:26:02.344213  3076 pruning_runner.cpp:284] Compression complete 0%
I0108 23:26:08.653674  3076 pruning_runner.cpp:284] Compression complete 0%
I0108 23:26:15.211563  3076 pruning_runner.cpp:284] Compression complete 0%
I0108 23:26:21.754808  3076 pruning_runner.cpp:284] Compression complete 0%
I0108 23:26:28.079207  3076 pruning_runner.cpp:284] Compression complete 0%
I0108 23:26:34.445319  3076 pruning_runner.cpp:284] Compression complete 0%
I0108 23:26:43.188627  3076 pruning_runner.cpp:337] pruning done, output model: pruning/alexnetBNnoLRN/regular_rate_0.4/sparse.caffemodel
I0108 23:26:43.188653  3076 pruning_runner.cpp:351] summary of REGULAR compression with rate 0.4:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.943749785    | 0.950999558    | 0.00724977255  |
+-------------------------------------------------------------------+
| Weights        | 3.7649951 M    | 1.037413 M     | -72.4458313%   |
+-------------------------------------------------------------------+
| Operations     | 2.1539185 G    | 1.23211837 G   | -42.7964211%   |
+-------------------------------------------------------------------+
To fine-tune the pruned model, please run:
vai_p_caffe finetune -config /workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/config4.prototxt
(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

W0108 23:26:43.354815  4221 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0108 23:26:43.355187  4221 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0108 23:26:43.355230  4221 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0108 23:26:43.359992  4221 vai_p_caffe.cpp:287] pruning/alexnetBNnoLRN/regular_rate_0.4/net_finetune.prototxt
I0108 23:26:43.531376  4221 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0108 23:26:43.531397  4221 gpu_memory.cpp:55] Total memory: 25620447232, Free: 25022103552, dev_info[0]: total=25620447232 free=25022103552
I0108 23:26:43.532176  4221 caffe_interface.cpp:509] Using GPUs 0
I0108 23:26:43.532493  4221 caffe_interface.cpp:514] GPU 0: Quadro P6000
I0108 23:26:44.391635  4221 solver.cpp:51] Initializing solver from parameters:
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 6000
snapshot_prefix: "pruning/alexnetBNnoLRN/regular_rate_0.4/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "pruning/alexnetBNnoLRN/regular_rate_0.4/net_finetune.prototxt"
type: "Adam"
I0108 23:26:44.391795  4221 solver.cpp:99] Creating training net from net file: pruning/alexnetBNnoLRN/regular_rate_0.4/net_finetune.prototxt
I0108 23:26:44.392082  4221 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0108 23:26:44.392096  4221 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0108 23:26:44.392099  4221 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0108 23:26:44.392105  4221 net.cpp:52] Initializing net from parameters:
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0108 23:26:44.392328  4221 layer_factory.hpp:77] Creating layer data
I0108 23:26:44.392455  4221 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 23:26:44.394109  4221 net.cpp:94] Creating Layer data
I0108 23:26:44.394119  4221 net.cpp:409] data -> data
I0108 23:26:44.394129  4221 net.cpp:409] data -> label
I0108 23:26:44.395411  4258 db_lmdb.cpp:35] Opened lmdb input/lmdb/train_lmdb
I0108 23:26:44.395434  4258 db_lmdb.cpp:38] Items count: 20000
I0108 23:26:44.395455  4258 data_reader.cpp:124] TRAIN: reading data using 1 channel(s)
I0108 23:26:44.395704  4221 data_layer.cpp:78] ReshapePrefetch 256, 3, 227, 227
I0108 23:26:44.395792  4221 data_layer.cpp:83] output data size: 256,3,227,227
I0108 23:26:44.866950  4221 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 23:26:44.867033  4221 net.cpp:144] Setting up data
I0108 23:26:44.867038  4221 net.cpp:151] Top shape: 256 3 227 227 (39574272)
I0108 23:26:44.867045  4221 net.cpp:151] Top shape: 256 (256)
I0108 23:26:44.867049  4221 net.cpp:159] Memory required for data: 158298112
I0108 23:26:44.867053  4221 layer_factory.hpp:77] Creating layer conv1
I0108 23:26:44.867064  4221 net.cpp:94] Creating Layer conv1
I0108 23:26:44.867069  4221 net.cpp:435] conv1 <- data
I0108 23:26:44.867074  4221 net.cpp:409] conv1 -> conv1
I0108 23:26:44.867636  4221 net.cpp:144] Setting up conv1
I0108 23:26:44.867643  4221 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0108 23:26:44.867648  4221 net.cpp:159] Memory required for data: 455667712
I0108 23:26:44.867660  4221 layer_factory.hpp:77] Creating layer bn1
I0108 23:26:44.867667  4221 net.cpp:94] Creating Layer bn1
I0108 23:26:44.867671  4221 net.cpp:435] bn1 <- conv1
I0108 23:26:44.867676  4221 net.cpp:409] bn1 -> bn1
I0108 23:26:44.868182  4221 net.cpp:144] Setting up bn1
I0108 23:26:44.868188  4221 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0108 23:26:44.868193  4221 net.cpp:159] Memory required for data: 753037312
I0108 23:26:44.868203  4221 layer_factory.hpp:77] Creating layer relu1
I0108 23:26:44.868208  4221 net.cpp:94] Creating Layer relu1
I0108 23:26:44.868212  4221 net.cpp:435] relu1 <- bn1
I0108 23:26:44.868216  4221 net.cpp:409] relu1 -> relu1
I0108 23:26:44.868232  4221 net.cpp:144] Setting up relu1
I0108 23:26:44.868237  4221 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0108 23:26:44.868242  4221 net.cpp:159] Memory required for data: 1050406912
I0108 23:26:44.868245  4221 layer_factory.hpp:77] Creating layer pool1
I0108 23:26:44.868252  4221 net.cpp:94] Creating Layer pool1
I0108 23:26:44.868255  4221 net.cpp:435] pool1 <- relu1
I0108 23:26:44.868260  4221 net.cpp:409] pool1 -> pool1
I0108 23:26:44.868283  4221 net.cpp:144] Setting up pool1
I0108 23:26:44.868288  4221 net.cpp:151] Top shape: 256 96 27 27 (17915904)
I0108 23:26:44.868292  4221 net.cpp:159] Memory required for data: 1122070528
I0108 23:26:44.868296  4221 layer_factory.hpp:77] Creating layer conv2
I0108 23:26:44.868304  4221 net.cpp:94] Creating Layer conv2
I0108 23:26:44.868307  4221 net.cpp:435] conv2 <- pool1
I0108 23:26:44.868312  4221 net.cpp:409] conv2 -> conv2
I0108 23:26:44.883502  4221 net.cpp:144] Setting up conv2
I0108 23:26:44.883515  4221 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0108 23:26:44.883523  4221 net.cpp:159] Memory required for data: 1313173504
I0108 23:26:44.883533  4221 layer_factory.hpp:77] Creating layer bn2
I0108 23:26:44.883539  4221 net.cpp:94] Creating Layer bn2
I0108 23:26:44.883543  4221 net.cpp:435] bn2 <- conv2
I0108 23:26:44.883548  4221 net.cpp:409] bn2 -> bn2
I0108 23:26:44.883994  4221 net.cpp:144] Setting up bn2
I0108 23:26:44.884001  4221 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0108 23:26:44.884006  4221 net.cpp:159] Memory required for data: 1504276480
I0108 23:26:44.884013  4221 layer_factory.hpp:77] Creating layer relu2
I0108 23:26:44.884018  4221 net.cpp:94] Creating Layer relu2
I0108 23:26:44.884021  4221 net.cpp:435] relu2 <- bn2
I0108 23:26:44.884027  4221 net.cpp:409] relu2 -> relu2
I0108 23:26:44.884043  4221 net.cpp:144] Setting up relu2
I0108 23:26:44.884049  4221 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0108 23:26:44.884054  4221 net.cpp:159] Memory required for data: 1695379456
I0108 23:26:44.884059  4221 layer_factory.hpp:77] Creating layer pool2
I0108 23:26:44.884064  4221 net.cpp:94] Creating Layer pool2
I0108 23:26:44.884068  4221 net.cpp:435] pool2 <- relu2
I0108 23:26:44.884073  4221 net.cpp:409] pool2 -> pool2
I0108 23:26:44.884095  4221 net.cpp:144] Setting up pool2
I0108 23:26:44.884104  4221 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0108 23:26:44.884109  4221 net.cpp:159] Memory required for data: 1739681792
I0108 23:26:44.884112  4221 layer_factory.hpp:77] Creating layer conv3
I0108 23:26:44.884131  4221 net.cpp:94] Creating Layer conv3
I0108 23:26:44.884135  4221 net.cpp:435] conv3 <- pool2
I0108 23:26:44.884140  4221 net.cpp:409] conv3 -> conv3
I0108 23:26:44.897075  4221 net.cpp:144] Setting up conv3
I0108 23:26:44.897099  4221 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 23:26:44.897114  4221 net.cpp:159] Memory required for data: 1806135296
I0108 23:26:44.897125  4221 layer_factory.hpp:77] Creating layer relu3
I0108 23:26:44.897135  4221 net.cpp:94] Creating Layer relu3
I0108 23:26:44.897141  4221 net.cpp:435] relu3 <- conv3
I0108 23:26:44.897173  4221 net.cpp:409] relu3 -> relu3
I0108 23:26:44.897233  4221 net.cpp:144] Setting up relu3
I0108 23:26:44.897255  4221 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 23:26:44.897281  4221 net.cpp:159] Memory required for data: 1872588800
I0108 23:26:44.897303  4221 layer_factory.hpp:77] Creating layer conv4
I0108 23:26:44.897333  4221 net.cpp:94] Creating Layer conv4
I0108 23:26:44.897356  4221 net.cpp:435] conv4 <- relu3
I0108 23:26:44.897382  4221 net.cpp:409] conv4 -> conv4
I0108 23:26:44.915027  4221 net.cpp:144] Setting up conv4
I0108 23:26:44.915046  4221 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 23:26:44.915055  4221 net.cpp:159] Memory required for data: 1939042304
I0108 23:26:44.915067  4221 layer_factory.hpp:77] Creating layer relu4
I0108 23:26:44.915077  4221 net.cpp:94] Creating Layer relu4
I0108 23:26:44.915083  4221 net.cpp:435] relu4 <- conv4
I0108 23:26:44.915091  4221 net.cpp:409] relu4 -> relu4
I0108 23:26:44.915144  4221 net.cpp:144] Setting up relu4
I0108 23:26:44.915151  4221 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0108 23:26:44.915156  4221 net.cpp:159] Memory required for data: 2005495808
I0108 23:26:44.915159  4221 layer_factory.hpp:77] Creating layer conv5
I0108 23:26:44.915170  4221 net.cpp:94] Creating Layer conv5
I0108 23:26:44.915182  4221 net.cpp:435] conv5 <- relu4
I0108 23:26:44.915189  4221 net.cpp:409] conv5 -> conv5
I0108 23:26:44.929725  4221 net.cpp:144] Setting up conv5
I0108 23:26:44.929745  4221 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0108 23:26:44.929759  4221 net.cpp:159] Memory required for data: 2049798144
I0108 23:26:44.929772  4221 layer_factory.hpp:77] Creating layer relu5
I0108 23:26:44.929805  4221 net.cpp:94] Creating Layer relu5
I0108 23:26:44.929832  4221 net.cpp:435] relu5 <- conv5
I0108 23:26:44.929859  4221 net.cpp:409] relu5 -> relu5
I0108 23:26:44.929920  4221 net.cpp:144] Setting up relu5
I0108 23:26:44.929949  4221 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0108 23:26:44.929980  4221 net.cpp:159] Memory required for data: 2094100480
I0108 23:26:44.930004  4221 layer_factory.hpp:77] Creating layer pool5
I0108 23:26:44.930035  4221 net.cpp:94] Creating Layer pool5
I0108 23:26:44.930065  4221 net.cpp:435] pool5 <- relu5
I0108 23:26:44.930091  4221 net.cpp:409] pool5 -> pool5
I0108 23:26:44.930158  4221 net.cpp:144] Setting up pool5
I0108 23:26:44.930181  4221 net.cpp:151] Top shape: 256 256 6 6 (2359296)
I0108 23:26:44.930205  4221 net.cpp:159] Memory required for data: 2103537664
I0108 23:26:44.930228  4221 layer_factory.hpp:77] Creating layer fc6
I0108 23:26:44.930272  4221 net.cpp:94] Creating Layer fc6
I0108 23:26:44.930299  4221 net.cpp:435] fc6 <- pool5
I0108 23:26:44.930333  4221 net.cpp:409] fc6 -> fc6
I0108 23:26:45.322350  4221 net.cpp:144] Setting up fc6
I0108 23:26:45.322374  4221 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 23:26:45.322382  4221 net.cpp:159] Memory required for data: 2107731968
I0108 23:26:45.322392  4221 layer_factory.hpp:77] Creating layer relu6
I0108 23:26:45.322398  4221 net.cpp:94] Creating Layer relu6
I0108 23:26:45.322402  4221 net.cpp:435] relu6 <- fc6
I0108 23:26:45.322407  4221 net.cpp:409] relu6 -> relu6
I0108 23:26:45.322423  4221 net.cpp:144] Setting up relu6
I0108 23:26:45.322427  4221 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 23:26:45.322430  4221 net.cpp:159] Memory required for data: 2111926272
I0108 23:26:45.322433  4221 layer_factory.hpp:77] Creating layer drop6
I0108 23:26:45.322450  4221 net.cpp:94] Creating Layer drop6
I0108 23:26:45.322496  4221 net.cpp:435] drop6 <- relu6
I0108 23:26:45.322504  4221 net.cpp:409] drop6 -> drop6
I0108 23:26:45.322533  4221 net.cpp:144] Setting up drop6
I0108 23:26:45.322538  4221 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 23:26:45.322543  4221 net.cpp:159] Memory required for data: 2116120576
I0108 23:26:45.322546  4221 layer_factory.hpp:77] Creating layer fc7
I0108 23:26:45.322553  4221 net.cpp:94] Creating Layer fc7
I0108 23:26:45.322557  4221 net.cpp:435] fc7 <- drop6
I0108 23:26:45.322564  4221 net.cpp:409] fc7 -> fc7
I0108 23:26:45.471649  4221 net.cpp:144] Setting up fc7
I0108 23:26:45.471673  4221 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 23:26:45.471680  4221 net.cpp:159] Memory required for data: 2120314880
I0108 23:26:45.471690  4221 layer_factory.hpp:77] Creating layer bn7
I0108 23:26:45.471698  4221 net.cpp:94] Creating Layer bn7
I0108 23:26:45.471702  4221 net.cpp:435] bn7 <- fc7
I0108 23:26:45.471707  4221 net.cpp:409] bn7 -> bn7
I0108 23:26:45.472184  4221 net.cpp:144] Setting up bn7
I0108 23:26:45.472193  4221 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 23:26:45.472198  4221 net.cpp:159] Memory required for data: 2124509184
I0108 23:26:45.472205  4221 layer_factory.hpp:77] Creating layer relu7
I0108 23:26:45.472210  4221 net.cpp:94] Creating Layer relu7
I0108 23:26:45.472218  4221 net.cpp:435] relu7 <- bn7
I0108 23:26:45.472225  4221 net.cpp:409] relu7 -> relu7
I0108 23:26:45.472250  4221 net.cpp:144] Setting up relu7
I0108 23:26:45.472255  4221 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 23:26:45.472259  4221 net.cpp:159] Memory required for data: 2128703488
I0108 23:26:45.472262  4221 layer_factory.hpp:77] Creating layer drop7
I0108 23:26:45.472267  4221 net.cpp:94] Creating Layer drop7
I0108 23:26:45.472270  4221 net.cpp:435] drop7 <- relu7
I0108 23:26:45.472275  4221 net.cpp:409] drop7 -> drop7
I0108 23:26:45.472308  4221 net.cpp:144] Setting up drop7
I0108 23:26:45.472316  4221 net.cpp:151] Top shape: 256 4096 (1048576)
I0108 23:26:45.472321  4221 net.cpp:159] Memory required for data: 2132897792
I0108 23:26:45.472326  4221 layer_factory.hpp:77] Creating layer fc8
I0108 23:26:45.472332  4221 net.cpp:94] Creating Layer fc8
I0108 23:26:45.472342  4221 net.cpp:435] fc8 <- drop7
I0108 23:26:45.472352  4221 net.cpp:409] fc8 -> fc8
I0108 23:26:45.472538  4221 net.cpp:144] Setting up fc8
I0108 23:26:45.472545  4221 net.cpp:151] Top shape: 256 2 (512)
I0108 23:26:45.472553  4221 net.cpp:159] Memory required for data: 2132899840
I0108 23:26:45.472560  4221 layer_factory.hpp:77] Creating layer loss
I0108 23:26:45.472568  4221 net.cpp:94] Creating Layer loss
I0108 23:26:45.472571  4221 net.cpp:435] loss <- fc8
I0108 23:26:45.472575  4221 net.cpp:435] loss <- label
I0108 23:26:45.472582  4221 net.cpp:409] loss -> loss
I0108 23:26:45.472589  4221 layer_factory.hpp:77] Creating layer loss
I0108 23:26:45.472648  4221 net.cpp:144] Setting up loss
I0108 23:26:45.472653  4221 net.cpp:151] Top shape: (1)
I0108 23:26:45.472657  4221 net.cpp:154]     with loss weight 1
I0108 23:26:45.472671  4221 net.cpp:159] Memory required for data: 2132899844
I0108 23:26:45.472676  4221 net.cpp:220] loss needs backward computation.
I0108 23:26:45.472681  4221 net.cpp:220] fc8 needs backward computation.
I0108 23:26:45.472683  4221 net.cpp:220] drop7 needs backward computation.
I0108 23:26:45.472687  4221 net.cpp:220] relu7 needs backward computation.
I0108 23:26:45.472690  4221 net.cpp:220] bn7 needs backward computation.
I0108 23:26:45.472694  4221 net.cpp:220] fc7 needs backward computation.
I0108 23:26:45.472699  4221 net.cpp:220] drop6 needs backward computation.
I0108 23:26:45.472704  4221 net.cpp:220] relu6 needs backward computation.
I0108 23:26:45.472708  4221 net.cpp:220] fc6 needs backward computation.
I0108 23:26:45.472712  4221 net.cpp:220] pool5 needs backward computation.
I0108 23:26:45.472718  4221 net.cpp:220] relu5 needs backward computation.
I0108 23:26:45.472720  4221 net.cpp:220] conv5 needs backward computation.
I0108 23:26:45.472724  4221 net.cpp:220] relu4 needs backward computation.
I0108 23:26:45.472740  4221 net.cpp:220] conv4 needs backward computation.
I0108 23:26:45.472745  4221 net.cpp:220] relu3 needs backward computation.
I0108 23:26:45.472751  4221 net.cpp:220] conv3 needs backward computation.
I0108 23:26:45.472756  4221 net.cpp:220] pool2 needs backward computation.
I0108 23:26:45.472761  4221 net.cpp:220] relu2 needs backward computation.
I0108 23:26:45.472769  4221 net.cpp:220] bn2 needs backward computation.
I0108 23:26:45.472772  4221 net.cpp:220] conv2 needs backward computation.
I0108 23:26:45.472779  4221 net.cpp:220] pool1 needs backward computation.
I0108 23:26:45.472784  4221 net.cpp:220] relu1 needs backward computation.
I0108 23:26:45.472805  4221 net.cpp:220] bn1 needs backward computation.
I0108 23:26:45.472811  4221 net.cpp:220] conv1 needs backward computation.
I0108 23:26:45.472817  4221 net.cpp:222] data does not need backward computation.
I0108 23:26:45.472823  4221 net.cpp:264] This network produces output loss
I0108 23:26:45.472851  4221 net.cpp:284] Network initialization done.
I0108 23:26:45.473223  4221 solver.cpp:189] Creating test net (#0) specified by net file: pruning/alexnetBNnoLRN/regular_rate_0.4/net_finetune.prototxt
I0108 23:26:45.473258  4221 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0108 23:26:45.473273  4221 net.cpp:52] Initializing net from parameters:
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0108 23:26:45.473551  4221 layer_factory.hpp:77] Creating layer data
I0108 23:26:45.473601  4221 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 23:26:45.475286  4221 net.cpp:94] Creating Layer data
I0108 23:26:45.475301  4221 net.cpp:409] data -> data
I0108 23:26:45.475311  4221 net.cpp:409] data -> label
I0108 23:26:45.476996  4288 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0108 23:26:45.477018  4288 db_lmdb.cpp:38] Items count: 4000
I0108 23:26:45.477039  4288 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0108 23:26:45.477356  4221 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0108 23:26:45.477468  4221 data_layer.cpp:83] output data size: 50,3,227,227
I0108 23:26:45.574385  4221 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0108 23:26:45.574487  4221 net.cpp:144] Setting up data
I0108 23:26:45.574492  4221 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0108 23:26:45.574501  4221 net.cpp:151] Top shape: 50 (50)
I0108 23:26:45.574504  4221 net.cpp:159] Memory required for data: 30917600
I0108 23:26:45.574509  4221 layer_factory.hpp:77] Creating layer label_data_1_split
I0108 23:26:45.574517  4221 net.cpp:94] Creating Layer label_data_1_split
I0108 23:26:45.574532  4221 net.cpp:435] label_data_1_split <- label
I0108 23:26:45.574537  4221 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0108 23:26:45.574544  4221 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0108 23:26:45.574549  4221 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0108 23:26:45.574615  4221 net.cpp:144] Setting up label_data_1_split
I0108 23:26:45.574618  4221 net.cpp:151] Top shape: 50 (50)
I0108 23:26:45.574622  4221 net.cpp:151] Top shape: 50 (50)
I0108 23:26:45.574626  4221 net.cpp:151] Top shape: 50 (50)
I0108 23:26:45.574630  4221 net.cpp:159] Memory required for data: 30918200
I0108 23:26:45.574633  4221 layer_factory.hpp:77] Creating layer conv1
I0108 23:26:45.574645  4221 net.cpp:94] Creating Layer conv1
I0108 23:26:45.574649  4221 net.cpp:435] conv1 <- data
I0108 23:26:45.574656  4221 net.cpp:409] conv1 -> conv1
I0108 23:26:45.575305  4221 net.cpp:144] Setting up conv1
I0108 23:26:45.575314  4221 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0108 23:26:45.575320  4221 net.cpp:159] Memory required for data: 88998200
I0108 23:26:45.575331  4221 layer_factory.hpp:77] Creating layer bn1
I0108 23:26:45.575340  4221 net.cpp:94] Creating Layer bn1
I0108 23:26:45.575343  4221 net.cpp:435] bn1 <- conv1
I0108 23:26:45.575348  4221 net.cpp:409] bn1 -> bn1
I0108 23:26:45.575912  4221 net.cpp:144] Setting up bn1
I0108 23:26:45.575920  4221 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0108 23:26:45.575925  4221 net.cpp:159] Memory required for data: 147078200
I0108 23:26:45.575937  4221 layer_factory.hpp:77] Creating layer relu1
I0108 23:26:45.575945  4221 net.cpp:94] Creating Layer relu1
I0108 23:26:45.575949  4221 net.cpp:435] relu1 <- bn1
I0108 23:26:45.575954  4221 net.cpp:409] relu1 -> relu1
I0108 23:26:45.575970  4221 net.cpp:144] Setting up relu1
I0108 23:26:45.575975  4221 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0108 23:26:45.575980  4221 net.cpp:159] Memory required for data: 205158200
I0108 23:26:45.575984  4221 layer_factory.hpp:77] Creating layer pool1
I0108 23:26:45.575990  4221 net.cpp:94] Creating Layer pool1
I0108 23:26:45.575996  4221 net.cpp:435] pool1 <- relu1
I0108 23:26:45.576001  4221 net.cpp:409] pool1 -> pool1
I0108 23:26:45.576028  4221 net.cpp:144] Setting up pool1
I0108 23:26:45.576035  4221 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0108 23:26:45.576042  4221 net.cpp:159] Memory required for data: 219155000
I0108 23:26:45.576047  4221 layer_factory.hpp:77] Creating layer conv2
I0108 23:26:45.576058  4221 net.cpp:94] Creating Layer conv2
I0108 23:26:45.576066  4221 net.cpp:435] conv2 <- pool1
I0108 23:26:45.576074  4221 net.cpp:409] conv2 -> conv2
I0108 23:26:45.582962  4221 net.cpp:144] Setting up conv2
I0108 23:26:45.582978  4221 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0108 23:26:45.582984  4221 net.cpp:159] Memory required for data: 256479800
I0108 23:26:45.582995  4221 layer_factory.hpp:77] Creating layer bn2
I0108 23:26:45.583003  4221 net.cpp:94] Creating Layer bn2
I0108 23:26:45.583009  4221 net.cpp:435] bn2 <- conv2
I0108 23:26:45.583014  4221 net.cpp:409] bn2 -> bn2
I0108 23:26:45.584503  4221 net.cpp:144] Setting up bn2
I0108 23:26:45.584528  4221 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0108 23:26:45.584542  4221 net.cpp:159] Memory required for data: 293804600
I0108 23:26:45.584561  4221 layer_factory.hpp:77] Creating layer relu2
I0108 23:26:45.584578  4221 net.cpp:94] Creating Layer relu2
I0108 23:26:45.584590  4221 net.cpp:435] relu2 <- bn2
I0108 23:26:45.584602  4221 net.cpp:409] relu2 -> relu2
I0108 23:26:45.584640  4221 net.cpp:144] Setting up relu2
I0108 23:26:45.584671  4221 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0108 23:26:45.584686  4221 net.cpp:159] Memory required for data: 331129400
I0108 23:26:45.584693  4221 layer_factory.hpp:77] Creating layer pool2
I0108 23:26:45.584704  4221 net.cpp:94] Creating Layer pool2
I0108 23:26:45.584717  4221 net.cpp:435] pool2 <- relu2
I0108 23:26:45.584726  4221 net.cpp:409] pool2 -> pool2
I0108 23:26:45.584784  4221 net.cpp:144] Setting up pool2
I0108 23:26:45.584794  4221 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0108 23:26:45.584803  4221 net.cpp:159] Memory required for data: 339782200
I0108 23:26:45.584811  4221 layer_factory.hpp:77] Creating layer conv3
I0108 23:26:45.584833  4221 net.cpp:94] Creating Layer conv3
I0108 23:26:45.584844  4221 net.cpp:435] conv3 <- pool2
I0108 23:26:45.584854  4221 net.cpp:409] conv3 -> conv3
I0108 23:26:45.605223  4221 net.cpp:144] Setting up conv3
I0108 23:26:45.605247  4221 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 23:26:45.605258  4221 net.cpp:159] Memory required for data: 352761400
I0108 23:26:45.605271  4221 layer_factory.hpp:77] Creating layer relu3
I0108 23:26:45.605281  4221 net.cpp:94] Creating Layer relu3
I0108 23:26:45.605288  4221 net.cpp:435] relu3 <- conv3
I0108 23:26:45.605295  4221 net.cpp:409] relu3 -> relu3
I0108 23:26:45.605330  4221 net.cpp:144] Setting up relu3
I0108 23:26:45.605338  4221 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 23:26:45.605345  4221 net.cpp:159] Memory required for data: 365740600
I0108 23:26:45.605350  4221 layer_factory.hpp:77] Creating layer conv4
I0108 23:26:45.605360  4221 net.cpp:94] Creating Layer conv4
I0108 23:26:45.605370  4221 net.cpp:435] conv4 <- relu3
I0108 23:26:45.605378  4221 net.cpp:409] conv4 -> conv4
I0108 23:26:45.623098  4221 net.cpp:144] Setting up conv4
I0108 23:26:45.623119  4221 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 23:26:45.623129  4221 net.cpp:159] Memory required for data: 378719800
I0108 23:26:45.623142  4221 layer_factory.hpp:77] Creating layer relu4
I0108 23:26:45.623148  4221 net.cpp:94] Creating Layer relu4
I0108 23:26:45.623153  4221 net.cpp:435] relu4 <- conv4
I0108 23:26:45.623160  4221 net.cpp:409] relu4 -> relu4
I0108 23:26:45.623183  4221 net.cpp:144] Setting up relu4
I0108 23:26:45.623188  4221 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0108 23:26:45.623193  4221 net.cpp:159] Memory required for data: 391699000
I0108 23:26:45.623196  4221 layer_factory.hpp:77] Creating layer conv5
I0108 23:26:45.623210  4221 net.cpp:94] Creating Layer conv5
I0108 23:26:45.623214  4221 net.cpp:435] conv5 <- relu4
I0108 23:26:45.623219  4221 net.cpp:409] conv5 -> conv5
I0108 23:26:45.636361  4221 net.cpp:144] Setting up conv5
I0108 23:26:45.636389  4221 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0108 23:26:45.636400  4221 net.cpp:159] Memory required for data: 400351800
I0108 23:26:45.636413  4221 layer_factory.hpp:77] Creating layer relu5
I0108 23:26:45.636426  4221 net.cpp:94] Creating Layer relu5
I0108 23:26:45.636432  4221 net.cpp:435] relu5 <- conv5
I0108 23:26:45.636442  4221 net.cpp:409] relu5 -> relu5
I0108 23:26:45.636476  4221 net.cpp:144] Setting up relu5
I0108 23:26:45.636510  4221 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0108 23:26:45.636535  4221 net.cpp:159] Memory required for data: 409004600
I0108 23:26:45.636557  4221 layer_factory.hpp:77] Creating layer pool5
I0108 23:26:45.636593  4221 net.cpp:94] Creating Layer pool5
I0108 23:26:45.636615  4221 net.cpp:435] pool5 <- relu5
I0108 23:26:45.636646  4221 net.cpp:409] pool5 -> pool5
I0108 23:26:45.636714  4221 net.cpp:144] Setting up pool5
I0108 23:26:45.636739  4221 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0108 23:26:45.636771  4221 net.cpp:159] Memory required for data: 410847800
I0108 23:26:45.636792  4221 layer_factory.hpp:77] Creating layer fc6
I0108 23:26:45.636826  4221 net.cpp:94] Creating Layer fc6
I0108 23:26:45.636855  4221 net.cpp:435] fc6 <- pool5
I0108 23:26:45.636884  4221 net.cpp:409] fc6 -> fc6
I0108 23:26:45.971683  4221 net.cpp:144] Setting up fc6
I0108 23:26:45.971707  4221 net.cpp:151] Top shape: 50 4096 (204800)
I0108 23:26:45.971750  4221 net.cpp:159] Memory required for data: 411667000
I0108 23:26:45.971760  4221 layer_factory.hpp:77] Creating layer relu6
I0108 23:26:45.971766  4221 net.cpp:94] Creating Layer relu6
I0108 23:26:45.971771  4221 net.cpp:435] relu6 <- fc6
I0108 23:26:45.971776  4221 net.cpp:409] relu6 -> relu6
I0108 23:26:45.971802  4221 net.cpp:144] Setting up relu6
I0108 23:26:45.971805  4221 net.cpp:151] Top shape: 50 4096 (204800)
I0108 23:26:45.971809  4221 net.cpp:159] Memory required for data: 412486200
I0108 23:26:45.971812  4221 layer_factory.hpp:77] Creating layer drop6
I0108 23:26:45.971817  4221 net.cpp:94] Creating Layer drop6
I0108 23:26:45.971820  4221 net.cpp:435] drop6 <- relu6
I0108 23:26:45.971824  4221 net.cpp:409] drop6 -> drop6
I0108 23:26:45.971845  4221 net.cpp:144] Setting up drop6
I0108 23:26:45.971850  4221 net.cpp:151] Top shape: 50 4096 (204800)
I0108 23:26:45.971854  4221 net.cpp:159] Memory required for data: 413305400
I0108 23:26:45.971858  4221 layer_factory.hpp:77] Creating layer fc7
I0108 23:26:45.971863  4221 net.cpp:94] Creating Layer fc7
I0108 23:26:45.971866  4221 net.cpp:435] fc7 <- drop6
I0108 23:26:45.971871  4221 net.cpp:409] fc7 -> fc7
I0108 23:26:46.116299  4221 net.cpp:144] Setting up fc7
I0108 23:26:46.116323  4221 net.cpp:151] Top shape: 50 4096 (204800)
I0108 23:26:46.116331  4221 net.cpp:159] Memory required for data: 414124600
I0108 23:26:46.116341  4221 layer_factory.hpp:77] Creating layer bn7
I0108 23:26:46.116350  4221 net.cpp:94] Creating Layer bn7
I0108 23:26:46.116354  4221 net.cpp:435] bn7 <- fc7
I0108 23:26:46.116360  4221 net.cpp:409] bn7 -> bn7
I0108 23:26:46.116848  4221 net.cpp:144] Setting up bn7
I0108 23:26:46.116854  4221 net.cpp:151] Top shape: 50 4096 (204800)
I0108 23:26:46.116859  4221 net.cpp:159] Memory required for data: 414943800
I0108 23:26:46.116866  4221 layer_factory.hpp:77] Creating layer relu7
I0108 23:26:46.116871  4221 net.cpp:94] Creating Layer relu7
I0108 23:26:46.116875  4221 net.cpp:435] relu7 <- bn7
I0108 23:26:46.116880  4221 net.cpp:409] relu7 -> relu7
I0108 23:26:46.116897  4221 net.cpp:144] Setting up relu7
I0108 23:26:46.116904  4221 net.cpp:151] Top shape: 50 4096 (204800)
I0108 23:26:46.116909  4221 net.cpp:159] Memory required for data: 415763000
I0108 23:26:46.116912  4221 layer_factory.hpp:77] Creating layer drop7
I0108 23:26:46.116917  4221 net.cpp:94] Creating Layer drop7
I0108 23:26:46.116920  4221 net.cpp:435] drop7 <- relu7
I0108 23:26:46.116925  4221 net.cpp:409] drop7 -> drop7
I0108 23:26:46.116948  4221 net.cpp:144] Setting up drop7
I0108 23:26:46.116953  4221 net.cpp:151] Top shape: 50 4096 (204800)
I0108 23:26:46.116957  4221 net.cpp:159] Memory required for data: 416582200
I0108 23:26:46.116961  4221 layer_factory.hpp:77] Creating layer fc8
I0108 23:26:46.116967  4221 net.cpp:94] Creating Layer fc8
I0108 23:26:46.116971  4221 net.cpp:435] fc8 <- drop7
I0108 23:26:46.116977  4221 net.cpp:409] fc8 -> fc8
I0108 23:26:46.117131  4221 net.cpp:144] Setting up fc8
I0108 23:26:46.117136  4221 net.cpp:151] Top shape: 50 2 (100)
I0108 23:26:46.117141  4221 net.cpp:159] Memory required for data: 416582600
I0108 23:26:46.117146  4221 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0108 23:26:46.117151  4221 net.cpp:94] Creating Layer fc8_fc8_0_split
I0108 23:26:46.117154  4221 net.cpp:435] fc8_fc8_0_split <- fc8
I0108 23:26:46.117158  4221 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0108 23:26:46.117164  4221 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0108 23:26:46.117172  4221 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0108 23:26:46.117202  4221 net.cpp:144] Setting up fc8_fc8_0_split
I0108 23:26:46.117208  4221 net.cpp:151] Top shape: 50 2 (100)
I0108 23:26:46.117211  4221 net.cpp:151] Top shape: 50 2 (100)
I0108 23:26:46.117215  4221 net.cpp:151] Top shape: 50 2 (100)
I0108 23:26:46.117219  4221 net.cpp:159] Memory required for data: 416583800
I0108 23:26:46.117223  4221 layer_factory.hpp:77] Creating layer accuracy
I0108 23:26:46.117229  4221 net.cpp:94] Creating Layer accuracy
I0108 23:26:46.117245  4221 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0108 23:26:46.117249  4221 net.cpp:435] accuracy <- label_data_1_split_0
I0108 23:26:46.117254  4221 net.cpp:409] accuracy -> accuracy
I0108 23:26:46.117261  4221 net.cpp:144] Setting up accuracy
I0108 23:26:46.117264  4221 net.cpp:151] Top shape: (1)
I0108 23:26:46.117269  4221 net.cpp:159] Memory required for data: 416583804
I0108 23:26:46.117271  4221 layer_factory.hpp:77] Creating layer loss
I0108 23:26:46.117278  4221 net.cpp:94] Creating Layer loss
I0108 23:26:46.117282  4221 net.cpp:435] loss <- fc8_fc8_0_split_1
I0108 23:26:46.117286  4221 net.cpp:435] loss <- label_data_1_split_1
I0108 23:26:46.117292  4221 net.cpp:409] loss -> loss
I0108 23:26:46.117302  4221 layer_factory.hpp:77] Creating layer loss
I0108 23:26:46.117395  4221 net.cpp:144] Setting up loss
I0108 23:26:46.117401  4221 net.cpp:151] Top shape: (1)
I0108 23:26:46.117405  4221 net.cpp:154]     with loss weight 1
I0108 23:26:46.117417  4221 net.cpp:159] Memory required for data: 416583808
I0108 23:26:46.117421  4221 layer_factory.hpp:77] Creating layer accuracy-top1
I0108 23:26:46.117426  4221 net.cpp:94] Creating Layer accuracy-top1
I0108 23:26:46.117430  4221 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0108 23:26:46.117434  4221 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0108 23:26:46.117439  4221 net.cpp:409] accuracy-top1 -> top-1
I0108 23:26:46.117445  4221 net.cpp:144] Setting up accuracy-top1
I0108 23:26:46.117449  4221 net.cpp:151] Top shape: (1)
I0108 23:26:46.117452  4221 net.cpp:159] Memory required for data: 416583812
I0108 23:26:46.117456  4221 net.cpp:222] accuracy-top1 does not need backward computation.
I0108 23:26:46.117460  4221 net.cpp:220] loss needs backward computation.
I0108 23:26:46.117465  4221 net.cpp:222] accuracy does not need backward computation.
I0108 23:26:46.117470  4221 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0108 23:26:46.117473  4221 net.cpp:220] fc8 needs backward computation.
I0108 23:26:46.117477  4221 net.cpp:220] drop7 needs backward computation.
I0108 23:26:46.117480  4221 net.cpp:220] relu7 needs backward computation.
I0108 23:26:46.117484  4221 net.cpp:220] bn7 needs backward computation.
I0108 23:26:46.117488  4221 net.cpp:220] fc7 needs backward computation.
I0108 23:26:46.117493  4221 net.cpp:220] drop6 needs backward computation.
I0108 23:26:46.117497  4221 net.cpp:220] relu6 needs backward computation.
I0108 23:26:46.117502  4221 net.cpp:220] fc6 needs backward computation.
I0108 23:26:46.117506  4221 net.cpp:220] pool5 needs backward computation.
I0108 23:26:46.117509  4221 net.cpp:220] relu5 needs backward computation.
I0108 23:26:46.117513  4221 net.cpp:220] conv5 needs backward computation.
I0108 23:26:46.117517  4221 net.cpp:220] relu4 needs backward computation.
I0108 23:26:46.117522  4221 net.cpp:220] conv4 needs backward computation.
I0108 23:26:46.117525  4221 net.cpp:220] relu3 needs backward computation.
I0108 23:26:46.117532  4221 net.cpp:220] conv3 needs backward computation.
I0108 23:26:46.117535  4221 net.cpp:220] pool2 needs backward computation.
I0108 23:26:46.117539  4221 net.cpp:220] relu2 needs backward computation.
I0108 23:26:46.117543  4221 net.cpp:220] bn2 needs backward computation.
I0108 23:26:46.117547  4221 net.cpp:220] conv2 needs backward computation.
I0108 23:26:46.117552  4221 net.cpp:220] pool1 needs backward computation.
I0108 23:26:46.117555  4221 net.cpp:220] relu1 needs backward computation.
I0108 23:26:46.117559  4221 net.cpp:220] bn1 needs backward computation.
I0108 23:26:46.117563  4221 net.cpp:220] conv1 needs backward computation.
I0108 23:26:46.117568  4221 net.cpp:222] label_data_1_split does not need backward computation.
I0108 23:26:46.117573  4221 net.cpp:222] data does not need backward computation.
I0108 23:26:46.117575  4221 net.cpp:264] This network produces output accuracy
I0108 23:26:46.117579  4221 net.cpp:264] This network produces output loss
I0108 23:26:46.117583  4221 net.cpp:264] This network produces output top-1
I0108 23:26:46.117615  4221 net.cpp:284] Network initialization done.
I0108 23:26:46.117691  4221 solver.cpp:63] Solver scaffolding done.
I0108 23:26:46.118794  4221 caffe_interface.cpp:109] Finetuning from pruning/alexnetBNnoLRN/regular_rate_0.4/sparse.caffemodel
I0108 23:26:48.470046  4221 caffe_interface.cpp:543] Starting Optimization
I0108 23:26:48.470068  4221 solver.cpp:341] Solving
I0108 23:26:48.470072  4221 solver.cpp:342] Learning Rate Policy: step
I0108 23:26:48.471393  4221 solver.cpp:424] Iteration 0, Testing net (#0)
I0108 23:26:49.984740  4221 solver.cpp:523]     Test net output #0: accuracy = 0.951
I0108 23:26:49.984773  4221 solver.cpp:523]     Test net output #1: loss = 0.291424 (* 1 = 0.291424 loss)
I0108 23:26:49.984779  4221 solver.cpp:523]     Test net output #2: top-1 = 0.951
I0108 23:26:50.245285  4221 solver.cpp:270] Iteration 0 (0 iter/s, 1.7751s/50 iter), loss = 0.00931582, remaining 333333 hours and 20 minutes
I0108 23:26:50.245317  4221 solver.cpp:291]     Train net output #0: loss = 0.00931582 (* 1 = 0.00931582 loss)
I0108 23:26:50.245342  4221 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0108 23:27:02.877317  4221 solver.cpp:270] Iteration 50 (3.95837 iter/s, 12.6315s/50 iter), loss = 0.0782623, remaining 0 hours and 50 minutes
I0108 23:27:02.877351  4221 solver.cpp:291]     Train net output #0: loss = 0.0782623 (* 1 = 0.0782623 loss)
I0108 23:27:02.877357  4221 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0108 23:27:15.587306  4221 solver.cpp:270] Iteration 100 (3.93409 iter/s, 12.7094s/50 iter), loss = 0.050518, remaining 0 hours and 50 minutes
I0108 23:27:15.587355  4221 solver.cpp:291]     Train net output #0: loss = 0.050518 (* 1 = 0.050518 loss)
I0108 23:27:15.587363  4221 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0108 23:27:28.398499  4221 solver.cpp:270] Iteration 150 (3.90302 iter/s, 12.8106s/50 iter), loss = 0.121649, remaining 0 hours and 50 minutes
I0108 23:27:28.398531  4221 solver.cpp:291]     Train net output #0: loss = 0.121649 (* 1 = 0.121649 loss)
I0108 23:27:28.398538  4221 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0108 23:27:41.236913  4221 solver.cpp:270] Iteration 200 (3.89474 iter/s, 12.8378s/50 iter), loss = 0.0846266, remaining 0 hours and 50 minutes
I0108 23:27:41.236945  4221 solver.cpp:291]     Train net output #0: loss = 0.0846266 (* 1 = 0.0846266 loss)
I0108 23:27:41.236953  4221 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0108 23:27:54.127146  4221 solver.cpp:270] Iteration 250 (3.87907 iter/s, 12.8897s/50 iter), loss = 0.10866, remaining 0 hours and 50 minutes
I0108 23:27:54.127192  4221 solver.cpp:291]     Train net output #0: loss = 0.10866 (* 1 = 0.10866 loss)
I0108 23:27:54.127199  4221 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0108 23:28:07.045006  4221 solver.cpp:270] Iteration 300 (3.87076 iter/s, 12.9173s/50 iter), loss = 0.0767079, remaining 0 hours and 50 minutes
I0108 23:28:07.045037  4221 solver.cpp:291]     Train net output #0: loss = 0.0767078 (* 1 = 0.0767078 loss)
I0108 23:28:07.045060  4221 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0108 23:28:20.063114  4221 solver.cpp:270] Iteration 350 (3.84095 iter/s, 13.0176s/50 iter), loss = 0.0666211, remaining 0 hours and 50 minutes
I0108 23:28:20.063148  4221 solver.cpp:291]     Train net output #0: loss = 0.0666211 (* 1 = 0.0666211 loss)
I0108 23:28:20.063154  4221 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0108 23:28:33.053822  4221 solver.cpp:270] Iteration 400 (3.84905 iter/s, 12.9902s/50 iter), loss = 0.0959055, remaining 0 hours and 50 minutes
I0108 23:28:33.053870  4221 solver.cpp:291]     Train net output #0: loss = 0.0959055 (* 1 = 0.0959055 loss)
I0108 23:28:33.053877  4221 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0108 23:28:46.032954  4221 solver.cpp:270] Iteration 450 (3.85249 iter/s, 12.9786s/50 iter), loss = 0.131205, remaining 0 hours and 49 minutes
I0108 23:28:46.032985  4221 solver.cpp:291]     Train net output #0: loss = 0.131205 (* 1 = 0.131205 loss)
I0108 23:28:46.032994  4221 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0108 23:28:59.012212  4221 solver.cpp:270] Iteration 500 (3.85245 iter/s, 12.9787s/50 iter), loss = 0.0554336, remaining 0 hours and 49 minutes
I0108 23:28:59.012243  4221 solver.cpp:291]     Train net output #0: loss = 0.0554336 (* 1 = 0.0554336 loss)
I0108 23:28:59.012249  4221 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0108 23:29:12.018913  4221 solver.cpp:270] Iteration 550 (3.84432 iter/s, 13.0062s/50 iter), loss = 0.0855052, remaining 0 hours and 49 minutes
I0108 23:29:12.018965  4221 solver.cpp:291]     Train net output #0: loss = 0.0855052 (* 1 = 0.0855052 loss)
I0108 23:29:12.018987  4221 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0108 23:29:25.026002  4221 solver.cpp:270] Iteration 600 (3.84422 iter/s, 13.0066s/50 iter), loss = 0.0540958, remaining 0 hours and 49 minutes
I0108 23:29:25.026037  4221 solver.cpp:291]     Train net output #0: loss = 0.0540958 (* 1 = 0.0540958 loss)
I0108 23:29:25.026044  4221 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0108 23:29:38.023417  4221 solver.cpp:270] Iteration 650 (3.84707 iter/s, 12.9969s/50 iter), loss = 0.0501467, remaining 0 hours and 49 minutes
I0108 23:29:38.023450  4221 solver.cpp:291]     Train net output #0: loss = 0.0501467 (* 1 = 0.0501467 loss)
I0108 23:29:38.023458  4221 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0108 23:29:51.028790  4221 solver.cpp:270] Iteration 700 (3.84472 iter/s, 13.0049s/50 iter), loss = 0.102338, remaining 0 hours and 48 minutes
I0108 23:29:51.028836  4221 solver.cpp:291]     Train net output #0: loss = 0.102338 (* 1 = 0.102338 loss)
I0108 23:29:51.028842  4221 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0108 23:30:04.030824  4221 solver.cpp:270] Iteration 750 (3.84571 iter/s, 13.0015s/50 iter), loss = 0.0729203, remaining 0 hours and 48 minutes
I0108 23:30:04.030855  4221 solver.cpp:291]     Train net output #0: loss = 0.0729203 (* 1 = 0.0729203 loss)
I0108 23:30:04.030862  4221 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0108 23:30:17.041311  4221 solver.cpp:270] Iteration 800 (3.84321 iter/s, 13.01s/50 iter), loss = 0.0719953, remaining 0 hours and 48 minutes
I0108 23:30:17.041342  4221 solver.cpp:291]     Train net output #0: loss = 0.0719952 (* 1 = 0.0719952 loss)
I0108 23:30:17.041348  4221 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0108 23:30:30.027108  4221 solver.cpp:270] Iteration 850 (3.85051 iter/s, 12.9853s/50 iter), loss = 0.0733799, remaining 0 hours and 48 minutes
I0108 23:30:30.027151  4221 solver.cpp:291]     Train net output #0: loss = 0.0733799 (* 1 = 0.0733799 loss)
I0108 23:30:30.027176  4221 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0108 23:30:43.018982  4221 solver.cpp:270] Iteration 900 (3.84872 iter/s, 12.9913s/50 iter), loss = 0.091232, remaining 0 hours and 48 minutes
I0108 23:30:43.019016  4221 solver.cpp:291]     Train net output #0: loss = 0.091232 (* 1 = 0.091232 loss)
I0108 23:30:43.019038  4221 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0108 23:30:56.026103  4221 solver.cpp:270] Iteration 950 (3.8442 iter/s, 13.0066s/50 iter), loss = 0.0679522, remaining 0 hours and 47 minutes
I0108 23:30:56.026134  4221 solver.cpp:291]     Train net output #0: loss = 0.0679522 (* 1 = 0.0679522 loss)
I0108 23:30:56.026140  4221 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0108 23:31:08.770078  4221 solver.cpp:424] Iteration 1000, Testing net (#0)
I0108 23:31:10.312927  4221 solver.cpp:523]     Test net output #0: accuracy = 0.90425
I0108 23:31:10.312956  4221 solver.cpp:523]     Test net output #1: loss = 0.34398 (* 1 = 0.34398 loss)
I0108 23:31:10.312961  4221 solver.cpp:523]     Test net output #2: top-1 = 0.90425
I0108 23:31:10.567219  4221 solver.cpp:270] Iteration 1000 (3.43866 iter/s, 14.5405s/50 iter), loss = 0.109702, remaining 0 hours and 53 minutes
I0108 23:31:10.567245  4221 solver.cpp:291]     Train net output #0: loss = 0.109702 (* 1 = 0.109702 loss)
I0108 23:31:10.567252  4221 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0108 23:31:23.556146  4221 solver.cpp:270] Iteration 1050 (3.84958 iter/s, 12.9884s/50 iter), loss = 0.129246, remaining 0 hours and 47 minutes
I0108 23:31:23.556180  4221 solver.cpp:291]     Train net output #0: loss = 0.129246 (* 1 = 0.129246 loss)
I0108 23:31:23.556187  4221 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0108 23:31:36.563994  4221 solver.cpp:270] Iteration 1100 (3.84399 iter/s, 13.0073s/50 iter), loss = 0.0668527, remaining 0 hours and 47 minutes
I0108 23:31:36.564028  4221 solver.cpp:291]     Train net output #0: loss = 0.0668527 (* 1 = 0.0668527 loss)
I0108 23:31:36.564050  4221 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0108 23:31:49.549458  4221 solver.cpp:270] Iteration 1150 (3.85061 iter/s, 12.9849s/50 iter), loss = 0.0967831, remaining 0 hours and 46 minutes
I0108 23:31:49.549512  4221 solver.cpp:291]     Train net output #0: loss = 0.0967831 (* 1 = 0.0967831 loss)
I0108 23:31:49.549520  4221 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0108 23:32:02.537317  4221 solver.cpp:270] Iteration 1200 (3.84991 iter/s, 12.9873s/50 iter), loss = 0.0751368, remaining 0 hours and 46 minutes
I0108 23:32:02.537350  4221 solver.cpp:291]     Train net output #0: loss = 0.0751368 (* 1 = 0.0751368 loss)
I0108 23:32:02.537358  4221 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0108 23:32:15.543627  4221 solver.cpp:270] Iteration 1250 (3.84444 iter/s, 13.0058s/50 iter), loss = 0.100813, remaining 0 hours and 46 minutes
I0108 23:32:15.543659  4221 solver.cpp:291]     Train net output #0: loss = 0.100813 (* 1 = 0.100813 loss)
I0108 23:32:15.543666  4221 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0108 23:32:28.554250  4221 solver.cpp:270] Iteration 1300 (3.84317 iter/s, 13.0101s/50 iter), loss = 0.0741883, remaining 0 hours and 46 minutes
I0108 23:32:28.554296  4221 solver.cpp:291]     Train net output #0: loss = 0.0741883 (* 1 = 0.0741883 loss)
I0108 23:32:28.554303  4221 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0108 23:32:41.539636  4221 solver.cpp:270] Iteration 1350 (3.85064 iter/s, 12.9849s/50 iter), loss = 0.0682863, remaining 0 hours and 45 minutes
I0108 23:32:41.539669  4221 solver.cpp:291]     Train net output #0: loss = 0.0682863 (* 1 = 0.0682863 loss)
I0108 23:32:41.539675  4221 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0108 23:32:54.525321  4221 solver.cpp:270] Iteration 1400 (3.85055 iter/s, 12.9852s/50 iter), loss = 0.0860551, remaining 0 hours and 45 minutes
I0108 23:32:54.525354  4221 solver.cpp:291]     Train net output #0: loss = 0.0860551 (* 1 = 0.0860551 loss)
I0108 23:32:54.525362  4221 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0108 23:33:07.528309  4221 solver.cpp:270] Iteration 1450 (3.84542 iter/s, 13.0025s/50 iter), loss = 0.0915072, remaining 0 hours and 45 minutes
I0108 23:33:07.528354  4221 solver.cpp:291]     Train net output #0: loss = 0.0915071 (* 1 = 0.0915071 loss)
I0108 23:33:07.528360  4221 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0108 23:33:20.562749  4221 solver.cpp:270] Iteration 1500 (3.83615 iter/s, 13.0339s/50 iter), loss = 0.0898547, remaining 0 hours and 45 minutes
I0108 23:33:20.562780  4221 solver.cpp:291]     Train net output #0: loss = 0.0898547 (* 1 = 0.0898547 loss)
I0108 23:33:20.562786  4221 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0108 23:33:33.541285  4221 solver.cpp:270] Iteration 1550 (3.85267 iter/s, 12.978s/50 iter), loss = 0.0646298, remaining 0 hours and 45 minutes
I0108 23:33:33.541318  4221 solver.cpp:291]     Train net output #0: loss = 0.0646298 (* 1 = 0.0646298 loss)
I0108 23:33:33.541342  4221 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0108 23:33:46.531067  4221 solver.cpp:270] Iteration 1600 (3.84933 iter/s, 12.9893s/50 iter), loss = 0.0995521, remaining 0 hours and 44 minutes
I0108 23:33:46.531114  4221 solver.cpp:291]     Train net output #0: loss = 0.0995521 (* 1 = 0.0995521 loss)
I0108 23:33:46.531121  4221 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0108 23:33:59.521382  4221 solver.cpp:270] Iteration 1650 (3.84918 iter/s, 12.9898s/50 iter), loss = 0.119536, remaining 0 hours and 44 minutes
I0108 23:33:59.521414  4221 solver.cpp:291]     Train net output #0: loss = 0.119536 (* 1 = 0.119536 loss)
I0108 23:33:59.521437  4221 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0108 23:34:12.519296  4221 solver.cpp:270] Iteration 1700 (3.84692 iter/s, 12.9974s/50 iter), loss = 0.0689094, remaining 0 hours and 44 minutes
I0108 23:34:12.519330  4221 solver.cpp:291]     Train net output #0: loss = 0.0689094 (* 1 = 0.0689094 loss)
I0108 23:34:12.519335  4221 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0108 23:34:25.495466  4221 solver.cpp:270] Iteration 1750 (3.85337 iter/s, 12.9757s/50 iter), loss = 0.0743801, remaining 0 hours and 44 minutes
I0108 23:34:25.495522  4221 solver.cpp:291]     Train net output #0: loss = 0.0743801 (* 1 = 0.0743801 loss)
I0108 23:34:25.495529  4221 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0108 23:34:38.468214  4221 solver.cpp:270] Iteration 1800 (3.85439 iter/s, 12.9722s/50 iter), loss = 0.0952708, remaining 0 hours and 44 minutes
I0108 23:34:38.468245  4221 solver.cpp:291]     Train net output #0: loss = 0.0952708 (* 1 = 0.0952708 loss)
I0108 23:34:38.468252  4221 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0108 23:34:51.451701  4221 solver.cpp:270] Iteration 1850 (3.8512 iter/s, 12.983s/50 iter), loss = 0.0551879, remaining 0 hours and 43 minutes
I0108 23:34:51.451733  4221 solver.cpp:291]     Train net output #0: loss = 0.0551878 (* 1 = 0.0551878 loss)
I0108 23:34:51.451756  4221 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0108 23:35:04.464279  4221 solver.cpp:270] Iteration 1900 (3.84259 iter/s, 13.0121s/50 iter), loss = 0.0959835, remaining 0 hours and 43 minutes
I0108 23:35:04.464325  4221 solver.cpp:291]     Train net output #0: loss = 0.0959835 (* 1 = 0.0959835 loss)
I0108 23:35:04.464334  4221 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0108 23:35:17.480260  4221 solver.cpp:270] Iteration 1950 (3.84159 iter/s, 13.0154s/50 iter), loss = 0.07459, remaining 0 hours and 43 minutes
I0108 23:35:17.480291  4221 solver.cpp:291]     Train net output #0: loss = 0.07459 (* 1 = 0.07459 loss)
I0108 23:35:17.480298  4221 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0108 23:35:30.196785  4221 solver.cpp:424] Iteration 2000, Testing net (#0)
I0108 23:35:31.724617  4221 solver.cpp:523]     Test net output #0: accuracy = 0.8975
I0108 23:35:31.724645  4221 solver.cpp:523]     Test net output #1: loss = 0.385428 (* 1 = 0.385428 loss)
I0108 23:35:31.724650  4221 solver.cpp:523]     Test net output #2: top-1 = 0.8975
I0108 23:35:31.977010  4221 solver.cpp:270] Iteration 2000 (3.44918 iter/s, 14.4962s/50 iter), loss = 0.10524, remaining 0 hours and 48 minutes
I0108 23:35:31.977036  4221 solver.cpp:291]     Train net output #0: loss = 0.10524 (* 1 = 0.10524 loss)
I0108 23:35:31.977043  4221 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0108 23:35:44.936525  4221 solver.cpp:270] Iteration 2050 (3.85832 iter/s, 12.959s/50 iter), loss = 0.0818779, remaining 0 hours and 42 minutes
I0108 23:35:44.936571  4221 solver.cpp:291]     Train net output #0: loss = 0.0818778 (* 1 = 0.0818778 loss)
I0108 23:35:44.936578  4221 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0108 23:35:57.937469  4221 solver.cpp:270] Iteration 2100 (3.84603 iter/s, 13.0004s/50 iter), loss = 0.064273, remaining 0 hours and 42 minutes
I0108 23:35:57.937502  4221 solver.cpp:291]     Train net output #0: loss = 0.064273 (* 1 = 0.064273 loss)
I0108 23:35:57.937508  4221 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0108 23:36:10.893501  4221 solver.cpp:270] Iteration 2150 (3.85936 iter/s, 12.9555s/50 iter), loss = 0.0803385, remaining 0 hours and 42 minutes
I0108 23:36:10.893534  4221 solver.cpp:291]     Train net output #0: loss = 0.0803384 (* 1 = 0.0803384 loss)
I0108 23:36:10.893540  4221 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0108 23:36:23.902325  4221 solver.cpp:270] Iteration 2200 (3.8437 iter/s, 13.0083s/50 iter), loss = 0.0886214, remaining 0 hours and 42 minutes
I0108 23:36:23.902367  4221 solver.cpp:291]     Train net output #0: loss = 0.0886214 (* 1 = 0.0886214 loss)
I0108 23:36:23.902374  4221 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0108 23:36:36.893182  4221 solver.cpp:270] Iteration 2250 (3.84902 iter/s, 12.9903s/50 iter), loss = 0.0814758, remaining 0 hours and 42 minutes
I0108 23:36:36.893214  4221 solver.cpp:291]     Train net output #0: loss = 0.0814758 (* 1 = 0.0814758 loss)
I0108 23:36:36.893221  4221 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0108 23:36:49.873360  4221 solver.cpp:270] Iteration 2300 (3.85218 iter/s, 12.9797s/50 iter), loss = 0.10528, remaining 0 hours and 41 minutes
I0108 23:36:49.873392  4221 solver.cpp:291]     Train net output #0: loss = 0.10528 (* 1 = 0.10528 loss)
I0108 23:36:49.873399  4221 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0108 23:37:02.843142  4221 solver.cpp:270] Iteration 2350 (3.85527 iter/s, 12.9693s/50 iter), loss = 0.0677277, remaining 0 hours and 41 minutes
I0108 23:37:02.843195  4221 solver.cpp:291]     Train net output #0: loss = 0.0677277 (* 1 = 0.0677277 loss)
I0108 23:37:02.843204  4221 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0108 23:37:15.817150  4221 solver.cpp:270] Iteration 2400 (3.85402 iter/s, 12.9735s/50 iter), loss = 0.163714, remaining 0 hours and 41 minutes
I0108 23:37:15.817183  4221 solver.cpp:291]     Train net output #0: loss = 0.163714 (* 1 = 0.163714 loss)
I0108 23:37:15.817189  4221 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0108 23:37:28.831620  4221 solver.cpp:270] Iteration 2450 (3.84203 iter/s, 13.014s/50 iter), loss = 0.107138, remaining 0 hours and 41 minutes
I0108 23:37:28.831653  4221 solver.cpp:291]     Train net output #0: loss = 0.107138 (* 1 = 0.107138 loss)
I0108 23:37:28.831660  4221 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0108 23:37:41.824697  4221 solver.cpp:270] Iteration 2500 (3.84836 iter/s, 12.9926s/50 iter), loss = 0.132514, remaining 0 hours and 41 minutes
I0108 23:37:41.824741  4221 solver.cpp:291]     Train net output #0: loss = 0.132514 (* 1 = 0.132514 loss)
I0108 23:37:41.824748  4221 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0108 23:37:54.792243  4221 solver.cpp:270] Iteration 2550 (3.85594 iter/s, 12.967s/50 iter), loss = 0.0719595, remaining 0 hours and 40 minutes
I0108 23:37:54.792274  4221 solver.cpp:291]     Train net output #0: loss = 0.0719594 (* 1 = 0.0719594 loss)
I0108 23:37:54.792281  4221 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0108 23:38:07.786533  4221 solver.cpp:270] Iteration 2600 (3.848 iter/s, 12.9938s/50 iter), loss = 0.0234347, remaining 0 hours and 40 minutes
I0108 23:38:07.786566  4221 solver.cpp:291]     Train net output #0: loss = 0.0234347 (* 1 = 0.0234347 loss)
I0108 23:38:07.786588  4221 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0108 23:38:20.761586  4221 solver.cpp:270] Iteration 2650 (3.8537 iter/s, 12.9745s/50 iter), loss = 0.0174451, remaining 0 hours and 40 minutes
I0108 23:38:20.761631  4221 solver.cpp:291]     Train net output #0: loss = 0.017445 (* 1 = 0.017445 loss)
I0108 23:38:20.761652  4221 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0108 23:38:33.744277  4221 solver.cpp:270] Iteration 2700 (3.85144 iter/s, 12.9822s/50 iter), loss = 0.0258324, remaining 0 hours and 40 minutes
I0108 23:38:33.744308  4221 solver.cpp:291]     Train net output #0: loss = 0.0258324 (* 1 = 0.0258324 loss)
I0108 23:38:33.744315  4221 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0108 23:38:46.727334  4221 solver.cpp:270] Iteration 2750 (3.85133 iter/s, 12.9825s/50 iter), loss = 0.0262614, remaining 0 hours and 39 minutes
I0108 23:38:46.727366  4221 solver.cpp:291]     Train net output #0: loss = 0.0262613 (* 1 = 0.0262613 loss)
I0108 23:38:46.727372  4221 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0108 23:38:59.689380  4221 solver.cpp:270] Iteration 2800 (3.85757 iter/s, 12.9615s/50 iter), loss = 0.0340849, remaining 0 hours and 39 minutes
I0108 23:38:59.689427  4221 solver.cpp:291]     Train net output #0: loss = 0.0340849 (* 1 = 0.0340849 loss)
I0108 23:38:59.689435  4221 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0108 23:39:12.673171  4221 solver.cpp:270] Iteration 2850 (3.85111 iter/s, 12.9833s/50 iter), loss = 0.0399431, remaining 0 hours and 39 minutes
I0108 23:39:12.673203  4221 solver.cpp:291]     Train net output #0: loss = 0.039943 (* 1 = 0.039943 loss)
I0108 23:39:12.673210  4221 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0108 23:39:25.661218  4221 solver.cpp:270] Iteration 2900 (3.84985 iter/s, 12.9875s/50 iter), loss = 0.024873, remaining 0 hours and 39 minutes
I0108 23:39:25.661252  4221 solver.cpp:291]     Train net output #0: loss = 0.024873 (* 1 = 0.024873 loss)
I0108 23:39:25.661258  4221 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0108 23:39:38.623139  4221 solver.cpp:270] Iteration 2950 (3.85761 iter/s, 12.9614s/50 iter), loss = 0.0203024, remaining 0 hours and 38 minutes
I0108 23:39:38.623194  4221 solver.cpp:291]     Train net output #0: loss = 0.0203024 (* 1 = 0.0203024 loss)
I0108 23:39:38.623203  4221 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0108 23:39:51.305418  4221 solver.cpp:424] Iteration 3000, Testing net (#0)
I0108 23:39:52.835718  4221 solver.cpp:523]     Test net output #0: accuracy = 0.9475
I0108 23:39:52.835747  4221 solver.cpp:523]     Test net output #1: loss = 0.137428 (* 1 = 0.137428 loss)
I0108 23:39:52.835753  4221 solver.cpp:523]     Test net output #2: top-1 = 0.9475
I0108 23:39:53.090167  4221 solver.cpp:270] Iteration 3000 (3.45628 iter/s, 14.4664s/50 iter), loss = 0.0147744, remaining 0 hours and 43 minutes
I0108 23:39:53.090193  4221 solver.cpp:291]     Train net output #0: loss = 0.0147744 (* 1 = 0.0147744 loss)
I0108 23:39:53.090201  4221 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0108 23:40:06.059738  4221 solver.cpp:270] Iteration 3050 (3.85533 iter/s, 12.9691s/50 iter), loss = 0.0231691, remaining 0 hours and 38 minutes
I0108 23:40:06.059772  4221 solver.cpp:291]     Train net output #0: loss = 0.0231691 (* 1 = 0.0231691 loss)
I0108 23:40:06.059778  4221 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0108 23:40:19.066936  4221 solver.cpp:270] Iteration 3100 (3.84418 iter/s, 13.0067s/50 iter), loss = 0.00671217, remaining 0 hours and 38 minutes
I0108 23:40:19.066983  4221 solver.cpp:291]     Train net output #0: loss = 0.00671215 (* 1 = 0.00671215 loss)
I0108 23:40:19.067006  4221 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0108 23:40:32.062062  4221 solver.cpp:270] Iteration 3150 (3.84775 iter/s, 12.9946s/50 iter), loss = 0.0467496, remaining 0 hours and 38 minutes
I0108 23:40:32.062093  4221 solver.cpp:291]     Train net output #0: loss = 0.0467496 (* 1 = 0.0467496 loss)
I0108 23:40:32.062115  4221 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0108 23:40:45.020820  4221 solver.cpp:270] Iteration 3200 (3.85855 iter/s, 12.9582s/50 iter), loss = 0.0192055, remaining 0 hours and 37 minutes
I0108 23:40:45.020853  4221 solver.cpp:291]     Train net output #0: loss = 0.0192055 (* 1 = 0.0192055 loss)
I0108 23:40:45.020859  4221 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0108 23:40:58.014770  4221 solver.cpp:270] Iteration 3250 (3.8481 iter/s, 12.9934s/50 iter), loss = 0.017849, remaining 0 hours and 37 minutes
I0108 23:40:58.014816  4221 solver.cpp:291]     Train net output #0: loss = 0.017849 (* 1 = 0.017849 loss)
I0108 23:40:58.014823  4221 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0108 23:41:10.999155  4221 solver.cpp:270] Iteration 3300 (3.85094 iter/s, 12.9839s/50 iter), loss = 0.0152598, remaining 0 hours and 37 minutes
I0108 23:41:10.999186  4221 solver.cpp:291]     Train net output #0: loss = 0.0152598 (* 1 = 0.0152598 loss)
I0108 23:41:10.999192  4221 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0108 23:41:23.983312  4221 solver.cpp:270] Iteration 3350 (3.851 iter/s, 12.9836s/50 iter), loss = 0.055168, remaining 0 hours and 37 minutes
I0108 23:41:23.983345  4221 solver.cpp:291]     Train net output #0: loss = 0.055168 (* 1 = 0.055168 loss)
I0108 23:41:23.983368  4221 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0108 23:41:36.961216  4221 solver.cpp:270] Iteration 3400 (3.85286 iter/s, 12.9774s/50 iter), loss = 0.0403665, remaining 0 hours and 37 minutes
I0108 23:41:36.961269  4221 solver.cpp:291]     Train net output #0: loss = 0.0403665 (* 1 = 0.0403665 loss)
I0108 23:41:36.961277  4221 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0108 23:41:49.936800  4221 solver.cpp:270] Iteration 3450 (3.85355 iter/s, 12.975s/50 iter), loss = 0.0318519, remaining 0 hours and 36 minutes
I0108 23:41:49.936832  4221 solver.cpp:291]     Train net output #0: loss = 0.0318519 (* 1 = 0.0318519 loss)
I0108 23:41:49.936839  4221 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0108 23:42:02.918743  4221 solver.cpp:270] Iteration 3500 (3.85166 iter/s, 12.9814s/50 iter), loss = 0.0222709, remaining 0 hours and 36 minutes
I0108 23:42:02.918776  4221 solver.cpp:291]     Train net output #0: loss = 0.0222709 (* 1 = 0.0222709 loss)
I0108 23:42:02.918782  4221 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0108 23:42:15.879951  4221 solver.cpp:270] Iteration 3550 (3.85782 iter/s, 12.9607s/50 iter), loss = 0.0388873, remaining 0 hours and 36 minutes
I0108 23:42:15.879997  4221 solver.cpp:291]     Train net output #0: loss = 0.0388873 (* 1 = 0.0388873 loss)
I0108 23:42:15.880004  4221 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0108 23:42:28.823475  4221 solver.cpp:270] Iteration 3600 (3.86309 iter/s, 12.943s/50 iter), loss = 0.0334645, remaining 0 hours and 36 minutes
I0108 23:42:28.823508  4221 solver.cpp:291]     Train net output #0: loss = 0.0334645 (* 1 = 0.0334645 loss)
I0108 23:42:28.823514  4221 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0108 23:42:41.831007  4221 solver.cpp:270] Iteration 3650 (3.84408 iter/s, 13.007s/50 iter), loss = 0.0108892, remaining 0 hours and 36 minutes
I0108 23:42:41.831038  4221 solver.cpp:291]     Train net output #0: loss = 0.0108892 (* 1 = 0.0108892 loss)
I0108 23:42:41.831060  4221 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0108 23:42:54.800964  4221 solver.cpp:270] Iteration 3700 (3.85522 iter/s, 12.9694s/50 iter), loss = 0.0195649, remaining 0 hours and 35 minutes
I0108 23:42:54.801010  4221 solver.cpp:291]     Train net output #0: loss = 0.0195649 (* 1 = 0.0195649 loss)
I0108 23:42:54.801033  4221 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0108 23:43:07.762876  4221 solver.cpp:270] Iteration 3750 (3.85761 iter/s, 12.9614s/50 iter), loss = 0.0279238, remaining 0 hours and 35 minutes
I0108 23:43:07.762907  4221 solver.cpp:291]     Train net output #0: loss = 0.0279238 (* 1 = 0.0279238 loss)
I0108 23:43:07.762913  4221 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0108 23:43:20.740577  4221 solver.cpp:270] Iteration 3800 (3.85292 iter/s, 12.9772s/50 iter), loss = 0.0203743, remaining 0 hours and 35 minutes
I0108 23:43:20.740609  4221 solver.cpp:291]     Train net output #0: loss = 0.0203743 (* 1 = 0.0203743 loss)
I0108 23:43:20.740617  4221 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0108 23:43:33.695438  4221 solver.cpp:270] Iteration 3850 (3.85971 iter/s, 12.9543s/50 iter), loss = 0.00613388, remaining 0 hours and 34 minutes
I0108 23:43:33.695483  4221 solver.cpp:291]     Train net output #0: loss = 0.00613389 (* 1 = 0.00613389 loss)
I0108 23:43:33.695490  4221 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0108 23:43:46.646308  4221 solver.cpp:270] Iteration 3900 (3.8609 iter/s, 12.9503s/50 iter), loss = 0.00935109, remaining 0 hours and 34 minutes
I0108 23:43:46.646342  4221 solver.cpp:291]     Train net output #0: loss = 0.00935109 (* 1 = 0.00935109 loss)
I0108 23:43:46.646348  4221 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0108 23:43:59.641469  4221 solver.cpp:270] Iteration 3950 (3.84774 iter/s, 12.9946s/50 iter), loss = 0.0265693, remaining 0 hours and 34 minutes
I0108 23:43:59.641503  4221 solver.cpp:291]     Train net output #0: loss = 0.0265693 (* 1 = 0.0265693 loss)
I0108 23:43:59.641510  4221 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0108 23:44:12.333386  4221 solver.cpp:424] Iteration 4000, Testing net (#0)
I0108 23:44:13.854426  4221 solver.cpp:523]     Test net output #0: accuracy = 0.94575
I0108 23:44:13.854455  4221 solver.cpp:523]     Test net output #1: loss = 0.146564 (* 1 = 0.146564 loss)
I0108 23:44:13.854460  4221 solver.cpp:523]     Test net output #2: top-1 = 0.94575
I0108 23:44:14.103202  4221 solver.cpp:270] Iteration 4000 (3.45754 iter/s, 14.4612s/50 iter), loss = 0.017245, remaining 0 hours and 38 minutes
I0108 23:44:14.103226  4221 solver.cpp:291]     Train net output #0: loss = 0.017245 (* 1 = 0.017245 loss)
I0108 23:44:14.103235  4221 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0108 23:44:27.055850  4221 solver.cpp:270] Iteration 4050 (3.86037 iter/s, 12.9521s/50 iter), loss = 0.0169508, remaining 0 hours and 34 minutes
I0108 23:44:27.055881  4221 solver.cpp:291]     Train net output #0: loss = 0.0169508 (* 1 = 0.0169508 loss)
I0108 23:44:27.055887  4221 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0108 23:44:40.005349  4221 solver.cpp:270] Iteration 4100 (3.86131 iter/s, 12.949s/50 iter), loss = 0.0167519, remaining 0 hours and 33 minutes
I0108 23:44:40.005381  4221 solver.cpp:291]     Train net output #0: loss = 0.0167519 (* 1 = 0.0167519 loss)
I0108 23:44:40.005403  4221 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0108 23:44:52.962277  4221 solver.cpp:270] Iteration 4150 (3.85909 iter/s, 12.9564s/50 iter), loss = 0.0237333, remaining 0 hours and 33 minutes
I0108 23:44:52.962330  4221 solver.cpp:291]     Train net output #0: loss = 0.0237333 (* 1 = 0.0237333 loss)
I0108 23:44:52.962354  4221 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0108 23:45:05.917510  4221 solver.cpp:270] Iteration 4200 (3.8596 iter/s, 12.9547s/50 iter), loss = 0.00781418, remaining 0 hours and 33 minutes
I0108 23:45:05.917542  4221 solver.cpp:291]     Train net output #0: loss = 0.00781417 (* 1 = 0.00781417 loss)
I0108 23:45:05.917549  4221 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0108 23:45:18.898381  4221 solver.cpp:270] Iteration 4250 (3.85197 iter/s, 12.9804s/50 iter), loss = 0.0142993, remaining 0 hours and 33 minutes
I0108 23:45:18.898416  4221 solver.cpp:291]     Train net output #0: loss = 0.0142993 (* 1 = 0.0142993 loss)
I0108 23:45:18.898422  4221 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0108 23:45:31.872556  4221 solver.cpp:270] Iteration 4300 (3.85396 iter/s, 12.9737s/50 iter), loss = 0.0157179, remaining 0 hours and 33 minutes
I0108 23:45:31.872603  4221 solver.cpp:291]     Train net output #0: loss = 0.0157179 (* 1 = 0.0157179 loss)
I0108 23:45:31.872611  4221 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0108 23:45:44.861177  4221 solver.cpp:270] Iteration 4350 (3.84968 iter/s, 12.9881s/50 iter), loss = 0.00992361, remaining 0 hours and 32 minutes
I0108 23:45:44.861207  4221 solver.cpp:291]     Train net output #0: loss = 0.00992361 (* 1 = 0.00992361 loss)
I0108 23:45:44.861213  4221 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0108 23:45:57.833532  4221 solver.cpp:270] Iteration 4400 (3.8545 iter/s, 12.9718s/50 iter), loss = 0.0251078, remaining 0 hours and 32 minutes
I0108 23:45:57.833566  4221 solver.cpp:291]     Train net output #0: loss = 0.0251078 (* 1 = 0.0251078 loss)
I0108 23:45:57.833573  4221 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0108 23:46:10.822367  4221 solver.cpp:270] Iteration 4450 (3.84961 iter/s, 12.9883s/50 iter), loss = 0.0129234, remaining 0 hours and 32 minutes
I0108 23:46:10.822412  4221 solver.cpp:291]     Train net output #0: loss = 0.0129234 (* 1 = 0.0129234 loss)
I0108 23:46:10.822419  4221 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0108 23:46:23.807472  4221 solver.cpp:270] Iteration 4500 (3.85072 iter/s, 12.9846s/50 iter), loss = 0.00545841, remaining 0 hours and 32 minutes
I0108 23:46:23.807503  4221 solver.cpp:291]     Train net output #0: loss = 0.00545841 (* 1 = 0.00545841 loss)
I0108 23:46:23.807512  4221 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0108 23:46:36.776912  4221 solver.cpp:270] Iteration 4550 (3.85537 iter/s, 12.9689s/50 iter), loss = 0.00376159, remaining 0 hours and 32 minutes
I0108 23:46:36.776944  4221 solver.cpp:291]     Train net output #0: loss = 0.00376159 (* 1 = 0.00376159 loss)
I0108 23:46:36.776950  4221 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0108 23:46:49.750157  4221 solver.cpp:270] Iteration 4600 (3.85424 iter/s, 12.9727s/50 iter), loss = 0.017973, remaining 0 hours and 31 minutes
I0108 23:46:49.750208  4221 solver.cpp:291]     Train net output #0: loss = 0.017973 (* 1 = 0.017973 loss)
I0108 23:46:49.750231  4221 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0108 23:47:02.724509  4221 solver.cpp:270] Iteration 4650 (3.85392 iter/s, 12.9738s/50 iter), loss = 0.0126759, remaining 0 hours and 31 minutes
I0108 23:47:02.724543  4221 solver.cpp:291]     Train net output #0: loss = 0.0126758 (* 1 = 0.0126758 loss)
I0108 23:47:02.724550  4221 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0108 23:47:15.680492  4221 solver.cpp:270] Iteration 4700 (3.85937 iter/s, 12.9555s/50 iter), loss = 0.0266425, remaining 0 hours and 31 minutes
I0108 23:47:15.680526  4221 solver.cpp:291]     Train net output #0: loss = 0.0266425 (* 1 = 0.0266425 loss)
I0108 23:47:15.680533  4221 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0108 23:47:28.653347  4221 solver.cpp:270] Iteration 4750 (3.85436 iter/s, 12.9723s/50 iter), loss = 0.0298473, remaining 0 hours and 31 minutes
I0108 23:47:28.653406  4221 solver.cpp:291]     Train net output #0: loss = 0.0298473 (* 1 = 0.0298473 loss)
I0108 23:47:28.653414  4221 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0108 23:47:41.616250  4221 solver.cpp:270] Iteration 4800 (3.85732 iter/s, 12.9624s/50 iter), loss = 0.0211087, remaining 0 hours and 31 minutes
I0108 23:47:41.616283  4221 solver.cpp:291]     Train net output #0: loss = 0.0211087 (* 1 = 0.0211087 loss)
I0108 23:47:41.616291  4221 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0108 23:47:54.577817  4221 solver.cpp:270] Iteration 4850 (3.85771 iter/s, 12.9611s/50 iter), loss = 0.0517911, remaining 0 hours and 30 minutes
I0108 23:47:54.577852  4221 solver.cpp:291]     Train net output #0: loss = 0.0517911 (* 1 = 0.0517911 loss)
I0108 23:47:54.577858  4221 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0108 23:48:07.541973  4221 solver.cpp:270] Iteration 4900 (3.85694 iter/s, 12.9636s/50 iter), loss = 0.00954167, remaining 0 hours and 30 minutes
I0108 23:48:07.542023  4221 solver.cpp:291]     Train net output #0: loss = 0.00954167 (* 1 = 0.00954167 loss)
I0108 23:48:07.542030  4221 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0108 23:48:20.517398  4221 solver.cpp:270] Iteration 4950 (3.8536 iter/s, 12.9749s/50 iter), loss = 0.0178911, remaining 0 hours and 30 minutes
I0108 23:48:20.517433  4221 solver.cpp:291]     Train net output #0: loss = 0.0178911 (* 1 = 0.0178911 loss)
I0108 23:48:20.517439  4221 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0108 23:48:33.217679  4221 solver.cpp:424] Iteration 5000, Testing net (#0)
I0108 23:48:34.718227  4221 solver.cpp:523]     Test net output #0: accuracy = 0.94275
I0108 23:48:34.718256  4221 solver.cpp:523]     Test net output #1: loss = 0.170578 (* 1 = 0.170578 loss)
I0108 23:48:34.718261  4221 solver.cpp:523]     Test net output #2: top-1 = 0.94275
I0108 23:48:34.969717  4221 solver.cpp:270] Iteration 5000 (3.45979 iter/s, 14.4517s/50 iter), loss = 0.00666573, remaining 0 hours and 33 minutes
I0108 23:48:34.969741  4221 solver.cpp:291]     Train net output #0: loss = 0.00666573 (* 1 = 0.00666573 loss)
I0108 23:48:34.969748  4221 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0108 23:48:47.932431  4221 solver.cpp:270] Iteration 5050 (3.85737 iter/s, 12.9622s/50 iter), loss = 0.00928582, remaining 0 hours and 29 minutes
I0108 23:48:47.932476  4221 solver.cpp:291]     Train net output #0: loss = 0.00928583 (* 1 = 0.00928583 loss)
I0108 23:48:47.932482  4221 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0108 23:49:00.894731  4221 solver.cpp:270] Iteration 5100 (3.8575 iter/s, 12.9618s/50 iter), loss = 0.00427278, remaining 0 hours and 29 minutes
I0108 23:49:00.894763  4221 solver.cpp:291]     Train net output #0: loss = 0.00427279 (* 1 = 0.00427279 loss)
I0108 23:49:00.894770  4221 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0108 23:49:13.883482  4221 solver.cpp:270] Iteration 5150 (3.84964 iter/s, 12.9882s/50 iter), loss = 0.0148051, remaining 0 hours and 29 minutes
I0108 23:49:13.883515  4221 solver.cpp:291]     Train net output #0: loss = 0.0148051 (* 1 = 0.0148051 loss)
I0108 23:49:13.883522  4221 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0108 23:49:26.816406  4221 solver.cpp:270] Iteration 5200 (3.86626 iter/s, 12.9324s/50 iter), loss = 0.0101659, remaining 0 hours and 29 minutes
I0108 23:49:26.816462  4221 solver.cpp:291]     Train net output #0: loss = 0.0101659 (* 1 = 0.0101659 loss)
I0108 23:49:26.816469  4221 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0108 23:49:39.802726  4221 solver.cpp:270] Iteration 5250 (3.85037 iter/s, 12.9858s/50 iter), loss = 0.00483275, remaining 0 hours and 29 minutes
I0108 23:49:39.802757  4221 solver.cpp:291]     Train net output #0: loss = 0.00483276 (* 1 = 0.00483276 loss)
I0108 23:49:39.802780  4221 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0108 23:49:52.761051  4221 solver.cpp:270] Iteration 5300 (3.85868 iter/s, 12.9578s/50 iter), loss = 0.0101288, remaining 0 hours and 28 minutes
I0108 23:49:52.761085  4221 solver.cpp:291]     Train net output #0: loss = 0.0101288 (* 1 = 0.0101288 loss)
I0108 23:49:52.761106  4221 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0108 23:50:05.705902  4221 solver.cpp:270] Iteration 5350 (3.86269 iter/s, 12.9443s/50 iter), loss = 0.00594886, remaining 0 hours and 28 minutes
I0108 23:50:05.705951  4221 solver.cpp:291]     Train net output #0: loss = 0.00594886 (* 1 = 0.00594886 loss)
I0108 23:50:05.705958  4221 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0108 23:50:18.694761  4221 solver.cpp:270] Iteration 5400 (3.84961 iter/s, 12.9883s/50 iter), loss = 0.00447495, remaining 0 hours and 28 minutes
I0108 23:50:18.694793  4221 solver.cpp:291]     Train net output #0: loss = 0.00447496 (* 1 = 0.00447496 loss)
I0108 23:50:18.694799  4221 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0108 23:50:31.639925  4221 solver.cpp:270] Iteration 5450 (3.8626 iter/s, 12.9446s/50 iter), loss = 0.008459, remaining 0 hours and 28 minutes
I0108 23:50:31.639956  4221 solver.cpp:291]     Train net output #0: loss = 0.00845901 (* 1 = 0.00845901 loss)
I0108 23:50:31.639979  4221 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0108 23:50:44.643668  4221 solver.cpp:270] Iteration 5500 (3.8452 iter/s, 13.0032s/50 iter), loss = 0.00292265, remaining 0 hours and 28 minutes
I0108 23:50:44.643716  4221 solver.cpp:291]     Train net output #0: loss = 0.00292266 (* 1 = 0.00292266 loss)
I0108 23:50:44.643723  4221 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0108 23:50:57.593103  4221 solver.cpp:270] Iteration 5550 (3.86133 iter/s, 12.9489s/50 iter), loss = 0.0023708, remaining 0 hours and 27 minutes
I0108 23:50:57.593135  4221 solver.cpp:291]     Train net output #0: loss = 0.00237081 (* 1 = 0.00237081 loss)
I0108 23:50:57.593158  4221 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0108 23:51:10.560727  4221 solver.cpp:270] Iteration 5600 (3.85591 iter/s, 12.9671s/50 iter), loss = 0.00123246, remaining 0 hours and 27 minutes
I0108 23:51:10.560760  4221 solver.cpp:291]     Train net output #0: loss = 0.00123247 (* 1 = 0.00123247 loss)
I0108 23:51:10.560782  4221 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0108 23:51:23.551959  4221 solver.cpp:270] Iteration 5650 (3.8489 iter/s, 12.9907s/50 iter), loss = 0.00206451, remaining 0 hours and 27 minutes
I0108 23:51:23.552008  4221 solver.cpp:291]     Train net output #0: loss = 0.00206452 (* 1 = 0.00206452 loss)
I0108 23:51:23.552016  4221 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0108 23:51:36.478118  4221 solver.cpp:270] Iteration 5700 (3.86828 iter/s, 12.9256s/50 iter), loss = 0.000771649, remaining 0 hours and 27 minutes
I0108 23:51:36.478150  4221 solver.cpp:291]     Train net output #0: loss = 0.00077166 (* 1 = 0.00077166 loss)
I0108 23:51:36.478157  4221 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0108 23:51:49.437243  4221 solver.cpp:270] Iteration 5750 (3.85844 iter/s, 12.9586s/50 iter), loss = 0.0143606, remaining 0 hours and 26 minutes
I0108 23:51:49.437278  4221 solver.cpp:291]     Train net output #0: loss = 0.0143606 (* 1 = 0.0143606 loss)
I0108 23:51:49.437284  4221 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0108 23:52:02.413226  4221 solver.cpp:270] Iteration 5800 (3.85343 iter/s, 12.9755s/50 iter), loss = 0.00118837, remaining 0 hours and 26 minutes
I0108 23:52:02.413281  4221 solver.cpp:291]     Train net output #0: loss = 0.00118838 (* 1 = 0.00118838 loss)
I0108 23:52:02.413305  4221 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0108 23:52:15.368863  4221 solver.cpp:270] Iteration 5850 (3.85948 iter/s, 12.9551s/50 iter), loss = 0.00292213, remaining 0 hours and 26 minutes
I0108 23:52:15.368896  4221 solver.cpp:291]     Train net output #0: loss = 0.00292214 (* 1 = 0.00292214 loss)
I0108 23:52:15.368919  4221 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0108 23:52:28.319743  4221 solver.cpp:270] Iteration 5900 (3.8609 iter/s, 12.9504s/50 iter), loss = 0.0254906, remaining 0 hours and 26 minutes
I0108 23:52:28.319777  4221 solver.cpp:291]     Train net output #0: loss = 0.0254906 (* 1 = 0.0254906 loss)
I0108 23:52:28.319783  4221 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0108 23:52:41.276973  4221 solver.cpp:270] Iteration 5950 (3.859 iter/s, 12.9567s/50 iter), loss = 0.00573553, remaining 0 hours and 25 minutes
I0108 23:52:41.277020  4221 solver.cpp:291]     Train net output #0: loss = 0.00573553 (* 1 = 0.00573553 loss)
I0108 23:52:41.277027  4221 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0108 23:52:53.961930  4221 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.4/snapshots/_iter_6000.caffemodel
I0108 23:52:56.518945  4221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.4/snapshots/_iter_6000.solverstate
I0108 23:52:56.748560  4221 solver.cpp:424] Iteration 6000, Testing net (#0)
I0108 23:52:58.218869  4221 solver.cpp:523]     Test net output #0: accuracy = 0.95275
I0108 23:52:58.218899  4221 solver.cpp:523]     Test net output #1: loss = 0.183466 (* 1 = 0.183466 loss)
I0108 23:52:58.218902  4221 solver.cpp:523]     Test net output #2: top-1 = 0.95275
I0108 23:52:58.462066  4221 solver.cpp:270] Iteration 6000 (2.90961 iter/s, 17.1844s/50 iter), loss = 0.0054815, remaining 0 hours and 34 minutes
I0108 23:52:58.462090  4221 solver.cpp:291]     Train net output #0: loss = 0.0054815 (* 1 = 0.0054815 loss)
I0108 23:52:58.462098  4221 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0108 23:53:11.396751  4221 solver.cpp:270] Iteration 6050 (3.86573 iter/s, 12.9342s/50 iter), loss = 0.00595625, remaining 0 hours and 25 minutes
I0108 23:53:11.396795  4221 solver.cpp:291]     Train net output #0: loss = 0.00595625 (* 1 = 0.00595625 loss)
I0108 23:53:11.396818  4221 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0108 23:53:24.327142  4221 solver.cpp:270] Iteration 6100 (3.86702 iter/s, 12.9299s/50 iter), loss = 0.00366982, remaining 0 hours and 25 minutes
I0108 23:53:24.327174  4221 solver.cpp:291]     Train net output #0: loss = 0.00366982 (* 1 = 0.00366982 loss)
I0108 23:53:24.327181  4221 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0108 23:53:37.272030  4221 solver.cpp:270] Iteration 6150 (3.86268 iter/s, 12.9444s/50 iter), loss = 0.00310533, remaining 0 hours and 25 minutes
I0108 23:53:37.272064  4221 solver.cpp:291]     Train net output #0: loss = 0.00310534 (* 1 = 0.00310534 loss)
I0108 23:53:37.272071  4221 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0108 23:53:50.223989  4221 solver.cpp:270] Iteration 6200 (3.86057 iter/s, 12.9514s/50 iter), loss = 0.00403784, remaining 0 hours and 24 minutes
I0108 23:53:50.224035  4221 solver.cpp:291]     Train net output #0: loss = 0.00403784 (* 1 = 0.00403784 loss)
I0108 23:53:50.224058  4221 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0108 23:54:03.171087  4221 solver.cpp:270] Iteration 6250 (3.86203 iter/s, 12.9466s/50 iter), loss = 0.00278678, remaining 0 hours and 24 minutes
I0108 23:54:03.171121  4221 solver.cpp:291]     Train net output #0: loss = 0.00278679 (* 1 = 0.00278679 loss)
I0108 23:54:03.171129  4221 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0108 23:54:16.139909  4221 solver.cpp:270] Iteration 6300 (3.85555 iter/s, 12.9683s/50 iter), loss = 0.00144061, remaining 0 hours and 24 minutes
I0108 23:54:16.139941  4221 solver.cpp:291]     Train net output #0: loss = 0.00144062 (* 1 = 0.00144062 loss)
I0108 23:54:16.139950  4221 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0108 23:54:29.120558  4221 solver.cpp:270] Iteration 6350 (3.85204 iter/s, 12.9801s/50 iter), loss = 0.00311007, remaining 0 hours and 24 minutes
I0108 23:54:29.120617  4221 solver.cpp:291]     Train net output #0: loss = 0.00311008 (* 1 = 0.00311008 loss)
I0108 23:54:29.120625  4221 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0108 23:54:42.066298  4221 solver.cpp:270] Iteration 6400 (3.86244 iter/s, 12.9452s/50 iter), loss = 0.00272217, remaining 0 hours and 24 minutes
I0108 23:54:42.066329  4221 solver.cpp:291]     Train net output #0: loss = 0.00272218 (* 1 = 0.00272218 loss)
I0108 23:54:42.066336  4221 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0108 23:54:55.065186  4221 solver.cpp:270] Iteration 6450 (3.84664 iter/s, 12.9984s/50 iter), loss = 0.00341838, remaining 0 hours and 23 minutes
I0108 23:54:55.065217  4221 solver.cpp:291]     Train net output #0: loss = 0.00341839 (* 1 = 0.00341839 loss)
I0108 23:54:55.065222  4221 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0108 23:55:08.023109  4221 solver.cpp:270] Iteration 6500 (3.8588 iter/s, 12.9574s/50 iter), loss = 0.00165154, remaining 0 hours and 23 minutes
I0108 23:55:08.023156  4221 solver.cpp:291]     Train net output #0: loss = 0.00165155 (* 1 = 0.00165155 loss)
I0108 23:55:08.023164  4221 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0108 23:55:20.987439  4221 solver.cpp:270] Iteration 6550 (3.85689 iter/s, 12.9638s/50 iter), loss = 0.00231852, remaining 0 hours and 23 minutes
I0108 23:55:20.987470  4221 solver.cpp:291]     Train net output #0: loss = 0.00231853 (* 1 = 0.00231853 loss)
I0108 23:55:20.987493  4221 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0108 23:55:33.975504  4221 solver.cpp:270] Iteration 6600 (3.84984 iter/s, 12.9875s/50 iter), loss = 0.00297502, remaining 0 hours and 23 minutes
I0108 23:55:33.975536  4221 solver.cpp:291]     Train net output #0: loss = 0.00297502 (* 1 = 0.00297502 loss)
I0108 23:55:33.975544  4221 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0108 23:55:46.931892  4221 solver.cpp:270] Iteration 6650 (3.85925 iter/s, 12.9559s/50 iter), loss = 0.000741775, remaining 0 hours and 23 minutes
I0108 23:55:46.931936  4221 solver.cpp:291]     Train net output #0: loss = 0.000741776 (* 1 = 0.000741776 loss)
I0108 23:55:46.931959  4221 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0108 23:55:59.924609  4221 solver.cpp:270] Iteration 6700 (3.84847 iter/s, 12.9922s/50 iter), loss = 0.00606738, remaining 0 hours and 22 minutes
I0108 23:55:59.924641  4221 solver.cpp:291]     Train net output #0: loss = 0.00606739 (* 1 = 0.00606739 loss)
I0108 23:55:59.924647  4221 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0108 23:56:12.888491  4221 solver.cpp:270] Iteration 6750 (3.85702 iter/s, 12.9634s/50 iter), loss = 0.0215981, remaining 0 hours and 22 minutes
I0108 23:56:12.888522  4221 solver.cpp:291]     Train net output #0: loss = 0.0215981 (* 1 = 0.0215981 loss)
I0108 23:56:12.888545  4221 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0108 23:56:25.867884  4221 solver.cpp:270] Iteration 6800 (3.85241 iter/s, 12.9789s/50 iter), loss = 0.00707938, remaining 0 hours and 22 minutes
I0108 23:56:25.867929  4221 solver.cpp:291]     Train net output #0: loss = 0.00707937 (* 1 = 0.00707937 loss)
I0108 23:56:25.867936  4221 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0108 23:56:38.831494  4221 solver.cpp:270] Iteration 6850 (3.85711 iter/s, 12.9631s/50 iter), loss = 0.00447903, remaining 0 hours and 22 minutes
I0108 23:56:38.831526  4221 solver.cpp:291]     Train net output #0: loss = 0.00447902 (* 1 = 0.00447902 loss)
I0108 23:56:38.831549  4221 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0108 23:56:51.785739  4221 solver.cpp:270] Iteration 6900 (3.85989 iter/s, 12.9537s/50 iter), loss = 0.0237801, remaining 0 hours and 22 minutes
I0108 23:56:51.785771  4221 solver.cpp:291]     Train net output #0: loss = 0.0237801 (* 1 = 0.0237801 loss)
I0108 23:56:51.785779  4221 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0108 23:57:04.773283  4221 solver.cpp:270] Iteration 6950 (3.85 iter/s, 12.987s/50 iter), loss = 0.00805274, remaining 0 hours and 21 minutes
I0108 23:57:04.773339  4221 solver.cpp:291]     Train net output #0: loss = 0.00805273 (* 1 = 0.00805273 loss)
I0108 23:57:04.773346  4221 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0108 23:57:17.477367  4221 solver.cpp:424] Iteration 7000, Testing net (#0)
I0108 23:57:19.027587  4221 solver.cpp:523]     Test net output #0: accuracy = 0.9525
I0108 23:57:19.027616  4221 solver.cpp:523]     Test net output #1: loss = 0.213902 (* 1 = 0.213902 loss)
I0108 23:57:19.027623  4221 solver.cpp:523]     Test net output #2: top-1 = 0.9525
I0108 23:57:19.277024  4221 solver.cpp:270] Iteration 7000 (3.44753 iter/s, 14.5031s/50 iter), loss = 0.0208004, remaining 0 hours and 24 minutes
I0108 23:57:19.277050  4221 solver.cpp:291]     Train net output #0: loss = 0.0208004 (* 1 = 0.0208004 loss)
I0108 23:57:19.277057  4221 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0108 23:57:32.236933  4221 solver.cpp:270] Iteration 7050 (3.8582 iter/s, 12.9594s/50 iter), loss = 0.00532496, remaining 0 hours and 21 minutes
I0108 23:57:32.236965  4221 solver.cpp:291]     Train net output #0: loss = 0.00532495 (* 1 = 0.00532495 loss)
I0108 23:57:32.236972  4221 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0108 23:57:45.212047  4221 solver.cpp:270] Iteration 7100 (3.85368 iter/s, 12.9746s/50 iter), loss = 0.000895292, remaining 0 hours and 21 minutes
I0108 23:57:45.212095  4221 solver.cpp:291]     Train net output #0: loss = 0.000895284 (* 1 = 0.000895284 loss)
I0108 23:57:45.212118  4221 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0108 23:57:58.170744  4221 solver.cpp:270] Iteration 7150 (3.85857 iter/s, 12.9582s/50 iter), loss = 0.00691315, remaining 0 hours and 20 minutes
I0108 23:57:58.170776  4221 solver.cpp:291]     Train net output #0: loss = 0.00691314 (* 1 = 0.00691314 loss)
I0108 23:57:58.170783  4221 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0108 23:58:11.139494  4221 solver.cpp:270] Iteration 7200 (3.85558 iter/s, 12.9682s/50 iter), loss = 0.0029277, remaining 0 hours and 20 minutes
I0108 23:58:11.139528  4221 solver.cpp:291]     Train net output #0: loss = 0.0029277 (* 1 = 0.0029277 loss)
I0108 23:58:11.139535  4221 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0108 23:58:24.101848  4221 solver.cpp:270] Iteration 7250 (3.85748 iter/s, 12.9618s/50 iter), loss = 0.0104876, remaining 0 hours and 20 minutes
I0108 23:58:24.101895  4221 solver.cpp:291]     Train net output #0: loss = 0.0104876 (* 1 = 0.0104876 loss)
I0108 23:58:24.101902  4221 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0108 23:58:37.067117  4221 solver.cpp:270] Iteration 7300 (3.85661 iter/s, 12.9647s/50 iter), loss = 0.026991, remaining 0 hours and 20 minutes
I0108 23:58:37.067152  4221 solver.cpp:291]     Train net output #0: loss = 0.026991 (* 1 = 0.026991 loss)
I0108 23:58:37.067158  4221 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0108 23:58:50.050351  4221 solver.cpp:270] Iteration 7350 (3.85127 iter/s, 12.9827s/50 iter), loss = 0.00666585, remaining 0 hours and 19 minutes
I0108 23:58:50.050382  4221 solver.cpp:291]     Train net output #0: loss = 0.00666584 (* 1 = 0.00666584 loss)
I0108 23:58:50.050390  4221 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0108 23:59:03.020166  4221 solver.cpp:270] Iteration 7400 (3.85526 iter/s, 12.9693s/50 iter), loss = 0.00330929, remaining 0 hours and 19 minutes
I0108 23:59:03.020213  4221 solver.cpp:291]     Train net output #0: loss = 0.00330929 (* 1 = 0.00330929 loss)
I0108 23:59:03.020220  4221 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0108 23:59:16.002264  4221 solver.cpp:270] Iteration 7450 (3.85161 iter/s, 12.9816s/50 iter), loss = 0.0129658, remaining 0 hours and 19 minutes
I0108 23:59:16.002296  4221 solver.cpp:291]     Train net output #0: loss = 0.0129658 (* 1 = 0.0129658 loss)
I0108 23:59:16.002303  4221 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0108 23:59:28.978217  4221 solver.cpp:270] Iteration 7500 (3.85343 iter/s, 12.9754s/50 iter), loss = 0.00144297, remaining 0 hours and 19 minutes
I0108 23:59:28.978253  4221 solver.cpp:291]     Train net output #0: loss = 0.00144296 (* 1 = 0.00144296 loss)
I0108 23:59:28.978276  4221 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0108 23:59:41.944221  4221 solver.cpp:270] Iteration 7550 (3.85639 iter/s, 12.9655s/50 iter), loss = 0.00182672, remaining 0 hours and 19 minutes
I0108 23:59:41.944274  4221 solver.cpp:291]     Train net output #0: loss = 0.00182671 (* 1 = 0.00182671 loss)
I0108 23:59:41.944283  4221 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0108 23:59:54.901454  4221 solver.cpp:270] Iteration 7600 (3.85901 iter/s, 12.9567s/50 iter), loss = 0.00351536, remaining 0 hours and 18 minutes
I0108 23:59:54.901489  4221 solver.cpp:291]     Train net output #0: loss = 0.00351535 (* 1 = 0.00351535 loss)
I0108 23:59:54.901495  4221 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0109 00:00:07.868747  4221 solver.cpp:270] Iteration 7650 (3.85601 iter/s, 12.9668s/50 iter), loss = 0.0024385, remaining 0 hours and 18 minutes
I0109 00:00:07.868780  4221 solver.cpp:291]     Train net output #0: loss = 0.0024385 (* 1 = 0.0024385 loss)
I0109 00:00:07.868803  4221 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0109 00:00:20.836629  4221 solver.cpp:270] Iteration 7700 (3.85583 iter/s, 12.9674s/50 iter), loss = 0.00513564, remaining 0 hours and 18 minutes
I0109 00:00:20.836674  4221 solver.cpp:291]     Train net output #0: loss = 0.00513564 (* 1 = 0.00513564 loss)
I0109 00:00:20.836683  4221 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0109 00:00:33.811158  4221 solver.cpp:270] Iteration 7750 (3.85386 iter/s, 12.974s/50 iter), loss = 0.00779887, remaining 0 hours and 18 minutes
I0109 00:00:33.811189  4221 solver.cpp:291]     Train net output #0: loss = 0.00779887 (* 1 = 0.00779887 loss)
I0109 00:00:33.811213  4221 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0109 00:00:46.787591  4221 solver.cpp:270] Iteration 7800 (3.85329 iter/s, 12.9759s/50 iter), loss = 0.0124879, remaining 0 hours and 18 minutes
I0109 00:00:46.787624  4221 solver.cpp:291]     Train net output #0: loss = 0.0124879 (* 1 = 0.0124879 loss)
I0109 00:00:46.787647  4221 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0109 00:00:59.775794  4221 solver.cpp:270] Iteration 7850 (3.8498 iter/s, 12.9877s/50 iter), loss = 0.00177114, remaining 0 hours and 17 minutes
I0109 00:00:59.775840  4221 solver.cpp:291]     Train net output #0: loss = 0.00177114 (* 1 = 0.00177114 loss)
I0109 00:00:59.775847  4221 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0109 00:01:12.735785  4221 solver.cpp:270] Iteration 7900 (3.85819 iter/s, 12.9595s/50 iter), loss = 0.0269138, remaining 0 hours and 17 minutes
I0109 00:01:12.735817  4221 solver.cpp:291]     Train net output #0: loss = 0.0269138 (* 1 = 0.0269138 loss)
I0109 00:01:12.735841  4221 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0109 00:01:25.718118  4221 solver.cpp:270] Iteration 7950 (3.85154 iter/s, 12.9818s/50 iter), loss = 0.00877075, remaining 0 hours and 17 minutes
I0109 00:01:25.718150  4221 solver.cpp:291]     Train net output #0: loss = 0.00877075 (* 1 = 0.00877075 loss)
I0109 00:01:25.718158  4221 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0109 00:01:38.427983  4221 solver.cpp:424] Iteration 8000, Testing net (#0)
I0109 00:01:39.981470  4221 solver.cpp:523]     Test net output #0: accuracy = 0.952
I0109 00:01:39.981500  4221 solver.cpp:523]     Test net output #1: loss = 0.24323 (* 1 = 0.24323 loss)
I0109 00:01:39.981505  4221 solver.cpp:523]     Test net output #2: top-1 = 0.952
I0109 00:01:40.230230  4221 solver.cpp:270] Iteration 8000 (3.44553 iter/s, 14.5115s/50 iter), loss = 0.000316481, remaining 0 hours and 19 minutes
I0109 00:01:40.230262  4221 solver.cpp:291]     Train net output #0: loss = 0.000316483 (* 1 = 0.000316483 loss)
I0109 00:01:40.230286  4221 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0109 00:01:53.164038  4221 solver.cpp:270] Iteration 8050 (3.86599 iter/s, 12.9333s/50 iter), loss = 0.00434556, remaining 0 hours and 16 minutes
I0109 00:01:53.164072  4221 solver.cpp:291]     Train net output #0: loss = 0.00434556 (* 1 = 0.00434556 loss)
I0109 00:01:53.164080  4221 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0109 00:02:06.133749  4221 solver.cpp:270] Iteration 8100 (3.85529 iter/s, 12.9692s/50 iter), loss = 0.00113513, remaining 0 hours and 16 minutes
I0109 00:02:06.133783  4221 solver.cpp:291]     Train net output #0: loss = 0.00113513 (* 1 = 0.00113513 loss)
I0109 00:02:06.133791  4221 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0109 00:02:19.107758  4221 solver.cpp:270] Iteration 8150 (3.85401 iter/s, 12.9735s/50 iter), loss = 0.00467464, remaining 0 hours and 16 minutes
I0109 00:02:19.107815  4221 solver.cpp:291]     Train net output #0: loss = 0.00467464 (* 1 = 0.00467464 loss)
I0109 00:02:19.107822  4221 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0109 00:02:32.118538  4221 solver.cpp:270] Iteration 8200 (3.84313 iter/s, 13.0102s/50 iter), loss = 0.00278759, remaining 0 hours and 16 minutes
I0109 00:02:32.118572  4221 solver.cpp:291]     Train net output #0: loss = 0.0027876 (* 1 = 0.0027876 loss)
I0109 00:02:32.118579  4221 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0109 00:02:45.072973  4221 solver.cpp:270] Iteration 8250 (3.85984 iter/s, 12.9539s/50 iter), loss = 0.000491722, remaining 0 hours and 16 minutes
I0109 00:02:45.073005  4221 solver.cpp:291]     Train net output #0: loss = 0.000491725 (* 1 = 0.000491725 loss)
I0109 00:02:45.073014  4221 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0109 00:02:58.036695  4221 solver.cpp:270] Iteration 8300 (3.85707 iter/s, 12.9632s/50 iter), loss = 0.000601181, remaining 0 hours and 15 minutes
I0109 00:02:58.036737  4221 solver.cpp:291]     Train net output #0: loss = 0.000601184 (* 1 = 0.000601184 loss)
I0109 00:02:58.036746  4221 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0109 00:03:11.023537  4221 solver.cpp:270] Iteration 8350 (3.85021 iter/s, 12.9863s/50 iter), loss = 0.00195751, remaining 0 hours and 15 minutes
I0109 00:03:11.023571  4221 solver.cpp:291]     Train net output #0: loss = 0.00195751 (* 1 = 0.00195751 loss)
I0109 00:03:11.023578  4221 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0109 00:03:23.978191  4221 solver.cpp:270] Iteration 8400 (3.85977 iter/s, 12.9541s/50 iter), loss = 0.00218883, remaining 0 hours and 15 minutes
I0109 00:03:23.978224  4221 solver.cpp:291]     Train net output #0: loss = 0.00218883 (* 1 = 0.00218883 loss)
I0109 00:03:23.978231  4221 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0109 00:03:36.941179  4221 solver.cpp:270] Iteration 8450 (3.85729 iter/s, 12.9625s/50 iter), loss = 0.00204097, remaining 0 hours and 15 minutes
I0109 00:03:36.941226  4221 solver.cpp:291]     Train net output #0: loss = 0.00204098 (* 1 = 0.00204098 loss)
I0109 00:03:36.941232  4221 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0109 00:03:49.923985  4221 solver.cpp:270] Iteration 8500 (3.85141 iter/s, 12.9823s/50 iter), loss = 0.0117783, remaining 0 hours and 15 minutes
I0109 00:03:49.924015  4221 solver.cpp:291]     Train net output #0: loss = 0.0117783 (* 1 = 0.0117783 loss)
I0109 00:03:49.924038  4221 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0109 00:04:02.879165  4221 solver.cpp:270] Iteration 8550 (3.85961 iter/s, 12.9547s/50 iter), loss = 0.0364381, remaining 0 hours and 14 minutes
I0109 00:04:02.879199  4221 solver.cpp:291]     Train net output #0: loss = 0.0364381 (* 1 = 0.0364381 loss)
I0109 00:04:02.879204  4221 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0109 00:04:15.854900  4221 solver.cpp:270] Iteration 8600 (3.8535 iter/s, 12.9752s/50 iter), loss = 0.00612208, remaining 0 hours and 14 minutes
I0109 00:04:15.854945  4221 solver.cpp:291]     Train net output #0: loss = 0.00612209 (* 1 = 0.00612209 loss)
I0109 00:04:15.854952  4221 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0109 00:04:28.828604  4221 solver.cpp:270] Iteration 8650 (3.85411 iter/s, 12.9732s/50 iter), loss = 0.0102906, remaining 0 hours and 14 minutes
I0109 00:04:28.828639  4221 solver.cpp:291]     Train net output #0: loss = 0.0102907 (* 1 = 0.0102907 loss)
I0109 00:04:28.828645  4221 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0109 00:04:41.784487  4221 solver.cpp:270] Iteration 8700 (3.8594 iter/s, 12.9554s/50 iter), loss = 0.00290962, remaining 0 hours and 14 minutes
I0109 00:04:41.784520  4221 solver.cpp:291]     Train net output #0: loss = 0.00290963 (* 1 = 0.00290963 loss)
I0109 00:04:41.784528  4221 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0109 00:04:54.763207  4221 solver.cpp:270] Iteration 8750 (3.85261 iter/s, 12.9782s/50 iter), loss = 0.00717464, remaining 0 hours and 14 minutes
I0109 00:04:54.763259  4221 solver.cpp:291]     Train net output #0: loss = 0.00717465 (* 1 = 0.00717465 loss)
I0109 00:04:54.763267  4221 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0109 00:05:07.733815  4221 solver.cpp:270] Iteration 8800 (3.85503 iter/s, 12.9701s/50 iter), loss = 0.00383847, remaining 0 hours and 13 minutes
I0109 00:05:07.733847  4221 solver.cpp:291]     Train net output #0: loss = 0.00383848 (* 1 = 0.00383848 loss)
I0109 00:05:07.733855  4221 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0109 00:05:20.698351  4221 solver.cpp:270] Iteration 8850 (3.85683 iter/s, 12.964s/50 iter), loss = 0.00529346, remaining 0 hours and 13 minutes
I0109 00:05:20.698383  4221 solver.cpp:291]     Train net output #0: loss = 0.00529347 (* 1 = 0.00529347 loss)
I0109 00:05:20.698391  4221 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0109 00:05:33.675232  4221 solver.cpp:270] Iteration 8900 (3.85316 iter/s, 12.9764s/50 iter), loss = 0.0221819, remaining 0 hours and 13 minutes
I0109 00:05:33.675277  4221 solver.cpp:291]     Train net output #0: loss = 0.0221819 (* 1 = 0.0221819 loss)
I0109 00:05:33.675284  4221 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0109 00:05:46.661589  4221 solver.cpp:270] Iteration 8950 (3.85035 iter/s, 12.9858s/50 iter), loss = 0.00649509, remaining 0 hours and 12 minutes
I0109 00:05:46.661621  4221 solver.cpp:291]     Train net output #0: loss = 0.00649509 (* 1 = 0.00649509 loss)
I0109 00:05:46.661629  4221 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0109 00:05:59.376905  4221 solver.cpp:424] Iteration 9000, Testing net (#0)
I0109 00:06:00.922328  4221 solver.cpp:523]     Test net output #0: accuracy = 0.953
I0109 00:06:00.922358  4221 solver.cpp:523]     Test net output #1: loss = 0.268193 (* 1 = 0.268193 loss)
I0109 00:06:00.922363  4221 solver.cpp:523]     Test net output #2: top-1 = 0.953
I0109 00:06:01.174481  4221 solver.cpp:270] Iteration 9000 (3.44535 iter/s, 14.5123s/50 iter), loss = 0.00266303, remaining 0 hours and 14 minutes
I0109 00:06:01.174507  4221 solver.cpp:291]     Train net output #0: loss = 0.00266304 (* 1 = 0.00266304 loss)
I0109 00:06:01.174516  4221 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0109 00:06:14.133882  4221 solver.cpp:270] Iteration 9050 (3.85836 iter/s, 12.9589s/50 iter), loss = 0.000368552, remaining 0 hours and 12 minutes
I0109 00:06:14.133930  4221 solver.cpp:291]     Train net output #0: loss = 0.000368556 (* 1 = 0.000368556 loss)
I0109 00:06:14.133939  4221 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0109 00:06:27.096261  4221 solver.cpp:270] Iteration 9100 (3.85747 iter/s, 12.9618s/50 iter), loss = 0.0136505, remaining 0 hours and 12 minutes
I0109 00:06:27.096292  4221 solver.cpp:291]     Train net output #0: loss = 0.0136505 (* 1 = 0.0136505 loss)
I0109 00:06:27.096300  4221 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0109 00:06:40.050822  4221 solver.cpp:270] Iteration 9150 (3.8598 iter/s, 12.954s/50 iter), loss = 0.000487035, remaining 0 hours and 12 minutes
I0109 00:06:40.050854  4221 solver.cpp:291]     Train net output #0: loss = 0.000487035 (* 1 = 0.000487035 loss)
I0109 00:06:40.050861  4221 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0109 00:06:53.022791  4221 solver.cpp:270] Iteration 9200 (3.85462 iter/s, 12.9715s/50 iter), loss = 0.00183132, remaining 0 hours and 11 minutes
I0109 00:06:53.022846  4221 solver.cpp:291]     Train net output #0: loss = 0.00183132 (* 1 = 0.00183132 loss)
I0109 00:06:53.022853  4221 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0109 00:07:05.997884  4221 solver.cpp:270] Iteration 9250 (3.8537 iter/s, 12.9746s/50 iter), loss = 0.000288152, remaining 0 hours and 11 minutes
I0109 00:07:05.997917  4221 solver.cpp:291]     Train net output #0: loss = 0.000288157 (* 1 = 0.000288157 loss)
I0109 00:07:05.997941  4221 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0109 00:07:18.967831  4221 solver.cpp:270] Iteration 9300 (3.85522 iter/s, 12.9694s/50 iter), loss = 0.00261977, remaining 0 hours and 11 minutes
I0109 00:07:18.967864  4221 solver.cpp:291]     Train net output #0: loss = 0.00261977 (* 1 = 0.00261977 loss)
I0109 00:07:18.967870  4221 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0109 00:07:31.914255  4221 solver.cpp:270] Iteration 9350 (3.86222 iter/s, 12.9459s/50 iter), loss = 0.000532561, remaining 0 hours and 11 minutes
I0109 00:07:31.914299  4221 solver.cpp:291]     Train net output #0: loss = 0.000532566 (* 1 = 0.000532566 loss)
I0109 00:07:31.914307  4221 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0109 00:07:44.918313  4221 solver.cpp:270] Iteration 9400 (3.84511 iter/s, 13.0035s/50 iter), loss = 0.00504741, remaining 0 hours and 11 minutes
I0109 00:07:44.918345  4221 solver.cpp:291]     Train net output #0: loss = 0.00504742 (* 1 = 0.00504742 loss)
I0109 00:07:44.918352  4221 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0109 00:07:57.860877  4221 solver.cpp:270] Iteration 9450 (3.86337 iter/s, 12.9421s/50 iter), loss = 0.000881867, remaining 0 hours and 10 minutes
I0109 00:07:57.860909  4221 solver.cpp:291]     Train net output #0: loss = 0.000881876 (* 1 = 0.000881876 loss)
I0109 00:07:57.860916  4221 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0109 00:08:10.825145  4221 solver.cpp:270] Iteration 9500 (3.85691 iter/s, 12.9638s/50 iter), loss = 0.00080114, remaining 0 hours and 10 minutes
I0109 00:08:10.825191  4221 solver.cpp:291]     Train net output #0: loss = 0.000801151 (* 1 = 0.000801151 loss)
I0109 00:08:10.825198  4221 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0109 00:08:23.798081  4221 solver.cpp:270] Iteration 9550 (3.85433 iter/s, 12.9724s/50 iter), loss = 9.34842e-05, remaining 0 hours and 10 minutes
I0109 00:08:23.798113  4221 solver.cpp:291]     Train net output #0: loss = 9.34946e-05 (* 1 = 9.34946e-05 loss)
I0109 00:08:23.798136  4221 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0109 00:08:36.760761  4221 solver.cpp:270] Iteration 9600 (3.85738 iter/s, 12.9622s/50 iter), loss = 0.0023986, remaining 0 hours and 10 minutes
I0109 00:08:36.760792  4221 solver.cpp:291]     Train net output #0: loss = 0.00239861 (* 1 = 0.00239861 loss)
I0109 00:08:36.760800  4221 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0109 00:08:49.727203  4221 solver.cpp:270] Iteration 9650 (3.85626 iter/s, 12.9659s/50 iter), loss = 0.0125305, remaining 0 hours and 10 minutes
I0109 00:08:49.727249  4221 solver.cpp:291]     Train net output #0: loss = 0.0125305 (* 1 = 0.0125305 loss)
I0109 00:08:49.727257  4221 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0109 00:09:02.722417  4221 solver.cpp:270] Iteration 9700 (3.84773 iter/s, 12.9947s/50 iter), loss = 0.0195842, remaining 0 hours and 9 minutes
I0109 00:09:02.722450  4221 solver.cpp:291]     Train net output #0: loss = 0.0195842 (* 1 = 0.0195842 loss)
I0109 00:09:02.722457  4221 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0109 00:09:15.706336  4221 solver.cpp:270] Iteration 9750 (3.85107 iter/s, 12.9834s/50 iter), loss = 0.0017943, remaining 0 hours and 9 minutes
I0109 00:09:15.706369  4221 solver.cpp:291]     Train net output #0: loss = 0.00179431 (* 1 = 0.00179431 loss)
I0109 00:09:15.706377  4221 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0109 00:09:28.665700  4221 solver.cpp:270] Iteration 9800 (3.85837 iter/s, 12.9588s/50 iter), loss = 0.0118107, remaining 0 hours and 9 minutes
I0109 00:09:28.665747  4221 solver.cpp:291]     Train net output #0: loss = 0.0118107 (* 1 = 0.0118107 loss)
I0109 00:09:28.665755  4221 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0109 00:09:41.603484  4221 solver.cpp:270] Iteration 9850 (3.86481 iter/s, 12.9373s/50 iter), loss = 0.0152618, remaining 0 hours and 9 minutes
I0109 00:09:41.603516  4221 solver.cpp:291]     Train net output #0: loss = 0.0152618 (* 1 = 0.0152618 loss)
I0109 00:09:41.603539  4221 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0109 00:09:54.588690  4221 solver.cpp:270] Iteration 9900 (3.85069 iter/s, 12.9847s/50 iter), loss = 0.00644481, remaining 0 hours and 9 minutes
I0109 00:09:54.588721  4221 solver.cpp:291]     Train net output #0: loss = 0.00644481 (* 1 = 0.00644481 loss)
I0109 00:09:54.588727  4221 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0109 00:10:07.546267  4221 solver.cpp:270] Iteration 9950 (3.8589 iter/s, 12.9571s/50 iter), loss = 0.013017, remaining 0 hours and 8 minutes
I0109 00:10:07.546319  4221 solver.cpp:291]     Train net output #0: loss = 0.013017 (* 1 = 0.013017 loss)
I0109 00:10:07.546327  4221 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0109 00:10:20.237007  4221 solver.cpp:424] Iteration 10000, Testing net (#0)
I0109 00:10:21.760403  4221 solver.cpp:523]     Test net output #0: accuracy = 0.952999
I0109 00:10:21.760433  4221 solver.cpp:523]     Test net output #1: loss = 0.281868 (* 1 = 0.281868 loss)
I0109 00:10:21.760438  4221 solver.cpp:523]     Test net output #2: top-1 = 0.952999
I0109 00:10:22.006675  4221 solver.cpp:270] Iteration 10000 (3.45786 iter/s, 14.4598s/50 iter), loss = 0.00283337, remaining 0 hours and 9 minutes
I0109 00:10:22.006700  4221 solver.cpp:291]     Train net output #0: loss = 0.00283337 (* 1 = 0.00283337 loss)
I0109 00:10:22.006709  4221 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0109 00:10:34.991741  4221 solver.cpp:270] Iteration 10050 (3.85073 iter/s, 12.9846s/50 iter), loss = 0.00234783, remaining 0 hours and 8 minutes
I0109 00:10:34.991772  4221 solver.cpp:291]     Train net output #0: loss = 0.00234783 (* 1 = 0.00234783 loss)
I0109 00:10:34.991780  4221 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0109 00:10:47.960162  4221 solver.cpp:270] Iteration 10100 (3.85567 iter/s, 12.9679s/50 iter), loss = 0.00133812, remaining 0 hours and 8 minutes
I0109 00:10:47.960212  4221 solver.cpp:291]     Train net output #0: loss = 0.00133812 (* 1 = 0.00133812 loss)
I0109 00:10:47.960219  4221 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0109 00:11:00.922180  4221 solver.cpp:270] Iteration 10150 (3.85758 iter/s, 12.9615s/50 iter), loss = 0.00684871, remaining 0 hours and 7 minutes
I0109 00:11:00.922212  4221 solver.cpp:291]     Train net output #0: loss = 0.00684871 (* 1 = 0.00684871 loss)
I0109 00:11:00.922219  4221 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0109 00:11:13.902252  4221 solver.cpp:270] Iteration 10200 (3.85221 iter/s, 12.9796s/50 iter), loss = 0.0119194, remaining 0 hours and 7 minutes
I0109 00:11:13.902283  4221 solver.cpp:291]     Train net output #0: loss = 0.0119194 (* 1 = 0.0119194 loss)
I0109 00:11:13.902307  4221 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0109 00:11:26.862046  4221 solver.cpp:270] Iteration 10250 (3.85824 iter/s, 12.9593s/50 iter), loss = 0.009639, remaining 0 hours and 7 minutes
I0109 00:11:26.862088  4221 solver.cpp:291]     Train net output #0: loss = 0.009639 (* 1 = 0.009639 loss)
I0109 00:11:26.862097  4221 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0109 00:11:39.812443  4221 solver.cpp:270] Iteration 10300 (3.86104 iter/s, 12.9499s/50 iter), loss = 0.0018747, remaining 0 hours and 7 minutes
I0109 00:11:39.812475  4221 solver.cpp:291]     Train net output #0: loss = 0.0018747 (* 1 = 0.0018747 loss)
I0109 00:11:39.812482  4221 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0109 00:11:52.787393  4221 solver.cpp:270] Iteration 10350 (3.85373 iter/s, 12.9744s/50 iter), loss = 0.00120539, remaining 0 hours and 7 minutes
I0109 00:11:52.787425  4221 solver.cpp:291]     Train net output #0: loss = 0.00120539 (* 1 = 0.00120539 loss)
I0109 00:11:52.787433  4221 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0109 00:12:05.760133  4221 solver.cpp:270] Iteration 10400 (3.85439 iter/s, 12.9722s/50 iter), loss = 0.0113292, remaining 0 hours and 6 minutes
I0109 00:12:05.760186  4221 solver.cpp:291]     Train net output #0: loss = 0.0113292 (* 1 = 0.0113292 loss)
I0109 00:12:05.760193  4221 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0109 00:12:18.715387  4221 solver.cpp:270] Iteration 10450 (3.8596 iter/s, 12.9547s/50 iter), loss = 0.00484936, remaining 0 hours and 6 minutes
I0109 00:12:18.715420  4221 solver.cpp:291]     Train net output #0: loss = 0.00484935 (* 1 = 0.00484935 loss)
I0109 00:12:18.715426  4221 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0109 00:12:31.689322  4221 solver.cpp:270] Iteration 10500 (3.85403 iter/s, 12.9734s/50 iter), loss = 0.000445964, remaining 0 hours and 6 minutes
I0109 00:12:31.689354  4221 solver.cpp:291]     Train net output #0: loss = 0.000445959 (* 1 = 0.000445959 loss)
I0109 00:12:31.689363  4221 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0109 00:12:44.677678  4221 solver.cpp:270] Iteration 10550 (3.84976 iter/s, 12.9878s/50 iter), loss = 0.00586055, remaining 0 hours and 6 minutes
I0109 00:12:44.677724  4221 solver.cpp:291]     Train net output #0: loss = 0.00586054 (* 1 = 0.00586054 loss)
I0109 00:12:44.677747  4221 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0109 00:12:57.661401  4221 solver.cpp:270] Iteration 10600 (3.85113 iter/s, 12.9832s/50 iter), loss = 0.00165715, remaining 0 hours and 5 minutes
I0109 00:12:57.661437  4221 solver.cpp:291]     Train net output #0: loss = 0.00165715 (* 1 = 0.00165715 loss)
I0109 00:12:57.661443  4221 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0109 00:13:10.616899  4221 solver.cpp:270] Iteration 10650 (3.85952 iter/s, 12.955s/50 iter), loss = 0.000794266, remaining 0 hours and 5 minutes
I0109 00:13:10.616931  4221 solver.cpp:291]     Train net output #0: loss = 0.000794258 (* 1 = 0.000794258 loss)
I0109 00:13:10.616940  4221 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0109 00:13:23.604036  4221 solver.cpp:270] Iteration 10700 (3.85012 iter/s, 12.9866s/50 iter), loss = 0.000887247, remaining 0 hours and 5 minutes
I0109 00:13:23.604084  4221 solver.cpp:291]     Train net output #0: loss = 0.00088724 (* 1 = 0.00088724 loss)
I0109 00:13:23.604092  4221 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0109 00:13:36.564390  4221 solver.cpp:270] Iteration 10750 (3.85808 iter/s, 12.9598s/50 iter), loss = 0.00461438, remaining 0 hours and 5 minutes
I0109 00:13:36.564422  4221 solver.cpp:291]     Train net output #0: loss = 0.00461438 (* 1 = 0.00461438 loss)
I0109 00:13:36.564429  4221 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0109 00:13:49.542485  4221 solver.cpp:270] Iteration 10800 (3.8528 iter/s, 12.9776s/50 iter), loss = 0.000426379, remaining 0 hours and 5 minutes
I0109 00:13:49.542517  4221 solver.cpp:291]     Train net output #0: loss = 0.00042637 (* 1 = 0.00042637 loss)
I0109 00:13:49.542524  4221 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0109 00:14:02.496219  4221 solver.cpp:270] Iteration 10850 (3.86004 iter/s, 12.9532s/50 iter), loss = 0.00203365, remaining 0 hours and 4 minutes
I0109 00:14:02.496264  4221 solver.cpp:291]     Train net output #0: loss = 0.00203364 (* 1 = 0.00203364 loss)
I0109 00:14:02.496271  4221 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0109 00:14:15.419039  4221 solver.cpp:270] Iteration 10900 (3.86928 iter/s, 12.9223s/50 iter), loss = 0.00340981, remaining 0 hours and 4 minutes
I0109 00:14:15.419072  4221 solver.cpp:291]     Train net output #0: loss = 0.0034098 (* 1 = 0.0034098 loss)
I0109 00:14:15.419080  4221 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0109 00:14:28.396852  4221 solver.cpp:270] Iteration 10950 (3.85288 iter/s, 12.9773s/50 iter), loss = 0.00641518, remaining 0 hours and 4 minutes
I0109 00:14:28.396884  4221 solver.cpp:291]     Train net output #0: loss = 0.00641517 (* 1 = 0.00641517 loss)
I0109 00:14:28.396891  4221 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0109 00:14:41.085470  4221 solver.cpp:424] Iteration 11000, Testing net (#0)
I0109 00:14:42.627135  4221 solver.cpp:523]     Test net output #0: accuracy = 0.9525
I0109 00:14:42.627164  4221 solver.cpp:523]     Test net output #1: loss = 0.290337 (* 1 = 0.290337 loss)
I0109 00:14:42.627168  4221 solver.cpp:523]     Test net output #2: top-1 = 0.9525
I0109 00:14:42.880676  4221 solver.cpp:270] Iteration 11000 (3.45226 iter/s, 14.4833s/50 iter), loss = 0.0098562, remaining 0 hours and 4 minutes
I0109 00:14:42.880702  4221 solver.cpp:291]     Train net output #0: loss = 0.00985619 (* 1 = 0.00985619 loss)
I0109 00:14:42.880710  4221 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0109 00:14:55.846813  4221 solver.cpp:270] Iteration 11050 (3.85635 iter/s, 12.9656s/50 iter), loss = 0.00842167, remaining 0 hours and 3 minutes
I0109 00:14:55.846846  4221 solver.cpp:291]     Train net output #0: loss = 0.00842166 (* 1 = 0.00842166 loss)
I0109 00:14:55.846853  4221 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0109 00:15:08.755445  4221 solver.cpp:270] Iteration 11100 (3.87353 iter/s, 12.9081s/50 iter), loss = 0.00131807, remaining 0 hours and 3 minutes
I0109 00:15:08.755478  4221 solver.cpp:291]     Train net output #0: loss = 0.00131807 (* 1 = 0.00131807 loss)
I0109 00:15:08.755501  4221 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0109 00:15:21.745764  4221 solver.cpp:270] Iteration 11150 (3.84917 iter/s, 12.9898s/50 iter), loss = 0.00817204, remaining 0 hours and 3 minutes
I0109 00:15:21.745811  4221 solver.cpp:291]     Train net output #0: loss = 0.00817203 (* 1 = 0.00817203 loss)
I0109 00:15:21.745834  4221 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0109 00:15:34.720261  4221 solver.cpp:270] Iteration 11200 (3.85387 iter/s, 12.974s/50 iter), loss = 0.00645761, remaining 0 hours and 3 minutes
I0109 00:15:34.720294  4221 solver.cpp:291]     Train net output #0: loss = 0.0064576 (* 1 = 0.0064576 loss)
I0109 00:15:34.720301  4221 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0109 00:15:47.683694  4221 solver.cpp:270] Iteration 11250 (3.85716 iter/s, 12.9629s/50 iter), loss = 0.00274551, remaining 0 hours and 3 minutes
I0109 00:15:47.683727  4221 solver.cpp:291]     Train net output #0: loss = 0.0027455 (* 1 = 0.0027455 loss)
I0109 00:15:47.683733  4221 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0109 00:16:00.662700  4221 solver.cpp:270] Iteration 11300 (3.85253 iter/s, 12.9785s/50 iter), loss = 0.00125011, remaining 0 hours and 2 minutes
I0109 00:16:00.662746  4221 solver.cpp:291]     Train net output #0: loss = 0.00125009 (* 1 = 0.00125009 loss)
I0109 00:16:00.662753  4221 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0109 00:16:13.621222  4221 solver.cpp:270] Iteration 11350 (3.85862 iter/s, 12.958s/50 iter), loss = 0.000987367, remaining 0 hours and 2 minutes
I0109 00:16:13.621254  4221 solver.cpp:291]     Train net output #0: loss = 0.000987354 (* 1 = 0.000987354 loss)
I0109 00:16:13.621263  4221 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0109 00:16:26.579013  4221 solver.cpp:270] Iteration 11400 (3.85884 iter/s, 12.9573s/50 iter), loss = 0.00556804, remaining 0 hours and 2 minutes
I0109 00:16:26.579043  4221 solver.cpp:291]     Train net output #0: loss = 0.00556803 (* 1 = 0.00556803 loss)
I0109 00:16:26.579051  4221 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0109 00:16:39.535928  4221 solver.cpp:270] Iteration 11450 (3.8591 iter/s, 12.9564s/50 iter), loss = 0.00227549, remaining 0 hours and 2 minutes
I0109 00:16:39.535974  4221 solver.cpp:291]     Train net output #0: loss = 0.00227548 (* 1 = 0.00227548 loss)
I0109 00:16:39.535982  4221 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0109 00:16:52.516467  4221 solver.cpp:270] Iteration 11500 (3.85208 iter/s, 12.98s/50 iter), loss = 0.00385084, remaining 0 hours and 2 minutes
I0109 00:16:52.516499  4221 solver.cpp:291]     Train net output #0: loss = 0.00385083 (* 1 = 0.00385083 loss)
I0109 00:16:52.516506  4221 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0109 00:17:05.509066  4221 solver.cpp:270] Iteration 11550 (3.8485 iter/s, 12.9921s/50 iter), loss = 0.000941192, remaining 0 hours and 1 minutes
I0109 00:17:05.509099  4221 solver.cpp:291]     Train net output #0: loss = 0.000941178 (* 1 = 0.000941178 loss)
I0109 00:17:05.509106  4221 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0109 00:17:18.455646  4221 solver.cpp:270] Iteration 11600 (3.86218 iter/s, 12.9461s/50 iter), loss = 0.00487189, remaining 0 hours and 1 minutes
I0109 00:17:18.455700  4221 solver.cpp:291]     Train net output #0: loss = 0.00487187 (* 1 = 0.00487187 loss)
I0109 00:17:18.455724  4221 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0109 00:17:31.426826  4221 solver.cpp:270] Iteration 11650 (3.85486 iter/s, 12.9706s/50 iter), loss = 0.0196745, remaining 0 hours and 1 minutes
I0109 00:17:31.426858  4221 solver.cpp:291]     Train net output #0: loss = 0.0196745 (* 1 = 0.0196745 loss)
I0109 00:17:31.426865  4221 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0109 00:17:44.400487  4221 solver.cpp:270] Iteration 11700 (3.85412 iter/s, 12.9731s/50 iter), loss = 0.00033527, remaining 0 hours and 1 minutes
I0109 00:17:44.400521  4221 solver.cpp:291]     Train net output #0: loss = 0.000335257 (* 1 = 0.000335257 loss)
I0109 00:17:44.400542  4221 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0109 00:17:57.369169  4221 solver.cpp:270] Iteration 11750 (3.8556 iter/s, 12.9682s/50 iter), loss = 0.00371356, remaining 0 hours and 1 minutes
I0109 00:17:57.369215  4221 solver.cpp:291]     Train net output #0: loss = 0.00371354 (* 1 = 0.00371354 loss)
I0109 00:17:57.369221  4221 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0109 00:18:10.344907  4221 solver.cpp:270] Iteration 11800 (3.8535 iter/s, 12.9752s/50 iter), loss = 0.00774659, remaining 0 hours and 0 minutes
I0109 00:18:10.344939  4221 solver.cpp:291]     Train net output #0: loss = 0.00774658 (* 1 = 0.00774658 loss)
I0109 00:18:10.344946  4221 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0109 00:18:23.330158  4221 solver.cpp:270] Iteration 11850 (3.85068 iter/s, 12.9847s/50 iter), loss = 0.00153956, remaining 0 hours and 0 minutes
I0109 00:18:23.330189  4221 solver.cpp:291]     Train net output #0: loss = 0.00153955 (* 1 = 0.00153955 loss)
I0109 00:18:23.330214  4221 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0109 00:18:36.300424  4221 solver.cpp:270] Iteration 11900 (3.85512 iter/s, 12.9698s/50 iter), loss = 0.00174166, remaining 0 hours and 0 minutes
I0109 00:18:36.300472  4221 solver.cpp:291]     Train net output #0: loss = 0.00174165 (* 1 = 0.00174165 loss)
I0109 00:18:36.300478  4221 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0109 00:18:49.258090  4221 solver.cpp:270] Iteration 11950 (3.85888 iter/s, 12.9571s/50 iter), loss = 0.00211665, remaining 0 hours and 0 minutes
I0109 00:18:49.258124  4221 solver.cpp:291]     Train net output #0: loss = 0.00211664 (* 1 = 0.00211664 loss)
I0109 00:18:49.258147  4221 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0109 00:19:01.961956  4221 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.4/snapshots/_iter_12000.caffemodel
I0109 00:19:04.334342  4221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.4/snapshots/_iter_12000.solverstate
I0109 00:19:04.651851  4221 solver.cpp:384] Iteration 12000, loss = 0.00158485
I0109 00:19:04.651877  4221 solver.cpp:424] Iteration 12000, Testing net (#0)
I0109 00:19:06.118886  4221 solver.cpp:523]     Test net output #0: accuracy = 0.9525
I0109 00:19:06.118916  4221 solver.cpp:523]     Test net output #1: loss = 0.293897 (* 1 = 0.293897 loss)
I0109 00:19:06.118921  4221 solver.cpp:523]     Test net output #2: top-1 = 0.9525
I0109 00:19:06.118924  4221 solver.cpp:392] Optimization Done (3.84534 iter/s).
I0109 00:19:06.118928  4221 caffe_interface.cpp:546] Optimization Done.
(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

I0109 00:19:06.791715  4318 pruning_runner.cpp:206] Analysis info found.
I0109 00:19:08.334662  4318 pruning_runner.cpp:237] Start pruning, please wait...
I0109 00:19:14.054813  4318 pruning_runner.cpp:284] Compression complete 0%
I0109 00:19:20.169117  4318 pruning_runner.cpp:284] Compression complete 0%
I0109 00:19:26.211016  4318 pruning_runner.cpp:284] Compression complete 0%
I0109 00:19:32.556174  4318 pruning_runner.cpp:284] Compression complete 0%
I0109 00:19:39.164135  4318 pruning_runner.cpp:284] Compression complete 0%
I0109 00:19:45.261243  4318 pruning_runner.cpp:284] Compression complete 0%
I0109 00:19:51.774137  4318 pruning_runner.cpp:284] Compression complete 0%
I0109 00:19:58.341607  4318 pruning_runner.cpp:284] Compression complete 0%
I0109 00:20:04.648743  4318 pruning_runner.cpp:284] Compression complete 0%
I0109 00:20:11.077287  4318 pruning_runner.cpp:284] Compression complete 87.5%
I0109 00:20:17.335947  4318 pruning_runner.cpp:284] Compression complete 96.5517%
I0109 00:20:23.654733  4318 pruning_runner.cpp:284] Compression complete 98.2759%
I0109 00:20:29.784961  4318 pruning_runner.cpp:284] Compression complete 99.1304%
I0109 00:20:36.300777  4318 pruning_runner.cpp:284] Compression complete 99.5652%
I0109 00:20:42.420943  4318 pruning_runner.cpp:284] Compression complete 99.7821%
I0109 00:20:48.856673  4318 pruning_runner.cpp:284] Compression complete 99.9455%
I0109 00:20:55.080462  4318 pruning_runner.cpp:284] Compression complete 99.9932%
I0109 00:21:01.420948  4318 pruning_runner.cpp:284] Compression complete 99.9966%
I0109 00:21:07.654363  4318 pruning_runner.cpp:284] Compression complete 99.9998%
I0109 00:21:13.998512  4318 pruning_runner.cpp:284] Compression complete 99.9999%
I0109 00:21:20.348848  4318 pruning_runner.cpp:284] Compression complete 100%
I0109 00:21:28.745093  4318 pruning_runner.cpp:337] pruning done, output model: pruning/alexnetBNnoLRN/regular_rate_0.5/sparse.caffemodel
I0109 00:21:28.745121  4318 pruning_runner.cpp:351] summary of REGULAR compression with rate 0.5:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.943749785    | 0.952749431    | 0.00899964571  |
+-------------------------------------------------------------------+
| Weights        | 3.7649951 M    | 783.421021 K   | -79.1919785%   |
+-------------------------------------------------------------------+
| Operations     | 2.1539185 G    | 1.14630151 G   | -46.7806473%   |
+-------------------------------------------------------------------+
To fine-tune the pruned model, please run:
vai_p_caffe finetune -config /workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/config5.prototxt
(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

W0109 00:21:28.905210  6363 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0109 00:21:28.905599  6363 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0109 00:21:28.905660  6363 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0109 00:21:28.910125  6363 vai_p_caffe.cpp:287] pruning/alexnetBNnoLRN/regular_rate_0.5/net_finetune.prototxt
I0109 00:21:29.078742  6363 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0109 00:21:29.078763  6363 gpu_memory.cpp:55] Total memory: 25620447232, Free: 25022103552, dev_info[0]: total=25620447232 free=25022103552
I0109 00:21:29.079630  6363 caffe_interface.cpp:509] Using GPUs 0
I0109 00:21:29.079906  6363 caffe_interface.cpp:514] GPU 0: Quadro P6000
I0109 00:21:29.943058  6363 solver.cpp:51] Initializing solver from parameters:
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 6000
snapshot_prefix: "pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "pruning/alexnetBNnoLRN/regular_rate_0.5/net_finetune.prototxt"
type: "Adam"
I0109 00:21:29.943218  6363 solver.cpp:99] Creating training net from net file: pruning/alexnetBNnoLRN/regular_rate_0.5/net_finetune.prototxt
I0109 00:21:29.943540  6363 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0109 00:21:29.943557  6363 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0109 00:21:29.943560  6363 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0109 00:21:29.943564  6363 net.cpp:52] Initializing net from parameters:
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0109 00:21:29.943799  6363 layer_factory.hpp:77] Creating layer data
I0109 00:21:29.943958  6363 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 00:21:29.945577  6363 net.cpp:94] Creating Layer data
I0109 00:21:29.945590  6363 net.cpp:409] data -> data
I0109 00:21:29.945600  6363 net.cpp:409] data -> label
I0109 00:21:29.946830  6400 db_lmdb.cpp:35] Opened lmdb input/lmdb/train_lmdb
I0109 00:21:29.946861  6400 db_lmdb.cpp:38] Items count: 20000
I0109 00:21:29.946882  6400 data_reader.cpp:124] TRAIN: reading data using 1 channel(s)
I0109 00:21:29.947140  6363 data_layer.cpp:78] ReshapePrefetch 256, 3, 227, 227
I0109 00:21:29.947232  6363 data_layer.cpp:83] output data size: 256,3,227,227
I0109 00:21:30.421221  6363 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 00:21:30.421308  6363 net.cpp:144] Setting up data
I0109 00:21:30.421312  6363 net.cpp:151] Top shape: 256 3 227 227 (39574272)
I0109 00:21:30.421339  6363 net.cpp:151] Top shape: 256 (256)
I0109 00:21:30.421342  6363 net.cpp:159] Memory required for data: 158298112
I0109 00:21:30.421348  6363 layer_factory.hpp:77] Creating layer conv1
I0109 00:21:30.421360  6363 net.cpp:94] Creating Layer conv1
I0109 00:21:30.421372  6363 net.cpp:435] conv1 <- data
I0109 00:21:30.421380  6363 net.cpp:409] conv1 -> conv1
I0109 00:21:30.421960  6363 net.cpp:144] Setting up conv1
I0109 00:21:30.421968  6363 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0109 00:21:30.421974  6363 net.cpp:159] Memory required for data: 455667712
I0109 00:21:30.421985  6363 layer_factory.hpp:77] Creating layer bn1
I0109 00:21:30.421994  6363 net.cpp:94] Creating Layer bn1
I0109 00:21:30.421998  6363 net.cpp:435] bn1 <- conv1
I0109 00:21:30.422003  6363 net.cpp:409] bn1 -> bn1
I0109 00:21:30.422497  6363 net.cpp:144] Setting up bn1
I0109 00:21:30.422503  6363 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0109 00:21:30.422509  6363 net.cpp:159] Memory required for data: 753037312
I0109 00:21:30.422518  6363 layer_factory.hpp:77] Creating layer relu1
I0109 00:21:30.422524  6363 net.cpp:94] Creating Layer relu1
I0109 00:21:30.422528  6363 net.cpp:435] relu1 <- bn1
I0109 00:21:30.422533  6363 net.cpp:409] relu1 -> relu1
I0109 00:21:30.422547  6363 net.cpp:144] Setting up relu1
I0109 00:21:30.422554  6363 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0109 00:21:30.422559  6363 net.cpp:159] Memory required for data: 1050406912
I0109 00:21:30.422561  6363 layer_factory.hpp:77] Creating layer pool1
I0109 00:21:30.422566  6363 net.cpp:94] Creating Layer pool1
I0109 00:21:30.422570  6363 net.cpp:435] pool1 <- relu1
I0109 00:21:30.422590  6363 net.cpp:409] pool1 -> pool1
I0109 00:21:30.422613  6363 net.cpp:144] Setting up pool1
I0109 00:21:30.422618  6363 net.cpp:151] Top shape: 256 96 27 27 (17915904)
I0109 00:21:30.422623  6363 net.cpp:159] Memory required for data: 1122070528
I0109 00:21:30.422627  6363 layer_factory.hpp:77] Creating layer conv2
I0109 00:21:30.422634  6363 net.cpp:94] Creating Layer conv2
I0109 00:21:30.422638  6363 net.cpp:435] conv2 <- pool1
I0109 00:21:30.422643  6363 net.cpp:409] conv2 -> conv2
I0109 00:21:30.437991  6363 net.cpp:144] Setting up conv2
I0109 00:21:30.438009  6363 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0109 00:21:30.438017  6363 net.cpp:159] Memory required for data: 1313173504
I0109 00:21:30.438027  6363 layer_factory.hpp:77] Creating layer bn2
I0109 00:21:30.438036  6363 net.cpp:94] Creating Layer bn2
I0109 00:21:30.438041  6363 net.cpp:435] bn2 <- conv2
I0109 00:21:30.438047  6363 net.cpp:409] bn2 -> bn2
I0109 00:21:30.438562  6363 net.cpp:144] Setting up bn2
I0109 00:21:30.438570  6363 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0109 00:21:30.438576  6363 net.cpp:159] Memory required for data: 1504276480
I0109 00:21:30.438585  6363 layer_factory.hpp:77] Creating layer relu2
I0109 00:21:30.438591  6363 net.cpp:94] Creating Layer relu2
I0109 00:21:30.438596  6363 net.cpp:435] relu2 <- bn2
I0109 00:21:30.438601  6363 net.cpp:409] relu2 -> relu2
I0109 00:21:30.438619  6363 net.cpp:144] Setting up relu2
I0109 00:21:30.438625  6363 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0109 00:21:30.438632  6363 net.cpp:159] Memory required for data: 1695379456
I0109 00:21:30.438634  6363 layer_factory.hpp:77] Creating layer pool2
I0109 00:21:30.438642  6363 net.cpp:94] Creating Layer pool2
I0109 00:21:30.438645  6363 net.cpp:435] pool2 <- relu2
I0109 00:21:30.438652  6363 net.cpp:409] pool2 -> pool2
I0109 00:21:30.438676  6363 net.cpp:144] Setting up pool2
I0109 00:21:30.438683  6363 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0109 00:21:30.438688  6363 net.cpp:159] Memory required for data: 1739681792
I0109 00:21:30.438691  6363 layer_factory.hpp:77] Creating layer conv3
I0109 00:21:30.438711  6363 net.cpp:94] Creating Layer conv3
I0109 00:21:30.438715  6363 net.cpp:435] conv3 <- pool2
I0109 00:21:30.438720  6363 net.cpp:409] conv3 -> conv3
I0109 00:21:30.450174  6363 net.cpp:144] Setting up conv3
I0109 00:21:30.450203  6363 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0109 00:21:30.450214  6363 net.cpp:159] Memory required for data: 1806135296
I0109 00:21:30.450227  6363 layer_factory.hpp:77] Creating layer relu3
I0109 00:21:30.450238  6363 net.cpp:94] Creating Layer relu3
I0109 00:21:30.450244  6363 net.cpp:435] relu3 <- conv3
I0109 00:21:30.450311  6363 net.cpp:409] relu3 -> relu3
I0109 00:21:30.450368  6363 net.cpp:144] Setting up relu3
I0109 00:21:30.450392  6363 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0109 00:21:30.450417  6363 net.cpp:159] Memory required for data: 1872588800
I0109 00:21:30.450439  6363 layer_factory.hpp:77] Creating layer conv4
I0109 00:21:30.450469  6363 net.cpp:94] Creating Layer conv4
I0109 00:21:30.450492  6363 net.cpp:435] conv4 <- relu3
I0109 00:21:30.450517  6363 net.cpp:409] conv4 -> conv4
I0109 00:21:30.469343  6363 net.cpp:144] Setting up conv4
I0109 00:21:30.469363  6363 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0109 00:21:30.469372  6363 net.cpp:159] Memory required for data: 1939042304
I0109 00:21:30.469384  6363 layer_factory.hpp:77] Creating layer relu4
I0109 00:21:30.469393  6363 net.cpp:94] Creating Layer relu4
I0109 00:21:30.469398  6363 net.cpp:435] relu4 <- conv4
I0109 00:21:30.469403  6363 net.cpp:409] relu4 -> relu4
I0109 00:21:30.469425  6363 net.cpp:144] Setting up relu4
I0109 00:21:30.469430  6363 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0109 00:21:30.469434  6363 net.cpp:159] Memory required for data: 2005495808
I0109 00:21:30.469439  6363 layer_factory.hpp:77] Creating layer conv5
I0109 00:21:30.469446  6363 net.cpp:94] Creating Layer conv5
I0109 00:21:30.469451  6363 net.cpp:435] conv5 <- relu4
I0109 00:21:30.469455  6363 net.cpp:409] conv5 -> conv5
I0109 00:21:30.484252  6363 net.cpp:144] Setting up conv5
I0109 00:21:30.484272  6363 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0109 00:21:30.484279  6363 net.cpp:159] Memory required for data: 2049798144
I0109 00:21:30.484288  6363 layer_factory.hpp:77] Creating layer relu5
I0109 00:21:30.484295  6363 net.cpp:94] Creating Layer relu5
I0109 00:21:30.484300  6363 net.cpp:435] relu5 <- conv5
I0109 00:21:30.484306  6363 net.cpp:409] relu5 -> relu5
I0109 00:21:30.484329  6363 net.cpp:144] Setting up relu5
I0109 00:21:30.484333  6363 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0109 00:21:30.484338  6363 net.cpp:159] Memory required for data: 2094100480
I0109 00:21:30.484341  6363 layer_factory.hpp:77] Creating layer pool5
I0109 00:21:30.484349  6363 net.cpp:94] Creating Layer pool5
I0109 00:21:30.484352  6363 net.cpp:435] pool5 <- relu5
I0109 00:21:30.484356  6363 net.cpp:409] pool5 -> pool5
I0109 00:21:30.484380  6363 net.cpp:144] Setting up pool5
I0109 00:21:30.484385  6363 net.cpp:151] Top shape: 256 256 6 6 (2359296)
I0109 00:21:30.484390  6363 net.cpp:159] Memory required for data: 2103537664
I0109 00:21:30.484393  6363 layer_factory.hpp:77] Creating layer fc6
I0109 00:21:30.484400  6363 net.cpp:94] Creating Layer fc6
I0109 00:21:30.484405  6363 net.cpp:435] fc6 <- pool5
I0109 00:21:30.484409  6363 net.cpp:409] fc6 -> fc6
I0109 00:21:30.885462  6363 net.cpp:144] Setting up fc6
I0109 00:21:30.885488  6363 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 00:21:30.885500  6363 net.cpp:159] Memory required for data: 2107731968
I0109 00:21:30.885511  6363 layer_factory.hpp:77] Creating layer relu6
I0109 00:21:30.885537  6363 net.cpp:94] Creating Layer relu6
I0109 00:21:30.885545  6363 net.cpp:435] relu6 <- fc6
I0109 00:21:30.885552  6363 net.cpp:409] relu6 -> relu6
I0109 00:21:30.885574  6363 net.cpp:144] Setting up relu6
I0109 00:21:30.885578  6363 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 00:21:30.885586  6363 net.cpp:159] Memory required for data: 2111926272
I0109 00:21:30.885591  6363 layer_factory.hpp:77] Creating layer drop6
I0109 00:21:30.885607  6363 net.cpp:94] Creating Layer drop6
I0109 00:21:30.885622  6363 net.cpp:435] drop6 <- relu6
I0109 00:21:30.885627  6363 net.cpp:409] drop6 -> drop6
I0109 00:21:30.885650  6363 net.cpp:144] Setting up drop6
I0109 00:21:30.885654  6363 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 00:21:30.885660  6363 net.cpp:159] Memory required for data: 2116120576
I0109 00:21:30.885664  6363 layer_factory.hpp:77] Creating layer fc7
I0109 00:21:30.885673  6363 net.cpp:94] Creating Layer fc7
I0109 00:21:30.885694  6363 net.cpp:435] fc7 <- drop6
I0109 00:21:30.885701  6363 net.cpp:409] fc7 -> fc7
I0109 00:21:31.030737  6363 net.cpp:144] Setting up fc7
I0109 00:21:31.030761  6363 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 00:21:31.030771  6363 net.cpp:159] Memory required for data: 2120314880
I0109 00:21:31.030782  6363 layer_factory.hpp:77] Creating layer bn7
I0109 00:21:31.030810  6363 net.cpp:94] Creating Layer bn7
I0109 00:21:31.030817  6363 net.cpp:435] bn7 <- fc7
I0109 00:21:31.030827  6363 net.cpp:409] bn7 -> bn7
I0109 00:21:31.031257  6363 net.cpp:144] Setting up bn7
I0109 00:21:31.031265  6363 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 00:21:31.031270  6363 net.cpp:159] Memory required for data: 2124509184
I0109 00:21:31.031282  6363 layer_factory.hpp:77] Creating layer relu7
I0109 00:21:31.031291  6363 net.cpp:94] Creating Layer relu7
I0109 00:21:31.031297  6363 net.cpp:435] relu7 <- bn7
I0109 00:21:31.031304  6363 net.cpp:409] relu7 -> relu7
I0109 00:21:31.031325  6363 net.cpp:144] Setting up relu7
I0109 00:21:31.031330  6363 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 00:21:31.031337  6363 net.cpp:159] Memory required for data: 2128703488
I0109 00:21:31.031342  6363 layer_factory.hpp:77] Creating layer drop7
I0109 00:21:31.031348  6363 net.cpp:94] Creating Layer drop7
I0109 00:21:31.031355  6363 net.cpp:435] drop7 <- relu7
I0109 00:21:31.031363  6363 net.cpp:409] drop7 -> drop7
I0109 00:21:31.031388  6363 net.cpp:144] Setting up drop7
I0109 00:21:31.031394  6363 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 00:21:31.031400  6363 net.cpp:159] Memory required for data: 2132897792
I0109 00:21:31.031405  6363 layer_factory.hpp:77] Creating layer fc8
I0109 00:21:31.031414  6363 net.cpp:94] Creating Layer fc8
I0109 00:21:31.031419  6363 net.cpp:435] fc8 <- drop7
I0109 00:21:31.031427  6363 net.cpp:409] fc8 -> fc8
I0109 00:21:31.031597  6363 net.cpp:144] Setting up fc8
I0109 00:21:31.031603  6363 net.cpp:151] Top shape: 256 2 (512)
I0109 00:21:31.031610  6363 net.cpp:159] Memory required for data: 2132899840
I0109 00:21:31.031618  6363 layer_factory.hpp:77] Creating layer loss
I0109 00:21:31.031627  6363 net.cpp:94] Creating Layer loss
I0109 00:21:31.031633  6363 net.cpp:435] loss <- fc8
I0109 00:21:31.031641  6363 net.cpp:435] loss <- label
I0109 00:21:31.031647  6363 net.cpp:409] loss -> loss
I0109 00:21:31.031658  6363 layer_factory.hpp:77] Creating layer loss
I0109 00:21:31.031724  6363 net.cpp:144] Setting up loss
I0109 00:21:31.031729  6363 net.cpp:151] Top shape: (1)
I0109 00:21:31.031735  6363 net.cpp:154]     with loss weight 1
I0109 00:21:31.031752  6363 net.cpp:159] Memory required for data: 2132899844
I0109 00:21:31.031757  6363 net.cpp:220] loss needs backward computation.
I0109 00:21:31.031765  6363 net.cpp:220] fc8 needs backward computation.
I0109 00:21:31.031772  6363 net.cpp:220] drop7 needs backward computation.
I0109 00:21:31.031780  6363 net.cpp:220] relu7 needs backward computation.
I0109 00:21:31.031785  6363 net.cpp:220] bn7 needs backward computation.
I0109 00:21:31.031791  6363 net.cpp:220] fc7 needs backward computation.
I0109 00:21:31.031800  6363 net.cpp:220] drop6 needs backward computation.
I0109 00:21:31.031806  6363 net.cpp:220] relu6 needs backward computation.
I0109 00:21:31.031813  6363 net.cpp:220] fc6 needs backward computation.
I0109 00:21:31.031821  6363 net.cpp:220] pool5 needs backward computation.
I0109 00:21:31.031827  6363 net.cpp:220] relu5 needs backward computation.
I0109 00:21:31.031832  6363 net.cpp:220] conv5 needs backward computation.
I0109 00:21:31.031838  6363 net.cpp:220] relu4 needs backward computation.
I0109 00:21:31.031855  6363 net.cpp:220] conv4 needs backward computation.
I0109 00:21:31.031862  6363 net.cpp:220] relu3 needs backward computation.
I0109 00:21:31.031868  6363 net.cpp:220] conv3 needs backward computation.
I0109 00:21:31.031875  6363 net.cpp:220] pool2 needs backward computation.
I0109 00:21:31.031883  6363 net.cpp:220] relu2 needs backward computation.
I0109 00:21:31.031888  6363 net.cpp:220] bn2 needs backward computation.
I0109 00:21:31.031895  6363 net.cpp:220] conv2 needs backward computation.
I0109 00:21:31.031903  6363 net.cpp:220] pool1 needs backward computation.
I0109 00:21:31.031910  6363 net.cpp:220] relu1 needs backward computation.
I0109 00:21:31.031917  6363 net.cpp:220] bn1 needs backward computation.
I0109 00:21:31.031924  6363 net.cpp:220] conv1 needs backward computation.
I0109 00:21:31.031932  6363 net.cpp:222] data does not need backward computation.
I0109 00:21:31.031939  6363 net.cpp:264] This network produces output loss
I0109 00:21:31.031963  6363 net.cpp:284] Network initialization done.
I0109 00:21:31.032333  6363 solver.cpp:189] Creating test net (#0) specified by net file: pruning/alexnetBNnoLRN/regular_rate_0.5/net_finetune.prototxt
I0109 00:21:31.032371  6363 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0109 00:21:31.032392  6363 net.cpp:52] Initializing net from parameters:
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0109 00:21:31.032647  6363 layer_factory.hpp:77] Creating layer data
I0109 00:21:31.032694  6363 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 00:21:31.034355  6363 net.cpp:94] Creating Layer data
I0109 00:21:31.034370  6363 net.cpp:409] data -> data
I0109 00:21:31.034382  6363 net.cpp:409] data -> label
I0109 00:21:31.035974  6430 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0109 00:21:31.035997  6430 db_lmdb.cpp:38] Items count: 4000
I0109 00:21:31.036020  6430 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0109 00:21:31.036283  6363 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0109 00:21:31.036379  6363 data_layer.cpp:83] output data size: 50,3,227,227
I0109 00:21:31.134102  6363 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 00:21:31.134227  6363 net.cpp:144] Setting up data
I0109 00:21:31.134234  6363 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0109 00:21:31.134251  6363 net.cpp:151] Top shape: 50 (50)
I0109 00:21:31.134271  6363 net.cpp:159] Memory required for data: 30917600
I0109 00:21:31.134276  6363 layer_factory.hpp:77] Creating layer label_data_1_split
I0109 00:21:31.134285  6363 net.cpp:94] Creating Layer label_data_1_split
I0109 00:21:31.134289  6363 net.cpp:435] label_data_1_split <- label
I0109 00:21:31.134295  6363 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0109 00:21:31.134320  6363 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0109 00:21:31.134325  6363 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0109 00:21:31.134387  6363 net.cpp:144] Setting up label_data_1_split
I0109 00:21:31.134392  6363 net.cpp:151] Top shape: 50 (50)
I0109 00:21:31.134397  6363 net.cpp:151] Top shape: 50 (50)
I0109 00:21:31.134402  6363 net.cpp:151] Top shape: 50 (50)
I0109 00:21:31.134405  6363 net.cpp:159] Memory required for data: 30918200
I0109 00:21:31.134408  6363 layer_factory.hpp:77] Creating layer conv1
I0109 00:21:31.134418  6363 net.cpp:94] Creating Layer conv1
I0109 00:21:31.134426  6363 net.cpp:435] conv1 <- data
I0109 00:21:31.134431  6363 net.cpp:409] conv1 -> conv1
I0109 00:21:31.135053  6363 net.cpp:144] Setting up conv1
I0109 00:21:31.135061  6363 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0109 00:21:31.135067  6363 net.cpp:159] Memory required for data: 88998200
I0109 00:21:31.135078  6363 layer_factory.hpp:77] Creating layer bn1
I0109 00:21:31.135087  6363 net.cpp:94] Creating Layer bn1
I0109 00:21:31.135092  6363 net.cpp:435] bn1 <- conv1
I0109 00:21:31.135097  6363 net.cpp:409] bn1 -> bn1
I0109 00:21:31.135632  6363 net.cpp:144] Setting up bn1
I0109 00:21:31.135639  6363 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0109 00:21:31.135644  6363 net.cpp:159] Memory required for data: 147078200
I0109 00:21:31.135653  6363 layer_factory.hpp:77] Creating layer relu1
I0109 00:21:31.135659  6363 net.cpp:94] Creating Layer relu1
I0109 00:21:31.135663  6363 net.cpp:435] relu1 <- bn1
I0109 00:21:31.135668  6363 net.cpp:409] relu1 -> relu1
I0109 00:21:31.135682  6363 net.cpp:144] Setting up relu1
I0109 00:21:31.135687  6363 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0109 00:21:31.135692  6363 net.cpp:159] Memory required for data: 205158200
I0109 00:21:31.135696  6363 layer_factory.hpp:77] Creating layer pool1
I0109 00:21:31.135701  6363 net.cpp:94] Creating Layer pool1
I0109 00:21:31.135705  6363 net.cpp:435] pool1 <- relu1
I0109 00:21:31.135710  6363 net.cpp:409] pool1 -> pool1
I0109 00:21:31.135733  6363 net.cpp:144] Setting up pool1
I0109 00:21:31.135738  6363 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0109 00:21:31.135743  6363 net.cpp:159] Memory required for data: 219155000
I0109 00:21:31.135747  6363 layer_factory.hpp:77] Creating layer conv2
I0109 00:21:31.135754  6363 net.cpp:94] Creating Layer conv2
I0109 00:21:31.135758  6363 net.cpp:435] conv2 <- pool1
I0109 00:21:31.135763  6363 net.cpp:409] conv2 -> conv2
I0109 00:21:31.142338  6363 net.cpp:144] Setting up conv2
I0109 00:21:31.142354  6363 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0109 00:21:31.142361  6363 net.cpp:159] Memory required for data: 256479800
I0109 00:21:31.142372  6363 layer_factory.hpp:77] Creating layer bn2
I0109 00:21:31.142381  6363 net.cpp:94] Creating Layer bn2
I0109 00:21:31.142385  6363 net.cpp:435] bn2 <- conv2
I0109 00:21:31.142391  6363 net.cpp:409] bn2 -> bn2
I0109 00:21:31.142856  6363 net.cpp:144] Setting up bn2
I0109 00:21:31.142863  6363 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0109 00:21:31.142868  6363 net.cpp:159] Memory required for data: 293804600
I0109 00:21:31.142876  6363 layer_factory.hpp:77] Creating layer relu2
I0109 00:21:31.142882  6363 net.cpp:94] Creating Layer relu2
I0109 00:21:31.142886  6363 net.cpp:435] relu2 <- bn2
I0109 00:21:31.142891  6363 net.cpp:409] relu2 -> relu2
I0109 00:21:31.142906  6363 net.cpp:144] Setting up relu2
I0109 00:21:31.142925  6363 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0109 00:21:31.142930  6363 net.cpp:159] Memory required for data: 331129400
I0109 00:21:31.142932  6363 layer_factory.hpp:77] Creating layer pool2
I0109 00:21:31.142938  6363 net.cpp:94] Creating Layer pool2
I0109 00:21:31.142942  6363 net.cpp:435] pool2 <- relu2
I0109 00:21:31.142947  6363 net.cpp:409] pool2 -> pool2
I0109 00:21:31.142971  6363 net.cpp:144] Setting up pool2
I0109 00:21:31.142977  6363 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0109 00:21:31.142982  6363 net.cpp:159] Memory required for data: 339782200
I0109 00:21:31.142987  6363 layer_factory.hpp:77] Creating layer conv3
I0109 00:21:31.142994  6363 net.cpp:94] Creating Layer conv3
I0109 00:21:31.142998  6363 net.cpp:435] conv3 <- pool2
I0109 00:21:31.143003  6363 net.cpp:409] conv3 -> conv3
I0109 00:21:31.153293  6363 net.cpp:144] Setting up conv3
I0109 00:21:31.153311  6363 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 00:21:31.153319  6363 net.cpp:159] Memory required for data: 352761400
I0109 00:21:31.153329  6363 layer_factory.hpp:77] Creating layer relu3
I0109 00:21:31.153337  6363 net.cpp:94] Creating Layer relu3
I0109 00:21:31.153342  6363 net.cpp:435] relu3 <- conv3
I0109 00:21:31.153347  6363 net.cpp:409] relu3 -> relu3
I0109 00:21:31.153371  6363 net.cpp:144] Setting up relu3
I0109 00:21:31.153374  6363 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 00:21:31.153379  6363 net.cpp:159] Memory required for data: 365740600
I0109 00:21:31.153383  6363 layer_factory.hpp:77] Creating layer conv4
I0109 00:21:31.153391  6363 net.cpp:94] Creating Layer conv4
I0109 00:21:31.153395  6363 net.cpp:435] conv4 <- relu3
I0109 00:21:31.153400  6363 net.cpp:409] conv4 -> conv4
I0109 00:21:31.167476  6363 net.cpp:144] Setting up conv4
I0109 00:21:31.167495  6363 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 00:21:31.167505  6363 net.cpp:159] Memory required for data: 378719800
I0109 00:21:31.167516  6363 layer_factory.hpp:77] Creating layer relu4
I0109 00:21:31.167523  6363 net.cpp:94] Creating Layer relu4
I0109 00:21:31.167527  6363 net.cpp:435] relu4 <- conv4
I0109 00:21:31.167533  6363 net.cpp:409] relu4 -> relu4
I0109 00:21:31.167553  6363 net.cpp:144] Setting up relu4
I0109 00:21:31.167558  6363 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 00:21:31.167578  6363 net.cpp:159] Memory required for data: 391699000
I0109 00:21:31.167582  6363 layer_factory.hpp:77] Creating layer conv5
I0109 00:21:31.167588  6363 net.cpp:94] Creating Layer conv5
I0109 00:21:31.167591  6363 net.cpp:435] conv5 <- relu4
I0109 00:21:31.167596  6363 net.cpp:409] conv5 -> conv5
I0109 00:21:31.180544  6363 net.cpp:144] Setting up conv5
I0109 00:21:31.180580  6363 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0109 00:21:31.180590  6363 net.cpp:159] Memory required for data: 400351800
I0109 00:21:31.180603  6363 layer_factory.hpp:77] Creating layer relu5
I0109 00:21:31.180611  6363 net.cpp:94] Creating Layer relu5
I0109 00:21:31.180616  6363 net.cpp:435] relu5 <- conv5
I0109 00:21:31.180624  6363 net.cpp:409] relu5 -> relu5
I0109 00:21:31.180652  6363 net.cpp:144] Setting up relu5
I0109 00:21:31.180657  6363 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0109 00:21:31.180662  6363 net.cpp:159] Memory required for data: 409004600
I0109 00:21:31.180665  6363 layer_factory.hpp:77] Creating layer pool5
I0109 00:21:31.180678  6363 net.cpp:94] Creating Layer pool5
I0109 00:21:31.180686  6363 net.cpp:435] pool5 <- relu5
I0109 00:21:31.180692  6363 net.cpp:409] pool5 -> pool5
I0109 00:21:31.180716  6363 net.cpp:144] Setting up pool5
I0109 00:21:31.180721  6363 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0109 00:21:31.180727  6363 net.cpp:159] Memory required for data: 410847800
I0109 00:21:31.180730  6363 layer_factory.hpp:77] Creating layer fc6
I0109 00:21:31.180737  6363 net.cpp:94] Creating Layer fc6
I0109 00:21:31.180742  6363 net.cpp:435] fc6 <- pool5
I0109 00:21:31.180747  6363 net.cpp:409] fc6 -> fc6
I0109 00:21:31.530036  6363 net.cpp:144] Setting up fc6
I0109 00:21:31.530062  6363 net.cpp:151] Top shape: 50 4096 (204800)
I0109 00:21:31.530104  6363 net.cpp:159] Memory required for data: 411667000
I0109 00:21:31.530114  6363 layer_factory.hpp:77] Creating layer relu6
I0109 00:21:31.530122  6363 net.cpp:94] Creating Layer relu6
I0109 00:21:31.530126  6363 net.cpp:435] relu6 <- fc6
I0109 00:21:31.530131  6363 net.cpp:409] relu6 -> relu6
I0109 00:21:31.530155  6363 net.cpp:144] Setting up relu6
I0109 00:21:31.530161  6363 net.cpp:151] Top shape: 50 4096 (204800)
I0109 00:21:31.530165  6363 net.cpp:159] Memory required for data: 412486200
I0109 00:21:31.530169  6363 layer_factory.hpp:77] Creating layer drop6
I0109 00:21:31.530174  6363 net.cpp:94] Creating Layer drop6
I0109 00:21:31.530177  6363 net.cpp:435] drop6 <- relu6
I0109 00:21:31.530181  6363 net.cpp:409] drop6 -> drop6
I0109 00:21:31.530201  6363 net.cpp:144] Setting up drop6
I0109 00:21:31.530205  6363 net.cpp:151] Top shape: 50 4096 (204800)
I0109 00:21:31.530210  6363 net.cpp:159] Memory required for data: 413305400
I0109 00:21:31.530212  6363 layer_factory.hpp:77] Creating layer fc7
I0109 00:21:31.530234  6363 net.cpp:94] Creating Layer fc7
I0109 00:21:31.530237  6363 net.cpp:435] fc7 <- drop6
I0109 00:21:31.530242  6363 net.cpp:409] fc7 -> fc7
I0109 00:21:31.674969  6363 net.cpp:144] Setting up fc7
I0109 00:21:31.674993  6363 net.cpp:151] Top shape: 50 4096 (204800)
I0109 00:21:31.675000  6363 net.cpp:159] Memory required for data: 414124600
I0109 00:21:31.675010  6363 layer_factory.hpp:77] Creating layer bn7
I0109 00:21:31.675020  6363 net.cpp:94] Creating Layer bn7
I0109 00:21:31.675024  6363 net.cpp:435] bn7 <- fc7
I0109 00:21:31.675030  6363 net.cpp:409] bn7 -> bn7
I0109 00:21:31.675493  6363 net.cpp:144] Setting up bn7
I0109 00:21:31.675503  6363 net.cpp:151] Top shape: 50 4096 (204800)
I0109 00:21:31.675508  6363 net.cpp:159] Memory required for data: 414943800
I0109 00:21:31.675514  6363 layer_factory.hpp:77] Creating layer relu7
I0109 00:21:31.675520  6363 net.cpp:94] Creating Layer relu7
I0109 00:21:31.675523  6363 net.cpp:435] relu7 <- bn7
I0109 00:21:31.675529  6363 net.cpp:409] relu7 -> relu7
I0109 00:21:31.675545  6363 net.cpp:144] Setting up relu7
I0109 00:21:31.675549  6363 net.cpp:151] Top shape: 50 4096 (204800)
I0109 00:21:31.675552  6363 net.cpp:159] Memory required for data: 415763000
I0109 00:21:31.675556  6363 layer_factory.hpp:77] Creating layer drop7
I0109 00:21:31.675561  6363 net.cpp:94] Creating Layer drop7
I0109 00:21:31.675565  6363 net.cpp:435] drop7 <- relu7
I0109 00:21:31.675570  6363 net.cpp:409] drop7 -> drop7
I0109 00:21:31.675591  6363 net.cpp:144] Setting up drop7
I0109 00:21:31.675596  6363 net.cpp:151] Top shape: 50 4096 (204800)
I0109 00:21:31.675601  6363 net.cpp:159] Memory required for data: 416582200
I0109 00:21:31.675604  6363 layer_factory.hpp:77] Creating layer fc8
I0109 00:21:31.675611  6363 net.cpp:94] Creating Layer fc8
I0109 00:21:31.675613  6363 net.cpp:435] fc8 <- drop7
I0109 00:21:31.675618  6363 net.cpp:409] fc8 -> fc8
I0109 00:21:31.675789  6363 net.cpp:144] Setting up fc8
I0109 00:21:31.675796  6363 net.cpp:151] Top shape: 50 2 (100)
I0109 00:21:31.675801  6363 net.cpp:159] Memory required for data: 416582600
I0109 00:21:31.675806  6363 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0109 00:21:31.675812  6363 net.cpp:94] Creating Layer fc8_fc8_0_split
I0109 00:21:31.675817  6363 net.cpp:435] fc8_fc8_0_split <- fc8
I0109 00:21:31.675820  6363 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0109 00:21:31.675827  6363 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0109 00:21:31.675832  6363 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0109 00:21:31.675863  6363 net.cpp:144] Setting up fc8_fc8_0_split
I0109 00:21:31.675868  6363 net.cpp:151] Top shape: 50 2 (100)
I0109 00:21:31.675873  6363 net.cpp:151] Top shape: 50 2 (100)
I0109 00:21:31.675876  6363 net.cpp:151] Top shape: 50 2 (100)
I0109 00:21:31.675880  6363 net.cpp:159] Memory required for data: 416583800
I0109 00:21:31.675884  6363 layer_factory.hpp:77] Creating layer accuracy
I0109 00:21:31.675890  6363 net.cpp:94] Creating Layer accuracy
I0109 00:21:31.675906  6363 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0109 00:21:31.675911  6363 net.cpp:435] accuracy <- label_data_1_split_0
I0109 00:21:31.675916  6363 net.cpp:409] accuracy -> accuracy
I0109 00:21:31.675922  6363 net.cpp:144] Setting up accuracy
I0109 00:21:31.675926  6363 net.cpp:151] Top shape: (1)
I0109 00:21:31.675930  6363 net.cpp:159] Memory required for data: 416583804
I0109 00:21:31.675933  6363 layer_factory.hpp:77] Creating layer loss
I0109 00:21:31.675940  6363 net.cpp:94] Creating Layer loss
I0109 00:21:31.675943  6363 net.cpp:435] loss <- fc8_fc8_0_split_1
I0109 00:21:31.675947  6363 net.cpp:435] loss <- label_data_1_split_1
I0109 00:21:31.675952  6363 net.cpp:409] loss -> loss
I0109 00:21:31.675966  6363 layer_factory.hpp:77] Creating layer loss
I0109 00:21:31.676039  6363 net.cpp:144] Setting up loss
I0109 00:21:31.676045  6363 net.cpp:151] Top shape: (1)
I0109 00:21:31.676049  6363 net.cpp:154]     with loss weight 1
I0109 00:21:31.676062  6363 net.cpp:159] Memory required for data: 416583808
I0109 00:21:31.676066  6363 layer_factory.hpp:77] Creating layer accuracy-top1
I0109 00:21:31.676071  6363 net.cpp:94] Creating Layer accuracy-top1
I0109 00:21:31.676075  6363 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0109 00:21:31.676079  6363 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0109 00:21:31.676084  6363 net.cpp:409] accuracy-top1 -> top-1
I0109 00:21:31.676090  6363 net.cpp:144] Setting up accuracy-top1
I0109 00:21:31.676095  6363 net.cpp:151] Top shape: (1)
I0109 00:21:31.676098  6363 net.cpp:159] Memory required for data: 416583812
I0109 00:21:31.676101  6363 net.cpp:222] accuracy-top1 does not need backward computation.
I0109 00:21:31.676106  6363 net.cpp:220] loss needs backward computation.
I0109 00:21:31.676110  6363 net.cpp:222] accuracy does not need backward computation.
I0109 00:21:31.676115  6363 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0109 00:21:31.676118  6363 net.cpp:220] fc8 needs backward computation.
I0109 00:21:31.676122  6363 net.cpp:220] drop7 needs backward computation.
I0109 00:21:31.676126  6363 net.cpp:220] relu7 needs backward computation.
I0109 00:21:31.676131  6363 net.cpp:220] bn7 needs backward computation.
I0109 00:21:31.676133  6363 net.cpp:220] fc7 needs backward computation.
I0109 00:21:31.676137  6363 net.cpp:220] drop6 needs backward computation.
I0109 00:21:31.676142  6363 net.cpp:220] relu6 needs backward computation.
I0109 00:21:31.676146  6363 net.cpp:220] fc6 needs backward computation.
I0109 00:21:31.676149  6363 net.cpp:220] pool5 needs backward computation.
I0109 00:21:31.676153  6363 net.cpp:220] relu5 needs backward computation.
I0109 00:21:31.676157  6363 net.cpp:220] conv5 needs backward computation.
I0109 00:21:31.676162  6363 net.cpp:220] relu4 needs backward computation.
I0109 00:21:31.676167  6363 net.cpp:220] conv4 needs backward computation.
I0109 00:21:31.676170  6363 net.cpp:220] relu3 needs backward computation.
I0109 00:21:31.676174  6363 net.cpp:220] conv3 needs backward computation.
I0109 00:21:31.676179  6363 net.cpp:220] pool2 needs backward computation.
I0109 00:21:31.676183  6363 net.cpp:220] relu2 needs backward computation.
I0109 00:21:31.676187  6363 net.cpp:220] bn2 needs backward computation.
I0109 00:21:31.676192  6363 net.cpp:220] conv2 needs backward computation.
I0109 00:21:31.676195  6363 net.cpp:220] pool1 needs backward computation.
I0109 00:21:31.676199  6363 net.cpp:220] relu1 needs backward computation.
I0109 00:21:31.676203  6363 net.cpp:220] bn1 needs backward computation.
I0109 00:21:31.676208  6363 net.cpp:220] conv1 needs backward computation.
I0109 00:21:31.676213  6363 net.cpp:222] label_data_1_split does not need backward computation.
I0109 00:21:31.676216  6363 net.cpp:222] data does not need backward computation.
I0109 00:21:31.676220  6363 net.cpp:264] This network produces output accuracy
I0109 00:21:31.676224  6363 net.cpp:264] This network produces output loss
I0109 00:21:31.676229  6363 net.cpp:264] This network produces output top-1
I0109 00:21:31.676257  6363 net.cpp:284] Network initialization done.
I0109 00:21:31.676326  6363 solver.cpp:63] Solver scaffolding done.
I0109 00:21:31.677350  6363 caffe_interface.cpp:109] Finetuning from pruning/alexnetBNnoLRN/regular_rate_0.5/sparse.caffemodel
I0109 00:21:33.973840  6363 caffe_interface.cpp:543] Starting Optimization
I0109 00:21:33.973865  6363 solver.cpp:341] Solving
I0109 00:21:33.973867  6363 solver.cpp:342] Learning Rate Policy: step
I0109 00:21:33.975265  6363 solver.cpp:424] Iteration 0, Testing net (#0)
I0109 00:21:35.501142  6363 solver.cpp:523]     Test net output #0: accuracy = 0.952749
I0109 00:21:35.501175  6363 solver.cpp:523]     Test net output #1: loss = 0.293615 (* 1 = 0.293615 loss)
I0109 00:21:35.501179  6363 solver.cpp:523]     Test net output #2: top-1 = 0.952749
I0109 00:21:35.761510  6363 solver.cpp:270] Iteration 0 (0 iter/s, 1.78752s/50 iter), loss = 0.00359541, remaining 333333 hours and 20 minutes
I0109 00:21:35.761539  6363 solver.cpp:291]     Train net output #0: loss = 0.00359541 (* 1 = 0.00359541 loss)
I0109 00:21:35.761548  6363 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0109 00:21:48.377873  6363 solver.cpp:270] Iteration 50 (3.96328 iter/s, 12.6158s/50 iter), loss = 0.104826, remaining 0 hours and 50 minutes
I0109 00:21:48.377905  6363 solver.cpp:291]     Train net output #0: loss = 0.104826 (* 1 = 0.104826 loss)
I0109 00:21:48.377912  6363 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0109 00:22:01.087787  6363 solver.cpp:270] Iteration 100 (3.93411 iter/s, 12.7093s/50 iter), loss = 0.0701176, remaining 0 hours and 50 minutes
I0109 00:22:01.087833  6363 solver.cpp:291]     Train net output #0: loss = 0.0701176 (* 1 = 0.0701176 loss)
I0109 00:22:01.087841  6363 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0109 00:22:13.881165  6363 solver.cpp:270] Iteration 150 (3.90845 iter/s, 12.7928s/50 iter), loss = 0.0414973, remaining 0 hours and 50 minutes
I0109 00:22:13.881196  6363 solver.cpp:291]     Train net output #0: loss = 0.0414973 (* 1 = 0.0414973 loss)
I0109 00:22:13.881204  6363 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0109 00:22:26.728101  6363 solver.cpp:270] Iteration 200 (3.89215 iter/s, 12.8464s/50 iter), loss = 0.0612325, remaining 0 hours and 50 minutes
I0109 00:22:26.728133  6363 solver.cpp:291]     Train net output #0: loss = 0.0612325 (* 1 = 0.0612325 loss)
I0109 00:22:26.728140  6363 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0109 00:22:39.593991  6363 solver.cpp:270] Iteration 250 (3.88642 iter/s, 12.8653s/50 iter), loss = 0.0804346, remaining 0 hours and 50 minutes
I0109 00:22:39.594035  6363 solver.cpp:291]     Train net output #0: loss = 0.0804346 (* 1 = 0.0804346 loss)
I0109 00:22:39.594043  6363 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0109 00:22:52.486925  6363 solver.cpp:270] Iteration 300 (3.87827 iter/s, 12.8923s/50 iter), loss = 0.0523854, remaining 0 hours and 50 minutes
I0109 00:22:52.486956  6363 solver.cpp:291]     Train net output #0: loss = 0.0523854 (* 1 = 0.0523854 loss)
I0109 00:22:52.486964  6363 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0109 00:23:05.427141  6363 solver.cpp:270] Iteration 350 (3.86409 iter/s, 12.9397s/50 iter), loss = 0.128801, remaining 0 hours and 50 minutes
I0109 00:23:05.427175  6363 solver.cpp:291]     Train net output #0: loss = 0.128801 (* 1 = 0.128801 loss)
I0109 00:23:05.427182  6363 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0109 00:23:18.338835  6363 solver.cpp:270] Iteration 400 (3.87261 iter/s, 12.9112s/50 iter), loss = 0.0914265, remaining 0 hours and 49 minutes
I0109 00:23:18.338879  6363 solver.cpp:291]     Train net output #0: loss = 0.0914265 (* 1 = 0.0914265 loss)
I0109 00:23:18.338887  6363 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0109 00:23:31.300758  6363 solver.cpp:270] Iteration 450 (3.8576 iter/s, 12.9614s/50 iter), loss = 0.125366, remaining 0 hours and 49 minutes
I0109 00:23:31.300788  6363 solver.cpp:291]     Train net output #0: loss = 0.125366 (* 1 = 0.125366 loss)
I0109 00:23:31.300796  6363 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0109 00:23:44.250923  6363 solver.cpp:270] Iteration 500 (3.8611 iter/s, 12.9497s/50 iter), loss = 0.0537244, remaining 0 hours and 49 minutes
I0109 00:23:44.250955  6363 solver.cpp:291]     Train net output #0: loss = 0.0537244 (* 1 = 0.0537244 loss)
I0109 00:23:44.250963  6363 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0109 00:23:57.183566  6363 solver.cpp:270] Iteration 550 (3.86634 iter/s, 12.9321s/50 iter), loss = 0.0826446, remaining 0 hours and 49 minutes
I0109 00:23:57.183620  6363 solver.cpp:291]     Train net output #0: loss = 0.0826446 (* 1 = 0.0826446 loss)
I0109 00:23:57.183629  6363 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0109 00:24:10.134621  6363 solver.cpp:270] Iteration 600 (3.86085 iter/s, 12.9505s/50 iter), loss = 0.056279, remaining 0 hours and 49 minutes
I0109 00:24:10.134652  6363 solver.cpp:291]     Train net output #0: loss = 0.056279 (* 1 = 0.056279 loss)
I0109 00:24:10.134660  6363 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0109 00:24:23.061985  6363 solver.cpp:270] Iteration 650 (3.86792 iter/s, 12.9269s/50 iter), loss = 0.0600165, remaining 0 hours and 48 minutes
I0109 00:24:23.062019  6363 solver.cpp:291]     Train net output #0: loss = 0.0600165 (* 1 = 0.0600165 loss)
I0109 00:24:23.062026  6363 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0109 00:24:36.036053  6363 solver.cpp:270] Iteration 700 (3.85399 iter/s, 12.9736s/50 iter), loss = 0.0771873, remaining 0 hours and 48 minutes
I0109 00:24:36.036099  6363 solver.cpp:291]     Train net output #0: loss = 0.0771873 (* 1 = 0.0771873 loss)
I0109 00:24:36.036108  6363 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0109 00:24:48.962560  6363 solver.cpp:270] Iteration 750 (3.86818 iter/s, 12.926s/50 iter), loss = 0.0710517, remaining 0 hours and 48 minutes
I0109 00:24:48.962592  6363 solver.cpp:291]     Train net output #0: loss = 0.0710517 (* 1 = 0.0710517 loss)
I0109 00:24:48.962599  6363 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0109 00:25:01.911761  6363 solver.cpp:270] Iteration 800 (3.8614 iter/s, 12.9487s/50 iter), loss = 0.051941, remaining 0 hours and 48 minutes
I0109 00:25:01.911792  6363 solver.cpp:291]     Train net output #0: loss = 0.051941 (* 1 = 0.051941 loss)
I0109 00:25:01.911815  6363 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0109 00:25:14.886169  6363 solver.cpp:270] Iteration 850 (3.85389 iter/s, 12.9739s/50 iter), loss = 0.0439956, remaining 0 hours and 48 minutes
I0109 00:25:14.886214  6363 solver.cpp:291]     Train net output #0: loss = 0.0439956 (* 1 = 0.0439956 loss)
I0109 00:25:14.886222  6363 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0109 00:25:27.822304  6363 solver.cpp:270] Iteration 900 (3.8653 iter/s, 12.9356s/50 iter), loss = 0.0747246, remaining 0 hours and 47 minutes
I0109 00:25:27.822336  6363 solver.cpp:291]     Train net output #0: loss = 0.0747246 (* 1 = 0.0747246 loss)
I0109 00:25:27.822345  6363 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0109 00:25:40.820690  6363 solver.cpp:270] Iteration 950 (3.84678 iter/s, 12.9979s/50 iter), loss = 0.0813608, remaining 0 hours and 47 minutes
I0109 00:25:40.820721  6363 solver.cpp:291]     Train net output #0: loss = 0.0813608 (* 1 = 0.0813608 loss)
I0109 00:25:40.820729  6363 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0109 00:25:53.538798  6363 solver.cpp:424] Iteration 1000, Testing net (#0)
I0109 00:25:55.057178  6363 solver.cpp:523]     Test net output #0: accuracy = 0.898
I0109 00:25:55.057205  6363 solver.cpp:523]     Test net output #1: loss = 0.346166 (* 1 = 0.346166 loss)
I0109 00:25:55.057211  6363 solver.cpp:523]     Test net output #2: top-1 = 0.898
I0109 00:25:55.309410  6363 solver.cpp:270] Iteration 1000 (3.4511 iter/s, 14.4882s/50 iter), loss = 0.104569, remaining 0 hours and 53 minutes
I0109 00:25:55.309437  6363 solver.cpp:291]     Train net output #0: loss = 0.104569 (* 1 = 0.104569 loss)
I0109 00:25:55.309444  6363 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0109 00:26:08.270562  6363 solver.cpp:270] Iteration 1050 (3.85783 iter/s, 12.9606s/50 iter), loss = 0.0949115, remaining 0 hours and 47 minutes
I0109 00:26:08.270593  6363 solver.cpp:291]     Train net output #0: loss = 0.0949115 (* 1 = 0.0949115 loss)
I0109 00:26:08.270601  6363 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0109 00:26:21.251142  6363 solver.cpp:270] Iteration 1100 (3.85206 iter/s, 12.9801s/50 iter), loss = 0.0831459, remaining 0 hours and 46 minutes
I0109 00:26:21.251176  6363 solver.cpp:291]     Train net output #0: loss = 0.0831459 (* 1 = 0.0831459 loss)
I0109 00:26:21.251184  6363 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0109 00:26:34.226408  6363 solver.cpp:270] Iteration 1150 (3.85364 iter/s, 12.9747s/50 iter), loss = 0.14133, remaining 0 hours and 46 minutes
I0109 00:26:34.226460  6363 solver.cpp:291]     Train net output #0: loss = 0.14133 (* 1 = 0.14133 loss)
I0109 00:26:34.226485  6363 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0109 00:26:47.211130  6363 solver.cpp:270] Iteration 1200 (3.85084 iter/s, 12.9842s/50 iter), loss = 0.0714659, remaining 0 hours and 46 minutes
I0109 00:26:47.211163  6363 solver.cpp:291]     Train net output #0: loss = 0.0714659 (* 1 = 0.0714659 loss)
I0109 00:26:47.211170  6363 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0109 00:27:00.189494  6363 solver.cpp:270] Iteration 1250 (3.85272 iter/s, 12.9778s/50 iter), loss = 0.0955046, remaining 0 hours and 46 minutes
I0109 00:27:00.189525  6363 solver.cpp:291]     Train net output #0: loss = 0.0955046 (* 1 = 0.0955046 loss)
I0109 00:27:00.189533  6363 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0109 00:27:13.137214  6363 solver.cpp:270] Iteration 1300 (3.86184 iter/s, 12.9472s/50 iter), loss = 0.063705, remaining 0 hours and 46 minutes
I0109 00:27:13.137259  6363 solver.cpp:291]     Train net output #0: loss = 0.063705 (* 1 = 0.063705 loss)
I0109 00:27:13.137284  6363 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0109 00:27:26.104542  6363 solver.cpp:270] Iteration 1350 (3.856 iter/s, 12.9668s/50 iter), loss = 0.0980887, remaining 0 hours and 45 minutes
I0109 00:27:26.104571  6363 solver.cpp:291]     Train net output #0: loss = 0.0980887 (* 1 = 0.0980887 loss)
I0109 00:27:26.104594  6363 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0109 00:27:39.060024  6363 solver.cpp:270] Iteration 1400 (3.85952 iter/s, 12.955s/50 iter), loss = 0.0702877, remaining 0 hours and 45 minutes
I0109 00:27:39.060056  6363 solver.cpp:291]     Train net output #0: loss = 0.0702877 (* 1 = 0.0702877 loss)
I0109 00:27:39.060063  6363 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0109 00:27:52.045012  6363 solver.cpp:270] Iteration 1450 (3.85075 iter/s, 12.9845s/50 iter), loss = 0.0874929, remaining 0 hours and 45 minutes
I0109 00:27:52.045058  6363 solver.cpp:291]     Train net output #0: loss = 0.0874929 (* 1 = 0.0874929 loss)
I0109 00:27:52.045065  6363 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0109 00:28:05.016448  6363 solver.cpp:270] Iteration 1500 (3.85478 iter/s, 12.9709s/50 iter), loss = 0.103976, remaining 0 hours and 45 minutes
I0109 00:28:05.016480  6363 solver.cpp:291]     Train net output #0: loss = 0.103976 (* 1 = 0.103976 loss)
I0109 00:28:05.016502  6363 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0109 00:28:17.961803  6363 solver.cpp:270] Iteration 1550 (3.86254 iter/s, 12.9448s/50 iter), loss = 0.0754282, remaining 0 hours and 45 minutes
I0109 00:28:17.961834  6363 solver.cpp:291]     Train net output #0: loss = 0.0754282 (* 1 = 0.0754282 loss)
I0109 00:28:17.961841  6363 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0109 00:28:30.948665  6363 solver.cpp:270] Iteration 1600 (3.8502 iter/s, 12.9863s/50 iter), loss = 0.0890098, remaining 0 hours and 44 minutes
I0109 00:28:30.948709  6363 solver.cpp:291]     Train net output #0: loss = 0.0890098 (* 1 = 0.0890098 loss)
I0109 00:28:30.948730  6363 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0109 00:28:43.921504  6363 solver.cpp:270] Iteration 1650 (3.85436 iter/s, 12.9723s/50 iter), loss = 0.101619, remaining 0 hours and 44 minutes
I0109 00:28:43.921535  6363 solver.cpp:291]     Train net output #0: loss = 0.101619 (* 1 = 0.101619 loss)
I0109 00:28:43.921558  6363 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0109 00:28:56.880585  6363 solver.cpp:270] Iteration 1700 (3.85845 iter/s, 12.9586s/50 iter), loss = 0.0406493, remaining 0 hours and 44 minutes
I0109 00:28:56.880618  6363 solver.cpp:291]     Train net output #0: loss = 0.0406493 (* 1 = 0.0406493 loss)
I0109 00:28:56.880641  6363 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0109 00:29:09.830760  6363 solver.cpp:270] Iteration 1750 (3.86111 iter/s, 12.9497s/50 iter), loss = 0.0952076, remaining 0 hours and 44 minutes
I0109 00:29:09.830809  6363 solver.cpp:291]     Train net output #0: loss = 0.0952076 (* 1 = 0.0952076 loss)
I0109 00:29:09.830832  6363 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0109 00:29:22.775218  6363 solver.cpp:270] Iteration 1800 (3.86282 iter/s, 12.9439s/50 iter), loss = 0.102511, remaining 0 hours and 44 minutes
I0109 00:29:22.775250  6363 solver.cpp:291]     Train net output #0: loss = 0.102511 (* 1 = 0.102511 loss)
I0109 00:29:22.775257  6363 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0109 00:29:35.722442  6363 solver.cpp:270] Iteration 1850 (3.86199 iter/s, 12.9467s/50 iter), loss = 0.0668626, remaining 0 hours and 43 minutes
I0109 00:29:35.722476  6363 solver.cpp:291]     Train net output #0: loss = 0.0668626 (* 1 = 0.0668626 loss)
I0109 00:29:35.722498  6363 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0109 00:29:48.682448  6363 solver.cpp:270] Iteration 1900 (3.85818 iter/s, 12.9595s/50 iter), loss = 0.0946677, remaining 0 hours and 43 minutes
I0109 00:29:48.682492  6363 solver.cpp:291]     Train net output #0: loss = 0.0946677 (* 1 = 0.0946677 loss)
I0109 00:29:48.682499  6363 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0109 00:30:01.673183  6363 solver.cpp:270] Iteration 1950 (3.84905 iter/s, 12.9902s/50 iter), loss = 0.0616746, remaining 0 hours and 43 minutes
I0109 00:30:01.673218  6363 solver.cpp:291]     Train net output #0: loss = 0.0616746 (* 1 = 0.0616746 loss)
I0109 00:30:01.673224  6363 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0109 00:30:14.389328  6363 solver.cpp:424] Iteration 2000, Testing net (#0)
I0109 00:30:15.902953  6363 solver.cpp:523]     Test net output #0: accuracy = 0.908
I0109 00:30:15.902981  6363 solver.cpp:523]     Test net output #1: loss = 0.357179 (* 1 = 0.357179 loss)
I0109 00:30:15.902987  6363 solver.cpp:523]     Test net output #2: top-1 = 0.908
I0109 00:30:16.153018  6363 solver.cpp:270] Iteration 2000 (3.45321 iter/s, 14.4793s/50 iter), loss = 0.103356, remaining 0 hours and 48 minutes
I0109 00:30:16.153044  6363 solver.cpp:291]     Train net output #0: loss = 0.103356 (* 1 = 0.103356 loss)
I0109 00:30:16.153050  6363 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0109 00:30:29.088490  6363 solver.cpp:270] Iteration 2050 (3.86549 iter/s, 12.935s/50 iter), loss = 0.109146, remaining 0 hours and 42 minutes
I0109 00:30:29.088537  6363 solver.cpp:291]     Train net output #0: loss = 0.109146 (* 1 = 0.109146 loss)
I0109 00:30:29.088546  6363 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0109 00:30:42.045508  6363 solver.cpp:270] Iteration 2100 (3.85907 iter/s, 12.9565s/50 iter), loss = 0.0532197, remaining 0 hours and 42 minutes
I0109 00:30:42.045540  6363 solver.cpp:291]     Train net output #0: loss = 0.0532197 (* 1 = 0.0532197 loss)
I0109 00:30:42.045563  6363 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0109 00:30:55.002321  6363 solver.cpp:270] Iteration 2150 (3.85913 iter/s, 12.9563s/50 iter), loss = 0.0790365, remaining 0 hours and 42 minutes
I0109 00:30:55.002353  6363 solver.cpp:291]     Train net output #0: loss = 0.0790365 (* 1 = 0.0790365 loss)
I0109 00:30:55.002360  6363 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0109 00:31:07.952497  6363 solver.cpp:270] Iteration 2200 (3.86111 iter/s, 12.9497s/50 iter), loss = 0.0798302, remaining 0 hours and 42 minutes
I0109 00:31:07.952550  6363 solver.cpp:291]     Train net output #0: loss = 0.0798302 (* 1 = 0.0798302 loss)
I0109 00:31:07.952574  6363 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0109 00:31:20.881060  6363 solver.cpp:270] Iteration 2250 (3.86757 iter/s, 12.928s/50 iter), loss = 0.0598335, remaining 0 hours and 41 minutes
I0109 00:31:20.881093  6363 solver.cpp:291]     Train net output #0: loss = 0.0598335 (* 1 = 0.0598335 loss)
I0109 00:31:20.881101  6363 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0109 00:31:33.838347  6363 solver.cpp:270] Iteration 2300 (3.85899 iter/s, 12.9568s/50 iter), loss = 0.150838, remaining 0 hours and 41 minutes
I0109 00:31:33.838378  6363 solver.cpp:291]     Train net output #0: loss = 0.150838 (* 1 = 0.150838 loss)
I0109 00:31:33.838385  6363 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0109 00:31:46.793090  6363 solver.cpp:270] Iteration 2350 (3.85974 iter/s, 12.9542s/50 iter), loss = 0.0952086, remaining 0 hours and 41 minutes
I0109 00:31:46.793138  6363 solver.cpp:291]     Train net output #0: loss = 0.0952086 (* 1 = 0.0952086 loss)
I0109 00:31:46.793145  6363 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0109 00:31:59.738433  6363 solver.cpp:270] Iteration 2400 (3.86255 iter/s, 12.9448s/50 iter), loss = 0.103149, remaining 0 hours and 41 minutes
I0109 00:31:59.738466  6363 solver.cpp:291]     Train net output #0: loss = 0.103149 (* 1 = 0.103149 loss)
I0109 00:31:59.738488  6363 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0109 00:32:12.696718  6363 solver.cpp:270] Iteration 2450 (3.85869 iter/s, 12.9578s/50 iter), loss = 0.0687407, remaining 0 hours and 41 minutes
I0109 00:32:12.696753  6363 solver.cpp:291]     Train net output #0: loss = 0.0687407 (* 1 = 0.0687407 loss)
I0109 00:32:12.696759  6363 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0109 00:32:25.646694  6363 solver.cpp:270] Iteration 2500 (3.86116 iter/s, 12.9495s/50 iter), loss = 0.0808827, remaining 0 hours and 40 minutes
I0109 00:32:25.646740  6363 solver.cpp:291]     Train net output #0: loss = 0.0808827 (* 1 = 0.0808827 loss)
I0109 00:32:25.646747  6363 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0109 00:32:38.612923  6363 solver.cpp:270] Iteration 2550 (3.85633 iter/s, 12.9657s/50 iter), loss = 0.0337812, remaining 0 hours and 40 minutes
I0109 00:32:38.612953  6363 solver.cpp:291]     Train net output #0: loss = 0.0337812 (* 1 = 0.0337812 loss)
I0109 00:32:38.612960  6363 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0109 00:32:51.563505  6363 solver.cpp:270] Iteration 2600 (3.86098 iter/s, 12.9501s/50 iter), loss = 0.0452037, remaining 0 hours and 40 minutes
I0109 00:32:51.563535  6363 solver.cpp:291]     Train net output #0: loss = 0.0452037 (* 1 = 0.0452037 loss)
I0109 00:32:51.563542  6363 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0109 00:33:04.529242  6363 solver.cpp:270] Iteration 2650 (3.85647 iter/s, 12.9652s/50 iter), loss = 0.0387542, remaining 0 hours and 40 minutes
I0109 00:33:04.529289  6363 solver.cpp:291]     Train net output #0: loss = 0.0387542 (* 1 = 0.0387542 loss)
I0109 00:33:04.529296  6363 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0109 00:33:17.482405  6363 solver.cpp:270] Iteration 2700 (3.86022 iter/s, 12.9526s/50 iter), loss = 0.0105266, remaining 0 hours and 40 minutes
I0109 00:33:17.482439  6363 solver.cpp:291]     Train net output #0: loss = 0.0105266 (* 1 = 0.0105266 loss)
I0109 00:33:17.482463  6363 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0109 00:33:30.418346  6363 solver.cpp:270] Iteration 2750 (3.86535 iter/s, 12.9354s/50 iter), loss = 0.0428511, remaining 0 hours and 39 minutes
I0109 00:33:30.418380  6363 solver.cpp:291]     Train net output #0: loss = 0.0428511 (* 1 = 0.0428511 loss)
I0109 00:33:30.418386  6363 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0109 00:33:43.357102  6363 solver.cpp:270] Iteration 2800 (3.86451 iter/s, 12.9382s/50 iter), loss = 0.0493443, remaining 0 hours and 39 minutes
I0109 00:33:43.357149  6363 solver.cpp:291]     Train net output #0: loss = 0.0493443 (* 1 = 0.0493443 loss)
I0109 00:33:43.357173  6363 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0109 00:33:56.335559  6363 solver.cpp:270] Iteration 2850 (3.8527 iter/s, 12.9779s/50 iter), loss = 0.0391749, remaining 0 hours and 39 minutes
I0109 00:33:56.335592  6363 solver.cpp:291]     Train net output #0: loss = 0.0391748 (* 1 = 0.0391748 loss)
I0109 00:33:56.335599  6363 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0109 00:34:09.293558  6363 solver.cpp:270] Iteration 2900 (3.85877 iter/s, 12.9575s/50 iter), loss = 0.0340987, remaining 0 hours and 39 minutes
I0109 00:34:09.293591  6363 solver.cpp:291]     Train net output #0: loss = 0.0340987 (* 1 = 0.0340987 loss)
I0109 00:34:09.293613  6363 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0109 00:34:22.231854  6363 solver.cpp:270] Iteration 2950 (3.86465 iter/s, 12.9378s/50 iter), loss = 0.0161549, remaining 0 hours and 38 minutes
I0109 00:34:22.231907  6363 solver.cpp:291]     Train net output #0: loss = 0.0161549 (* 1 = 0.0161549 loss)
I0109 00:34:22.231915  6363 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0109 00:34:34.924036  6363 solver.cpp:424] Iteration 3000, Testing net (#0)
I0109 00:34:36.461383  6363 solver.cpp:523]     Test net output #0: accuracy = 0.9475
I0109 00:34:36.461411  6363 solver.cpp:523]     Test net output #1: loss = 0.134207 (* 1 = 0.134207 loss)
I0109 00:34:36.461416  6363 solver.cpp:523]     Test net output #2: top-1 = 0.9475
I0109 00:34:36.712682  6363 solver.cpp:270] Iteration 3000 (3.45298 iter/s, 14.4802s/50 iter), loss = 0.0142967, remaining 0 hours and 43 minutes
I0109 00:34:36.712709  6363 solver.cpp:291]     Train net output #0: loss = 0.0142967 (* 1 = 0.0142967 loss)
I0109 00:34:36.712716  6363 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0109 00:34:49.650498  6363 solver.cpp:270] Iteration 3050 (3.86479 iter/s, 12.9373s/50 iter), loss = 0.0289499, remaining 0 hours and 38 minutes
I0109 00:34:49.650530  6363 solver.cpp:291]     Train net output #0: loss = 0.0289499 (* 1 = 0.0289499 loss)
I0109 00:34:49.650539  6363 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0109 00:35:02.596604  6363 solver.cpp:270] Iteration 3100 (3.86232 iter/s, 12.9456s/50 iter), loss = 0.00458616, remaining 0 hours and 38 minutes
I0109 00:35:02.596649  6363 solver.cpp:291]     Train net output #0: loss = 0.00458614 (* 1 = 0.00458614 loss)
I0109 00:35:02.596657  6363 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0109 00:35:15.549820  6363 solver.cpp:270] Iteration 3150 (3.8602 iter/s, 12.9527s/50 iter), loss = 0.0190792, remaining 0 hours and 38 minutes
I0109 00:35:15.549854  6363 solver.cpp:291]     Train net output #0: loss = 0.0190792 (* 1 = 0.0190792 loss)
I0109 00:35:15.549860  6363 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0109 00:35:28.505431  6363 solver.cpp:270] Iteration 3200 (3.85949 iter/s, 12.9551s/50 iter), loss = 0.0123098, remaining 0 hours and 37 minutes
I0109 00:35:28.505463  6363 solver.cpp:291]     Train net output #0: loss = 0.0123098 (* 1 = 0.0123098 loss)
I0109 00:35:28.505470  6363 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0109 00:35:41.457466  6363 solver.cpp:270] Iteration 3250 (3.86055 iter/s, 12.9515s/50 iter), loss = 0.0279676, remaining 0 hours and 37 minutes
I0109 00:35:41.457530  6363 solver.cpp:291]     Train net output #0: loss = 0.0279675 (* 1 = 0.0279675 loss)
I0109 00:35:41.457537  6363 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0109 00:35:54.441334  6363 solver.cpp:270] Iteration 3300 (3.85109 iter/s, 12.9833s/50 iter), loss = 0.0105243, remaining 0 hours and 37 minutes
I0109 00:35:54.441365  6363 solver.cpp:291]     Train net output #0: loss = 0.0105243 (* 1 = 0.0105243 loss)
I0109 00:35:54.441372  6363 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0109 00:36:07.366457  6363 solver.cpp:270] Iteration 3350 (3.86859 iter/s, 12.9246s/50 iter), loss = 0.0452963, remaining 0 hours and 37 minutes
I0109 00:36:07.366488  6363 solver.cpp:291]     Train net output #0: loss = 0.0452963 (* 1 = 0.0452963 loss)
I0109 00:36:07.366495  6363 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0109 00:36:20.327119  6363 solver.cpp:270] Iteration 3400 (3.85798 iter/s, 12.9601s/50 iter), loss = 0.0377052, remaining 0 hours and 37 minutes
I0109 00:36:20.327175  6363 solver.cpp:291]     Train net output #0: loss = 0.0377052 (* 1 = 0.0377052 loss)
I0109 00:36:20.327199  6363 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0109 00:36:33.292587  6363 solver.cpp:270] Iteration 3450 (3.85656 iter/s, 12.9649s/50 iter), loss = 0.0310163, remaining 0 hours and 36 minutes
I0109 00:36:33.292618  6363 solver.cpp:291]     Train net output #0: loss = 0.0310163 (* 1 = 0.0310163 loss)
I0109 00:36:33.292625  6363 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0109 00:36:46.241590  6363 solver.cpp:270] Iteration 3500 (3.86145 iter/s, 12.9485s/50 iter), loss = 0.0246244, remaining 0 hours and 36 minutes
I0109 00:36:46.241622  6363 solver.cpp:291]     Train net output #0: loss = 0.0246243 (* 1 = 0.0246243 loss)
I0109 00:36:46.241629  6363 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0109 00:36:59.198916  6363 solver.cpp:270] Iteration 3550 (3.85897 iter/s, 12.9568s/50 iter), loss = 0.0230198, remaining 0 hours and 36 minutes
I0109 00:36:59.198961  6363 solver.cpp:291]     Train net output #0: loss = 0.0230198 (* 1 = 0.0230198 loss)
I0109 00:36:59.198968  6363 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0109 00:37:12.140120  6363 solver.cpp:270] Iteration 3600 (3.86379 iter/s, 12.9407s/50 iter), loss = 0.0294603, remaining 0 hours and 36 minutes
I0109 00:37:12.140151  6363 solver.cpp:291]     Train net output #0: loss = 0.0294603 (* 1 = 0.0294603 loss)
I0109 00:37:12.140158  6363 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0109 00:37:25.090759  6363 solver.cpp:270] Iteration 3650 (3.86097 iter/s, 12.9501s/50 iter), loss = 0.023547, remaining 0 hours and 36 minutes
I0109 00:37:25.090793  6363 solver.cpp:291]     Train net output #0: loss = 0.023547 (* 1 = 0.023547 loss)
I0109 00:37:25.090801  6363 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0109 00:37:38.044559  6363 solver.cpp:270] Iteration 3700 (3.86003 iter/s, 12.9533s/50 iter), loss = 0.0299193, remaining 0 hours and 35 minutes
I0109 00:37:38.044605  6363 solver.cpp:291]     Train net output #0: loss = 0.0299192 (* 1 = 0.0299192 loss)
I0109 00:37:38.044629  6363 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0109 00:37:50.974799  6363 solver.cpp:270] Iteration 3750 (3.86706 iter/s, 12.9297s/50 iter), loss = 0.0295412, remaining 0 hours and 35 minutes
I0109 00:37:50.974830  6363 solver.cpp:291]     Train net output #0: loss = 0.0295411 (* 1 = 0.0295411 loss)
I0109 00:37:50.974838  6363 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0109 00:38:03.925105  6363 solver.cpp:270] Iteration 3800 (3.86107 iter/s, 12.9498s/50 iter), loss = 0.00734739, remaining 0 hours and 35 minutes
I0109 00:38:03.925137  6363 solver.cpp:291]     Train net output #0: loss = 0.00734737 (* 1 = 0.00734737 loss)
I0109 00:38:03.925159  6363 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0109 00:38:16.840144  6363 solver.cpp:270] Iteration 3850 (3.87161 iter/s, 12.9145s/50 iter), loss = 0.011238, remaining 0 hours and 34 minutes
I0109 00:38:16.840188  6363 solver.cpp:291]     Train net output #0: loss = 0.011238 (* 1 = 0.011238 loss)
I0109 00:38:16.840212  6363 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0109 00:38:29.788658  6363 solver.cpp:270] Iteration 3900 (3.8616 iter/s, 12.948s/50 iter), loss = 0.00887385, remaining 0 hours and 34 minutes
I0109 00:38:29.788691  6363 solver.cpp:291]     Train net output #0: loss = 0.00887383 (* 1 = 0.00887383 loss)
I0109 00:38:29.788698  6363 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0109 00:38:42.727890  6363 solver.cpp:270] Iteration 3950 (3.86437 iter/s, 12.9387s/50 iter), loss = 0.00865378, remaining 0 hours and 34 minutes
I0109 00:38:42.727921  6363 solver.cpp:291]     Train net output #0: loss = 0.00865376 (* 1 = 0.00865376 loss)
I0109 00:38:42.727946  6363 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0109 00:38:55.417575  6363 solver.cpp:424] Iteration 4000, Testing net (#0)
I0109 00:38:56.920037  6363 solver.cpp:523]     Test net output #0: accuracy = 0.943
I0109 00:38:56.920068  6363 solver.cpp:523]     Test net output #1: loss = 0.14529 (* 1 = 0.14529 loss)
I0109 00:38:56.920073  6363 solver.cpp:523]     Test net output #2: top-1 = 0.943
I0109 00:38:57.170872  6363 solver.cpp:270] Iteration 4000 (3.46202 iter/s, 14.4424s/50 iter), loss = 0.00512028, remaining 0 hours and 38 minutes
I0109 00:38:57.170902  6363 solver.cpp:291]     Train net output #0: loss = 0.00512026 (* 1 = 0.00512026 loss)
I0109 00:38:57.170908  6363 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0109 00:39:10.098826  6363 solver.cpp:270] Iteration 4050 (3.86774 iter/s, 12.9274s/50 iter), loss = 0.0301869, remaining 0 hours and 34 minutes
I0109 00:39:10.098860  6363 solver.cpp:291]     Train net output #0: loss = 0.0301869 (* 1 = 0.0301869 loss)
I0109 00:39:10.098867  6363 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0109 00:39:23.030264  6363 solver.cpp:270] Iteration 4100 (3.8667 iter/s, 12.9309s/50 iter), loss = 0.0198592, remaining 0 hours and 33 minutes
I0109 00:39:23.030297  6363 solver.cpp:291]     Train net output #0: loss = 0.0198591 (* 1 = 0.0198591 loss)
I0109 00:39:23.030305  6363 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0109 00:39:35.950736  6363 solver.cpp:270] Iteration 4150 (3.86998 iter/s, 12.92s/50 iter), loss = 0.00822668, remaining 0 hours and 33 minutes
I0109 00:39:35.950790  6363 solver.cpp:291]     Train net output #0: loss = 0.00822666 (* 1 = 0.00822666 loss)
I0109 00:39:35.950814  6363 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0109 00:39:48.888772  6363 solver.cpp:270] Iteration 4200 (3.86473 iter/s, 12.9375s/50 iter), loss = 0.0146385, remaining 0 hours and 33 minutes
I0109 00:39:48.888804  6363 solver.cpp:291]     Train net output #0: loss = 0.0146385 (* 1 = 0.0146385 loss)
I0109 00:39:48.888811  6363 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0109 00:40:01.831322  6363 solver.cpp:270] Iteration 4250 (3.86338 iter/s, 12.942s/50 iter), loss = 0.00922509, remaining 0 hours and 33 minutes
I0109 00:40:01.831353  6363 solver.cpp:291]     Train net output #0: loss = 0.00922507 (* 1 = 0.00922507 loss)
I0109 00:40:01.831362  6363 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0109 00:40:14.756863  6363 solver.cpp:270] Iteration 4300 (3.86846 iter/s, 12.925s/50 iter), loss = 0.028733, remaining 0 hours and 33 minutes
I0109 00:40:14.756908  6363 solver.cpp:291]     Train net output #0: loss = 0.028733 (* 1 = 0.028733 loss)
I0109 00:40:14.756916  6363 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0109 00:40:27.707085  6363 solver.cpp:270] Iteration 4350 (3.8611 iter/s, 12.9497s/50 iter), loss = 0.00316023, remaining 0 hours and 32 minutes
I0109 00:40:27.707118  6363 solver.cpp:291]     Train net output #0: loss = 0.00316022 (* 1 = 0.00316022 loss)
I0109 00:40:27.707141  6363 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0109 00:40:40.661128  6363 solver.cpp:270] Iteration 4400 (3.85995 iter/s, 12.9535s/50 iter), loss = 0.0146742, remaining 0 hours and 32 minutes
I0109 00:40:40.661159  6363 solver.cpp:291]     Train net output #0: loss = 0.0146742 (* 1 = 0.0146742 loss)
I0109 00:40:40.661182  6363 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0109 00:40:53.579885  6363 solver.cpp:270] Iteration 4450 (3.87049 iter/s, 12.9182s/50 iter), loss = 0.0208061, remaining 0 hours and 32 minutes
I0109 00:40:53.579931  6363 solver.cpp:291]     Train net output #0: loss = 0.0208061 (* 1 = 0.0208061 loss)
I0109 00:40:53.579939  6363 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0109 00:41:06.523277  6363 solver.cpp:270] Iteration 4500 (3.86313 iter/s, 12.9429s/50 iter), loss = 0.0118363, remaining 0 hours and 32 minutes
I0109 00:41:06.523309  6363 solver.cpp:291]     Train net output #0: loss = 0.0118363 (* 1 = 0.0118363 loss)
I0109 00:41:06.523316  6363 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0109 00:41:19.441277  6363 solver.cpp:270] Iteration 4550 (3.87072 iter/s, 12.9175s/50 iter), loss = 0.00338593, remaining 0 hours and 32 minutes
I0109 00:41:19.441308  6363 solver.cpp:291]     Train net output #0: loss = 0.00338593 (* 1 = 0.00338593 loss)
I0109 00:41:19.441332  6363 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0109 00:41:32.379487  6363 solver.cpp:270] Iteration 4600 (3.86468 iter/s, 12.9377s/50 iter), loss = 0.00436129, remaining 0 hours and 31 minutes
I0109 00:41:32.379560  6363 solver.cpp:291]     Train net output #0: loss = 0.00436129 (* 1 = 0.00436129 loss)
I0109 00:41:32.379570  6363 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0109 00:41:45.346201  6363 solver.cpp:270] Iteration 4650 (3.85619 iter/s, 12.9662s/50 iter), loss = 0.00414475, remaining 0 hours and 31 minutes
I0109 00:41:45.346233  6363 solver.cpp:291]     Train net output #0: loss = 0.00414475 (* 1 = 0.00414475 loss)
I0109 00:41:45.346240  6363 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0109 00:41:58.301656  6363 solver.cpp:270] Iteration 4700 (3.85953 iter/s, 12.9549s/50 iter), loss = 0.0108452, remaining 0 hours and 31 minutes
I0109 00:41:58.301688  6363 solver.cpp:291]     Train net output #0: loss = 0.0108452 (* 1 = 0.0108452 loss)
I0109 00:41:58.301697  6363 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0109 00:42:11.232991  6363 solver.cpp:270] Iteration 4750 (3.86673 iter/s, 12.9308s/50 iter), loss = 0.0104524, remaining 0 hours and 31 minutes
I0109 00:42:11.233037  6363 solver.cpp:291]     Train net output #0: loss = 0.0104524 (* 1 = 0.0104524 loss)
I0109 00:42:11.233062  6363 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0109 00:42:24.173692  6363 solver.cpp:270] Iteration 4800 (3.86394 iter/s, 12.9402s/50 iter), loss = 0.0228768, remaining 0 hours and 31 minutes
I0109 00:42:24.173725  6363 solver.cpp:291]     Train net output #0: loss = 0.0228768 (* 1 = 0.0228768 loss)
I0109 00:42:24.173734  6363 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0109 00:42:37.116295  6363 solver.cpp:270] Iteration 4850 (3.86336 iter/s, 12.9421s/50 iter), loss = 0.0376611, remaining 0 hours and 30 minutes
I0109 00:42:37.116328  6363 solver.cpp:291]     Train net output #0: loss = 0.0376611 (* 1 = 0.0376611 loss)
I0109 00:42:37.116335  6363 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0109 00:42:50.062937  6363 solver.cpp:270] Iteration 4900 (3.86216 iter/s, 12.9461s/50 iter), loss = 0.00917938, remaining 0 hours and 30 minutes
I0109 00:42:50.062983  6363 solver.cpp:291]     Train net output #0: loss = 0.00917939 (* 1 = 0.00917939 loss)
I0109 00:42:50.062989  6363 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0109 00:43:03.013907  6363 solver.cpp:270] Iteration 4950 (3.86087 iter/s, 12.9504s/50 iter), loss = 0.0149895, remaining 0 hours and 30 minutes
I0109 00:43:03.013942  6363 solver.cpp:291]     Train net output #0: loss = 0.0149895 (* 1 = 0.0149895 loss)
I0109 00:43:03.013964  6363 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0109 00:43:15.678575  6363 solver.cpp:424] Iteration 5000, Testing net (#0)
I0109 00:43:17.206429  6363 solver.cpp:523]     Test net output #0: accuracy = 0.94175
I0109 00:43:17.206459  6363 solver.cpp:523]     Test net output #1: loss = 0.170996 (* 1 = 0.170996 loss)
I0109 00:43:17.206465  6363 solver.cpp:523]     Test net output #2: top-1 = 0.94175
I0109 00:43:17.454388  6363 solver.cpp:270] Iteration 5000 (3.46263 iter/s, 14.4399s/50 iter), loss = 0.0179852, remaining 0 hours and 33 minutes
I0109 00:43:17.454416  6363 solver.cpp:291]     Train net output #0: loss = 0.0179852 (* 1 = 0.0179852 loss)
I0109 00:43:17.454425  6363 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0109 00:43:30.379019  6363 solver.cpp:270] Iteration 5050 (3.86874 iter/s, 12.9241s/50 iter), loss = 0.00842858, remaining 0 hours and 29 minutes
I0109 00:43:30.379065  6363 solver.cpp:291]     Train net output #0: loss = 0.0084286 (* 1 = 0.0084286 loss)
I0109 00:43:30.379072  6363 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0109 00:43:43.300890  6363 solver.cpp:270] Iteration 5100 (3.86957 iter/s, 12.9213s/50 iter), loss = 0.00426927, remaining 0 hours and 29 minutes
I0109 00:43:43.300930  6363 solver.cpp:291]     Train net output #0: loss = 0.00426929 (* 1 = 0.00426929 loss)
I0109 00:43:43.300940  6363 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0109 00:43:56.235219  6363 solver.cpp:270] Iteration 5150 (3.86584 iter/s, 12.9338s/50 iter), loss = 0.0108613, remaining 0 hours and 29 minutes
I0109 00:43:56.235251  6363 solver.cpp:291]     Train net output #0: loss = 0.0108613 (* 1 = 0.0108613 loss)
I0109 00:43:56.235275  6363 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0109 00:44:09.192247  6363 solver.cpp:270] Iteration 5200 (3.85906 iter/s, 12.9565s/50 iter), loss = 0.0114239, remaining 0 hours and 29 minutes
I0109 00:44:09.192301  6363 solver.cpp:291]     Train net output #0: loss = 0.0114239 (* 1 = 0.0114239 loss)
I0109 00:44:09.192309  6363 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0109 00:44:22.139124  6363 solver.cpp:270] Iteration 5250 (3.86209 iter/s, 12.9463s/50 iter), loss = 0.00647776, remaining 0 hours and 28 minutes
I0109 00:44:22.139156  6363 solver.cpp:291]     Train net output #0: loss = 0.00647779 (* 1 = 0.00647779 loss)
I0109 00:44:22.139179  6363 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0109 00:44:35.077081  6363 solver.cpp:270] Iteration 5300 (3.86475 iter/s, 12.9374s/50 iter), loss = 0.0173089, remaining 0 hours and 28 minutes
I0109 00:44:35.077113  6363 solver.cpp:291]     Train net output #0: loss = 0.0173089 (* 1 = 0.0173089 loss)
I0109 00:44:35.077121  6363 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0109 00:44:48.027828  6363 solver.cpp:270] Iteration 5350 (3.86093 iter/s, 12.9502s/50 iter), loss = 0.0255099, remaining 0 hours and 28 minutes
I0109 00:44:48.027873  6363 solver.cpp:291]     Train net output #0: loss = 0.02551 (* 1 = 0.02551 loss)
I0109 00:44:48.027879  6363 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0109 00:45:00.944372  6363 solver.cpp:270] Iteration 5400 (3.87116 iter/s, 12.916s/50 iter), loss = 0.00887171, remaining 0 hours and 28 minutes
I0109 00:45:00.944403  6363 solver.cpp:291]     Train net output #0: loss = 0.00887174 (* 1 = 0.00887174 loss)
I0109 00:45:00.944411  6363 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0109 00:45:13.855011  6363 solver.cpp:270] Iteration 5450 (3.87293 iter/s, 12.9101s/50 iter), loss = 0.0032437, remaining 0 hours and 28 minutes
I0109 00:45:13.855044  6363 solver.cpp:291]     Train net output #0: loss = 0.00324373 (* 1 = 0.00324373 loss)
I0109 00:45:13.855052  6363 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0109 00:45:26.803887  6363 solver.cpp:270] Iteration 5500 (3.86149 iter/s, 12.9484s/50 iter), loss = 0.0164707, remaining 0 hours and 27 minutes
I0109 00:45:26.803931  6363 solver.cpp:291]     Train net output #0: loss = 0.0164707 (* 1 = 0.0164707 loss)
I0109 00:45:26.803956  6363 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0109 00:45:39.734431  6363 solver.cpp:270] Iteration 5550 (3.86697 iter/s, 12.93s/50 iter), loss = 0.00346362, remaining 0 hours and 27 minutes
I0109 00:45:39.734463  6363 solver.cpp:291]     Train net output #0: loss = 0.00346365 (* 1 = 0.00346365 loss)
I0109 00:45:39.734470  6363 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0109 00:45:52.665482  6363 solver.cpp:270] Iteration 5600 (3.86682 iter/s, 12.9305s/50 iter), loss = 0.000523292, remaining 0 hours and 27 minutes
I0109 00:45:52.665513  6363 solver.cpp:291]     Train net output #0: loss = 0.000523315 (* 1 = 0.000523315 loss)
I0109 00:45:52.665520  6363 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0109 00:46:05.606297  6363 solver.cpp:270] Iteration 5650 (3.8639 iter/s, 12.9403s/50 iter), loss = 0.00508532, remaining 0 hours and 27 minutes
I0109 00:46:05.606343  6363 solver.cpp:291]     Train net output #0: loss = 0.00508534 (* 1 = 0.00508534 loss)
I0109 00:46:05.606351  6363 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0109 00:46:18.555796  6363 solver.cpp:270] Iteration 5700 (3.86131 iter/s, 12.949s/50 iter), loss = 0.0119026, remaining 0 hours and 27 minutes
I0109 00:46:18.555827  6363 solver.cpp:291]     Train net output #0: loss = 0.0119026 (* 1 = 0.0119026 loss)
I0109 00:46:18.555850  6363 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0109 00:46:31.475589  6363 solver.cpp:270] Iteration 5750 (3.87018 iter/s, 12.9193s/50 iter), loss = 0.00830266, remaining 0 hours and 26 minutes
I0109 00:46:31.475621  6363 solver.cpp:291]     Train net output #0: loss = 0.00830269 (* 1 = 0.00830269 loss)
I0109 00:46:31.475628  6363 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0109 00:46:44.411499  6363 solver.cpp:270] Iteration 5800 (3.86536 iter/s, 12.9354s/50 iter), loss = 0.000635155, remaining 0 hours and 26 minutes
I0109 00:46:44.411550  6363 solver.cpp:291]     Train net output #0: loss = 0.000635177 (* 1 = 0.000635177 loss)
I0109 00:46:44.411556  6363 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0109 00:46:57.337082  6363 solver.cpp:270] Iteration 5850 (3.86846 iter/s, 12.9251s/50 iter), loss = 0.0074361, remaining 0 hours and 26 minutes
I0109 00:46:57.337113  6363 solver.cpp:291]     Train net output #0: loss = 0.00743612 (* 1 = 0.00743612 loss)
I0109 00:46:57.337121  6363 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0109 00:47:10.277364  6363 solver.cpp:270] Iteration 5900 (3.86406 iter/s, 12.9398s/50 iter), loss = 0.0161018, remaining 0 hours and 26 minutes
I0109 00:47:10.277395  6363 solver.cpp:291]     Train net output #0: loss = 0.0161018 (* 1 = 0.0161018 loss)
I0109 00:47:10.277401  6363 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0109 00:47:23.210402  6363 solver.cpp:270] Iteration 5950 (3.86622 iter/s, 12.9325s/50 iter), loss = 0.00457532, remaining 0 hours and 25 minutes
I0109 00:47:23.210448  6363 solver.cpp:291]     Train net output #0: loss = 0.00457534 (* 1 = 0.00457534 loss)
I0109 00:47:23.210455  6363 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0109 00:47:35.882555  6363 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_6000.caffemodel
I0109 00:47:38.364821  6363 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_6000.solverstate
I0109 00:47:38.586810  6363 solver.cpp:424] Iteration 6000, Testing net (#0)
I0109 00:47:40.053232  6363 solver.cpp:523]     Test net output #0: accuracy = 0.9515
I0109 00:47:40.053262  6363 solver.cpp:523]     Test net output #1: loss = 0.197807 (* 1 = 0.197807 loss)
I0109 00:47:40.053267  6363 solver.cpp:523]     Test net output #2: top-1 = 0.9515
I0109 00:47:40.298713  6363 solver.cpp:270] Iteration 6000 (2.92609 iter/s, 17.0876s/50 iter), loss = 0.00169379, remaining 0 hours and 34 minutes
I0109 00:47:40.298741  6363 solver.cpp:291]     Train net output #0: loss = 0.00169381 (* 1 = 0.00169381 loss)
I0109 00:47:40.298748  6363 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0109 00:47:53.238358  6363 solver.cpp:270] Iteration 6050 (3.86425 iter/s, 12.9391s/50 iter), loss = 0.00251505, remaining 0 hours and 25 minutes
I0109 00:47:53.238401  6363 solver.cpp:291]     Train net output #0: loss = 0.00251507 (* 1 = 0.00251507 loss)
I0109 00:47:53.238409  6363 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0109 00:48:06.189436  6363 solver.cpp:270] Iteration 6100 (3.86084 iter/s, 12.9506s/50 iter), loss = 0.00210742, remaining 0 hours and 25 minutes
I0109 00:48:06.189467  6363 solver.cpp:291]     Train net output #0: loss = 0.00210745 (* 1 = 0.00210745 loss)
I0109 00:48:06.189491  6363 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0109 00:48:19.103328  6363 solver.cpp:270] Iteration 6150 (3.87195 iter/s, 12.9134s/50 iter), loss = 0.00351019, remaining 0 hours and 25 minutes
I0109 00:48:19.103361  6363 solver.cpp:291]     Train net output #0: loss = 0.00351022 (* 1 = 0.00351022 loss)
I0109 00:48:19.103385  6363 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0109 00:48:32.044550  6363 solver.cpp:270] Iteration 6200 (3.86378 iter/s, 12.9407s/50 iter), loss = 0.00486735, remaining 0 hours and 24 minutes
I0109 00:48:32.044595  6363 solver.cpp:291]     Train net output #0: loss = 0.00486737 (* 1 = 0.00486737 loss)
I0109 00:48:32.044602  6363 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0109 00:48:44.978644  6363 solver.cpp:270] Iteration 6250 (3.86591 iter/s, 12.9336s/50 iter), loss = 0.000615367, remaining 0 hours and 24 minutes
I0109 00:48:44.978675  6363 solver.cpp:291]     Train net output #0: loss = 0.000615393 (* 1 = 0.000615393 loss)
I0109 00:48:44.978699  6363 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0109 00:48:57.903874  6363 solver.cpp:270] Iteration 6300 (3.86856 iter/s, 12.9247s/50 iter), loss = 0.00110392, remaining 0 hours and 24 minutes
I0109 00:48:57.903908  6363 solver.cpp:291]     Train net output #0: loss = 0.00110395 (* 1 = 0.00110395 loss)
I0109 00:48:57.903931  6363 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0109 00:49:10.869240  6363 solver.cpp:270] Iteration 6350 (3.85658 iter/s, 12.9649s/50 iter), loss = 0.00251843, remaining 0 hours and 24 minutes
I0109 00:49:10.869292  6363 solver.cpp:291]     Train net output #0: loss = 0.00251846 (* 1 = 0.00251846 loss)
I0109 00:49:10.869300  6363 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0109 00:49:23.798312  6363 solver.cpp:270] Iteration 6400 (3.86741 iter/s, 12.9285s/50 iter), loss = 0.0039599, remaining 0 hours and 24 minutes
I0109 00:49:23.798341  6363 solver.cpp:291]     Train net output #0: loss = 0.00395992 (* 1 = 0.00395992 loss)
I0109 00:49:23.798349  6363 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0109 00:49:36.757987  6363 solver.cpp:270] Iteration 6450 (3.85827 iter/s, 12.9592s/50 iter), loss = 0.00214615, remaining 0 hours and 23 minutes
I0109 00:49:36.758018  6363 solver.cpp:291]     Train net output #0: loss = 0.00214618 (* 1 = 0.00214618 loss)
I0109 00:49:36.758024  6363 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0109 00:49:49.693958  6363 solver.cpp:270] Iteration 6500 (3.86535 iter/s, 12.9355s/50 iter), loss = 0.00311865, remaining 0 hours and 23 minutes
I0109 00:49:49.694005  6363 solver.cpp:291]     Train net output #0: loss = 0.00311867 (* 1 = 0.00311867 loss)
I0109 00:49:49.694012  6363 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0109 00:50:02.627795  6363 solver.cpp:270] Iteration 6550 (3.86599 iter/s, 12.9333s/50 iter), loss = 0.0224318, remaining 0 hours and 23 minutes
I0109 00:50:02.627826  6363 solver.cpp:291]     Train net output #0: loss = 0.0224319 (* 1 = 0.0224319 loss)
I0109 00:50:02.627851  6363 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0109 00:50:15.559569  6363 solver.cpp:270] Iteration 6600 (3.8666 iter/s, 12.9313s/50 iter), loss = 0.00127657, remaining 0 hours and 23 minutes
I0109 00:50:15.559602  6363 solver.cpp:291]     Train net output #0: loss = 0.00127659 (* 1 = 0.00127659 loss)
I0109 00:50:15.559609  6363 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0109 00:50:28.499270  6363 solver.cpp:270] Iteration 6650 (3.86423 iter/s, 12.9392s/50 iter), loss = 0.000439152, remaining 0 hours and 23 minutes
I0109 00:50:28.499315  6363 solver.cpp:291]     Train net output #0: loss = 0.000439175 (* 1 = 0.000439175 loss)
I0109 00:50:28.499322  6363 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0109 00:50:41.434636  6363 solver.cpp:270] Iteration 6700 (3.86553 iter/s, 12.9348s/50 iter), loss = 0.00217887, remaining 0 hours and 22 minutes
I0109 00:50:41.434669  6363 solver.cpp:291]     Train net output #0: loss = 0.00217889 (* 1 = 0.00217889 loss)
I0109 00:50:41.434675  6363 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0109 00:50:54.383462  6363 solver.cpp:270] Iteration 6750 (3.86151 iter/s, 12.9483s/50 iter), loss = 0.011764, remaining 0 hours and 22 minutes
I0109 00:50:54.383493  6363 solver.cpp:291]     Train net output #0: loss = 0.011764 (* 1 = 0.011764 loss)
I0109 00:50:54.383515  6363 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0109 00:51:07.314894  6363 solver.cpp:270] Iteration 6800 (3.8667 iter/s, 12.9309s/50 iter), loss = 0.00862321, remaining 0 hours and 22 minutes
I0109 00:51:07.314939  6363 solver.cpp:291]     Train net output #0: loss = 0.00862323 (* 1 = 0.00862323 loss)
I0109 00:51:07.314945  6363 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0109 00:51:20.235826  6363 solver.cpp:270] Iteration 6850 (3.86985 iter/s, 12.9204s/50 iter), loss = 0.00227126, remaining 0 hours and 21 minutes
I0109 00:51:20.235857  6363 solver.cpp:291]     Train net output #0: loss = 0.00227128 (* 1 = 0.00227128 loss)
I0109 00:51:20.235865  6363 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0109 00:51:33.199250  6363 solver.cpp:270] Iteration 6900 (3.85716 iter/s, 12.9629s/50 iter), loss = 0.0137214, remaining 0 hours and 22 minutes
I0109 00:51:33.199283  6363 solver.cpp:291]     Train net output #0: loss = 0.0137215 (* 1 = 0.0137215 loss)
I0109 00:51:33.199291  6363 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0109 00:51:46.138451  6363 solver.cpp:270] Iteration 6950 (3.86438 iter/s, 12.9387s/50 iter), loss = 0.00258827, remaining 0 hours and 21 minutes
I0109 00:51:46.138507  6363 solver.cpp:291]     Train net output #0: loss = 0.00258829 (* 1 = 0.00258829 loss)
I0109 00:51:46.138514  6363 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0109 00:51:58.809073  6363 solver.cpp:424] Iteration 7000, Testing net (#0)
I0109 00:52:00.329049  6363 solver.cpp:523]     Test net output #0: accuracy = 0.95
I0109 00:52:00.329078  6363 solver.cpp:523]     Test net output #1: loss = 0.233368 (* 1 = 0.233368 loss)
I0109 00:52:00.329084  6363 solver.cpp:523]     Test net output #2: top-1 = 0.95
I0109 00:52:00.580700  6363 solver.cpp:270] Iteration 7000 (3.46221 iter/s, 14.4417s/50 iter), loss = 0.0118211, remaining 0 hours and 23 minutes
I0109 00:52:00.580727  6363 solver.cpp:291]     Train net output #0: loss = 0.0118211 (* 1 = 0.0118211 loss)
I0109 00:52:00.580735  6363 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0109 00:52:13.540597  6363 solver.cpp:270] Iteration 7050 (3.85821 iter/s, 12.9594s/50 iter), loss = 0.00371948, remaining 0 hours and 21 minutes
I0109 00:52:13.540629  6363 solver.cpp:291]     Train net output #0: loss = 0.0037195 (* 1 = 0.0037195 loss)
I0109 00:52:13.540637  6363 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0109 00:52:26.441222  6363 solver.cpp:270] Iteration 7100 (3.87594 iter/s, 12.9001s/50 iter), loss = 0.00918676, remaining 0 hours and 20 minutes
I0109 00:52:26.441272  6363 solver.cpp:291]     Train net output #0: loss = 0.00918677 (* 1 = 0.00918677 loss)
I0109 00:52:26.441280  6363 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0109 00:52:39.358402  6363 solver.cpp:270] Iteration 7150 (3.87097 iter/s, 12.9166s/50 iter), loss = 0.00565075, remaining 0 hours and 20 minutes
I0109 00:52:39.358434  6363 solver.cpp:291]     Train net output #0: loss = 0.00565077 (* 1 = 0.00565077 loss)
I0109 00:52:39.358443  6363 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0109 00:52:52.278673  6363 solver.cpp:270] Iteration 7200 (3.87004 iter/s, 12.9198s/50 iter), loss = 0.00642314, remaining 0 hours and 20 minutes
I0109 00:52:52.278704  6363 solver.cpp:291]     Train net output #0: loss = 0.00642315 (* 1 = 0.00642315 loss)
I0109 00:52:52.278728  6363 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0109 00:53:05.205240  6363 solver.cpp:270] Iteration 7250 (3.86816 iter/s, 12.9261s/50 iter), loss = 0.0154475, remaining 0 hours and 20 minutes
I0109 00:53:05.205284  6363 solver.cpp:291]     Train net output #0: loss = 0.0154475 (* 1 = 0.0154475 loss)
I0109 00:53:05.205307  6363 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0109 00:53:18.124617  6363 solver.cpp:270] Iteration 7300 (3.87031 iter/s, 12.9189s/50 iter), loss = 0.0115109, remaining 0 hours and 20 minutes
I0109 00:53:18.124648  6363 solver.cpp:291]     Train net output #0: loss = 0.0115109 (* 1 = 0.0115109 loss)
I0109 00:53:18.124671  6363 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0109 00:53:31.085614  6363 solver.cpp:270] Iteration 7350 (3.85788 iter/s, 12.9605s/50 iter), loss = 0.0162726, remaining 0 hours and 19 minutes
I0109 00:53:31.085649  6363 solver.cpp:291]     Train net output #0: loss = 0.0162727 (* 1 = 0.0162727 loss)
I0109 00:53:31.085672  6363 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0109 00:53:44.023299  6363 solver.cpp:270] Iteration 7400 (3.86483 iter/s, 12.9372s/50 iter), loss = 0.0189395, remaining 0 hours and 19 minutes
I0109 00:53:44.023353  6363 solver.cpp:291]     Train net output #0: loss = 0.0189395 (* 1 = 0.0189395 loss)
I0109 00:53:44.023366  6363 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0109 00:53:56.940882  6363 solver.cpp:270] Iteration 7450 (3.87085 iter/s, 12.9171s/50 iter), loss = 0.0191233, remaining 0 hours and 19 minutes
I0109 00:53:56.940922  6363 solver.cpp:291]     Train net output #0: loss = 0.0191233 (* 1 = 0.0191233 loss)
I0109 00:53:56.940932  6363 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0109 00:54:09.915341  6363 solver.cpp:270] Iteration 7500 (3.85388 iter/s, 12.9739s/50 iter), loss = 0.00105071, remaining 0 hours and 19 minutes
I0109 00:54:09.915380  6363 solver.cpp:291]     Train net output #0: loss = 0.00105073 (* 1 = 0.00105073 loss)
I0109 00:54:09.915393  6363 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0109 00:54:22.838451  6363 solver.cpp:270] Iteration 7550 (3.86919 iter/s, 12.9226s/50 iter), loss = 0.0061669, remaining 0 hours and 19 minutes
I0109 00:54:22.838510  6363 solver.cpp:291]     Train net output #0: loss = 0.00616693 (* 1 = 0.00616693 loss)
I0109 00:54:22.838521  6363 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0109 00:54:35.788841  6363 solver.cpp:270] Iteration 7600 (3.86105 iter/s, 12.9499s/50 iter), loss = 0.00127814, remaining 0 hours and 18 minutes
I0109 00:54:35.788882  6363 solver.cpp:291]     Train net output #0: loss = 0.00127817 (* 1 = 0.00127817 loss)
I0109 00:54:35.788894  6363 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0109 00:54:48.732450  6363 solver.cpp:270] Iteration 7650 (3.86307 iter/s, 12.9431s/50 iter), loss = 0.00271301, remaining 0 hours and 18 minutes
I0109 00:54:48.732483  6363 solver.cpp:291]     Train net output #0: loss = 0.00271304 (* 1 = 0.00271304 loss)
I0109 00:54:48.732506  6363 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0109 00:55:01.678824  6363 solver.cpp:270] Iteration 7700 (3.86224 iter/s, 12.9459s/50 iter), loss = 0.00704628, remaining 0 hours and 18 minutes
I0109 00:55:01.678872  6363 solver.cpp:291]     Train net output #0: loss = 0.00704631 (* 1 = 0.00704631 loss)
I0109 00:55:01.678879  6363 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0109 00:55:14.636629  6363 solver.cpp:270] Iteration 7750 (3.85884 iter/s, 12.9573s/50 iter), loss = 0.00620258, remaining 0 hours and 18 minutes
I0109 00:55:14.636662  6363 solver.cpp:291]     Train net output #0: loss = 0.00620261 (* 1 = 0.00620261 loss)
I0109 00:55:14.636685  6363 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0109 00:55:27.562631  6363 solver.cpp:270] Iteration 7800 (3.86833 iter/s, 12.9255s/50 iter), loss = 0.0125535, remaining 0 hours and 18 minutes
I0109 00:55:27.562664  6363 solver.cpp:291]     Train net output #0: loss = 0.0125536 (* 1 = 0.0125536 loss)
I0109 00:55:27.562672  6363 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0109 00:55:40.499054  6363 solver.cpp:270] Iteration 7850 (3.86521 iter/s, 12.9359s/50 iter), loss = 0.00342682, remaining 0 hours and 17 minutes
I0109 00:55:40.499099  6363 solver.cpp:291]     Train net output #0: loss = 0.00342685 (* 1 = 0.00342685 loss)
I0109 00:55:40.499107  6363 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0109 00:55:53.436560  6363 solver.cpp:270] Iteration 7900 (3.86489 iter/s, 12.937s/50 iter), loss = 0.013525, remaining 0 hours and 17 minutes
I0109 00:55:53.436592  6363 solver.cpp:291]     Train net output #0: loss = 0.013525 (* 1 = 0.013525 loss)
I0109 00:55:53.436615  6363 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0109 00:56:06.385285  6363 solver.cpp:270] Iteration 7950 (3.86154 iter/s, 12.9482s/50 iter), loss = 0.002656, remaining 0 hours and 17 minutes
I0109 00:56:06.385316  6363 solver.cpp:291]     Train net output #0: loss = 0.00265604 (* 1 = 0.00265604 loss)
I0109 00:56:06.385339  6363 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0109 00:56:19.045900  6363 solver.cpp:424] Iteration 8000, Testing net (#0)
I0109 00:56:20.593147  6363 solver.cpp:523]     Test net output #0: accuracy = 0.953
I0109 00:56:20.593175  6363 solver.cpp:523]     Test net output #1: loss = 0.258043 (* 1 = 0.258043 loss)
I0109 00:56:20.593180  6363 solver.cpp:523]     Test net output #2: top-1 = 0.953
I0109 00:56:20.839884  6363 solver.cpp:270] Iteration 8000 (3.45924 iter/s, 14.454s/50 iter), loss = 0.000210291, remaining 0 hours and 19 minutes
I0109 00:56:20.839910  6363 solver.cpp:291]     Train net output #0: loss = 0.000210329 (* 1 = 0.000210329 loss)
I0109 00:56:20.839918  6363 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0109 00:56:33.766878  6363 solver.cpp:270] Iteration 8050 (3.86803 iter/s, 12.9265s/50 iter), loss = 0.00471207, remaining 0 hours and 16 minutes
I0109 00:56:33.766911  6363 solver.cpp:291]     Train net output #0: loss = 0.0047121 (* 1 = 0.0047121 loss)
I0109 00:56:33.766918  6363 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0109 00:56:46.731992  6363 solver.cpp:270] Iteration 8100 (3.85666 iter/s, 12.9646s/50 iter), loss = 0.00157798, remaining 0 hours and 16 minutes
I0109 00:56:46.732024  6363 solver.cpp:291]     Train net output #0: loss = 0.00157801 (* 1 = 0.00157801 loss)
I0109 00:56:46.732033  6363 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0109 00:56:59.647797  6363 solver.cpp:270] Iteration 8150 (3.87138 iter/s, 12.9153s/50 iter), loss = 0.00157374, remaining 0 hours and 16 minutes
I0109 00:56:59.647850  6363 solver.cpp:291]     Train net output #0: loss = 0.00157378 (* 1 = 0.00157378 loss)
I0109 00:56:59.647874  6363 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0109 00:57:12.582039  6363 solver.cpp:270] Iteration 8200 (3.86587 iter/s, 12.9337s/50 iter), loss = 0.0018933, remaining 0 hours and 16 minutes
I0109 00:57:12.582070  6363 solver.cpp:291]     Train net output #0: loss = 0.00189333 (* 1 = 0.00189333 loss)
I0109 00:57:12.582093  6363 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0109 00:57:25.527729  6363 solver.cpp:270] Iteration 8250 (3.86244 iter/s, 12.9452s/50 iter), loss = 0.000264163, remaining 0 hours and 16 minutes
I0109 00:57:25.527760  6363 solver.cpp:291]     Train net output #0: loss = 0.000264205 (* 1 = 0.000264205 loss)
I0109 00:57:25.527783  6363 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0109 00:57:38.468585  6363 solver.cpp:270] Iteration 8300 (3.86388 iter/s, 12.9403s/50 iter), loss = 0.000924311, remaining 0 hours and 15 minutes
I0109 00:57:38.468629  6363 solver.cpp:291]     Train net output #0: loss = 0.000924353 (* 1 = 0.000924353 loss)
I0109 00:57:38.468654  6363 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0109 00:57:51.400919  6363 solver.cpp:270] Iteration 8350 (3.86644 iter/s, 12.9318s/50 iter), loss = 0.00256272, remaining 0 hours and 15 minutes
I0109 00:57:51.400951  6363 solver.cpp:291]     Train net output #0: loss = 0.00256276 (* 1 = 0.00256276 loss)
I0109 00:57:51.400974  6363 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0109 00:58:04.368921  6363 solver.cpp:270] Iteration 8400 (3.8558 iter/s, 12.9675s/50 iter), loss = 0.00386108, remaining 0 hours and 15 minutes
I0109 00:58:04.368952  6363 solver.cpp:291]     Train net output #0: loss = 0.00386112 (* 1 = 0.00386112 loss)
I0109 00:58:04.368960  6363 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0109 00:58:17.306041  6363 solver.cpp:270] Iteration 8450 (3.865 iter/s, 12.9366s/50 iter), loss = 0.00156268, remaining 0 hours and 15 minutes
I0109 00:58:17.306087  6363 solver.cpp:291]     Train net output #0: loss = 0.00156272 (* 1 = 0.00156272 loss)
I0109 00:58:17.306110  6363 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0109 00:58:30.245988  6363 solver.cpp:270] Iteration 8500 (3.86416 iter/s, 12.9394s/50 iter), loss = 0.00807896, remaining 0 hours and 15 minutes
I0109 00:58:30.246021  6363 solver.cpp:291]     Train net output #0: loss = 0.008079 (* 1 = 0.008079 loss)
I0109 00:58:30.246043  6363 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0109 00:58:43.182389  6363 solver.cpp:270] Iteration 8550 (3.86522 iter/s, 12.9359s/50 iter), loss = 0.0263554, remaining 0 hours and 14 minutes
I0109 00:58:43.182420  6363 solver.cpp:291]     Train net output #0: loss = 0.0263554 (* 1 = 0.0263554 loss)
I0109 00:58:43.182427  6363 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0109 00:58:56.095235  6363 solver.cpp:270] Iteration 8600 (3.87227 iter/s, 12.9123s/50 iter), loss = 0.0115083, remaining 0 hours and 14 minutes
I0109 00:58:56.095283  6363 solver.cpp:291]     Train net output #0: loss = 0.0115084 (* 1 = 0.0115084 loss)
I0109 00:58:56.095290  6363 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0109 00:59:09.080957  6363 solver.cpp:270] Iteration 8650 (3.85054 iter/s, 12.9852s/50 iter), loss = 0.00991724, remaining 0 hours and 14 minutes
I0109 00:59:09.080989  6363 solver.cpp:291]     Train net output #0: loss = 0.00991729 (* 1 = 0.00991729 loss)
I0109 00:59:09.080997  6363 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0109 00:59:22.031226  6363 solver.cpp:270] Iteration 8700 (3.86108 iter/s, 12.9498s/50 iter), loss = 0.0124522, remaining 0 hours and 14 minutes
I0109 00:59:22.031260  6363 solver.cpp:291]     Train net output #0: loss = 0.0124522 (* 1 = 0.0124522 loss)
I0109 00:59:22.031267  6363 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0109 00:59:34.987028  6363 solver.cpp:270] Iteration 8750 (3.85943 iter/s, 12.9553s/50 iter), loss = 0.00208768, remaining 0 hours and 13 minutes
I0109 00:59:34.987082  6363 solver.cpp:291]     Train net output #0: loss = 0.00208773 (* 1 = 0.00208773 loss)
I0109 00:59:34.987088  6363 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0109 00:59:47.920226  6363 solver.cpp:270] Iteration 8800 (3.86618 iter/s, 12.9327s/50 iter), loss = 0.00968006, remaining 0 hours and 13 minutes
I0109 00:59:47.920258  6363 solver.cpp:291]     Train net output #0: loss = 0.0096801 (* 1 = 0.0096801 loss)
I0109 00:59:47.920281  6363 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0109 01:00:00.871702  6363 solver.cpp:270] Iteration 8850 (3.86072 iter/s, 12.951s/50 iter), loss = 0.000788501, remaining 0 hours and 13 minutes
I0109 01:00:00.871737  6363 solver.cpp:291]     Train net output #0: loss = 0.000788547 (* 1 = 0.000788547 loss)
I0109 01:00:00.871760  6363 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0109 01:00:13.799257  6363 solver.cpp:270] Iteration 8900 (3.86786 iter/s, 12.927s/50 iter), loss = 0.00596408, remaining 0 hours and 13 minutes
I0109 01:00:13.799302  6363 solver.cpp:291]     Train net output #0: loss = 0.00596413 (* 1 = 0.00596413 loss)
I0109 01:00:13.799310  6363 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0109 01:00:26.721853  6363 solver.cpp:270] Iteration 8950 (3.86935 iter/s, 12.9221s/50 iter), loss = 0.00267604, remaining 0 hours and 12 minutes
I0109 01:00:26.721885  6363 solver.cpp:291]     Train net output #0: loss = 0.00267609 (* 1 = 0.00267609 loss)
I0109 01:00:26.721892  6363 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0109 01:00:39.418901  6363 solver.cpp:424] Iteration 9000, Testing net (#0)
I0109 01:00:40.908445  6363 solver.cpp:523]     Test net output #0: accuracy = 0.95225
I0109 01:00:40.908473  6363 solver.cpp:523]     Test net output #1: loss = 0.280003 (* 1 = 0.280003 loss)
I0109 01:00:40.908478  6363 solver.cpp:523]     Test net output #2: top-1 = 0.95225
I0109 01:00:41.159895  6363 solver.cpp:270] Iteration 9000 (3.46321 iter/s, 14.4375s/50 iter), loss = 0.00187425, remaining 0 hours and 14 minutes
I0109 01:00:41.159931  6363 solver.cpp:291]     Train net output #0: loss = 0.00187429 (* 1 = 0.00187429 loss)
I0109 01:00:41.159941  6363 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0109 01:00:54.098239  6363 solver.cpp:270] Iteration 9050 (3.86464 iter/s, 12.9378s/50 iter), loss = 0.000431711, remaining 0 hours and 12 minutes
I0109 01:00:54.098285  6363 solver.cpp:291]     Train net output #0: loss = 0.000431756 (* 1 = 0.000431756 loss)
I0109 01:00:54.098309  6363 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0109 01:01:07.031888  6363 solver.cpp:270] Iteration 9100 (3.86604 iter/s, 12.9331s/50 iter), loss = 0.0225357, remaining 0 hours and 12 minutes
I0109 01:01:07.031919  6363 solver.cpp:291]     Train net output #0: loss = 0.0225358 (* 1 = 0.0225358 loss)
I0109 01:01:07.031927  6363 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0109 01:01:19.967563  6363 solver.cpp:270] Iteration 9150 (3.86543 iter/s, 12.9352s/50 iter), loss = 0.00305336, remaining 0 hours and 12 minutes
I0109 01:01:19.967593  6363 solver.cpp:291]     Train net output #0: loss = 0.00305341 (* 1 = 0.00305341 loss)
I0109 01:01:19.967602  6363 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0109 01:01:32.930836  6363 solver.cpp:270] Iteration 9200 (3.8572 iter/s, 12.9628s/50 iter), loss = 0.00374593, remaining 0 hours and 11 minutes
I0109 01:01:32.930891  6363 solver.cpp:291]     Train net output #0: loss = 0.00374597 (* 1 = 0.00374597 loss)
I0109 01:01:32.930898  6363 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0109 01:01:45.869958  6363 solver.cpp:270] Iteration 9250 (3.86441 iter/s, 12.9386s/50 iter), loss = 0.000186265, remaining 0 hours and 11 minutes
I0109 01:01:45.869990  6363 solver.cpp:291]     Train net output #0: loss = 0.000186311 (* 1 = 0.000186311 loss)
I0109 01:01:45.870013  6363 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0109 01:01:58.828236  6363 solver.cpp:270] Iteration 9300 (3.85869 iter/s, 12.9578s/50 iter), loss = 0.00796454, remaining 0 hours and 11 minutes
I0109 01:01:58.828269  6363 solver.cpp:291]     Train net output #0: loss = 0.00796459 (* 1 = 0.00796459 loss)
I0109 01:01:58.828276  6363 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0109 01:02:11.748961  6363 solver.cpp:270] Iteration 9350 (3.86991 iter/s, 12.9202s/50 iter), loss = 0.00278334, remaining 0 hours and 11 minutes
I0109 01:02:11.749006  6363 solver.cpp:291]     Train net output #0: loss = 0.00278338 (* 1 = 0.00278338 loss)
I0109 01:02:11.749032  6363 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0109 01:02:24.667886  6363 solver.cpp:270] Iteration 9400 (3.87045 iter/s, 12.9184s/50 iter), loss = 0.00571206, remaining 0 hours and 11 minutes
I0109 01:02:24.667917  6363 solver.cpp:291]     Train net output #0: loss = 0.00571211 (* 1 = 0.00571211 loss)
I0109 01:02:24.667924  6363 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0109 01:02:37.595741  6363 solver.cpp:270] Iteration 9450 (3.86777 iter/s, 12.9273s/50 iter), loss = 0.0021625, remaining 0 hours and 10 minutes
I0109 01:02:37.595772  6363 solver.cpp:291]     Train net output #0: loss = 0.00216255 (* 1 = 0.00216255 loss)
I0109 01:02:37.595779  6363 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0109 01:02:50.552847  6363 solver.cpp:270] Iteration 9500 (3.85904 iter/s, 12.9566s/50 iter), loss = 0.00689673, remaining 0 hours and 10 minutes
I0109 01:02:50.552893  6363 solver.cpp:291]     Train net output #0: loss = 0.00689677 (* 1 = 0.00689677 loss)
I0109 01:02:50.552901  6363 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0109 01:03:03.488823  6363 solver.cpp:270] Iteration 9550 (3.86535 iter/s, 12.9354s/50 iter), loss = 0.000252367, remaining 0 hours and 10 minutes
I0109 01:03:03.488855  6363 solver.cpp:291]     Train net output #0: loss = 0.000252408 (* 1 = 0.000252408 loss)
I0109 01:03:03.488878  6363 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0109 01:03:16.408212  6363 solver.cpp:270] Iteration 9600 (3.87031 iter/s, 12.9189s/50 iter), loss = 0.000768952, remaining 0 hours and 10 minutes
I0109 01:03:16.408243  6363 solver.cpp:291]     Train net output #0: loss = 0.000768996 (* 1 = 0.000768996 loss)
I0109 01:03:16.408252  6363 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0109 01:03:29.356657  6363 solver.cpp:270] Iteration 9650 (3.86162 iter/s, 12.9479s/50 iter), loss = 0.0196158, remaining 0 hours and 10 minutes
I0109 01:03:29.356701  6363 solver.cpp:291]     Train net output #0: loss = 0.0196158 (* 1 = 0.0196158 loss)
I0109 01:03:29.356725  6363 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0109 01:03:42.275302  6363 solver.cpp:270] Iteration 9700 (3.87053 iter/s, 12.9181s/50 iter), loss = 0.00433831, remaining 0 hours and 9 minutes
I0109 01:03:42.275332  6363 solver.cpp:291]     Train net output #0: loss = 0.00433835 (* 1 = 0.00433835 loss)
I0109 01:03:42.275341  6363 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0109 01:03:55.215272  6363 solver.cpp:270] Iteration 9750 (3.86415 iter/s, 12.9395s/50 iter), loss = 0.00291971, remaining 0 hours and 9 minutes
I0109 01:03:55.215303  6363 solver.cpp:291]     Train net output #0: loss = 0.00291975 (* 1 = 0.00291975 loss)
I0109 01:03:55.215310  6363 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0109 01:04:08.158854  6363 solver.cpp:270] Iteration 9800 (3.86307 iter/s, 12.9431s/50 iter), loss = 0.00471458, remaining 0 hours and 9 minutes
I0109 01:04:08.158901  6363 solver.cpp:291]     Train net output #0: loss = 0.00471463 (* 1 = 0.00471463 loss)
I0109 01:04:08.158926  6363 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0109 01:04:21.104182  6363 solver.cpp:270] Iteration 9850 (3.86256 iter/s, 12.9448s/50 iter), loss = 0.00349093, remaining 0 hours and 9 minutes
I0109 01:04:21.104215  6363 solver.cpp:291]     Train net output #0: loss = 0.00349098 (* 1 = 0.00349098 loss)
I0109 01:04:21.104223  6363 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0109 01:04:34.036275  6363 solver.cpp:270] Iteration 9900 (3.8665 iter/s, 12.9316s/50 iter), loss = 0.00167925, remaining 0 hours and 9 minutes
I0109 01:04:34.036306  6363 solver.cpp:291]     Train net output #0: loss = 0.00167929 (* 1 = 0.00167929 loss)
I0109 01:04:34.036314  6363 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0109 01:04:46.955689  6363 solver.cpp:270] Iteration 9950 (3.8703 iter/s, 12.9189s/50 iter), loss = 0.0127996, remaining 0 hours and 8 minutes
I0109 01:04:46.955742  6363 solver.cpp:291]     Train net output #0: loss = 0.0127996 (* 1 = 0.0127996 loss)
I0109 01:04:46.955750  6363 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0109 01:04:59.634200  6363 solver.cpp:424] Iteration 10000, Testing net (#0)
I0109 01:05:01.179461  6363 solver.cpp:523]     Test net output #0: accuracy = 0.9525
I0109 01:05:01.179489  6363 solver.cpp:523]     Test net output #1: loss = 0.294045 (* 1 = 0.294045 loss)
I0109 01:05:01.179493  6363 solver.cpp:523]     Test net output #2: top-1 = 0.9525
I0109 01:05:01.426839  6363 solver.cpp:270] Iteration 10000 (3.45529 iter/s, 14.4706s/50 iter), loss = 0.00263153, remaining 0 hours and 9 minutes
I0109 01:05:01.426867  6363 solver.cpp:291]     Train net output #0: loss = 0.00263157 (* 1 = 0.00263157 loss)
I0109 01:05:01.426875  6363 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0109 01:05:14.367660  6363 solver.cpp:270] Iteration 10050 (3.86389 iter/s, 12.9403s/50 iter), loss = 0.00302525, remaining 0 hours and 8 minutes
I0109 01:05:14.367694  6363 solver.cpp:291]     Train net output #0: loss = 0.00302529 (* 1 = 0.00302529 loss)
I0109 01:05:14.367702  6363 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0109 01:05:27.292908  6363 solver.cpp:270] Iteration 10100 (3.86855 iter/s, 12.9247s/50 iter), loss = 0.00290699, remaining 0 hours and 8 minutes
I0109 01:05:27.292953  6363 solver.cpp:291]     Train net output #0: loss = 0.00290703 (* 1 = 0.00290703 loss)
I0109 01:05:27.292961  6363 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0109 01:05:40.229240  6363 solver.cpp:270] Iteration 10150 (3.86524 iter/s, 12.9358s/50 iter), loss = 0.0011579, remaining 0 hours and 7 minutes
I0109 01:05:40.229271  6363 solver.cpp:291]     Train net output #0: loss = 0.00115794 (* 1 = 0.00115794 loss)
I0109 01:05:40.229279  6363 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0109 01:05:53.175540  6363 solver.cpp:270] Iteration 10200 (3.86226 iter/s, 12.9458s/50 iter), loss = 0.00656637, remaining 0 hours and 7 minutes
I0109 01:05:53.175572  6363 solver.cpp:291]     Train net output #0: loss = 0.00656641 (* 1 = 0.00656641 loss)
I0109 01:05:53.175595  6363 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0109 01:06:06.090966  6363 solver.cpp:270] Iteration 10250 (3.87149 iter/s, 12.9149s/50 iter), loss = 0.0130598, remaining 0 hours and 7 minutes
I0109 01:06:06.091013  6363 solver.cpp:291]     Train net output #0: loss = 0.0130598 (* 1 = 0.0130598 loss)
I0109 01:06:06.091022  6363 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0109 01:06:19.000226  6363 solver.cpp:270] Iteration 10300 (3.87335 iter/s, 12.9087s/50 iter), loss = 0.00201206, remaining 0 hours and 7 minutes
I0109 01:06:19.000257  6363 solver.cpp:291]     Train net output #0: loss = 0.00201209 (* 1 = 0.00201209 loss)
I0109 01:06:19.000263  6363 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0109 01:06:31.968717  6363 solver.cpp:270] Iteration 10350 (3.85565 iter/s, 12.968s/50 iter), loss = 0.0010312, remaining 0 hours and 7 minutes
I0109 01:06:31.968750  6363 solver.cpp:291]     Train net output #0: loss = 0.00103124 (* 1 = 0.00103124 loss)
I0109 01:06:31.968758  6363 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0109 01:06:44.907627  6363 solver.cpp:270] Iteration 10400 (3.86447 iter/s, 12.9384s/50 iter), loss = 0.00768616, remaining 0 hours and 6 minutes
I0109 01:06:44.907681  6363 solver.cpp:291]     Train net output #0: loss = 0.0076862 (* 1 = 0.0076862 loss)
I0109 01:06:44.907688  6363 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0109 01:06:57.838352  6363 solver.cpp:270] Iteration 10450 (3.86692 iter/s, 12.9302s/50 iter), loss = 0.00171393, remaining 0 hours and 6 minutes
I0109 01:06:57.838384  6363 solver.cpp:291]     Train net output #0: loss = 0.00171396 (* 1 = 0.00171396 loss)
I0109 01:06:57.838407  6363 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0109 01:07:10.776082  6363 solver.cpp:270] Iteration 10500 (3.86482 iter/s, 12.9372s/50 iter), loss = 0.00180287, remaining 0 hours and 6 minutes
I0109 01:07:10.776114  6363 solver.cpp:291]     Train net output #0: loss = 0.00180291 (* 1 = 0.00180291 loss)
I0109 01:07:10.776122  6363 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0109 01:07:23.712539  6363 solver.cpp:270] Iteration 10550 (3.8652 iter/s, 12.9359s/50 iter), loss = 0.0021096, remaining 0 hours and 6 minutes
I0109 01:07:23.712584  6363 solver.cpp:291]     Train net output #0: loss = 0.00210964 (* 1 = 0.00210964 loss)
I0109 01:07:23.712608  6363 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0109 01:07:36.649451  6363 solver.cpp:270] Iteration 10600 (3.86507 iter/s, 12.9364s/50 iter), loss = 0.000314637, remaining 0 hours and 5 minutes
I0109 01:07:36.649482  6363 solver.cpp:291]     Train net output #0: loss = 0.000314677 (* 1 = 0.000314677 loss)
I0109 01:07:36.649505  6363 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0109 01:07:49.600283  6363 solver.cpp:270] Iteration 10650 (3.86091 iter/s, 12.9503s/50 iter), loss = 0.00252867, remaining 0 hours and 5 minutes
I0109 01:07:49.600315  6363 solver.cpp:291]     Train net output #0: loss = 0.00252871 (* 1 = 0.00252871 loss)
I0109 01:07:49.600339  6363 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0109 01:08:02.522356  6363 solver.cpp:270] Iteration 10700 (3.8695 iter/s, 12.9216s/50 iter), loss = 0.000885018, remaining 0 hours and 5 minutes
I0109 01:08:02.522403  6363 solver.cpp:291]     Train net output #0: loss = 0.000885056 (* 1 = 0.000885056 loss)
I0109 01:08:02.522428  6363 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0109 01:08:15.475752  6363 solver.cpp:270] Iteration 10750 (3.86015 iter/s, 12.9529s/50 iter), loss = 0.00200174, remaining 0 hours and 5 minutes
I0109 01:08:15.475783  6363 solver.cpp:291]     Train net output #0: loss = 0.00200178 (* 1 = 0.00200178 loss)
I0109 01:08:15.475791  6363 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0109 01:08:28.410679  6363 solver.cpp:270] Iteration 10800 (3.86566 iter/s, 12.9344s/50 iter), loss = 0.00405738, remaining 0 hours and 5 minutes
I0109 01:08:28.410709  6363 solver.cpp:291]     Train net output #0: loss = 0.00405742 (* 1 = 0.00405742 loss)
I0109 01:08:28.410733  6363 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0109 01:08:41.334528  6363 solver.cpp:270] Iteration 10850 (3.86897 iter/s, 12.9233s/50 iter), loss = 0.0012801, remaining 0 hours and 4 minutes
I0109 01:08:41.334574  6363 solver.cpp:291]     Train net output #0: loss = 0.00128014 (* 1 = 0.00128014 loss)
I0109 01:08:41.334583  6363 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0109 01:08:54.300092  6363 solver.cpp:270] Iteration 10900 (3.85653 iter/s, 12.965s/50 iter), loss = 0.00383179, remaining 0 hours and 4 minutes
I0109 01:08:54.300123  6363 solver.cpp:291]     Train net output #0: loss = 0.00383183 (* 1 = 0.00383183 loss)
I0109 01:08:54.300148  6363 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0109 01:09:07.232587  6363 solver.cpp:270] Iteration 10950 (3.86638 iter/s, 12.932s/50 iter), loss = 0.00491444, remaining 0 hours and 4 minutes
I0109 01:09:07.232617  6363 solver.cpp:291]     Train net output #0: loss = 0.00491448 (* 1 = 0.00491448 loss)
I0109 01:09:07.232625  6363 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0109 01:09:19.905071  6363 solver.cpp:424] Iteration 11000, Testing net (#0)
I0109 01:09:21.404652  6363 solver.cpp:523]     Test net output #0: accuracy = 0.95225
I0109 01:09:21.404678  6363 solver.cpp:523]     Test net output #1: loss = 0.303889 (* 1 = 0.303889 loss)
I0109 01:09:21.404683  6363 solver.cpp:523]     Test net output #2: top-1 = 0.95225
I0109 01:09:21.654985  6363 solver.cpp:270] Iteration 11000 (3.46697 iter/s, 14.4218s/50 iter), loss = 0.00716737, remaining 0 hours and 4 minutes
I0109 01:09:21.655011  6363 solver.cpp:291]     Train net output #0: loss = 0.00716741 (* 1 = 0.00716741 loss)
I0109 01:09:21.655020  6363 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0109 01:09:34.587393  6363 solver.cpp:270] Iteration 11050 (3.86641 iter/s, 12.9319s/50 iter), loss = 0.00239308, remaining 0 hours and 3 minutes
I0109 01:09:34.587424  6363 solver.cpp:291]     Train net output #0: loss = 0.00239312 (* 1 = 0.00239312 loss)
I0109 01:09:34.587447  6363 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0109 01:09:47.520227  6363 solver.cpp:270] Iteration 11100 (3.86628 iter/s, 12.9323s/50 iter), loss = 0.00112354, remaining 0 hours and 3 minutes
I0109 01:09:47.520258  6363 solver.cpp:291]     Train net output #0: loss = 0.00112357 (* 1 = 0.00112357 loss)
I0109 01:09:47.520267  6363 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0109 01:10:00.446328  6363 solver.cpp:270] Iteration 11150 (3.8683 iter/s, 12.9256s/50 iter), loss = 0.00126735, remaining 0 hours and 3 minutes
I0109 01:10:00.446374  6363 solver.cpp:291]     Train net output #0: loss = 0.00126738 (* 1 = 0.00126738 loss)
I0109 01:10:00.446382  6363 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0109 01:10:13.380497  6363 solver.cpp:270] Iteration 11200 (3.86589 iter/s, 12.9336s/50 iter), loss = 0.0082371, remaining 0 hours and 3 minutes
I0109 01:10:13.380530  6363 solver.cpp:291]     Train net output #0: loss = 0.00823713 (* 1 = 0.00823713 loss)
I0109 01:10:13.380538  6363 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0109 01:10:26.330593  6363 solver.cpp:270] Iteration 11250 (3.86113 iter/s, 12.9496s/50 iter), loss = 0.00255906, remaining 0 hours and 3 minutes
I0109 01:10:26.330627  6363 solver.cpp:291]     Train net output #0: loss = 0.0025591 (* 1 = 0.0025591 loss)
I0109 01:10:26.330636  6363 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0109 01:10:39.263417  6363 solver.cpp:270] Iteration 11300 (3.86629 iter/s, 12.9323s/50 iter), loss = 0.00249026, remaining 0 hours and 2 minutes
I0109 01:10:39.263463  6363 solver.cpp:291]     Train net output #0: loss = 0.0024903 (* 1 = 0.0024903 loss)
I0109 01:10:39.263469  6363 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0109 01:10:52.213702  6363 solver.cpp:270] Iteration 11350 (3.86108 iter/s, 12.9498s/50 iter), loss = 0.00162632, remaining 0 hours and 2 minutes
I0109 01:10:52.213734  6363 solver.cpp:291]     Train net output #0: loss = 0.00162636 (* 1 = 0.00162636 loss)
I0109 01:10:52.213742  6363 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0109 01:11:05.144912  6363 solver.cpp:270] Iteration 11400 (3.86677 iter/s, 12.9307s/50 iter), loss = 0.0048339, remaining 0 hours and 2 minutes
I0109 01:11:05.144942  6363 solver.cpp:291]     Train net output #0: loss = 0.00483394 (* 1 = 0.00483394 loss)
I0109 01:11:05.144949  6363 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0109 01:11:18.107875  6363 solver.cpp:270] Iteration 11450 (3.8573 iter/s, 12.9625s/50 iter), loss = 0.0058745, remaining 0 hours and 2 minutes
I0109 01:11:18.107921  6363 solver.cpp:291]     Train net output #0: loss = 0.00587455 (* 1 = 0.00587455 loss)
I0109 01:11:18.107929  6363 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0109 01:11:31.045408  6363 solver.cpp:270] Iteration 11500 (3.86488 iter/s, 12.937s/50 iter), loss = 0.00199327, remaining 0 hours and 2 minutes
I0109 01:11:31.045440  6363 solver.cpp:291]     Train net output #0: loss = 0.00199332 (* 1 = 0.00199332 loss)
I0109 01:11:31.045449  6363 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0109 01:11:43.974272  6363 solver.cpp:270] Iteration 11550 (3.86747 iter/s, 12.9283s/50 iter), loss = 0.00189107, remaining 0 hours and 1 minutes
I0109 01:11:43.974303  6363 solver.cpp:291]     Train net output #0: loss = 0.00189112 (* 1 = 0.00189112 loss)
I0109 01:11:43.974326  6363 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0109 01:11:56.916755  6363 solver.cpp:270] Iteration 11600 (3.8634 iter/s, 12.942s/50 iter), loss = 0.00106881, remaining 0 hours and 1 minutes
I0109 01:11:56.916810  6363 solver.cpp:291]     Train net output #0: loss = 0.00106886 (* 1 = 0.00106886 loss)
I0109 01:11:56.916817  6363 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0109 01:12:09.878778  6363 solver.cpp:270] Iteration 11650 (3.85758 iter/s, 12.9615s/50 iter), loss = 0.0085112, remaining 0 hours and 1 minutes
I0109 01:12:09.878809  6363 solver.cpp:291]     Train net output #0: loss = 0.00851125 (* 1 = 0.00851125 loss)
I0109 01:12:09.878816  6363 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0109 01:12:22.826655  6363 solver.cpp:270] Iteration 11700 (3.86179 iter/s, 12.9474s/50 iter), loss = 0.00339246, remaining 0 hours and 1 minutes
I0109 01:12:22.826692  6363 solver.cpp:291]     Train net output #0: loss = 0.0033925 (* 1 = 0.0033925 loss)
I0109 01:12:22.826700  6363 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0109 01:12:35.799882  6363 solver.cpp:270] Iteration 11750 (3.85425 iter/s, 12.9727s/50 iter), loss = 0.00111616, remaining 0 hours and 1 minutes
I0109 01:12:35.799926  6363 solver.cpp:291]     Train net output #0: loss = 0.00111621 (* 1 = 0.00111621 loss)
I0109 01:12:35.799935  6363 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0109 01:12:48.730330  6363 solver.cpp:270] Iteration 11800 (3.867 iter/s, 12.9299s/50 iter), loss = 0.0140874, remaining 0 hours and 0 minutes
I0109 01:12:48.730362  6363 solver.cpp:291]     Train net output #0: loss = 0.0140874 (* 1 = 0.0140874 loss)
I0109 01:12:48.730370  6363 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0109 01:13:01.685151  6363 solver.cpp:270] Iteration 11850 (3.85972 iter/s, 12.9543s/50 iter), loss = 0.000845623, remaining 0 hours and 0 minutes
I0109 01:13:01.685184  6363 solver.cpp:291]     Train net output #0: loss = 0.00084567 (* 1 = 0.00084567 loss)
I0109 01:13:01.685207  6363 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0109 01:13:14.623787  6363 solver.cpp:270] Iteration 11900 (3.86455 iter/s, 12.9381s/50 iter), loss = 0.000568187, remaining 0 hours and 0 minutes
I0109 01:13:14.623836  6363 solver.cpp:291]     Train net output #0: loss = 0.000568235 (* 1 = 0.000568235 loss)
I0109 01:13:14.623843  6363 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0109 01:13:27.548604  6363 solver.cpp:270] Iteration 11950 (3.86869 iter/s, 12.9243s/50 iter), loss = 0.00156356, remaining 0 hours and 0 minutes
I0109 01:13:27.548635  6363 solver.cpp:291]     Train net output #0: loss = 0.00156361 (* 1 = 0.00156361 loss)
I0109 01:13:27.548658  6363 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0109 01:13:40.231492  6363 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_12000.caffemodel
I0109 01:13:42.611907  6363 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.5/snapshots/_iter_12000.solverstate
I0109 01:13:42.930078  6363 solver.cpp:384] Iteration 12000, loss = 0.000606238
I0109 01:13:42.930104  6363 solver.cpp:424] Iteration 12000, Testing net (#0)
I0109 01:13:44.393853  6363 solver.cpp:523]     Test net output #0: accuracy = 0.95225
I0109 01:13:44.393880  6363 solver.cpp:523]     Test net output #1: loss = 0.308382 (* 1 = 0.308382 loss)
I0109 01:13:44.393885  6363 solver.cpp:523]     Test net output #2: top-1 = 0.95225
I0109 01:13:44.393889  6363 solver.cpp:392] Optimization Done (3.85425 iter/s).
I0109 01:13:44.393909  6363 caffe_interface.cpp:546] Optimization Done.
(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

I0109 01:13:45.061542  6460 pruning_runner.cpp:206] Analysis info found.
I0109 01:13:46.612408  6460 pruning_runner.cpp:237] Start pruning, please wait...
I0109 01:13:52.375006  6460 pruning_runner.cpp:284] Compression complete 0%
I0109 01:13:58.388887  6460 pruning_runner.cpp:284] Compression complete 0%
I0109 01:14:04.711370  6460 pruning_runner.cpp:284] Compression complete 0%
I0109 01:14:10.735359  6460 pruning_runner.cpp:284] Compression complete 0%
I0109 01:14:16.724359  6460 pruning_runner.cpp:284] Compression complete 0%
I0109 01:14:22.776348  6460 pruning_runner.cpp:284] Compression complete 0%
I0109 01:14:29.096338  6460 pruning_runner.cpp:284] Compression complete 0%
I0109 01:14:35.594497  6460 pruning_runner.cpp:284] Compression complete 0%
I0109 01:14:41.892107  6460 pruning_runner.cpp:284] Compression complete 50%
I0109 01:14:48.138196  6460 pruning_runner.cpp:284] Compression complete 87.5%
I0109 01:14:54.441886  6460 pruning_runner.cpp:284] Compression complete 96.5517%
I0109 01:15:00.887113  6460 pruning_runner.cpp:284] Compression complete 98.2759%
I0109 01:15:06.966668  6460 pruning_runner.cpp:284] Compression complete 99.1304%
I0109 01:15:13.014060  6460 pruning_runner.cpp:284] Compression complete 99.5652%
I0109 01:15:19.087636  6460 pruning_runner.cpp:284] Compression complete 99.7821%
I0109 01:15:25.135299  6460 pruning_runner.cpp:284] Compression complete 99.9455%
I0109 01:15:31.436828  6460 pruning_runner.cpp:284] Compression complete 99.9966%
I0109 01:15:37.576926  6460 pruning_runner.cpp:284] Compression complete 99.9991%
I0109 01:15:43.669240  6460 pruning_runner.cpp:284] Compression complete 99.9998%
I0109 01:15:50.061599  6460 pruning_runner.cpp:284] Compression complete 99.9999%
I0109 01:15:56.207049  6460 pruning_runner.cpp:284] Compression complete 100%
I0109 01:16:04.518997  6460 pruning_runner.cpp:337] pruning done, output model: pruning/alexnetBNnoLRN/regular_rate_0.6/sparse.caffemodel
I0109 01:16:04.519024  6460 pruning_runner.cpp:351] summary of REGULAR compression with rate 0.6:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.943749785    | 0.950499535    | 0.00674974918  |
+-------------------------------------------------------------------+
| Weights        | 3.7649951 M    | 601.026978 K   | -84.0364456%   |
+-------------------------------------------------------------------+
| Operations     | 2.1539185 G    | 887.557983 M   | -58.7933311%   |
+-------------------------------------------------------------------+
To fine-tune the pruned model, please run:
vai_p_caffe finetune -config /workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/config6.prototxt
(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

W0109 01:16:04.675016  8505 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0109 01:16:04.675230  8505 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0109 01:16:04.675252  8505 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0109 01:16:04.679530  8505 vai_p_caffe.cpp:287] pruning/alexnetBNnoLRN/regular_rate_0.6/net_finetune.prototxt
I0109 01:16:04.840716  8505 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0109 01:16:04.840736  8505 gpu_memory.cpp:55] Total memory: 25620447232, Free: 25022103552, dev_info[0]: total=25620447232 free=25022103552
I0109 01:16:04.841536  8505 caffe_interface.cpp:509] Using GPUs 0
I0109 01:16:04.841792  8505 caffe_interface.cpp:514] GPU 0: Quadro P6000
I0109 01:16:05.704221  8505 solver.cpp:51] Initializing solver from parameters:
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 6000
snapshot_prefix: "pruning/alexnetBNnoLRN/regular_rate_0.6/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "pruning/alexnetBNnoLRN/regular_rate_0.6/net_finetune.prototxt"
type: "Adam"
I0109 01:16:05.704385  8505 solver.cpp:99] Creating training net from net file: pruning/alexnetBNnoLRN/regular_rate_0.6/net_finetune.prototxt
I0109 01:16:05.704694  8505 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0109 01:16:05.704708  8505 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0109 01:16:05.704711  8505 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0109 01:16:05.704716  8505 net.cpp:52] Initializing net from parameters:
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0109 01:16:05.704952  8505 layer_factory.hpp:77] Creating layer data
I0109 01:16:05.705087  8505 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 01:16:05.706746  8505 net.cpp:94] Creating Layer data
I0109 01:16:05.706759  8505 net.cpp:409] data -> data
I0109 01:16:05.706774  8505 net.cpp:409] data -> label
I0109 01:16:05.708020  8542 db_lmdb.cpp:35] Opened lmdb input/lmdb/train_lmdb
I0109 01:16:05.708042  8542 db_lmdb.cpp:38] Items count: 20000
I0109 01:16:05.708065  8542 data_reader.cpp:124] TRAIN: reading data using 1 channel(s)
I0109 01:16:05.708314  8505 data_layer.cpp:78] ReshapePrefetch 256, 3, 227, 227
I0109 01:16:05.708400  8505 data_layer.cpp:83] output data size: 256,3,227,227
I0109 01:16:06.176324  8505 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 01:16:06.176409  8505 net.cpp:144] Setting up data
I0109 01:16:06.176414  8505 net.cpp:151] Top shape: 256 3 227 227 (39574272)
I0109 01:16:06.176438  8505 net.cpp:151] Top shape: 256 (256)
I0109 01:16:06.176442  8505 net.cpp:159] Memory required for data: 158298112
I0109 01:16:06.176447  8505 layer_factory.hpp:77] Creating layer conv1
I0109 01:16:06.176458  8505 net.cpp:94] Creating Layer conv1
I0109 01:16:06.176471  8505 net.cpp:435] conv1 <- data
I0109 01:16:06.176477  8505 net.cpp:409] conv1 -> conv1
I0109 01:16:06.177048  8505 net.cpp:144] Setting up conv1
I0109 01:16:06.177054  8505 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0109 01:16:06.177060  8505 net.cpp:159] Memory required for data: 455667712
I0109 01:16:06.177071  8505 layer_factory.hpp:77] Creating layer bn1
I0109 01:16:06.177079  8505 net.cpp:94] Creating Layer bn1
I0109 01:16:06.177083  8505 net.cpp:435] bn1 <- conv1
I0109 01:16:06.177088  8505 net.cpp:409] bn1 -> bn1
I0109 01:16:06.177605  8505 net.cpp:144] Setting up bn1
I0109 01:16:06.177611  8505 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0109 01:16:06.177618  8505 net.cpp:159] Memory required for data: 753037312
I0109 01:16:06.177626  8505 layer_factory.hpp:77] Creating layer relu1
I0109 01:16:06.177631  8505 net.cpp:94] Creating Layer relu1
I0109 01:16:06.177635  8505 net.cpp:435] relu1 <- bn1
I0109 01:16:06.177640  8505 net.cpp:409] relu1 -> relu1
I0109 01:16:06.177659  8505 net.cpp:144] Setting up relu1
I0109 01:16:06.177664  8505 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0109 01:16:06.177668  8505 net.cpp:159] Memory required for data: 1050406912
I0109 01:16:06.177672  8505 layer_factory.hpp:77] Creating layer pool1
I0109 01:16:06.177677  8505 net.cpp:94] Creating Layer pool1
I0109 01:16:06.177681  8505 net.cpp:435] pool1 <- relu1
I0109 01:16:06.177686  8505 net.cpp:409] pool1 -> pool1
I0109 01:16:06.177709  8505 net.cpp:144] Setting up pool1
I0109 01:16:06.177714  8505 net.cpp:151] Top shape: 256 96 27 27 (17915904)
I0109 01:16:06.177719  8505 net.cpp:159] Memory required for data: 1122070528
I0109 01:16:06.177722  8505 layer_factory.hpp:77] Creating layer conv2
I0109 01:16:06.177729  8505 net.cpp:94] Creating Layer conv2
I0109 01:16:06.177733  8505 net.cpp:435] conv2 <- pool1
I0109 01:16:06.177738  8505 net.cpp:409] conv2 -> conv2
I0109 01:16:06.192895  8505 net.cpp:144] Setting up conv2
I0109 01:16:06.192909  8505 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0109 01:16:06.192915  8505 net.cpp:159] Memory required for data: 1313173504
I0109 01:16:06.192939  8505 layer_factory.hpp:77] Creating layer bn2
I0109 01:16:06.192946  8505 net.cpp:94] Creating Layer bn2
I0109 01:16:06.192950  8505 net.cpp:435] bn2 <- conv2
I0109 01:16:06.192956  8505 net.cpp:409] bn2 -> bn2
I0109 01:16:06.193405  8505 net.cpp:144] Setting up bn2
I0109 01:16:06.193413  8505 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0109 01:16:06.193418  8505 net.cpp:159] Memory required for data: 1504276480
I0109 01:16:06.193425  8505 layer_factory.hpp:77] Creating layer relu2
I0109 01:16:06.193430  8505 net.cpp:94] Creating Layer relu2
I0109 01:16:06.193434  8505 net.cpp:435] relu2 <- bn2
I0109 01:16:06.193439  8505 net.cpp:409] relu2 -> relu2
I0109 01:16:06.193455  8505 net.cpp:144] Setting up relu2
I0109 01:16:06.193461  8505 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0109 01:16:06.193466  8505 net.cpp:159] Memory required for data: 1695379456
I0109 01:16:06.193470  8505 layer_factory.hpp:77] Creating layer pool2
I0109 01:16:06.193475  8505 net.cpp:94] Creating Layer pool2
I0109 01:16:06.193480  8505 net.cpp:435] pool2 <- relu2
I0109 01:16:06.193485  8505 net.cpp:409] pool2 -> pool2
I0109 01:16:06.193511  8505 net.cpp:144] Setting up pool2
I0109 01:16:06.193519  8505 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0109 01:16:06.193526  8505 net.cpp:159] Memory required for data: 1739681792
I0109 01:16:06.193531  8505 layer_factory.hpp:77] Creating layer conv3
I0109 01:16:06.193554  8505 net.cpp:94] Creating Layer conv3
I0109 01:16:06.193558  8505 net.cpp:435] conv3 <- pool2
I0109 01:16:06.193563  8505 net.cpp:409] conv3 -> conv3
I0109 01:16:06.206581  8505 net.cpp:144] Setting up conv3
I0109 01:16:06.206606  8505 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0109 01:16:06.206619  8505 net.cpp:159] Memory required for data: 1806135296
I0109 01:16:06.206636  8505 layer_factory.hpp:77] Creating layer relu3
I0109 01:16:06.206647  8505 net.cpp:94] Creating Layer relu3
I0109 01:16:06.206653  8505 net.cpp:435] relu3 <- conv3
I0109 01:16:06.206666  8505 net.cpp:409] relu3 -> relu3
I0109 01:16:06.206703  8505 net.cpp:144] Setting up relu3
I0109 01:16:06.206710  8505 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0109 01:16:06.206717  8505 net.cpp:159] Memory required for data: 1872588800
I0109 01:16:06.206722  8505 layer_factory.hpp:77] Creating layer conv4
I0109 01:16:06.206733  8505 net.cpp:94] Creating Layer conv4
I0109 01:16:06.206738  8505 net.cpp:435] conv4 <- relu3
I0109 01:16:06.206745  8505 net.cpp:409] conv4 -> conv4
I0109 01:16:06.236068  8505 net.cpp:144] Setting up conv4
I0109 01:16:06.236101  8505 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0109 01:16:06.236121  8505 net.cpp:159] Memory required for data: 1939042304
I0109 01:16:06.236145  8505 layer_factory.hpp:77] Creating layer relu4
I0109 01:16:06.236160  8505 net.cpp:94] Creating Layer relu4
I0109 01:16:06.236171  8505 net.cpp:435] relu4 <- conv4
I0109 01:16:06.236187  8505 net.cpp:409] relu4 -> relu4
I0109 01:16:06.236251  8505 net.cpp:144] Setting up relu4
I0109 01:16:06.236264  8505 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0109 01:16:06.236281  8505 net.cpp:159] Memory required for data: 2005495808
I0109 01:16:06.236290  8505 layer_factory.hpp:77] Creating layer conv5
I0109 01:16:06.236308  8505 net.cpp:94] Creating Layer conv5
I0109 01:16:06.236321  8505 net.cpp:435] conv5 <- relu4
I0109 01:16:06.236335  8505 net.cpp:409] conv5 -> conv5
I0109 01:16:06.250288  8505 net.cpp:144] Setting up conv5
I0109 01:16:06.250310  8505 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0109 01:16:06.250319  8505 net.cpp:159] Memory required for data: 2049798144
I0109 01:16:06.250329  8505 layer_factory.hpp:77] Creating layer relu5
I0109 01:16:06.250337  8505 net.cpp:94] Creating Layer relu5
I0109 01:16:06.250342  8505 net.cpp:435] relu5 <- conv5
I0109 01:16:06.250349  8505 net.cpp:409] relu5 -> relu5
I0109 01:16:06.250378  8505 net.cpp:144] Setting up relu5
I0109 01:16:06.250385  8505 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0109 01:16:06.250388  8505 net.cpp:159] Memory required for data: 2094100480
I0109 01:16:06.250392  8505 layer_factory.hpp:77] Creating layer pool5
I0109 01:16:06.250398  8505 net.cpp:94] Creating Layer pool5
I0109 01:16:06.250402  8505 net.cpp:435] pool5 <- relu5
I0109 01:16:06.250407  8505 net.cpp:409] pool5 -> pool5
I0109 01:16:06.250449  8505 net.cpp:144] Setting up pool5
I0109 01:16:06.250459  8505 net.cpp:151] Top shape: 256 256 6 6 (2359296)
I0109 01:16:06.250465  8505 net.cpp:159] Memory required for data: 2103537664
I0109 01:16:06.250468  8505 layer_factory.hpp:77] Creating layer fc6
I0109 01:16:06.250478  8505 net.cpp:94] Creating Layer fc6
I0109 01:16:06.250485  8505 net.cpp:435] fc6 <- pool5
I0109 01:16:06.250494  8505 net.cpp:409] fc6 -> fc6
I0109 01:16:06.622082  8505 net.cpp:144] Setting up fc6
I0109 01:16:06.622107  8505 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 01:16:06.622115  8505 net.cpp:159] Memory required for data: 2107731968
I0109 01:16:06.622125  8505 layer_factory.hpp:77] Creating layer relu6
I0109 01:16:06.622133  8505 net.cpp:94] Creating Layer relu6
I0109 01:16:06.622138  8505 net.cpp:435] relu6 <- fc6
I0109 01:16:06.622143  8505 net.cpp:409] relu6 -> relu6
I0109 01:16:06.622159  8505 net.cpp:144] Setting up relu6
I0109 01:16:06.622166  8505 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 01:16:06.622175  8505 net.cpp:159] Memory required for data: 2111926272
I0109 01:16:06.622180  8505 layer_factory.hpp:77] Creating layer drop6
I0109 01:16:06.622200  8505 net.cpp:94] Creating Layer drop6
I0109 01:16:06.622221  8505 net.cpp:435] drop6 <- relu6
I0109 01:16:06.622228  8505 net.cpp:409] drop6 -> drop6
I0109 01:16:06.622268  8505 net.cpp:144] Setting up drop6
I0109 01:16:06.622277  8505 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 01:16:06.622282  8505 net.cpp:159] Memory required for data: 2116120576
I0109 01:16:06.622284  8505 layer_factory.hpp:77] Creating layer fc7
I0109 01:16:06.622290  8505 net.cpp:94] Creating Layer fc7
I0109 01:16:06.622294  8505 net.cpp:435] fc7 <- drop6
I0109 01:16:06.622299  8505 net.cpp:409] fc7 -> fc7
I0109 01:16:06.778784  8505 net.cpp:144] Setting up fc7
I0109 01:16:06.778810  8505 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 01:16:06.778818  8505 net.cpp:159] Memory required for data: 2120314880
I0109 01:16:06.778828  8505 layer_factory.hpp:77] Creating layer bn7
I0109 01:16:06.778837  8505 net.cpp:94] Creating Layer bn7
I0109 01:16:06.778841  8505 net.cpp:435] bn7 <- fc7
I0109 01:16:06.778863  8505 net.cpp:409] bn7 -> bn7
I0109 01:16:06.779392  8505 net.cpp:144] Setting up bn7
I0109 01:16:06.779402  8505 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 01:16:06.779407  8505 net.cpp:159] Memory required for data: 2124509184
I0109 01:16:06.779417  8505 layer_factory.hpp:77] Creating layer relu7
I0109 01:16:06.779423  8505 net.cpp:94] Creating Layer relu7
I0109 01:16:06.779428  8505 net.cpp:435] relu7 <- bn7
I0109 01:16:06.779433  8505 net.cpp:409] relu7 -> relu7
I0109 01:16:06.779461  8505 net.cpp:144] Setting up relu7
I0109 01:16:06.779471  8505 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 01:16:06.779476  8505 net.cpp:159] Memory required for data: 2128703488
I0109 01:16:06.779481  8505 layer_factory.hpp:77] Creating layer drop7
I0109 01:16:06.779487  8505 net.cpp:94] Creating Layer drop7
I0109 01:16:06.779491  8505 net.cpp:435] drop7 <- relu7
I0109 01:16:06.779495  8505 net.cpp:409] drop7 -> drop7
I0109 01:16:06.779523  8505 net.cpp:144] Setting up drop7
I0109 01:16:06.779531  8505 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 01:16:06.779537  8505 net.cpp:159] Memory required for data: 2132897792
I0109 01:16:06.779542  8505 layer_factory.hpp:77] Creating layer fc8
I0109 01:16:06.779564  8505 net.cpp:94] Creating Layer fc8
I0109 01:16:06.779574  8505 net.cpp:435] fc8 <- drop7
I0109 01:16:06.779582  8505 net.cpp:409] fc8 -> fc8
I0109 01:16:06.779758  8505 net.cpp:144] Setting up fc8
I0109 01:16:06.779765  8505 net.cpp:151] Top shape: 256 2 (512)
I0109 01:16:06.779770  8505 net.cpp:159] Memory required for data: 2132899840
I0109 01:16:06.779776  8505 layer_factory.hpp:77] Creating layer loss
I0109 01:16:06.779781  8505 net.cpp:94] Creating Layer loss
I0109 01:16:06.779785  8505 net.cpp:435] loss <- fc8
I0109 01:16:06.779789  8505 net.cpp:435] loss <- label
I0109 01:16:06.779794  8505 net.cpp:409] loss -> loss
I0109 01:16:06.779801  8505 layer_factory.hpp:77] Creating layer loss
I0109 01:16:06.779870  8505 net.cpp:144] Setting up loss
I0109 01:16:06.779875  8505 net.cpp:151] Top shape: (1)
I0109 01:16:06.779879  8505 net.cpp:154]     with loss weight 1
I0109 01:16:06.779897  8505 net.cpp:159] Memory required for data: 2132899844
I0109 01:16:06.779902  8505 net.cpp:220] loss needs backward computation.
I0109 01:16:06.779907  8505 net.cpp:220] fc8 needs backward computation.
I0109 01:16:06.779911  8505 net.cpp:220] drop7 needs backward computation.
I0109 01:16:06.779914  8505 net.cpp:220] relu7 needs backward computation.
I0109 01:16:06.779918  8505 net.cpp:220] bn7 needs backward computation.
I0109 01:16:06.779922  8505 net.cpp:220] fc7 needs backward computation.
I0109 01:16:06.779927  8505 net.cpp:220] drop6 needs backward computation.
I0109 01:16:06.779932  8505 net.cpp:220] relu6 needs backward computation.
I0109 01:16:06.779935  8505 net.cpp:220] fc6 needs backward computation.
I0109 01:16:06.779939  8505 net.cpp:220] pool5 needs backward computation.
I0109 01:16:06.779943  8505 net.cpp:220] relu5 needs backward computation.
I0109 01:16:06.779947  8505 net.cpp:220] conv5 needs backward computation.
I0109 01:16:06.779951  8505 net.cpp:220] relu4 needs backward computation.
I0109 01:16:06.779964  8505 net.cpp:220] conv4 needs backward computation.
I0109 01:16:06.779969  8505 net.cpp:220] relu3 needs backward computation.
I0109 01:16:06.779973  8505 net.cpp:220] conv3 needs backward computation.
I0109 01:16:06.779978  8505 net.cpp:220] pool2 needs backward computation.
I0109 01:16:06.779981  8505 net.cpp:220] relu2 needs backward computation.
I0109 01:16:06.779986  8505 net.cpp:220] bn2 needs backward computation.
I0109 01:16:06.779991  8505 net.cpp:220] conv2 needs backward computation.
I0109 01:16:06.779997  8505 net.cpp:220] pool1 needs backward computation.
I0109 01:16:06.780004  8505 net.cpp:220] relu1 needs backward computation.
I0109 01:16:06.780009  8505 net.cpp:220] bn1 needs backward computation.
I0109 01:16:06.780012  8505 net.cpp:220] conv1 needs backward computation.
I0109 01:16:06.780016  8505 net.cpp:222] data does not need backward computation.
I0109 01:16:06.780021  8505 net.cpp:264] This network produces output loss
I0109 01:16:06.780048  8505 net.cpp:284] Network initialization done.
I0109 01:16:06.780432  8505 solver.cpp:189] Creating test net (#0) specified by net file: pruning/alexnetBNnoLRN/regular_rate_0.6/net_finetune.prototxt
I0109 01:16:06.780467  8505 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0109 01:16:06.780483  8505 net.cpp:52] Initializing net from parameters:
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0109 01:16:06.780746  8505 layer_factory.hpp:77] Creating layer data
I0109 01:16:06.780804  8505 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 01:16:06.782474  8505 net.cpp:94] Creating Layer data
I0109 01:16:06.782488  8505 net.cpp:409] data -> data
I0109 01:16:06.782497  8505 net.cpp:409] data -> label
I0109 01:16:06.784158  8572 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0109 01:16:06.784180  8572 db_lmdb.cpp:38] Items count: 4000
I0109 01:16:06.784201  8572 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0109 01:16:06.784520  8505 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0109 01:16:06.784621  8505 data_layer.cpp:83] output data size: 50,3,227,227
I0109 01:16:06.882035  8505 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 01:16:06.882138  8505 net.cpp:144] Setting up data
I0109 01:16:06.882143  8505 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0109 01:16:06.882150  8505 net.cpp:151] Top shape: 50 (50)
I0109 01:16:06.882154  8505 net.cpp:159] Memory required for data: 30917600
I0109 01:16:06.882158  8505 layer_factory.hpp:77] Creating layer label_data_1_split
I0109 01:16:06.882166  8505 net.cpp:94] Creating Layer label_data_1_split
I0109 01:16:06.882176  8505 net.cpp:435] label_data_1_split <- label
I0109 01:16:06.882182  8505 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0109 01:16:06.882190  8505 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0109 01:16:06.882194  8505 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0109 01:16:06.882246  8505 net.cpp:144] Setting up label_data_1_split
I0109 01:16:06.882270  8505 net.cpp:151] Top shape: 50 (50)
I0109 01:16:06.882274  8505 net.cpp:151] Top shape: 50 (50)
I0109 01:16:06.882278  8505 net.cpp:151] Top shape: 50 (50)
I0109 01:16:06.882282  8505 net.cpp:159] Memory required for data: 30918200
I0109 01:16:06.882285  8505 layer_factory.hpp:77] Creating layer conv1
I0109 01:16:06.882295  8505 net.cpp:94] Creating Layer conv1
I0109 01:16:06.882299  8505 net.cpp:435] conv1 <- data
I0109 01:16:06.882304  8505 net.cpp:409] conv1 -> conv1
I0109 01:16:06.882936  8505 net.cpp:144] Setting up conv1
I0109 01:16:06.882944  8505 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0109 01:16:06.882951  8505 net.cpp:159] Memory required for data: 88998200
I0109 01:16:06.882961  8505 layer_factory.hpp:77] Creating layer bn1
I0109 01:16:06.882969  8505 net.cpp:94] Creating Layer bn1
I0109 01:16:06.882973  8505 net.cpp:435] bn1 <- conv1
I0109 01:16:06.882978  8505 net.cpp:409] bn1 -> bn1
I0109 01:16:06.883531  8505 net.cpp:144] Setting up bn1
I0109 01:16:06.883538  8505 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0109 01:16:06.883544  8505 net.cpp:159] Memory required for data: 147078200
I0109 01:16:06.883553  8505 layer_factory.hpp:77] Creating layer relu1
I0109 01:16:06.883560  8505 net.cpp:94] Creating Layer relu1
I0109 01:16:06.883563  8505 net.cpp:435] relu1 <- bn1
I0109 01:16:06.883569  8505 net.cpp:409] relu1 -> relu1
I0109 01:16:06.883585  8505 net.cpp:144] Setting up relu1
I0109 01:16:06.883591  8505 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0109 01:16:06.883595  8505 net.cpp:159] Memory required for data: 205158200
I0109 01:16:06.883599  8505 layer_factory.hpp:77] Creating layer pool1
I0109 01:16:06.883605  8505 net.cpp:94] Creating Layer pool1
I0109 01:16:06.883608  8505 net.cpp:435] pool1 <- relu1
I0109 01:16:06.883613  8505 net.cpp:409] pool1 -> pool1
I0109 01:16:06.883637  8505 net.cpp:144] Setting up pool1
I0109 01:16:06.883643  8505 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0109 01:16:06.883648  8505 net.cpp:159] Memory required for data: 219155000
I0109 01:16:06.883651  8505 layer_factory.hpp:77] Creating layer conv2
I0109 01:16:06.883661  8505 net.cpp:94] Creating Layer conv2
I0109 01:16:06.883668  8505 net.cpp:435] conv2 <- pool1
I0109 01:16:06.883675  8505 net.cpp:409] conv2 -> conv2
I0109 01:16:06.890763  8505 net.cpp:144] Setting up conv2
I0109 01:16:06.890779  8505 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0109 01:16:06.890785  8505 net.cpp:159] Memory required for data: 256479800
I0109 01:16:06.890795  8505 layer_factory.hpp:77] Creating layer bn2
I0109 01:16:06.890805  8505 net.cpp:94] Creating Layer bn2
I0109 01:16:06.890810  8505 net.cpp:435] bn2 <- conv2
I0109 01:16:06.890815  8505 net.cpp:409] bn2 -> bn2
I0109 01:16:06.891311  8505 net.cpp:144] Setting up bn2
I0109 01:16:06.891319  8505 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0109 01:16:06.891324  8505 net.cpp:159] Memory required for data: 293804600
I0109 01:16:06.891332  8505 layer_factory.hpp:77] Creating layer relu2
I0109 01:16:06.891338  8505 net.cpp:94] Creating Layer relu2
I0109 01:16:06.891342  8505 net.cpp:435] relu2 <- bn2
I0109 01:16:06.891347  8505 net.cpp:409] relu2 -> relu2
I0109 01:16:06.891364  8505 net.cpp:144] Setting up relu2
I0109 01:16:06.891381  8505 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0109 01:16:06.891386  8505 net.cpp:159] Memory required for data: 331129400
I0109 01:16:06.891389  8505 layer_factory.hpp:77] Creating layer pool2
I0109 01:16:06.891394  8505 net.cpp:94] Creating Layer pool2
I0109 01:16:06.891398  8505 net.cpp:435] pool2 <- relu2
I0109 01:16:06.891402  8505 net.cpp:409] pool2 -> pool2
I0109 01:16:06.891427  8505 net.cpp:144] Setting up pool2
I0109 01:16:06.891433  8505 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0109 01:16:06.891438  8505 net.cpp:159] Memory required for data: 339782200
I0109 01:16:06.891441  8505 layer_factory.hpp:77] Creating layer conv3
I0109 01:16:06.891449  8505 net.cpp:94] Creating Layer conv3
I0109 01:16:06.891455  8505 net.cpp:435] conv3 <- pool2
I0109 01:16:06.891460  8505 net.cpp:409] conv3 -> conv3
I0109 01:16:06.902298  8505 net.cpp:144] Setting up conv3
I0109 01:16:06.902318  8505 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 01:16:06.902325  8505 net.cpp:159] Memory required for data: 352761400
I0109 01:16:06.902334  8505 layer_factory.hpp:77] Creating layer relu3
I0109 01:16:06.902343  8505 net.cpp:94] Creating Layer relu3
I0109 01:16:06.902348  8505 net.cpp:435] relu3 <- conv3
I0109 01:16:06.902354  8505 net.cpp:409] relu3 -> relu3
I0109 01:16:06.902377  8505 net.cpp:144] Setting up relu3
I0109 01:16:06.902380  8505 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 01:16:06.902385  8505 net.cpp:159] Memory required for data: 365740600
I0109 01:16:06.902390  8505 layer_factory.hpp:77] Creating layer conv4
I0109 01:16:06.902398  8505 net.cpp:94] Creating Layer conv4
I0109 01:16:06.902402  8505 net.cpp:435] conv4 <- relu3
I0109 01:16:06.902407  8505 net.cpp:409] conv4 -> conv4
I0109 01:16:06.918824  8505 net.cpp:144] Setting up conv4
I0109 01:16:06.918859  8505 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 01:16:06.918869  8505 net.cpp:159] Memory required for data: 378719800
I0109 01:16:06.918880  8505 layer_factory.hpp:77] Creating layer relu4
I0109 01:16:06.918889  8505 net.cpp:94] Creating Layer relu4
I0109 01:16:06.918893  8505 net.cpp:435] relu4 <- conv4
I0109 01:16:06.918900  8505 net.cpp:409] relu4 -> relu4
I0109 01:16:06.918928  8505 net.cpp:144] Setting up relu4
I0109 01:16:06.918932  8505 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 01:16:06.918937  8505 net.cpp:159] Memory required for data: 391699000
I0109 01:16:06.918941  8505 layer_factory.hpp:77] Creating layer conv5
I0109 01:16:06.918959  8505 net.cpp:94] Creating Layer conv5
I0109 01:16:06.918963  8505 net.cpp:435] conv5 <- relu4
I0109 01:16:06.918968  8505 net.cpp:409] conv5 -> conv5
I0109 01:16:06.929154  8505 net.cpp:144] Setting up conv5
I0109 01:16:06.929175  8505 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0109 01:16:06.929190  8505 net.cpp:159] Memory required for data: 400351800
I0109 01:16:06.929203  8505 layer_factory.hpp:77] Creating layer relu5
I0109 01:16:06.929214  8505 net.cpp:94] Creating Layer relu5
I0109 01:16:06.929224  8505 net.cpp:435] relu5 <- conv5
I0109 01:16:06.929237  8505 net.cpp:409] relu5 -> relu5
I0109 01:16:06.929287  8505 net.cpp:144] Setting up relu5
I0109 01:16:06.929294  8505 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0109 01:16:06.929301  8505 net.cpp:159] Memory required for data: 409004600
I0109 01:16:06.929307  8505 layer_factory.hpp:77] Creating layer pool5
I0109 01:16:06.929317  8505 net.cpp:94] Creating Layer pool5
I0109 01:16:06.929322  8505 net.cpp:435] pool5 <- relu5
I0109 01:16:06.929330  8505 net.cpp:409] pool5 -> pool5
I0109 01:16:06.929365  8505 net.cpp:144] Setting up pool5
I0109 01:16:06.929370  8505 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0109 01:16:06.929378  8505 net.cpp:159] Memory required for data: 410847800
I0109 01:16:06.929383  8505 layer_factory.hpp:77] Creating layer fc6
I0109 01:16:06.929391  8505 net.cpp:94] Creating Layer fc6
I0109 01:16:06.929396  8505 net.cpp:435] fc6 <- pool5
I0109 01:16:06.929406  8505 net.cpp:409] fc6 -> fc6
I0109 01:16:07.268276  8505 net.cpp:144] Setting up fc6
I0109 01:16:07.268303  8505 net.cpp:151] Top shape: 50 4096 (204800)
I0109 01:16:07.268334  8505 net.cpp:159] Memory required for data: 411667000
I0109 01:16:07.268347  8505 layer_factory.hpp:77] Creating layer relu6
I0109 01:16:07.268360  8505 net.cpp:94] Creating Layer relu6
I0109 01:16:07.268383  8505 net.cpp:435] relu6 <- fc6
I0109 01:16:07.268391  8505 net.cpp:409] relu6 -> relu6
I0109 01:16:07.268425  8505 net.cpp:144] Setting up relu6
I0109 01:16:07.268433  8505 net.cpp:151] Top shape: 50 4096 (204800)
I0109 01:16:07.268437  8505 net.cpp:159] Memory required for data: 412486200
I0109 01:16:07.268440  8505 layer_factory.hpp:77] Creating layer drop6
I0109 01:16:07.268445  8505 net.cpp:94] Creating Layer drop6
I0109 01:16:07.268448  8505 net.cpp:435] drop6 <- relu6
I0109 01:16:07.268455  8505 net.cpp:409] drop6 -> drop6
I0109 01:16:07.268477  8505 net.cpp:144] Setting up drop6
I0109 01:16:07.268481  8505 net.cpp:151] Top shape: 50 4096 (204800)
I0109 01:16:07.268484  8505 net.cpp:159] Memory required for data: 413305400
I0109 01:16:07.268487  8505 layer_factory.hpp:77] Creating layer fc7
I0109 01:16:07.268493  8505 net.cpp:94] Creating Layer fc7
I0109 01:16:07.268496  8505 net.cpp:435] fc7 <- drop6
I0109 01:16:07.268501  8505 net.cpp:409] fc7 -> fc7
I0109 01:16:07.418776  8505 net.cpp:144] Setting up fc7
I0109 01:16:07.418802  8505 net.cpp:151] Top shape: 50 4096 (204800)
I0109 01:16:07.418809  8505 net.cpp:159] Memory required for data: 414124600
I0109 01:16:07.418835  8505 layer_factory.hpp:77] Creating layer bn7
I0109 01:16:07.418844  8505 net.cpp:94] Creating Layer bn7
I0109 01:16:07.418849  8505 net.cpp:435] bn7 <- fc7
I0109 01:16:07.418856  8505 net.cpp:409] bn7 -> bn7
I0109 01:16:07.419382  8505 net.cpp:144] Setting up bn7
I0109 01:16:07.419391  8505 net.cpp:151] Top shape: 50 4096 (204800)
I0109 01:16:07.419396  8505 net.cpp:159] Memory required for data: 414943800
I0109 01:16:07.419406  8505 layer_factory.hpp:77] Creating layer relu7
I0109 01:16:07.419412  8505 net.cpp:94] Creating Layer relu7
I0109 01:16:07.419416  8505 net.cpp:435] relu7 <- bn7
I0109 01:16:07.419421  8505 net.cpp:409] relu7 -> relu7
I0109 01:16:07.419438  8505 net.cpp:144] Setting up relu7
I0109 01:16:07.419443  8505 net.cpp:151] Top shape: 50 4096 (204800)
I0109 01:16:07.419447  8505 net.cpp:159] Memory required for data: 415763000
I0109 01:16:07.419451  8505 layer_factory.hpp:77] Creating layer drop7
I0109 01:16:07.419456  8505 net.cpp:94] Creating Layer drop7
I0109 01:16:07.419461  8505 net.cpp:435] drop7 <- relu7
I0109 01:16:07.419466  8505 net.cpp:409] drop7 -> drop7
I0109 01:16:07.419495  8505 net.cpp:144] Setting up drop7
I0109 01:16:07.419500  8505 net.cpp:151] Top shape: 50 4096 (204800)
I0109 01:16:07.419505  8505 net.cpp:159] Memory required for data: 416582200
I0109 01:16:07.419508  8505 layer_factory.hpp:77] Creating layer fc8
I0109 01:16:07.419514  8505 net.cpp:94] Creating Layer fc8
I0109 01:16:07.419518  8505 net.cpp:435] fc8 <- drop7
I0109 01:16:07.419523  8505 net.cpp:409] fc8 -> fc8
I0109 01:16:07.419698  8505 net.cpp:144] Setting up fc8
I0109 01:16:07.419705  8505 net.cpp:151] Top shape: 50 2 (100)
I0109 01:16:07.419709  8505 net.cpp:159] Memory required for data: 416582600
I0109 01:16:07.419715  8505 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0109 01:16:07.419720  8505 net.cpp:94] Creating Layer fc8_fc8_0_split
I0109 01:16:07.419724  8505 net.cpp:435] fc8_fc8_0_split <- fc8
I0109 01:16:07.419729  8505 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0109 01:16:07.419735  8505 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0109 01:16:07.419740  8505 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0109 01:16:07.419775  8505 net.cpp:144] Setting up fc8_fc8_0_split
I0109 01:16:07.419780  8505 net.cpp:151] Top shape: 50 2 (100)
I0109 01:16:07.419785  8505 net.cpp:151] Top shape: 50 2 (100)
I0109 01:16:07.419790  8505 net.cpp:151] Top shape: 50 2 (100)
I0109 01:16:07.419793  8505 net.cpp:159] Memory required for data: 416583800
I0109 01:16:07.419796  8505 layer_factory.hpp:77] Creating layer accuracy
I0109 01:16:07.419804  8505 net.cpp:94] Creating Layer accuracy
I0109 01:16:07.419817  8505 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0109 01:16:07.419822  8505 net.cpp:435] accuracy <- label_data_1_split_0
I0109 01:16:07.419828  8505 net.cpp:409] accuracy -> accuracy
I0109 01:16:07.419836  8505 net.cpp:144] Setting up accuracy
I0109 01:16:07.419839  8505 net.cpp:151] Top shape: (1)
I0109 01:16:07.419842  8505 net.cpp:159] Memory required for data: 416583804
I0109 01:16:07.419847  8505 layer_factory.hpp:77] Creating layer loss
I0109 01:16:07.419852  8505 net.cpp:94] Creating Layer loss
I0109 01:16:07.419855  8505 net.cpp:435] loss <- fc8_fc8_0_split_1
I0109 01:16:07.419860  8505 net.cpp:435] loss <- label_data_1_split_1
I0109 01:16:07.419864  8505 net.cpp:409] loss -> loss
I0109 01:16:07.419878  8505 layer_factory.hpp:77] Creating layer loss
I0109 01:16:07.419971  8505 net.cpp:144] Setting up loss
I0109 01:16:07.419977  8505 net.cpp:151] Top shape: (1)
I0109 01:16:07.419982  8505 net.cpp:154]     with loss weight 1
I0109 01:16:07.419993  8505 net.cpp:159] Memory required for data: 416583808
I0109 01:16:07.419997  8505 layer_factory.hpp:77] Creating layer accuracy-top1
I0109 01:16:07.420002  8505 net.cpp:94] Creating Layer accuracy-top1
I0109 01:16:07.420006  8505 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0109 01:16:07.420011  8505 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0109 01:16:07.420015  8505 net.cpp:409] accuracy-top1 -> top-1
I0109 01:16:07.420022  8505 net.cpp:144] Setting up accuracy-top1
I0109 01:16:07.420027  8505 net.cpp:151] Top shape: (1)
I0109 01:16:07.420030  8505 net.cpp:159] Memory required for data: 416583812
I0109 01:16:07.420035  8505 net.cpp:222] accuracy-top1 does not need backward computation.
I0109 01:16:07.420042  8505 net.cpp:220] loss needs backward computation.
I0109 01:16:07.420048  8505 net.cpp:222] accuracy does not need backward computation.
I0109 01:16:07.420054  8505 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0109 01:16:07.420058  8505 net.cpp:220] fc8 needs backward computation.
I0109 01:16:07.420063  8505 net.cpp:220] drop7 needs backward computation.
I0109 01:16:07.420068  8505 net.cpp:220] relu7 needs backward computation.
I0109 01:16:07.420073  8505 net.cpp:220] bn7 needs backward computation.
I0109 01:16:07.420078  8505 net.cpp:220] fc7 needs backward computation.
I0109 01:16:07.420083  8505 net.cpp:220] drop6 needs backward computation.
I0109 01:16:07.420089  8505 net.cpp:220] relu6 needs backward computation.
I0109 01:16:07.420094  8505 net.cpp:220] fc6 needs backward computation.
I0109 01:16:07.420099  8505 net.cpp:220] pool5 needs backward computation.
I0109 01:16:07.420104  8505 net.cpp:220] relu5 needs backward computation.
I0109 01:16:07.420107  8505 net.cpp:220] conv5 needs backward computation.
I0109 01:16:07.420111  8505 net.cpp:220] relu4 needs backward computation.
I0109 01:16:07.420115  8505 net.cpp:220] conv4 needs backward computation.
I0109 01:16:07.420121  8505 net.cpp:220] relu3 needs backward computation.
I0109 01:16:07.420126  8505 net.cpp:220] conv3 needs backward computation.
I0109 01:16:07.420131  8505 net.cpp:220] pool2 needs backward computation.
I0109 01:16:07.420136  8505 net.cpp:220] relu2 needs backward computation.
I0109 01:16:07.420141  8505 net.cpp:220] bn2 needs backward computation.
I0109 01:16:07.420146  8505 net.cpp:220] conv2 needs backward computation.
I0109 01:16:07.420151  8505 net.cpp:220] pool1 needs backward computation.
I0109 01:16:07.420157  8505 net.cpp:220] relu1 needs backward computation.
I0109 01:16:07.420162  8505 net.cpp:220] bn1 needs backward computation.
I0109 01:16:07.420166  8505 net.cpp:220] conv1 needs backward computation.
I0109 01:16:07.420171  8505 net.cpp:222] label_data_1_split does not need backward computation.
I0109 01:16:07.420178  8505 net.cpp:222] data does not need backward computation.
I0109 01:16:07.420181  8505 net.cpp:264] This network produces output accuracy
I0109 01:16:07.420186  8505 net.cpp:264] This network produces output loss
I0109 01:16:07.420189  8505 net.cpp:264] This network produces output top-1
I0109 01:16:07.420222  8505 net.cpp:284] Network initialization done.
I0109 01:16:07.420296  8505 solver.cpp:63] Solver scaffolding done.
I0109 01:16:07.421423  8505 caffe_interface.cpp:109] Finetuning from pruning/alexnetBNnoLRN/regular_rate_0.6/sparse.caffemodel
I0109 01:16:09.751624  8505 caffe_interface.cpp:543] Starting Optimization
I0109 01:16:09.751647  8505 solver.cpp:341] Solving
I0109 01:16:09.751650  8505 solver.cpp:342] Learning Rate Policy: step
I0109 01:16:09.753002  8505 solver.cpp:424] Iteration 0, Testing net (#0)
I0109 01:16:11.280786  8505 solver.cpp:523]     Test net output #0: accuracy = 0.9505
I0109 01:16:11.280819  8505 solver.cpp:523]     Test net output #1: loss = 0.316086 (* 1 = 0.316086 loss)
I0109 01:16:11.280824  8505 solver.cpp:523]     Test net output #2: top-1 = 0.9505
I0109 01:16:11.535212  8505 solver.cpp:270] Iteration 0 (0 iter/s, 1.78344s/50 iter), loss = 0.00482895, remaining 333333 hours and 20 minutes
I0109 01:16:11.535243  8505 solver.cpp:291]     Train net output #0: loss = 0.00482895 (* 1 = 0.00482895 loss)
I0109 01:16:11.535250  8505 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0109 01:16:24.124321  8505 solver.cpp:270] Iteration 50 (3.97187 iter/s, 12.5885s/50 iter), loss = 0.054948, remaining 0 hours and 50 minutes
I0109 01:16:24.124356  8505 solver.cpp:291]     Train net output #0: loss = 0.054948 (* 1 = 0.054948 loss)
I0109 01:16:24.124362  8505 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0109 01:16:36.709404  8505 solver.cpp:270] Iteration 100 (3.97314 iter/s, 12.5845s/50 iter), loss = 0.0813185, remaining 0 hours and 49 minutes
I0109 01:16:36.709450  8505 solver.cpp:291]     Train net output #0: loss = 0.0813185 (* 1 = 0.0813185 loss)
I0109 01:16:36.709457  8505 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0109 01:16:49.321362  8505 solver.cpp:270] Iteration 150 (3.96468 iter/s, 12.6114s/50 iter), loss = 0.0924435, remaining 0 hours and 49 minutes
I0109 01:16:49.321393  8505 solver.cpp:291]     Train net output #0: loss = 0.0924435 (* 1 = 0.0924435 loss)
I0109 01:16:49.321400  8505 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0109 01:17:02.000680  8505 solver.cpp:270] Iteration 200 (3.94361 iter/s, 12.6787s/50 iter), loss = 0.0759177, remaining 0 hours and 49 minutes
I0109 01:17:02.000713  8505 solver.cpp:291]     Train net output #0: loss = 0.0759177 (* 1 = 0.0759177 loss)
I0109 01:17:02.000721  8505 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0109 01:17:14.678822  8505 solver.cpp:270] Iteration 250 (3.94397 iter/s, 12.6776s/50 iter), loss = 0.0603308, remaining 0 hours and 49 minutes
I0109 01:17:14.678867  8505 solver.cpp:291]     Train net output #0: loss = 0.0603308 (* 1 = 0.0603308 loss)
I0109 01:17:14.678874  8505 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0109 01:17:27.454224  8505 solver.cpp:270] Iteration 300 (3.91395 iter/s, 12.7748s/50 iter), loss = 0.102074, remaining 0 hours and 49 minutes
I0109 01:17:27.454257  8505 solver.cpp:291]     Train net output #0: loss = 0.102074 (* 1 = 0.102074 loss)
I0109 01:17:27.454280  8505 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0109 01:17:40.281069  8505 solver.cpp:270] Iteration 350 (3.89824 iter/s, 12.8263s/50 iter), loss = 0.0492022, remaining 0 hours and 49 minutes
I0109 01:17:40.281101  8505 solver.cpp:291]     Train net output #0: loss = 0.0492022 (* 1 = 0.0492022 loss)
I0109 01:17:40.281123  8505 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0109 01:17:53.086040  8505 solver.cpp:270] Iteration 400 (3.90488 iter/s, 12.8045s/50 iter), loss = 0.100431, remaining 0 hours and 49 minutes
I0109 01:17:53.086086  8505 solver.cpp:291]     Train net output #0: loss = 0.100431 (* 1 = 0.100431 loss)
I0109 01:17:53.086093  8505 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0109 01:18:05.946462  8505 solver.cpp:270] Iteration 450 (3.88805 iter/s, 12.8599s/50 iter), loss = 0.0368069, remaining 0 hours and 49 minutes
I0109 01:18:05.946496  8505 solver.cpp:291]     Train net output #0: loss = 0.0368069 (* 1 = 0.0368069 loss)
I0109 01:18:05.946503  8505 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0109 01:18:18.790307  8505 solver.cpp:270] Iteration 500 (3.89307 iter/s, 12.8433s/50 iter), loss = 0.0747824, remaining 0 hours and 49 minutes
I0109 01:18:18.790340  8505 solver.cpp:291]     Train net output #0: loss = 0.0747824 (* 1 = 0.0747824 loss)
I0109 01:18:18.790347  8505 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0109 01:18:31.642912  8505 solver.cpp:270] Iteration 550 (3.89041 iter/s, 12.8521s/50 iter), loss = 0.110345, remaining 0 hours and 48 minutes
I0109 01:18:31.642963  8505 solver.cpp:291]     Train net output #0: loss = 0.110345 (* 1 = 0.110345 loss)
I0109 01:18:31.642971  8505 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0109 01:18:44.496608  8505 solver.cpp:270] Iteration 600 (3.89009 iter/s, 12.8532s/50 iter), loss = 0.0581882, remaining 0 hours and 48 minutes
I0109 01:18:44.496639  8505 solver.cpp:291]     Train net output #0: loss = 0.0581882 (* 1 = 0.0581882 loss)
I0109 01:18:44.496662  8505 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0109 01:18:57.386065  8505 solver.cpp:270] Iteration 650 (3.87929 iter/s, 12.889s/50 iter), loss = 0.0701785, remaining 0 hours and 48 minutes
I0109 01:18:57.386097  8505 solver.cpp:291]     Train net output #0: loss = 0.0701785 (* 1 = 0.0701785 loss)
I0109 01:18:57.386104  8505 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0109 01:19:10.295089  8505 solver.cpp:270] Iteration 700 (3.87341 iter/s, 12.9085s/50 iter), loss = 0.102562, remaining 0 hours and 48 minutes
I0109 01:19:10.295135  8505 solver.cpp:291]     Train net output #0: loss = 0.102562 (* 1 = 0.102562 loss)
I0109 01:19:10.295143  8505 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0109 01:19:23.147035  8505 solver.cpp:270] Iteration 750 (3.89062 iter/s, 12.8514s/50 iter), loss = 0.0501729, remaining 0 hours and 48 minutes
I0109 01:19:23.147068  8505 solver.cpp:291]     Train net output #0: loss = 0.0501729 (* 1 = 0.0501729 loss)
I0109 01:19:23.147076  8505 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0109 01:19:36.022738  8505 solver.cpp:270] Iteration 800 (3.88344 iter/s, 12.8752s/50 iter), loss = 0.0645605, remaining 0 hours and 47 minutes
I0109 01:19:36.022770  8505 solver.cpp:291]     Train net output #0: loss = 0.0645605 (* 1 = 0.0645605 loss)
I0109 01:19:36.022778  8505 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0109 01:19:48.899652  8505 solver.cpp:270] Iteration 850 (3.88307 iter/s, 12.8764s/50 iter), loss = 0.0630979, remaining 0 hours and 47 minutes
I0109 01:19:48.899715  8505 solver.cpp:291]     Train net output #0: loss = 0.0630979 (* 1 = 0.0630979 loss)
I0109 01:19:48.899724  8505 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0109 01:20:01.773742  8505 solver.cpp:270] Iteration 900 (3.88393 iter/s, 12.8736s/50 iter), loss = 0.0729654, remaining 0 hours and 47 minutes
I0109 01:20:01.773774  8505 solver.cpp:291]     Train net output #0: loss = 0.0729654 (* 1 = 0.0729654 loss)
I0109 01:20:01.773782  8505 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0109 01:20:14.666278  8505 solver.cpp:270] Iteration 950 (3.87837 iter/s, 12.892s/50 iter), loss = 0.0628721, remaining 0 hours and 47 minutes
I0109 01:20:14.666309  8505 solver.cpp:291]     Train net output #0: loss = 0.0628722 (* 1 = 0.0628722 loss)
I0109 01:20:14.666316  8505 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0109 01:20:27.295929  8505 solver.cpp:424] Iteration 1000, Testing net (#0)
I0109 01:20:28.808650  8505 solver.cpp:523]     Test net output #0: accuracy = 0.898
I0109 01:20:28.808676  8505 solver.cpp:523]     Test net output #1: loss = 0.341377 (* 1 = 0.341377 loss)
I0109 01:20:28.808681  8505 solver.cpp:523]     Test net output #2: top-1 = 0.898
I0109 01:20:29.058553  8505 solver.cpp:270] Iteration 1000 (3.47422 iter/s, 14.3917s/50 iter), loss = 0.0515758, remaining 0 hours and 52 minutes
I0109 01:20:29.058578  8505 solver.cpp:291]     Train net output #0: loss = 0.0515758 (* 1 = 0.0515758 loss)
I0109 01:20:29.058586  8505 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0109 01:20:41.930626  8505 solver.cpp:270] Iteration 1050 (3.88453 iter/s, 12.8716s/50 iter), loss = 0.0964603, remaining 0 hours and 46 minutes
I0109 01:20:41.930656  8505 solver.cpp:291]     Train net output #0: loss = 0.0964603 (* 1 = 0.0964603 loss)
I0109 01:20:41.930662  8505 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0109 01:20:54.846863  8505 solver.cpp:270] Iteration 1100 (3.87125 iter/s, 12.9157s/50 iter), loss = 0.0589936, remaining 0 hours and 46 minutes
I0109 01:20:54.846894  8505 solver.cpp:291]     Train net output #0: loss = 0.0589936 (* 1 = 0.0589936 loss)
I0109 01:20:54.846900  8505 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0109 01:21:07.788050  8505 solver.cpp:270] Iteration 1150 (3.86379 iter/s, 12.9407s/50 iter), loss = 0.127795, remaining 0 hours and 46 minutes
I0109 01:21:07.788102  8505 solver.cpp:291]     Train net output #0: loss = 0.127795 (* 1 = 0.127795 loss)
I0109 01:21:07.788110  8505 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0109 01:21:20.638633  8505 solver.cpp:270] Iteration 1200 (3.89104 iter/s, 12.85s/50 iter), loss = 0.0511623, remaining 0 hours and 46 minutes
I0109 01:21:20.638664  8505 solver.cpp:291]     Train net output #0: loss = 0.0511623 (* 1 = 0.0511623 loss)
I0109 01:21:20.638671  8505 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0109 01:21:33.527053  8505 solver.cpp:270] Iteration 1250 (3.87961 iter/s, 12.8879s/50 iter), loss = 0.0847193, remaining 0 hours and 46 minutes
I0109 01:21:33.527087  8505 solver.cpp:291]     Train net output #0: loss = 0.0847193 (* 1 = 0.0847193 loss)
I0109 01:21:33.527094  8505 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0109 01:21:46.429711  8505 solver.cpp:270] Iteration 1300 (3.87533 iter/s, 12.9021s/50 iter), loss = 0.0932863, remaining 0 hours and 45 minutes
I0109 01:21:46.429759  8505 solver.cpp:291]     Train net output #0: loss = 0.0932863 (* 1 = 0.0932863 loss)
I0109 01:21:46.429765  8505 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0109 01:21:59.341048  8505 solver.cpp:270] Iteration 1350 (3.87272 iter/s, 12.9108s/50 iter), loss = 0.097398, remaining 0 hours and 45 minutes
I0109 01:21:59.341080  8505 solver.cpp:291]     Train net output #0: loss = 0.097398 (* 1 = 0.097398 loss)
I0109 01:21:59.341104  8505 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0109 01:22:12.198654  8505 solver.cpp:270] Iteration 1400 (3.8889 iter/s, 12.8571s/50 iter), loss = 0.0884378, remaining 0 hours and 45 minutes
I0109 01:22:12.198686  8505 solver.cpp:291]     Train net output #0: loss = 0.0884378 (* 1 = 0.0884378 loss)
I0109 01:22:12.198694  8505 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0109 01:22:25.074275  8505 solver.cpp:270] Iteration 1450 (3.88346 iter/s, 12.8751s/50 iter), loss = 0.0723572, remaining 0 hours and 45 minutes
I0109 01:22:25.074319  8505 solver.cpp:291]     Train net output #0: loss = 0.0723572 (* 1 = 0.0723572 loss)
I0109 01:22:25.074326  8505 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0109 01:22:37.946918  8505 solver.cpp:270] Iteration 1500 (3.88436 iter/s, 12.8721s/50 iter), loss = 0.0652462, remaining 0 hours and 45 minutes
I0109 01:22:37.946949  8505 solver.cpp:291]     Train net output #0: loss = 0.0652462 (* 1 = 0.0652462 loss)
I0109 01:22:37.946972  8505 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0109 01:22:50.828747  8505 solver.cpp:270] Iteration 1550 (3.88159 iter/s, 12.8813s/50 iter), loss = 0.0587723, remaining 0 hours and 44 minutes
I0109 01:22:50.828778  8505 solver.cpp:291]     Train net output #0: loss = 0.0587723 (* 1 = 0.0587723 loss)
I0109 01:22:50.828785  8505 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0109 01:23:03.687853  8505 solver.cpp:270] Iteration 1600 (3.88845 iter/s, 12.8586s/50 iter), loss = 0.0787361, remaining 0 hours and 44 minutes
I0109 01:23:03.687898  8505 solver.cpp:291]     Train net output #0: loss = 0.0787361 (* 1 = 0.0787361 loss)
I0109 01:23:03.687906  8505 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0109 01:23:16.533437  8505 solver.cpp:270] Iteration 1650 (3.89255 iter/s, 12.8451s/50 iter), loss = 0.0797052, remaining 0 hours and 44 minutes
I0109 01:23:16.533468  8505 solver.cpp:291]     Train net output #0: loss = 0.0797052 (* 1 = 0.0797052 loss)
I0109 01:23:16.533474  8505 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0109 01:23:29.395584  8505 solver.cpp:270] Iteration 1700 (3.88753 iter/s, 12.8616s/50 iter), loss = 0.0456982, remaining 0 hours and 43 minutes
I0109 01:23:29.395617  8505 solver.cpp:291]     Train net output #0: loss = 0.0456982 (* 1 = 0.0456982 loss)
I0109 01:23:29.395625  8505 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0109 01:23:42.272326  8505 solver.cpp:270] Iteration 1750 (3.88313 iter/s, 12.8762s/50 iter), loss = 0.0739712, remaining 0 hours and 43 minutes
I0109 01:23:42.272383  8505 solver.cpp:291]     Train net output #0: loss = 0.0739712 (* 1 = 0.0739712 loss)
I0109 01:23:42.272552  8505 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0109 01:23:55.177794  8505 solver.cpp:270] Iteration 1800 (3.87454 iter/s, 12.9048s/50 iter), loss = 0.0958799, remaining 0 hours and 43 minutes
I0109 01:23:55.177826  8505 solver.cpp:291]     Train net output #0: loss = 0.09588 (* 1 = 0.09588 loss)
I0109 01:23:55.177834  8505 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0109 01:24:08.062235  8505 solver.cpp:270] Iteration 1850 (3.8808 iter/s, 12.8839s/50 iter), loss = 0.0650443, remaining 0 hours and 43 minutes
I0109 01:24:08.062269  8505 solver.cpp:291]     Train net output #0: loss = 0.0650444 (* 1 = 0.0650444 loss)
I0109 01:24:08.062292  8505 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0109 01:24:20.933956  8505 solver.cpp:270] Iteration 1900 (3.88464 iter/s, 12.8712s/50 iter), loss = 0.0943546, remaining 0 hours and 43 minutes
I0109 01:24:20.934005  8505 solver.cpp:291]     Train net output #0: loss = 0.0943546 (* 1 = 0.0943546 loss)
I0109 01:24:20.934012  8505 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0109 01:24:33.780885  8505 solver.cpp:270] Iteration 1950 (3.89214 iter/s, 12.8464s/50 iter), loss = 0.035593, remaining 0 hours and 42 minutes
I0109 01:24:33.780917  8505 solver.cpp:291]     Train net output #0: loss = 0.035593 (* 1 = 0.035593 loss)
I0109 01:24:33.780941  8505 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0109 01:24:46.398427  8505 solver.cpp:424] Iteration 2000, Testing net (#0)
I0109 01:24:47.907434  8505 solver.cpp:523]     Test net output #0: accuracy = 0.9235
I0109 01:24:47.907464  8505 solver.cpp:523]     Test net output #1: loss = 0.285929 (* 1 = 0.285929 loss)
I0109 01:24:47.907469  8505 solver.cpp:523]     Test net output #2: top-1 = 0.9235
I0109 01:24:48.158776  8505 solver.cpp:270] Iteration 2000 (3.4777 iter/s, 14.3773s/50 iter), loss = 0.0612771, remaining 0 hours and 47 minutes
I0109 01:24:48.158800  8505 solver.cpp:291]     Train net output #0: loss = 0.0612771 (* 1 = 0.0612771 loss)
I0109 01:24:48.158808  8505 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0109 01:25:01.057870  8505 solver.cpp:270] Iteration 2050 (3.87639 iter/s, 12.8986s/50 iter), loss = 0.0618246, remaining 0 hours and 42 minutes
I0109 01:25:01.057917  8505 solver.cpp:291]     Train net output #0: loss = 0.0618246 (* 1 = 0.0618246 loss)
I0109 01:25:01.057925  8505 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0109 01:25:13.885259  8505 solver.cpp:270] Iteration 2100 (3.89807 iter/s, 12.8269s/50 iter), loss = 0.0431278, remaining 0 hours and 42 minutes
I0109 01:25:13.885290  8505 solver.cpp:291]     Train net output #0: loss = 0.0431278 (* 1 = 0.0431278 loss)
I0109 01:25:13.885298  8505 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0109 01:25:26.740835  8505 solver.cpp:270] Iteration 2150 (3.88952 iter/s, 12.8551s/50 iter), loss = 0.0727489, remaining 0 hours and 42 minutes
I0109 01:25:26.740866  8505 solver.cpp:291]     Train net output #0: loss = 0.072749 (* 1 = 0.072749 loss)
I0109 01:25:26.740873  8505 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0109 01:25:39.645476  8505 solver.cpp:270] Iteration 2200 (3.87473 iter/s, 12.9041s/50 iter), loss = 0.072299, remaining 0 hours and 42 minutes
I0109 01:25:39.645530  8505 solver.cpp:291]     Train net output #0: loss = 0.072299 (* 1 = 0.072299 loss)
I0109 01:25:39.645555  8505 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0109 01:25:52.481067  8505 solver.cpp:270] Iteration 2250 (3.89558 iter/s, 12.8351s/50 iter), loss = 0.0659944, remaining 0 hours and 41 minutes
I0109 01:25:52.481101  8505 solver.cpp:291]     Train net output #0: loss = 0.0659945 (* 1 = 0.0659945 loss)
I0109 01:25:52.481107  8505 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0109 01:26:05.355608  8505 solver.cpp:270] Iteration 2300 (3.88379 iter/s, 12.874s/50 iter), loss = 0.0963972, remaining 0 hours and 41 minutes
I0109 01:26:05.355641  8505 solver.cpp:291]     Train net output #0: loss = 0.0963972 (* 1 = 0.0963972 loss)
I0109 01:26:05.355648  8505 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0109 01:26:18.275713  8505 solver.cpp:270] Iteration 2350 (3.87009 iter/s, 12.9196s/50 iter), loss = 0.0489095, remaining 0 hours and 41 minutes
I0109 01:26:18.275758  8505 solver.cpp:291]     Train net output #0: loss = 0.0489096 (* 1 = 0.0489096 loss)
I0109 01:26:18.275781  8505 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0109 01:26:31.154290  8505 solver.cpp:270] Iteration 2400 (3.88257 iter/s, 12.8781s/50 iter), loss = 0.0690336, remaining 0 hours and 41 minutes
I0109 01:26:31.154323  8505 solver.cpp:291]     Train net output #0: loss = 0.0690336 (* 1 = 0.0690336 loss)
I0109 01:26:31.154330  8505 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0109 01:26:44.026158  8505 solver.cpp:270] Iteration 2450 (3.8846 iter/s, 12.8714s/50 iter), loss = 0.128243, remaining 0 hours and 40 minutes
I0109 01:26:44.026192  8505 solver.cpp:291]     Train net output #0: loss = 0.128243 (* 1 = 0.128243 loss)
I0109 01:26:44.026216  8505 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0109 01:26:56.871942  8505 solver.cpp:270] Iteration 2500 (3.89248 iter/s, 12.8453s/50 iter), loss = 0.0706605, remaining 0 hours and 40 minutes
I0109 01:26:56.871987  8505 solver.cpp:291]     Train net output #0: loss = 0.0706605 (* 1 = 0.0706605 loss)
I0109 01:26:56.871994  8505 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0109 01:27:09.747763  8505 solver.cpp:270] Iteration 2550 (3.88341 iter/s, 12.8753s/50 iter), loss = 0.0425268, remaining 0 hours and 40 minutes
I0109 01:27:09.747795  8505 solver.cpp:291]     Train net output #0: loss = 0.0425268 (* 1 = 0.0425268 loss)
I0109 01:27:09.747802  8505 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0109 01:27:22.635751  8505 solver.cpp:270] Iteration 2600 (3.87974 iter/s, 12.8875s/50 iter), loss = 0.0178011, remaining 0 hours and 40 minutes
I0109 01:27:22.635783  8505 solver.cpp:291]     Train net output #0: loss = 0.0178011 (* 1 = 0.0178011 loss)
I0109 01:27:22.635805  8505 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0109 01:27:35.512456  8505 solver.cpp:270] Iteration 2650 (3.88314 iter/s, 12.8762s/50 iter), loss = 0.0330769, remaining 0 hours and 39 minutes
I0109 01:27:35.512502  8505 solver.cpp:291]     Train net output #0: loss = 0.0330769 (* 1 = 0.0330769 loss)
I0109 01:27:35.512511  8505 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0109 01:27:48.388290  8505 solver.cpp:270] Iteration 2700 (3.8834 iter/s, 12.8753s/50 iter), loss = 0.0118007, remaining 0 hours and 39 minutes
I0109 01:27:48.388321  8505 solver.cpp:291]     Train net output #0: loss = 0.0118007 (* 1 = 0.0118007 loss)
I0109 01:27:48.388329  8505 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0109 01:28:01.246495  8505 solver.cpp:270] Iteration 2750 (3.88872 iter/s, 12.8577s/50 iter), loss = 0.0276767, remaining 0 hours and 39 minutes
I0109 01:28:01.246526  8505 solver.cpp:291]     Train net output #0: loss = 0.0276767 (* 1 = 0.0276767 loss)
I0109 01:28:01.246532  8505 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0109 01:28:14.092830  8505 solver.cpp:270] Iteration 2800 (3.89231 iter/s, 12.8458s/50 iter), loss = 0.0538309, remaining 0 hours and 39 minutes
I0109 01:28:14.092878  8505 solver.cpp:291]     Train net output #0: loss = 0.0538309 (* 1 = 0.0538309 loss)
I0109 01:28:14.092886  8505 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0109 01:28:26.936247  8505 solver.cpp:270] Iteration 2850 (3.8932 iter/s, 12.8429s/50 iter), loss = 0.0287026, remaining 0 hours and 39 minutes
I0109 01:28:26.936280  8505 solver.cpp:291]     Train net output #0: loss = 0.0287026 (* 1 = 0.0287026 loss)
I0109 01:28:26.936303  8505 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0109 01:28:39.800977  8505 solver.cpp:270] Iteration 2900 (3.88675 iter/s, 12.8642s/50 iter), loss = 0.0127701, remaining 0 hours and 38 minutes
I0109 01:28:39.801007  8505 solver.cpp:291]     Train net output #0: loss = 0.0127701 (* 1 = 0.0127701 loss)
I0109 01:28:39.801014  8505 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0109 01:28:52.685365  8505 solver.cpp:270] Iteration 2950 (3.88082 iter/s, 12.8839s/50 iter), loss = 0.0227921, remaining 0 hours and 38 minutes
I0109 01:28:52.685417  8505 solver.cpp:291]     Train net output #0: loss = 0.0227921 (* 1 = 0.0227921 loss)
I0109 01:28:52.685441  8505 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0109 01:29:05.302659  8505 solver.cpp:424] Iteration 3000, Testing net (#0)
I0109 01:29:06.784081  8505 solver.cpp:523]     Test net output #0: accuracy = 0.9505
I0109 01:29:06.784108  8505 solver.cpp:523]     Test net output #1: loss = 0.137755 (* 1 = 0.137755 loss)
I0109 01:29:06.784112  8505 solver.cpp:523]     Test net output #2: top-1 = 0.9505
I0109 01:29:07.033054  8505 solver.cpp:270] Iteration 3000 (3.48502 iter/s, 14.3471s/50 iter), loss = 0.0188174, remaining 0 hours and 43 minutes
I0109 01:29:07.033078  8505 solver.cpp:291]     Train net output #0: loss = 0.0188174 (* 1 = 0.0188174 loss)
I0109 01:29:07.033085  8505 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0109 01:29:19.933296  8505 solver.cpp:270] Iteration 3050 (3.87605 iter/s, 12.8997s/50 iter), loss = 0.0125341, remaining 0 hours and 38 minutes
I0109 01:29:19.933329  8505 solver.cpp:291]     Train net output #0: loss = 0.0125341 (* 1 = 0.0125341 loss)
I0109 01:29:19.933336  8505 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0109 01:29:32.807267  8505 solver.cpp:270] Iteration 3100 (3.88396 iter/s, 12.8735s/50 iter), loss = 0.00628346, remaining 0 hours and 38 minutes
I0109 01:29:32.807313  8505 solver.cpp:291]     Train net output #0: loss = 0.00628346 (* 1 = 0.00628346 loss)
I0109 01:29:32.807337  8505 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0109 01:29:45.673966  8505 solver.cpp:270] Iteration 3150 (3.88616 iter/s, 12.8662s/50 iter), loss = 0.0166058, remaining 0 hours and 37 minutes
I0109 01:29:45.673998  8505 solver.cpp:291]     Train net output #0: loss = 0.0166058 (* 1 = 0.0166058 loss)
I0109 01:29:45.674005  8505 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0109 01:29:58.559338  8505 solver.cpp:270] Iteration 3200 (3.88052 iter/s, 12.8849s/50 iter), loss = 0.0278035, remaining 0 hours and 37 minutes
I0109 01:29:58.559370  8505 solver.cpp:291]     Train net output #0: loss = 0.0278035 (* 1 = 0.0278035 loss)
I0109 01:29:58.559377  8505 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0109 01:30:11.414217  8505 solver.cpp:270] Iteration 3250 (3.88973 iter/s, 12.8544s/50 iter), loss = 0.0194181, remaining 0 hours and 37 minutes
I0109 01:30:11.414264  8505 solver.cpp:291]     Train net output #0: loss = 0.0194181 (* 1 = 0.0194181 loss)
I0109 01:30:11.414288  8505 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0109 01:30:24.287052  8505 solver.cpp:270] Iteration 3300 (3.88431 iter/s, 12.8723s/50 iter), loss = 0.0177703, remaining 0 hours and 37 minutes
I0109 01:30:24.287084  8505 solver.cpp:291]     Train net output #0: loss = 0.0177703 (* 1 = 0.0177703 loss)
I0109 01:30:24.287091  8505 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0109 01:30:37.164285  8505 solver.cpp:270] Iteration 3350 (3.88298 iter/s, 12.8767s/50 iter), loss = 0.0411274, remaining 0 hours and 37 minutes
I0109 01:30:37.164317  8505 solver.cpp:291]     Train net output #0: loss = 0.0411275 (* 1 = 0.0411275 loss)
I0109 01:30:37.164324  8505 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0109 01:30:50.041666  8505 solver.cpp:270] Iteration 3400 (3.88293 iter/s, 12.8769s/50 iter), loss = 0.0444954, remaining 0 hours and 36 minutes
I0109 01:30:50.041718  8505 solver.cpp:291]     Train net output #0: loss = 0.0444954 (* 1 = 0.0444954 loss)
I0109 01:30:50.041741  8505 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0109 01:31:02.908119  8505 solver.cpp:270] Iteration 3450 (3.88624 iter/s, 12.8659s/50 iter), loss = 0.0121548, remaining 0 hours and 36 minutes
I0109 01:31:02.908151  8505 solver.cpp:291]     Train net output #0: loss = 0.0121548 (* 1 = 0.0121548 loss)
I0109 01:31:02.908159  8505 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0109 01:31:15.821252  8505 solver.cpp:270] Iteration 3500 (3.87218 iter/s, 12.9126s/50 iter), loss = 0.0138073, remaining 0 hours and 36 minutes
I0109 01:31:15.821285  8505 solver.cpp:291]     Train net output #0: loss = 0.0138073 (* 1 = 0.0138073 loss)
I0109 01:31:15.821291  8505 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0109 01:31:28.675139  8505 solver.cpp:270] Iteration 3550 (3.89003 iter/s, 12.8534s/50 iter), loss = 0.0168437, remaining 0 hours and 35 minutes
I0109 01:31:28.675184  8505 solver.cpp:291]     Train net output #0: loss = 0.0168437 (* 1 = 0.0168437 loss)
I0109 01:31:28.675191  8505 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0109 01:31:41.561512  8505 solver.cpp:270] Iteration 3600 (3.88023 iter/s, 12.8858s/50 iter), loss = 0.0102265, remaining 0 hours and 36 minutes
I0109 01:31:41.561547  8505 solver.cpp:291]     Train net output #0: loss = 0.0102265 (* 1 = 0.0102265 loss)
I0109 01:31:41.561553  8505 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0109 01:31:54.423044  8505 solver.cpp:270] Iteration 3650 (3.88772 iter/s, 12.861s/50 iter), loss = 0.0252916, remaining 0 hours and 35 minutes
I0109 01:31:54.423076  8505 solver.cpp:291]     Train net output #0: loss = 0.0252916 (* 1 = 0.0252916 loss)
I0109 01:31:54.423084  8505 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0109 01:32:07.285557  8505 solver.cpp:270] Iteration 3700 (3.88742 iter/s, 12.862s/50 iter), loss = 0.0076241, remaining 0 hours and 35 minutes
I0109 01:32:07.285602  8505 solver.cpp:291]     Train net output #0: loss = 0.00762411 (* 1 = 0.00762411 loss)
I0109 01:32:07.285626  8505 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0109 01:32:20.145292  8505 solver.cpp:270] Iteration 3750 (3.88826 iter/s, 12.8592s/50 iter), loss = 0.0153858, remaining 0 hours and 35 minutes
I0109 01:32:20.145323  8505 solver.cpp:291]     Train net output #0: loss = 0.0153858 (* 1 = 0.0153858 loss)
I0109 01:32:20.145329  8505 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0109 01:32:33.000154  8505 solver.cpp:270] Iteration 3800 (3.88973 iter/s, 12.8544s/50 iter), loss = 0.014859, remaining 0 hours and 34 minutes
I0109 01:32:33.000186  8505 solver.cpp:291]     Train net output #0: loss = 0.014859 (* 1 = 0.014859 loss)
I0109 01:32:33.000195  8505 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0109 01:32:45.813910  8505 solver.cpp:270] Iteration 3850 (3.90221 iter/s, 12.8132s/50 iter), loss = 0.0101718, remaining 0 hours and 34 minutes
I0109 01:32:45.813957  8505 solver.cpp:291]     Train net output #0: loss = 0.0101718 (* 1 = 0.0101718 loss)
I0109 01:32:45.813966  8505 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0109 01:32:58.657655  8505 solver.cpp:270] Iteration 3900 (3.89311 iter/s, 12.8432s/50 iter), loss = 0.00917356, remaining 0 hours and 34 minutes
I0109 01:32:58.657687  8505 solver.cpp:291]     Train net output #0: loss = 0.00917357 (* 1 = 0.00917357 loss)
I0109 01:32:58.657694  8505 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0109 01:33:11.524197  8505 solver.cpp:270] Iteration 3950 (3.8862 iter/s, 12.866s/50 iter), loss = 0.0349435, remaining 0 hours and 34 minutes
I0109 01:33:11.524231  8505 solver.cpp:291]     Train net output #0: loss = 0.0349435 (* 1 = 0.0349435 loss)
I0109 01:33:11.524238  8505 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0109 01:33:24.098279  8505 solver.cpp:424] Iteration 4000, Testing net (#0)
I0109 01:33:25.604485  8505 solver.cpp:523]     Test net output #0: accuracy = 0.9435
I0109 01:33:25.604512  8505 solver.cpp:523]     Test net output #1: loss = 0.160805 (* 1 = 0.160805 loss)
I0109 01:33:25.604517  8505 solver.cpp:523]     Test net output #2: top-1 = 0.9435
I0109 01:33:25.851706  8505 solver.cpp:270] Iteration 4000 (3.48993 iter/s, 14.3269s/50 iter), loss = 0.0095182, remaining 0 hours and 38 minutes
I0109 01:33:25.851732  8505 solver.cpp:291]     Train net output #0: loss = 0.00951821 (* 1 = 0.00951821 loss)
I0109 01:33:25.851740  8505 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0109 01:33:38.681699  8505 solver.cpp:270] Iteration 4050 (3.89727 iter/s, 12.8295s/50 iter), loss = 0.0184384, remaining 0 hours and 33 minutes
I0109 01:33:38.681728  8505 solver.cpp:291]     Train net output #0: loss = 0.0184384 (* 1 = 0.0184384 loss)
I0109 01:33:38.681735  8505 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0109 01:33:51.519291  8505 solver.cpp:270] Iteration 4100 (3.89497 iter/s, 12.8371s/50 iter), loss = 0.0314576, remaining 0 hours and 33 minutes
I0109 01:33:51.519322  8505 solver.cpp:291]     Train net output #0: loss = 0.0314576 (* 1 = 0.0314576 loss)
I0109 01:33:51.519330  8505 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0109 01:34:04.394547  8505 solver.cpp:270] Iteration 4150 (3.88357 iter/s, 12.8747s/50 iter), loss = 0.0197496, remaining 0 hours and 33 minutes
I0109 01:34:04.394599  8505 solver.cpp:291]     Train net output #0: loss = 0.0197496 (* 1 = 0.0197496 loss)
I0109 01:34:04.394623  8505 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0109 01:34:17.208281  8505 solver.cpp:270] Iteration 4200 (3.90223 iter/s, 12.8132s/50 iter), loss = 0.011266, remaining 0 hours and 33 minutes
I0109 01:34:17.208312  8505 solver.cpp:291]     Train net output #0: loss = 0.011266 (* 1 = 0.011266 loss)
I0109 01:34:17.208335  8505 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0109 01:34:30.065344  8505 solver.cpp:270] Iteration 4250 (3.88907 iter/s, 12.8566s/50 iter), loss = 0.0199774, remaining 0 hours and 33 minutes
I0109 01:34:30.065376  8505 solver.cpp:291]     Train net output #0: loss = 0.0199775 (* 1 = 0.0199775 loss)
I0109 01:34:30.065384  8505 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0109 01:34:42.903470  8505 solver.cpp:270] Iteration 4300 (3.89481 iter/s, 12.8376s/50 iter), loss = 0.023408, remaining 0 hours and 32 minutes
I0109 01:34:42.903518  8505 solver.cpp:291]     Train net output #0: loss = 0.023408 (* 1 = 0.023408 loss)
I0109 01:34:42.903525  8505 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0109 01:34:55.740983  8505 solver.cpp:270] Iteration 4350 (3.895 iter/s, 12.837s/50 iter), loss = 0.00386072, remaining 0 hours and 32 minutes
I0109 01:34:55.741016  8505 solver.cpp:291]     Train net output #0: loss = 0.00386075 (* 1 = 0.00386075 loss)
I0109 01:34:55.741024  8505 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0109 01:35:08.618306  8505 solver.cpp:270] Iteration 4400 (3.88295 iter/s, 12.8768s/50 iter), loss = 0.00966623, remaining 0 hours and 32 minutes
I0109 01:35:08.618336  8505 solver.cpp:291]     Train net output #0: loss = 0.00966626 (* 1 = 0.00966626 loss)
I0109 01:35:08.618360  8505 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0109 01:35:21.462236  8505 solver.cpp:270] Iteration 4450 (3.89304 iter/s, 12.8434s/50 iter), loss = 0.0166946, remaining 0 hours and 32 minutes
I0109 01:35:21.462285  8505 solver.cpp:291]     Train net output #0: loss = 0.0166946 (* 1 = 0.0166946 loss)
I0109 01:35:21.462291  8505 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0109 01:35:34.281333  8505 solver.cpp:270] Iteration 4500 (3.90059 iter/s, 12.8186s/50 iter), loss = 0.0118822, remaining 0 hours and 32 minutes
I0109 01:35:34.281368  8505 solver.cpp:291]     Train net output #0: loss = 0.0118823 (* 1 = 0.0118823 loss)
I0109 01:35:34.281390  8505 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0109 01:35:47.143343  8505 solver.cpp:270] Iteration 4550 (3.88757 iter/s, 12.8615s/50 iter), loss = 0.00226417, remaining 0 hours and 31 minutes
I0109 01:35:47.143376  8505 solver.cpp:291]     Train net output #0: loss = 0.00226419 (* 1 = 0.00226419 loss)
I0109 01:35:47.143384  8505 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0109 01:35:59.996352  8505 solver.cpp:270] Iteration 4600 (3.89029 iter/s, 12.8525s/50 iter), loss = 0.00984072, remaining 0 hours and 31 minutes
I0109 01:35:59.996403  8505 solver.cpp:291]     Train net output #0: loss = 0.00984074 (* 1 = 0.00984074 loss)
I0109 01:35:59.996410  8505 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0109 01:36:12.855111  8505 solver.cpp:270] Iteration 4650 (3.88856 iter/s, 12.8582s/50 iter), loss = 0.0209791, remaining 0 hours and 31 minutes
I0109 01:36:12.855144  8505 solver.cpp:291]     Train net output #0: loss = 0.0209791 (* 1 = 0.0209791 loss)
I0109 01:36:12.855166  8505 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0109 01:36:25.683109  8505 solver.cpp:270] Iteration 4700 (3.89788 iter/s, 12.8275s/50 iter), loss = 0.0124973, remaining 0 hours and 31 minutes
I0109 01:36:25.683140  8505 solver.cpp:291]     Train net output #0: loss = 0.0124973 (* 1 = 0.0124973 loss)
I0109 01:36:25.683163  8505 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0109 01:36:38.503466  8505 solver.cpp:270] Iteration 4750 (3.9002 iter/s, 12.8198s/50 iter), loss = 0.0232298, remaining 0 hours and 30 minutes
I0109 01:36:38.503504  8505 solver.cpp:291]     Train net output #0: loss = 0.0232298 (* 1 = 0.0232298 loss)
I0109 01:36:38.503511  8505 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0109 01:36:51.360399  8505 solver.cpp:270] Iteration 4800 (3.88911 iter/s, 12.8564s/50 iter), loss = 0.0189417, remaining 0 hours and 30 minutes
I0109 01:36:51.360431  8505 solver.cpp:291]     Train net output #0: loss = 0.0189417 (* 1 = 0.0189417 loss)
I0109 01:36:51.360438  8505 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0109 01:37:04.209977  8505 solver.cpp:270] Iteration 4850 (3.89133 iter/s, 12.8491s/50 iter), loss = 0.032885, remaining 0 hours and 30 minutes
I0109 01:37:04.210008  8505 solver.cpp:291]     Train net output #0: loss = 0.032885 (* 1 = 0.032885 loss)
I0109 01:37:04.210032  8505 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0109 01:37:17.065399  8505 solver.cpp:270] Iteration 4900 (3.88956 iter/s, 12.8549s/50 iter), loss = 0.00925212, remaining 0 hours and 30 minutes
I0109 01:37:17.065445  8505 solver.cpp:291]     Train net output #0: loss = 0.00925214 (* 1 = 0.00925214 loss)
I0109 01:37:17.065454  8505 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0109 01:37:29.889513  8505 solver.cpp:270] Iteration 4950 (3.89907 iter/s, 12.8236s/50 iter), loss = 0.0283195, remaining 0 hours and 30 minutes
I0109 01:37:29.889544  8505 solver.cpp:291]     Train net output #0: loss = 0.0283195 (* 1 = 0.0283195 loss)
I0109 01:37:29.889551  8505 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0109 01:37:42.456974  8505 solver.cpp:424] Iteration 5000, Testing net (#0)
I0109 01:37:43.949270  8505 solver.cpp:523]     Test net output #0: accuracy = 0.949
I0109 01:37:43.949297  8505 solver.cpp:523]     Test net output #1: loss = 0.167463 (* 1 = 0.167463 loss)
I0109 01:37:43.949301  8505 solver.cpp:523]     Test net output #2: top-1 = 0.949
I0109 01:37:44.199400  8505 solver.cpp:270] Iteration 5000 (3.49422 iter/s, 14.3093s/50 iter), loss = 0.0122788, remaining 0 hours and 33 minutes
I0109 01:37:44.199425  8505 solver.cpp:291]     Train net output #0: loss = 0.0122788 (* 1 = 0.0122788 loss)
I0109 01:37:44.199434  8505 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0109 01:37:57.031590  8505 solver.cpp:270] Iteration 5050 (3.8966 iter/s, 12.8317s/50 iter), loss = 0.00812148, remaining 0 hours and 29 minutes
I0109 01:37:57.031637  8505 solver.cpp:291]     Train net output #0: loss = 0.00812151 (* 1 = 0.00812151 loss)
I0109 01:37:57.031644  8505 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0109 01:38:09.897279  8505 solver.cpp:270] Iteration 5100 (3.88647 iter/s, 12.8652s/50 iter), loss = 0.00413374, remaining 0 hours and 29 minutes
I0109 01:38:09.897310  8505 solver.cpp:291]     Train net output #0: loss = 0.00413377 (* 1 = 0.00413377 loss)
I0109 01:38:09.897316  8505 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0109 01:38:22.731153  8505 solver.cpp:270] Iteration 5150 (3.89609 iter/s, 12.8334s/50 iter), loss = 0.00260951, remaining 0 hours and 29 minutes
I0109 01:38:22.731185  8505 solver.cpp:291]     Train net output #0: loss = 0.00260954 (* 1 = 0.00260954 loss)
I0109 01:38:22.731209  8505 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0109 01:38:35.584368  8505 solver.cpp:270] Iteration 5200 (3.89023 iter/s, 12.8527s/50 iter), loss = 0.00356959, remaining 0 hours and 29 minutes
I0109 01:38:35.584421  8505 solver.cpp:291]     Train net output #0: loss = 0.00356962 (* 1 = 0.00356962 loss)
I0109 01:38:35.584429  8505 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0109 01:38:48.419890  8505 solver.cpp:270] Iteration 5250 (3.8956 iter/s, 12.835s/50 iter), loss = 0.00507436, remaining 0 hours and 28 minutes
I0109 01:38:48.419921  8505 solver.cpp:291]     Train net output #0: loss = 0.00507439 (* 1 = 0.00507439 loss)
I0109 01:38:48.419945  8505 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0109 01:39:01.228269  8505 solver.cpp:270] Iteration 5300 (3.90385 iter/s, 12.8079s/50 iter), loss = 0.00574169, remaining 0 hours and 28 minutes
I0109 01:39:01.228300  8505 solver.cpp:291]     Train net output #0: loss = 0.00574172 (* 1 = 0.00574172 loss)
I0109 01:39:01.228308  8505 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0109 01:39:14.055351  8505 solver.cpp:270] Iteration 5350 (3.89816 iter/s, 12.8266s/50 iter), loss = 0.0063039, remaining 0 hours and 28 minutes
I0109 01:39:14.055397  8505 solver.cpp:291]     Train net output #0: loss = 0.00630393 (* 1 = 0.00630393 loss)
I0109 01:39:14.055419  8505 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0109 01:39:26.894322  8505 solver.cpp:270] Iteration 5400 (3.89455 iter/s, 12.8384s/50 iter), loss = 0.00137629, remaining 0 hours and 28 minutes
I0109 01:39:26.894356  8505 solver.cpp:291]     Train net output #0: loss = 0.00137632 (* 1 = 0.00137632 loss)
I0109 01:39:26.894362  8505 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0109 01:39:39.739315  8505 solver.cpp:270] Iteration 5450 (3.89272 iter/s, 12.8445s/50 iter), loss = 0.0091987, remaining 0 hours and 28 minutes
I0109 01:39:39.739347  8505 solver.cpp:291]     Train net output #0: loss = 0.00919873 (* 1 = 0.00919873 loss)
I0109 01:39:39.739356  8505 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0109 01:39:52.555092  8505 solver.cpp:270] Iteration 5500 (3.9016 iter/s, 12.8153s/50 iter), loss = 0.00106819, remaining 0 hours and 27 minutes
I0109 01:39:52.555141  8505 solver.cpp:291]     Train net output #0: loss = 0.00106822 (* 1 = 0.00106822 loss)
I0109 01:39:52.555150  8505 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0109 01:40:05.409991  8505 solver.cpp:270] Iteration 5550 (3.88973 iter/s, 12.8544s/50 iter), loss = 0.00764736, remaining 0 hours and 27 minutes
I0109 01:40:05.410022  8505 solver.cpp:291]     Train net output #0: loss = 0.00764739 (* 1 = 0.00764739 loss)
I0109 01:40:05.410045  8505 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0109 01:40:18.274807  8505 solver.cpp:270] Iteration 5600 (3.88672 iter/s, 12.8643s/50 iter), loss = 0.000971581, remaining 0 hours and 27 minutes
I0109 01:40:18.274839  8505 solver.cpp:291]     Train net output #0: loss = 0.000971612 (* 1 = 0.000971612 loss)
I0109 01:40:18.274847  8505 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0109 01:40:31.105418  8505 solver.cpp:270] Iteration 5650 (3.89709 iter/s, 12.8301s/50 iter), loss = 0.0171405, remaining 0 hours and 26 minutes
I0109 01:40:31.105468  8505 solver.cpp:291]     Train net output #0: loss = 0.0171405 (* 1 = 0.0171405 loss)
I0109 01:40:31.105475  8505 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0109 01:40:43.959223  8505 solver.cpp:270] Iteration 5700 (3.89006 iter/s, 12.8533s/50 iter), loss = 0.00730113, remaining 0 hours and 26 minutes
I0109 01:40:43.959254  8505 solver.cpp:291]     Train net output #0: loss = 0.00730116 (* 1 = 0.00730116 loss)
I0109 01:40:43.959261  8505 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0109 01:40:56.807900  8505 solver.cpp:270] Iteration 5750 (3.89161 iter/s, 12.8482s/50 iter), loss = 0.00843161, remaining 0 hours and 26 minutes
I0109 01:40:56.807932  8505 solver.cpp:291]     Train net output #0: loss = 0.00843163 (* 1 = 0.00843163 loss)
I0109 01:40:56.807940  8505 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0109 01:41:09.650738  8505 solver.cpp:270] Iteration 5800 (3.89338 iter/s, 12.8423s/50 iter), loss = 0.000405934, remaining 0 hours and 26 minutes
I0109 01:41:09.650799  8505 solver.cpp:291]     Train net output #0: loss = 0.000405958 (* 1 = 0.000405958 loss)
I0109 01:41:09.650825  8505 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0109 01:41:22.481865  8505 solver.cpp:270] Iteration 5850 (3.89694 iter/s, 12.8306s/50 iter), loss = 0.00797871, remaining 0 hours and 26 minutes
I0109 01:41:22.481896  8505 solver.cpp:291]     Train net output #0: loss = 0.00797873 (* 1 = 0.00797873 loss)
I0109 01:41:22.481904  8505 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0109 01:41:35.325532  8505 solver.cpp:270] Iteration 5900 (3.89312 iter/s, 12.8432s/50 iter), loss = 0.0258242, remaining 0 hours and 25 minutes
I0109 01:41:35.325565  8505 solver.cpp:291]     Train net output #0: loss = 0.0258242 (* 1 = 0.0258242 loss)
I0109 01:41:35.325589  8505 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0109 01:41:48.188536  8505 solver.cpp:270] Iteration 5950 (3.88727 iter/s, 12.8625s/50 iter), loss = 0.00598284, remaining 0 hours and 25 minutes
I0109 01:41:48.188585  8505 solver.cpp:291]     Train net output #0: loss = 0.00598287 (* 1 = 0.00598287 loss)
I0109 01:41:48.188593  8505 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0109 01:42:00.789710  8505 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.6/snapshots/_iter_6000.caffemodel
I0109 01:42:03.257817  8505 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.6/snapshots/_iter_6000.solverstate
I0109 01:42:03.480463  8505 solver.cpp:424] Iteration 6000, Testing net (#0)
I0109 01:42:04.942546  8505 solver.cpp:523]     Test net output #0: accuracy = 0.95375
I0109 01:42:04.942576  8505 solver.cpp:523]     Test net output #1: loss = 0.199677 (* 1 = 0.199677 loss)
I0109 01:42:04.942580  8505 solver.cpp:523]     Test net output #2: top-1 = 0.95375
I0109 01:42:05.184185  8505 solver.cpp:270] Iteration 6000 (2.94205 iter/s, 16.995s/50 iter), loss = 0.00193064, remaining 0 hours and 33 minutes
I0109 01:42:05.184213  8505 solver.cpp:291]     Train net output #0: loss = 0.00193066 (* 1 = 0.00193066 loss)
I0109 01:42:05.184237  8505 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0109 01:42:17.969091  8505 solver.cpp:270] Iteration 6050 (3.91102 iter/s, 12.7844s/50 iter), loss = 0.00347268, remaining 0 hours and 25 minutes
I0109 01:42:17.969123  8505 solver.cpp:291]     Train net output #0: loss = 0.00347271 (* 1 = 0.00347271 loss)
I0109 01:42:17.969131  8505 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0109 01:42:30.746593  8505 solver.cpp:270] Iteration 6100 (3.91328 iter/s, 12.777s/50 iter), loss = 0.00605574, remaining 0 hours and 25 minutes
I0109 01:42:30.746640  8505 solver.cpp:291]     Train net output #0: loss = 0.00605576 (* 1 = 0.00605576 loss)
I0109 01:42:30.746649  8505 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0109 01:42:43.580761  8505 solver.cpp:270] Iteration 6150 (3.89601 iter/s, 12.8336s/50 iter), loss = 0.00192515, remaining 0 hours and 24 minutes
I0109 01:42:43.580793  8505 solver.cpp:291]     Train net output #0: loss = 0.00192517 (* 1 = 0.00192517 loss)
I0109 01:42:43.580801  8505 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0109 01:42:56.393353  8505 solver.cpp:270] Iteration 6200 (3.90257 iter/s, 12.8121s/50 iter), loss = 0.00918105, remaining 0 hours and 24 minutes
I0109 01:42:56.393384  8505 solver.cpp:291]     Train net output #0: loss = 0.00918108 (* 1 = 0.00918108 loss)
I0109 01:42:56.393393  8505 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0109 01:43:09.238363  8505 solver.cpp:270] Iteration 6250 (3.89272 iter/s, 12.8445s/50 iter), loss = 0.000133726, remaining 0 hours and 24 minutes
I0109 01:43:09.238409  8505 solver.cpp:291]     Train net output #0: loss = 0.000133753 (* 1 = 0.000133753 loss)
I0109 01:43:09.238431  8505 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0109 01:43:22.080631  8505 solver.cpp:270] Iteration 6300 (3.89355 iter/s, 12.8417s/50 iter), loss = 0.00315735, remaining 0 hours and 24 minutes
I0109 01:43:22.080663  8505 solver.cpp:291]     Train net output #0: loss = 0.00315738 (* 1 = 0.00315738 loss)
I0109 01:43:22.080672  8505 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0109 01:43:34.929651  8505 solver.cpp:270] Iteration 6350 (3.8915 iter/s, 12.8485s/50 iter), loss = 0.000595972, remaining 0 hours and 24 minutes
I0109 01:43:34.929682  8505 solver.cpp:291]     Train net output #0: loss = 0.000595998 (* 1 = 0.000595998 loss)
I0109 01:43:34.929689  8505 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0109 01:43:47.767236  8505 solver.cpp:270] Iteration 6400 (3.89497 iter/s, 12.8371s/50 iter), loss = 0.00366701, remaining 0 hours and 23 minutes
I0109 01:43:47.767292  8505 solver.cpp:291]     Train net output #0: loss = 0.00366703 (* 1 = 0.00366703 loss)
I0109 01:43:47.767300  8505 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0109 01:44:00.620247  8505 solver.cpp:270] Iteration 6450 (3.8903 iter/s, 12.8525s/50 iter), loss = 0.00448791, remaining 0 hours and 23 minutes
I0109 01:44:00.620280  8505 solver.cpp:291]     Train net output #0: loss = 0.00448793 (* 1 = 0.00448793 loss)
I0109 01:44:00.620302  8505 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0109 01:44:13.456329  8505 solver.cpp:270] Iteration 6500 (3.89543 iter/s, 12.8356s/50 iter), loss = 0.00419806, remaining 0 hours and 23 minutes
I0109 01:44:13.456363  8505 solver.cpp:291]     Train net output #0: loss = 0.00419808 (* 1 = 0.00419808 loss)
I0109 01:44:13.456387  8505 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0109 01:44:26.309168  8505 solver.cpp:270] Iteration 6550 (3.89035 iter/s, 12.8523s/50 iter), loss = 0.000923446, remaining 0 hours and 23 minutes
I0109 01:44:26.309214  8505 solver.cpp:291]     Train net output #0: loss = 0.000923467 (* 1 = 0.000923467 loss)
I0109 01:44:26.309221  8505 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0109 01:44:39.174082  8505 solver.cpp:270] Iteration 6600 (3.8867 iter/s, 12.8644s/50 iter), loss = 0.00207439, remaining 0 hours and 23 minutes
I0109 01:44:39.174115  8505 solver.cpp:291]     Train net output #0: loss = 0.00207441 (* 1 = 0.00207441 loss)
I0109 01:44:39.174122  8505 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0109 01:44:52.004938  8505 solver.cpp:270] Iteration 6650 (3.89701 iter/s, 12.8303s/50 iter), loss = 0.00133462, remaining 0 hours and 22 minutes
I0109 01:44:52.004969  8505 solver.cpp:291]     Train net output #0: loss = 0.00133464 (* 1 = 0.00133464 loss)
I0109 01:44:52.004993  8505 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0109 01:45:04.859477  8505 solver.cpp:270] Iteration 6700 (3.88983 iter/s, 12.854s/50 iter), loss = 0.00398342, remaining 0 hours and 22 minutes
I0109 01:45:04.859524  8505 solver.cpp:291]     Train net output #0: loss = 0.00398344 (* 1 = 0.00398344 loss)
I0109 01:45:04.859532  8505 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0109 01:45:17.700834  8505 solver.cpp:270] Iteration 6750 (3.89383 iter/s, 12.8408s/50 iter), loss = 0.00244645, remaining 0 hours and 22 minutes
I0109 01:45:17.700867  8505 solver.cpp:291]     Train net output #0: loss = 0.00244647 (* 1 = 0.00244647 loss)
I0109 01:45:17.700875  8505 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0109 01:45:30.546671  8505 solver.cpp:270] Iteration 6800 (3.89247 iter/s, 12.8453s/50 iter), loss = 0.010322, remaining 0 hours and 22 minutes
I0109 01:45:30.546705  8505 solver.cpp:291]     Train net output #0: loss = 0.010322 (* 1 = 0.010322 loss)
I0109 01:45:30.546712  8505 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0109 01:45:43.398969  8505 solver.cpp:270] Iteration 6850 (3.89051 iter/s, 12.8518s/50 iter), loss = 0.00211978, remaining 0 hours and 21 minutes
I0109 01:45:43.399016  8505 solver.cpp:291]     Train net output #0: loss = 0.0021198 (* 1 = 0.0021198 loss)
I0109 01:45:43.399024  8505 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0109 01:45:56.212638  8505 solver.cpp:270] Iteration 6900 (3.90224 iter/s, 12.8131s/50 iter), loss = 0.00246387, remaining 0 hours and 21 minutes
I0109 01:45:56.212668  8505 solver.cpp:291]     Train net output #0: loss = 0.0024639 (* 1 = 0.0024639 loss)
I0109 01:45:56.212675  8505 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0109 01:46:09.083806  8505 solver.cpp:270] Iteration 6950 (3.88481 iter/s, 12.8707s/50 iter), loss = 0.00509816, remaining 0 hours and 21 minutes
I0109 01:46:09.083835  8505 solver.cpp:291]     Train net output #0: loss = 0.00509819 (* 1 = 0.00509819 loss)
I0109 01:46:09.083843  8505 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0109 01:46:21.671629  8505 solver.cpp:424] Iteration 7000, Testing net (#0)
I0109 01:46:23.172438  8505 solver.cpp:523]     Test net output #0: accuracy = 0.9555
I0109 01:46:23.172466  8505 solver.cpp:523]     Test net output #1: loss = 0.21641 (* 1 = 0.21641 loss)
I0109 01:46:23.172472  8505 solver.cpp:523]     Test net output #2: top-1 = 0.9555
I0109 01:46:23.423010  8505 solver.cpp:270] Iteration 7000 (3.48708 iter/s, 14.3386s/50 iter), loss = 0.0119617, remaining 0 hours and 23 minutes
I0109 01:46:23.423034  8505 solver.cpp:291]     Train net output #0: loss = 0.0119617 (* 1 = 0.0119617 loss)
I0109 01:46:23.423041  8505 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0109 01:46:36.295081  8505 solver.cpp:270] Iteration 7050 (3.88453 iter/s, 12.8716s/50 iter), loss = 0.00573146, remaining 0 hours and 21 minutes
I0109 01:46:36.295114  8505 solver.cpp:291]     Train net output #0: loss = 0.00573148 (* 1 = 0.00573148 loss)
I0109 01:46:36.295137  8505 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0109 01:46:49.131376  8505 solver.cpp:270] Iteration 7100 (3.89536 iter/s, 12.8358s/50 iter), loss = 0.00208408, remaining 0 hours and 20 minutes
I0109 01:46:49.131409  8505 solver.cpp:291]     Train net output #0: loss = 0.0020841 (* 1 = 0.0020841 loss)
I0109 01:46:49.131433  8505 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0109 01:47:01.960005  8505 solver.cpp:270] Iteration 7150 (3.89769 iter/s, 12.8281s/50 iter), loss = 0.00791433, remaining 0 hours and 20 minutes
I0109 01:47:01.960052  8505 solver.cpp:291]     Train net output #0: loss = 0.00791435 (* 1 = 0.00791435 loss)
I0109 01:47:01.960058  8505 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0109 01:47:14.771162  8505 solver.cpp:270] Iteration 7200 (3.90301 iter/s, 12.8106s/50 iter), loss = 0.00333864, remaining 0 hours and 20 minutes
I0109 01:47:14.771193  8505 solver.cpp:291]     Train net output #0: loss = 0.00333867 (* 1 = 0.00333867 loss)
I0109 01:47:14.771200  8505 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0109 01:47:27.626399  8505 solver.cpp:270] Iteration 7250 (3.88962 iter/s, 12.8547s/50 iter), loss = 0.0098902, remaining 0 hours and 20 minutes
I0109 01:47:27.626431  8505 solver.cpp:291]     Train net output #0: loss = 0.00989023 (* 1 = 0.00989023 loss)
I0109 01:47:27.626438  8505 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0109 01:47:40.482738  8505 solver.cpp:270] Iteration 7300 (3.88929 iter/s, 12.8558s/50 iter), loss = 0.0166805, remaining 0 hours and 20 minutes
I0109 01:47:40.482782  8505 solver.cpp:291]     Train net output #0: loss = 0.0166806 (* 1 = 0.0166806 loss)
I0109 01:47:40.482806  8505 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0109 01:47:53.311942  8505 solver.cpp:270] Iteration 7350 (3.89752 iter/s, 12.8287s/50 iter), loss = 0.0141136, remaining 0 hours and 19 minutes
I0109 01:47:53.311975  8505 solver.cpp:291]     Train net output #0: loss = 0.0141137 (* 1 = 0.0141137 loss)
I0109 01:47:53.311983  8505 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0109 01:48:06.153098  8505 solver.cpp:270] Iteration 7400 (3.89389 iter/s, 12.8406s/50 iter), loss = 0.00446581, remaining 0 hours and 19 minutes
I0109 01:48:06.153129  8505 solver.cpp:291]     Train net output #0: loss = 0.00446583 (* 1 = 0.00446583 loss)
I0109 01:48:06.153152  8505 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0109 01:48:19.007146  8505 solver.cpp:270] Iteration 7450 (3.88998 iter/s, 12.8535s/50 iter), loss = 0.0182701, remaining 0 hours and 19 minutes
I0109 01:48:19.007195  8505 solver.cpp:291]     Train net output #0: loss = 0.0182702 (* 1 = 0.0182702 loss)
I0109 01:48:19.007220  8505 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0109 01:48:31.856954  8505 solver.cpp:270] Iteration 7500 (3.89127 iter/s, 12.8493s/50 iter), loss = 0.00934932, remaining 0 hours and 19 minutes
I0109 01:48:31.856986  8505 solver.cpp:291]     Train net output #0: loss = 0.00934935 (* 1 = 0.00934935 loss)
I0109 01:48:31.856993  8505 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0109 01:48:44.680543  8505 solver.cpp:270] Iteration 7550 (3.89922 iter/s, 12.8231s/50 iter), loss = 0.00318912, remaining 0 hours and 18 minutes
I0109 01:48:44.680574  8505 solver.cpp:291]     Train net output #0: loss = 0.00318915 (* 1 = 0.00318915 loss)
I0109 01:48:44.680583  8505 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0109 01:48:57.525923  8505 solver.cpp:270] Iteration 7600 (3.89261 iter/s, 12.8449s/50 iter), loss = 0.00509209, remaining 0 hours and 18 minutes
I0109 01:48:57.525969  8505 solver.cpp:291]     Train net output #0: loss = 0.00509212 (* 1 = 0.00509212 loss)
I0109 01:48:57.525976  8505 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0109 01:49:10.331166  8505 solver.cpp:270] Iteration 7650 (3.90481 iter/s, 12.8047s/50 iter), loss = 0.00102323, remaining 0 hours and 18 minutes
I0109 01:49:10.331199  8505 solver.cpp:291]     Train net output #0: loss = 0.00102326 (* 1 = 0.00102326 loss)
I0109 01:49:10.331207  8505 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0109 01:49:23.188139  8505 solver.cpp:270] Iteration 7700 (3.8891 iter/s, 12.8565s/50 iter), loss = 0.00200138, remaining 0 hours and 18 minutes
I0109 01:49:23.188169  8505 solver.cpp:291]     Train net output #0: loss = 0.0020014 (* 1 = 0.0020014 loss)
I0109 01:49:23.188194  8505 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0109 01:49:36.053401  8505 solver.cpp:270] Iteration 7750 (3.88659 iter/s, 12.8648s/50 iter), loss = 0.0082407, remaining 0 hours and 18 minutes
I0109 01:49:36.053447  8505 solver.cpp:291]     Train net output #0: loss = 0.00824073 (* 1 = 0.00824073 loss)
I0109 01:49:36.053470  8505 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0109 01:49:48.898981  8505 solver.cpp:270] Iteration 7800 (3.89255 iter/s, 12.8451s/50 iter), loss = 0.00734768, remaining 0 hours and 17 minutes
I0109 01:49:48.899013  8505 solver.cpp:291]     Train net output #0: loss = 0.0073477 (* 1 = 0.0073477 loss)
I0109 01:49:48.899021  8505 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0109 01:50:01.738190  8505 solver.cpp:270] Iteration 7850 (3.89448 iter/s, 12.8387s/50 iter), loss = 0.00454285, remaining 0 hours and 17 minutes
I0109 01:50:01.738224  8505 solver.cpp:291]     Train net output #0: loss = 0.00454287 (* 1 = 0.00454287 loss)
I0109 01:50:01.738250  8505 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0109 01:50:14.612722  8505 solver.cpp:270] Iteration 7900 (3.88379 iter/s, 12.874s/50 iter), loss = 0.00285723, remaining 0 hours and 17 minutes
I0109 01:50:14.612769  8505 solver.cpp:291]     Train net output #0: loss = 0.00285726 (* 1 = 0.00285726 loss)
I0109 01:50:14.612778  8505 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0109 01:50:27.441300  8505 solver.cpp:270] Iteration 7950 (3.89771 iter/s, 12.8281s/50 iter), loss = 0.00229478, remaining 0 hours and 17 minutes
I0109 01:50:27.441332  8505 solver.cpp:291]     Train net output #0: loss = 0.00229481 (* 1 = 0.00229481 loss)
I0109 01:50:27.441339  8505 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0109 01:50:40.035020  8505 solver.cpp:424] Iteration 8000, Testing net (#0)
I0109 01:50:41.528369  8505 solver.cpp:523]     Test net output #0: accuracy = 0.955
I0109 01:50:41.528398  8505 solver.cpp:523]     Test net output #1: loss = 0.243566 (* 1 = 0.243566 loss)
I0109 01:50:41.528401  8505 solver.cpp:523]     Test net output #2: top-1 = 0.955
I0109 01:50:41.773928  8505 solver.cpp:270] Iteration 8000 (3.48868 iter/s, 14.3321s/50 iter), loss = 0.000410397, remaining 0 hours and 18 minutes
I0109 01:50:41.773954  8505 solver.cpp:291]     Train net output #0: loss = 0.000410416 (* 1 = 0.000410416 loss)
I0109 01:50:41.773962  8505 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0109 01:50:54.582609  8505 solver.cpp:270] Iteration 8050 (3.90376 iter/s, 12.8082s/50 iter), loss = 0.010402, remaining 0 hours and 16 minutes
I0109 01:50:54.582664  8505 solver.cpp:291]     Train net output #0: loss = 0.010402 (* 1 = 0.010402 loss)
I0109 01:50:54.582688  8505 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0109 01:51:07.417336  8505 solver.cpp:270] Iteration 8100 (3.89584 iter/s, 12.8342s/50 iter), loss = 0.00358591, remaining 0 hours and 16 minutes
I0109 01:51:07.417368  8505 solver.cpp:291]     Train net output #0: loss = 0.00358593 (* 1 = 0.00358593 loss)
I0109 01:51:07.417392  8505 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0109 01:51:20.285209  8505 solver.cpp:270] Iteration 8150 (3.8858 iter/s, 12.8674s/50 iter), loss = 0.0015812, remaining 0 hours and 16 minutes
I0109 01:51:20.285240  8505 solver.cpp:291]     Train net output #0: loss = 0.00158121 (* 1 = 0.00158121 loss)
I0109 01:51:20.285248  8505 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0109 01:51:33.110023  8505 solver.cpp:270] Iteration 8200 (3.89885 iter/s, 12.8243s/50 iter), loss = 0.000716129, remaining 0 hours and 16 minutes
I0109 01:51:33.110067  8505 solver.cpp:291]     Train net output #0: loss = 0.000716146 (* 1 = 0.000716146 loss)
I0109 01:51:33.110075  8505 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0109 01:51:45.954013  8505 solver.cpp:270] Iteration 8250 (3.89303 iter/s, 12.8435s/50 iter), loss = 0.000492213, remaining 0 hours and 15 minutes
I0109 01:51:45.954046  8505 solver.cpp:291]     Train net output #0: loss = 0.00049223 (* 1 = 0.00049223 loss)
I0109 01:51:45.954053  8505 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0109 01:51:58.798982  8505 solver.cpp:270] Iteration 8300 (3.89273 iter/s, 12.8445s/50 iter), loss = 0.000623123, remaining 0 hours and 15 minutes
I0109 01:51:58.799015  8505 solver.cpp:291]     Train net output #0: loss = 0.000623138 (* 1 = 0.000623138 loss)
I0109 01:51:58.799039  8505 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0109 01:52:11.649911  8505 solver.cpp:270] Iteration 8350 (3.89092 iter/s, 12.8504s/50 iter), loss = 0.0016638, remaining 0 hours and 15 minutes
I0109 01:52:11.649957  8505 solver.cpp:291]     Train net output #0: loss = 0.00166382 (* 1 = 0.00166382 loss)
I0109 01:52:11.649966  8505 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0109 01:52:24.490885  8505 solver.cpp:270] Iteration 8400 (3.89394 iter/s, 12.8404s/50 iter), loss = 0.00224441, remaining 0 hours and 15 minutes
I0109 01:52:24.490917  8505 solver.cpp:291]     Train net output #0: loss = 0.00224443 (* 1 = 0.00224443 loss)
I0109 01:52:24.490926  8505 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0109 01:52:37.329521  8505 solver.cpp:270] Iteration 8450 (3.89465 iter/s, 12.8381s/50 iter), loss = 0.00403176, remaining 0 hours and 15 minutes
I0109 01:52:37.329553  8505 solver.cpp:291]     Train net output #0: loss = 0.00403177 (* 1 = 0.00403177 loss)
I0109 01:52:37.329562  8505 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0109 01:52:50.155357  8505 solver.cpp:270] Iteration 8500 (3.89854 iter/s, 12.8253s/50 iter), loss = 0.00409719, remaining 0 hours and 14 minutes
I0109 01:52:50.155405  8505 solver.cpp:291]     Train net output #0: loss = 0.00409721 (* 1 = 0.00409721 loss)
I0109 01:52:50.155414  8505 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0109 01:53:02.994743  8505 solver.cpp:270] Iteration 8550 (3.89443 iter/s, 12.8389s/50 iter), loss = 0.0158826, remaining 0 hours and 14 minutes
I0109 01:53:02.994774  8505 solver.cpp:291]     Train net output #0: loss = 0.0158827 (* 1 = 0.0158827 loss)
I0109 01:53:02.994797  8505 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0109 01:53:15.825246  8505 solver.cpp:270] Iteration 8600 (3.89712 iter/s, 12.83s/50 iter), loss = 0.0034683, remaining 0 hours and 14 minutes
I0109 01:53:15.825278  8505 solver.cpp:291]     Train net output #0: loss = 0.00346831 (* 1 = 0.00346831 loss)
I0109 01:53:15.825285  8505 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0109 01:53:28.680630  8505 solver.cpp:270] Iteration 8650 (3.88958 iter/s, 12.8549s/50 iter), loss = 0.00201288, remaining 0 hours and 14 minutes
I0109 01:53:28.680702  8505 solver.cpp:291]     Train net output #0: loss = 0.0020129 (* 1 = 0.0020129 loss)
I0109 01:53:28.680711  8505 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0109 01:53:41.548981  8505 solver.cpp:270] Iteration 8700 (3.88567 iter/s, 12.8678s/50 iter), loss = 0.0109441, remaining 0 hours and 14 minutes
I0109 01:53:41.549013  8505 solver.cpp:291]     Train net output #0: loss = 0.0109441 (* 1 = 0.0109441 loss)
I0109 01:53:41.549037  8505 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0109 01:53:54.366360  8505 solver.cpp:270] Iteration 8750 (3.90111 iter/s, 12.8169s/50 iter), loss = 0.000605098, remaining 0 hours and 13 minutes
I0109 01:53:54.366391  8505 solver.cpp:291]     Train net output #0: loss = 0.000605118 (* 1 = 0.000605118 loss)
I0109 01:53:54.366415  8505 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0109 01:54:07.217780  8505 solver.cpp:270] Iteration 8800 (3.89077 iter/s, 12.8509s/50 iter), loss = 0.00674671, remaining 0 hours and 13 minutes
I0109 01:54:07.217823  8505 solver.cpp:291]     Train net output #0: loss = 0.00674672 (* 1 = 0.00674672 loss)
I0109 01:54:07.217831  8505 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0109 01:54:20.064519  8505 solver.cpp:270] Iteration 8850 (3.8922 iter/s, 12.8462s/50 iter), loss = 0.000130716, remaining 0 hours and 13 minutes
I0109 01:54:20.064550  8505 solver.cpp:291]     Train net output #0: loss = 0.000130733 (* 1 = 0.000130733 loss)
I0109 01:54:20.064574  8505 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0109 01:54:32.905195  8505 solver.cpp:270] Iteration 8900 (3.89403 iter/s, 12.8402s/50 iter), loss = 0.0178312, remaining 0 hours and 13 minutes
I0109 01:54:32.905230  8505 solver.cpp:291]     Train net output #0: loss = 0.0178312 (* 1 = 0.0178312 loss)
I0109 01:54:32.905237  8505 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0109 01:54:45.769120  8505 solver.cpp:270] Iteration 8950 (3.88699 iter/s, 12.8634s/50 iter), loss = 0.00843803, remaining 0 hours and 12 minutes
I0109 01:54:45.769170  8505 solver.cpp:291]     Train net output #0: loss = 0.00843806 (* 1 = 0.00843806 loss)
I0109 01:54:45.769177  8505 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0109 01:54:58.358402  8505 solver.cpp:424] Iteration 9000, Testing net (#0)
I0109 01:54:59.857282  8505 solver.cpp:523]     Test net output #0: accuracy = 0.95425
I0109 01:54:59.857312  8505 solver.cpp:523]     Test net output #1: loss = 0.271834 (* 1 = 0.271834 loss)
I0109 01:54:59.857317  8505 solver.cpp:523]     Test net output #2: top-1 = 0.95425
I0109 01:55:00.109788  8505 solver.cpp:270] Iteration 9000 (3.48673 iter/s, 14.3401s/50 iter), loss = 0.00191455, remaining 0 hours and 14 minutes
I0109 01:55:00.109815  8505 solver.cpp:291]     Train net output #0: loss = 0.00191457 (* 1 = 0.00191457 loss)
I0109 01:55:00.109824  8505 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0109 01:55:12.939219  8505 solver.cpp:270] Iteration 9050 (3.89744 iter/s, 12.8289s/50 iter), loss = 0.00034888, remaining 0 hours and 12 minutes
I0109 01:55:12.939251  8505 solver.cpp:291]     Train net output #0: loss = 0.000348903 (* 1 = 0.000348903 loss)
I0109 01:55:12.939260  8505 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0109 01:55:25.767979  8505 solver.cpp:270] Iteration 9100 (3.89765 iter/s, 12.8282s/50 iter), loss = 0.0191614, remaining 0 hours and 12 minutes
I0109 01:55:25.768025  8505 solver.cpp:291]     Train net output #0: loss = 0.0191614 (* 1 = 0.0191614 loss)
I0109 01:55:25.768049  8505 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0109 01:55:38.598045  8505 solver.cpp:270] Iteration 9150 (3.89726 iter/s, 12.8295s/50 iter), loss = 0.000845513, remaining 0 hours and 12 minutes
I0109 01:55:38.598078  8505 solver.cpp:291]     Train net output #0: loss = 0.000845534 (* 1 = 0.000845534 loss)
I0109 01:55:38.598085  8505 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0109 01:55:51.434264  8505 solver.cpp:270] Iteration 9200 (3.89538 iter/s, 12.8357s/50 iter), loss = 0.000526515, remaining 0 hours and 11 minutes
I0109 01:55:51.434295  8505 solver.cpp:291]     Train net output #0: loss = 0.000526533 (* 1 = 0.000526533 loss)
I0109 01:55:51.434319  8505 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0109 01:56:04.297830  8505 solver.cpp:270] Iteration 9250 (3.8871 iter/s, 12.8631s/50 iter), loss = 0.000201725, remaining 0 hours and 11 minutes
I0109 01:56:04.297900  8505 solver.cpp:291]     Train net output #0: loss = 0.000201744 (* 1 = 0.000201744 loss)
I0109 01:56:04.297909  8505 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0109 01:56:17.117069  8505 solver.cpp:270] Iteration 9300 (3.90055 iter/s, 12.8187s/50 iter), loss = 0.00100985, remaining 0 hours and 11 minutes
I0109 01:56:17.117102  8505 solver.cpp:291]     Train net output #0: loss = 0.00100987 (* 1 = 0.00100987 loss)
I0109 01:56:17.117110  8505 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0109 01:56:29.953899  8505 solver.cpp:270] Iteration 9350 (3.8952 iter/s, 12.8363s/50 iter), loss = 0.0156218, remaining 0 hours and 11 minutes
I0109 01:56:29.953930  8505 solver.cpp:291]     Train net output #0: loss = 0.0156218 (* 1 = 0.0156218 loss)
I0109 01:56:29.953939  8505 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0109 01:56:42.781111  8505 solver.cpp:270] Iteration 9400 (3.89812 iter/s, 12.8267s/50 iter), loss = 0.00397205, remaining 0 hours and 11 minutes
I0109 01:56:42.781155  8505 solver.cpp:291]     Train net output #0: loss = 0.00397207 (* 1 = 0.00397207 loss)
I0109 01:56:42.781163  8505 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0109 01:56:55.601950  8505 solver.cpp:270] Iteration 9450 (3.90006 iter/s, 12.8203s/50 iter), loss = 0.00104184, remaining 0 hours and 10 minutes
I0109 01:56:55.601982  8505 solver.cpp:291]     Train net output #0: loss = 0.00104186 (* 1 = 0.00104186 loss)
I0109 01:56:55.601990  8505 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0109 01:57:08.452777  8505 solver.cpp:270] Iteration 9500 (3.89096 iter/s, 12.8503s/50 iter), loss = 0.0151852, remaining 0 hours and 10 minutes
I0109 01:57:08.452811  8505 solver.cpp:291]     Train net output #0: loss = 0.0151852 (* 1 = 0.0151852 loss)
I0109 01:57:08.452834  8505 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0109 01:57:21.306609  8505 solver.cpp:270] Iteration 9550 (3.89005 iter/s, 12.8533s/50 iter), loss = 0.00013076, remaining 0 hours and 10 minutes
I0109 01:57:21.306656  8505 solver.cpp:291]     Train net output #0: loss = 0.000130782 (* 1 = 0.000130782 loss)
I0109 01:57:21.306664  8505 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0109 01:57:34.151871  8505 solver.cpp:270] Iteration 9600 (3.89264 iter/s, 12.8447s/50 iter), loss = 0.000892435, remaining 0 hours and 10 minutes
I0109 01:57:34.151906  8505 solver.cpp:291]     Train net output #0: loss = 0.00089246 (* 1 = 0.00089246 loss)
I0109 01:57:34.151928  8505 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0109 01:57:46.970132  8505 solver.cpp:270] Iteration 9650 (3.90084 iter/s, 12.8178s/50 iter), loss = 0.022592, remaining 0 hours and 9 minutes
I0109 01:57:46.970163  8505 solver.cpp:291]     Train net output #0: loss = 0.022592 (* 1 = 0.022592 loss)
I0109 01:57:46.970187  8505 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0109 01:57:59.823222  8505 solver.cpp:270] Iteration 9700 (3.89027 iter/s, 12.8526s/50 iter), loss = 0.00567429, remaining 0 hours and 9 minutes
I0109 01:57:59.823266  8505 solver.cpp:291]     Train net output #0: loss = 0.00567432 (* 1 = 0.00567432 loss)
I0109 01:57:59.823276  8505 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0109 01:58:12.671170  8505 solver.cpp:270] Iteration 9750 (3.89183 iter/s, 12.8474s/50 iter), loss = 0.00489282, remaining 0 hours and 9 minutes
I0109 01:58:12.671203  8505 solver.cpp:291]     Train net output #0: loss = 0.00489284 (* 1 = 0.00489284 loss)
I0109 01:58:12.671227  8505 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0109 01:58:25.514024  8505 solver.cpp:270] Iteration 9800 (3.89337 iter/s, 12.8423s/50 iter), loss = 0.0159083, remaining 0 hours and 9 minutes
I0109 01:58:25.514056  8505 solver.cpp:291]     Train net output #0: loss = 0.0159083 (* 1 = 0.0159083 loss)
I0109 01:58:25.514065  8505 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0109 01:58:38.356622  8505 solver.cpp:270] Iteration 9850 (3.89345 iter/s, 12.8421s/50 iter), loss = 0.000955623, remaining 0 hours and 8 minutes
I0109 01:58:38.356678  8505 solver.cpp:291]     Train net output #0: loss = 0.000955643 (* 1 = 0.000955643 loss)
I0109 01:58:38.356688  8505 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0109 01:58:51.188194  8505 solver.cpp:270] Iteration 9900 (3.8968 iter/s, 12.831s/50 iter), loss = 0.00273024, remaining 0 hours and 8 minutes
I0109 01:58:51.188228  8505 solver.cpp:291]     Train net output #0: loss = 0.00273026 (* 1 = 0.00273026 loss)
I0109 01:58:51.188236  8505 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0109 01:59:04.034845  8505 solver.cpp:270] Iteration 9950 (3.89222 iter/s, 12.8461s/50 iter), loss = 0.00773293, remaining 0 hours and 8 minutes
I0109 01:59:04.034878  8505 solver.cpp:291]     Train net output #0: loss = 0.00773295 (* 1 = 0.00773295 loss)
I0109 01:59:04.034900  8505 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0109 01:59:16.603804  8505 solver.cpp:424] Iteration 10000, Testing net (#0)
I0109 01:59:18.091303  8505 solver.cpp:523]     Test net output #0: accuracy = 0.9545
I0109 01:59:18.091331  8505 solver.cpp:523]     Test net output #1: loss = 0.285556 (* 1 = 0.285556 loss)
I0109 01:59:18.091336  8505 solver.cpp:523]     Test net output #2: top-1 = 0.9545
I0109 01:59:18.342605  8505 solver.cpp:270] Iteration 10000 (3.49474 iter/s, 14.3072s/50 iter), loss = 0.000728771, remaining 0 hours and 9 minutes
I0109 01:59:18.342630  8505 solver.cpp:291]     Train net output #0: loss = 0.000728792 (* 1 = 0.000728792 loss)
I0109 01:59:18.342638  8505 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0109 01:59:31.211388  8505 solver.cpp:270] Iteration 10050 (3.88552 iter/s, 12.8683s/50 iter), loss = 0.00220975, remaining 0 hours and 8 minutes
I0109 01:59:31.211421  8505 solver.cpp:291]     Train net output #0: loss = 0.00220977 (* 1 = 0.00220977 loss)
I0109 01:59:31.211444  8505 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0109 01:59:44.051821  8505 solver.cpp:270] Iteration 10100 (3.8941 iter/s, 12.8399s/50 iter), loss = 0.00257558, remaining 0 hours and 7 minutes
I0109 01:59:44.051853  8505 solver.cpp:291]     Train net output #0: loss = 0.00257561 (* 1 = 0.00257561 loss)
I0109 01:59:44.051877  8505 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0109 01:59:56.907486  8505 solver.cpp:270] Iteration 10150 (3.88949 iter/s, 12.8552s/50 iter), loss = 0.00194034, remaining 0 hours and 7 minutes
I0109 01:59:56.907534  8505 solver.cpp:291]     Train net output #0: loss = 0.00194037 (* 1 = 0.00194037 loss)
I0109 01:59:56.907559  8505 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0109 02:00:09.721937  8505 solver.cpp:270] Iteration 10200 (3.902 iter/s, 12.8139s/50 iter), loss = 0.00399283, remaining 0 hours and 7 minutes
I0109 02:00:09.721971  8505 solver.cpp:291]     Train net output #0: loss = 0.00399285 (* 1 = 0.00399285 loss)
I0109 02:00:09.721993  8505 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0109 02:00:22.513480  8505 solver.cpp:270] Iteration 10250 (3.90899 iter/s, 12.791s/50 iter), loss = 0.00537401, remaining 0 hours and 7 minutes
I0109 02:00:22.513512  8505 solver.cpp:291]     Train net output #0: loss = 0.00537403 (* 1 = 0.00537403 loss)
I0109 02:00:22.513521  8505 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0109 02:00:35.360901  8505 solver.cpp:270] Iteration 10300 (3.89199 iter/s, 12.8469s/50 iter), loss = 0.00516984, remaining 0 hours and 7 minutes
I0109 02:00:35.360947  8505 solver.cpp:291]     Train net output #0: loss = 0.00516987 (* 1 = 0.00516987 loss)
I0109 02:00:35.360954  8505 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0109 02:00:48.201603  8505 solver.cpp:270] Iteration 10350 (3.89403 iter/s, 12.8402s/50 iter), loss = 0.00215178, remaining 0 hours and 6 minutes
I0109 02:00:48.201637  8505 solver.cpp:291]     Train net output #0: loss = 0.00215181 (* 1 = 0.00215181 loss)
I0109 02:00:48.201644  8505 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0109 02:01:01.019309  8505 solver.cpp:270] Iteration 10400 (3.90101 iter/s, 12.8172s/50 iter), loss = 0.00563433, remaining 0 hours and 6 minutes
I0109 02:01:01.019340  8505 solver.cpp:291]     Train net output #0: loss = 0.00563436 (* 1 = 0.00563436 loss)
I0109 02:01:01.019347  8505 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0109 02:01:13.871865  8505 solver.cpp:270] Iteration 10450 (3.89043 iter/s, 12.852s/50 iter), loss = 0.00290178, remaining 0 hours and 6 minutes
I0109 02:01:13.871920  8505 solver.cpp:291]     Train net output #0: loss = 0.0029018 (* 1 = 0.0029018 loss)
I0109 02:01:13.871928  8505 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0109 02:01:26.721969  8505 solver.cpp:270] Iteration 10500 (3.89118 iter/s, 12.8496s/50 iter), loss = 0.000287281, remaining 0 hours and 6 minutes
I0109 02:01:26.722002  8505 solver.cpp:291]     Train net output #0: loss = 0.000287309 (* 1 = 0.000287309 loss)
I0109 02:01:26.722008  8505 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0109 02:01:39.576454  8505 solver.cpp:270] Iteration 10550 (3.88985 iter/s, 12.854s/50 iter), loss = 0.00163691, remaining 0 hours and 6 minutes
I0109 02:01:39.576485  8505 solver.cpp:291]     Train net output #0: loss = 0.00163694 (* 1 = 0.00163694 loss)
I0109 02:01:39.576493  8505 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0109 02:01:52.417132  8505 solver.cpp:270] Iteration 10600 (3.89403 iter/s, 12.8402s/50 iter), loss = 0.00226693, remaining 0 hours and 5 minutes
I0109 02:01:52.417179  8505 solver.cpp:291]     Train net output #0: loss = 0.00226696 (* 1 = 0.00226696 loss)
I0109 02:01:52.417203  8505 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0109 02:02:05.251469  8505 solver.cpp:270] Iteration 10650 (3.89596 iter/s, 12.8338s/50 iter), loss = 0.00077936, remaining 0 hours and 5 minutes
I0109 02:02:05.251502  8505 solver.cpp:291]     Train net output #0: loss = 0.000779388 (* 1 = 0.000779388 loss)
I0109 02:02:05.251510  8505 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0109 02:02:18.097079  8505 solver.cpp:270] Iteration 10700 (3.89254 iter/s, 12.8451s/50 iter), loss = 0.00136023, remaining 0 hours and 5 minutes
I0109 02:02:18.097111  8505 solver.cpp:291]     Train net output #0: loss = 0.00136026 (* 1 = 0.00136026 loss)
I0109 02:02:18.097136  8505 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0109 02:02:30.954916  8505 solver.cpp:270] Iteration 10750 (3.88883 iter/s, 12.8573s/50 iter), loss = 0.00105385, remaining 0 hours and 5 minutes
I0109 02:02:30.954962  8505 solver.cpp:291]     Train net output #0: loss = 0.00105388 (* 1 = 0.00105388 loss)
I0109 02:02:30.954985  8505 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0109 02:02:43.778749  8505 solver.cpp:270] Iteration 10800 (3.89915 iter/s, 12.8233s/50 iter), loss = 0.00141491, remaining 0 hours and 5 minutes
I0109 02:02:43.778784  8505 solver.cpp:291]     Train net output #0: loss = 0.00141494 (* 1 = 0.00141494 loss)
I0109 02:02:43.778793  8505 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0109 02:02:56.612810  8505 solver.cpp:270] Iteration 10850 (3.89604 iter/s, 12.8335s/50 iter), loss = 0.0034972, remaining 0 hours and 4 minutes
I0109 02:02:56.612843  8505 solver.cpp:291]     Train net output #0: loss = 0.00349723 (* 1 = 0.00349723 loss)
I0109 02:02:56.612851  8505 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0109 02:03:09.427107  8505 solver.cpp:270] Iteration 10900 (3.90205 iter/s, 12.8138s/50 iter), loss = 0.00192937, remaining 0 hours and 4 minutes
I0109 02:03:09.427155  8505 solver.cpp:291]     Train net output #0: loss = 0.0019294 (* 1 = 0.0019294 loss)
I0109 02:03:09.427163  8505 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0109 02:03:22.270282  8505 solver.cpp:270] Iteration 10950 (3.89328 iter/s, 12.8427s/50 iter), loss = 0.0174494, remaining 0 hours and 4 minutes
I0109 02:03:22.270318  8505 solver.cpp:291]     Train net output #0: loss = 0.0174494 (* 1 = 0.0174494 loss)
I0109 02:03:22.270325  8505 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0109 02:03:34.859277  8505 solver.cpp:424] Iteration 11000, Testing net (#0)
I0109 02:03:36.373558  8505 solver.cpp:523]     Test net output #0: accuracy = 0.95425
I0109 02:03:36.373585  8505 solver.cpp:523]     Test net output #1: loss = 0.294279 (* 1 = 0.294279 loss)
I0109 02:03:36.373589  8505 solver.cpp:523]     Test net output #2: top-1 = 0.95425
I0109 02:03:36.617229  8505 solver.cpp:270] Iteration 11000 (3.4852 iter/s, 14.3464s/50 iter), loss = 0.00549851, remaining 0 hours and 4 minutes
I0109 02:03:36.617254  8505 solver.cpp:291]     Train net output #0: loss = 0.00549854 (* 1 = 0.00549854 loss)
I0109 02:03:36.617261  8505 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0109 02:03:49.468961  8505 solver.cpp:270] Iteration 11050 (3.89068 iter/s, 12.8512s/50 iter), loss = 0.0023015, remaining 0 hours and 3 minutes
I0109 02:03:49.469015  8505 solver.cpp:291]     Train net output #0: loss = 0.00230153 (* 1 = 0.00230153 loss)
I0109 02:03:49.469023  8505 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0109 02:04:02.318804  8505 solver.cpp:270] Iteration 11100 (3.89126 iter/s, 12.8493s/50 iter), loss = 0.000544655, remaining 0 hours and 3 minutes
I0109 02:04:02.318836  8505 solver.cpp:291]     Train net output #0: loss = 0.000544681 (* 1 = 0.000544681 loss)
I0109 02:04:02.318843  8505 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0109 02:04:15.190817  8505 solver.cpp:270] Iteration 11150 (3.88455 iter/s, 12.8715s/50 iter), loss = 0.000664539, remaining 0 hours and 3 minutes
I0109 02:04:15.190850  8505 solver.cpp:291]     Train net output #0: loss = 0.000664565 (* 1 = 0.000664565 loss)
I0109 02:04:15.190857  8505 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0109 02:04:27.991730  8505 solver.cpp:270] Iteration 11200 (3.90613 iter/s, 12.8004s/50 iter), loss = 0.00677042, remaining 0 hours and 3 minutes
I0109 02:04:27.991775  8505 solver.cpp:291]     Train net output #0: loss = 0.00677045 (* 1 = 0.00677045 loss)
I0109 02:04:27.991783  8505 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0109 02:04:40.830041  8505 solver.cpp:270] Iteration 11250 (3.89475 iter/s, 12.8378s/50 iter), loss = 0.00114031, remaining 0 hours and 3 minutes
I0109 02:04:40.830073  8505 solver.cpp:291]     Train net output #0: loss = 0.00114034 (* 1 = 0.00114034 loss)
I0109 02:04:40.830081  8505 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0109 02:04:53.646206  8505 solver.cpp:270] Iteration 11300 (3.90148 iter/s, 12.8157s/50 iter), loss = 0.00477205, remaining 0 hours and 2 minutes
I0109 02:04:53.646239  8505 solver.cpp:291]     Train net output #0: loss = 0.00477207 (* 1 = 0.00477207 loss)
I0109 02:04:53.646247  8505 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0109 02:05:06.538003  8505 solver.cpp:270] Iteration 11350 (3.87859 iter/s, 12.8913s/50 iter), loss = 0.00146109, remaining 0 hours and 2 minutes
I0109 02:05:06.538051  8505 solver.cpp:291]     Train net output #0: loss = 0.00146112 (* 1 = 0.00146112 loss)
I0109 02:05:06.538075  8505 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0109 02:05:19.376704  8505 solver.cpp:270] Iteration 11400 (3.89463 iter/s, 12.8382s/50 iter), loss = 0.00260445, remaining 0 hours and 2 minutes
I0109 02:05:19.376735  8505 solver.cpp:291]     Train net output #0: loss = 0.00260448 (* 1 = 0.00260448 loss)
I0109 02:05:19.376742  8505 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0109 02:05:32.241544  8505 solver.cpp:270] Iteration 11450 (3.88672 iter/s, 12.8643s/50 iter), loss = 0.0259096, remaining 0 hours and 2 minutes
I0109 02:05:32.241576  8505 solver.cpp:291]     Train net output #0: loss = 0.0259097 (* 1 = 0.0259097 loss)
I0109 02:05:32.241600  8505 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0109 02:05:45.071648  8505 solver.cpp:270] Iteration 11500 (3.89724 iter/s, 12.8296s/50 iter), loss = 0.000989654, remaining 0 hours and 2 minutes
I0109 02:05:45.071693  8505 solver.cpp:291]     Train net output #0: loss = 0.000989672 (* 1 = 0.000989672 loss)
I0109 02:05:45.071700  8505 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0109 02:05:57.882012  8505 solver.cpp:270] Iteration 11550 (3.90325 iter/s, 12.8098s/50 iter), loss = 0.00131075, remaining 0 hours and 1 minutes
I0109 02:05:57.882047  8505 solver.cpp:291]     Train net output #0: loss = 0.00131077 (* 1 = 0.00131077 loss)
I0109 02:05:57.882055  8505 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0109 02:06:10.779336  8505 solver.cpp:270] Iteration 11600 (3.87693 iter/s, 12.8968s/50 iter), loss = 0.00475224, remaining 0 hours and 1 minutes
I0109 02:06:10.779368  8505 solver.cpp:291]     Train net output #0: loss = 0.00475226 (* 1 = 0.00475226 loss)
I0109 02:06:10.779377  8505 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0109 02:06:23.600607  8505 solver.cpp:270] Iteration 11650 (3.89992 iter/s, 12.8208s/50 iter), loss = 0.0177913, remaining 0 hours and 1 minutes
I0109 02:06:23.600663  8505 solver.cpp:291]     Train net output #0: loss = 0.0177913 (* 1 = 0.0177913 loss)
I0109 02:06:23.600687  8505 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0109 02:06:36.444559  8505 solver.cpp:270] Iteration 11700 (3.89305 iter/s, 12.8434s/50 iter), loss = 0.0130088, remaining 0 hours and 1 minutes
I0109 02:06:36.444593  8505 solver.cpp:291]     Train net output #0: loss = 0.0130088 (* 1 = 0.0130088 loss)
I0109 02:06:36.444617  8505 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0109 02:06:49.287029  8505 solver.cpp:270] Iteration 11750 (3.89349 iter/s, 12.842s/50 iter), loss = 0.0320145, remaining 0 hours and 1 minutes
I0109 02:06:49.287060  8505 solver.cpp:291]     Train net output #0: loss = 0.0320145 (* 1 = 0.0320145 loss)
I0109 02:06:49.287066  8505 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0109 02:07:02.113775  8505 solver.cpp:270] Iteration 11800 (3.89826 iter/s, 12.8262s/50 iter), loss = 0.00880763, remaining 0 hours and 0 minutes
I0109 02:07:02.113824  8505 solver.cpp:291]     Train net output #0: loss = 0.00880764 (* 1 = 0.00880764 loss)
I0109 02:07:02.113848  8505 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0109 02:07:14.986925  8505 solver.cpp:270] Iteration 11850 (3.88421 iter/s, 12.8726s/50 iter), loss = 0.00274015, remaining 0 hours and 0 minutes
I0109 02:07:14.986958  8505 solver.cpp:291]     Train net output #0: loss = 0.00274016 (* 1 = 0.00274016 loss)
I0109 02:07:14.986964  8505 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0109 02:07:27.822943  8505 solver.cpp:270] Iteration 11900 (3.89544 iter/s, 12.8355s/50 iter), loss = 0.000861269, remaining 0 hours and 0 minutes
I0109 02:07:27.822976  8505 solver.cpp:291]     Train net output #0: loss = 0.000861282 (* 1 = 0.000861282 loss)
I0109 02:07:27.822999  8505 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0109 02:07:40.627959  8505 solver.cpp:270] Iteration 11950 (3.90488 iter/s, 12.8045s/50 iter), loss = 0.000348406, remaining 0 hours and 0 minutes
I0109 02:07:40.628021  8505 solver.cpp:291]     Train net output #0: loss = 0.000348421 (* 1 = 0.000348421 loss)
I0109 02:07:40.628029  8505 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0109 02:07:53.205477  8505 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.6/snapshots/_iter_12000.caffemodel
I0109 02:07:55.640055  8505 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.6/snapshots/_iter_12000.solverstate
I0109 02:07:55.956672  8505 solver.cpp:384] Iteration 12000, loss = 0.00235838
I0109 02:07:55.956698  8505 solver.cpp:424] Iteration 12000, Testing net (#0)
I0109 02:07:57.410267  8505 solver.cpp:523]     Test net output #0: accuracy = 0.95475
I0109 02:07:57.410295  8505 solver.cpp:523]     Test net output #1: loss = 0.298171 (* 1 = 0.298171 loss)
I0109 02:07:57.410300  8505 solver.cpp:523]     Test net output #2: top-1 = 0.95475
I0109 02:07:57.410305  8505 solver.cpp:392] Optimization Done (3.88255 iter/s).
I0109 02:07:57.410308  8505 caffe_interface.cpp:546] Optimization Done.
(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

I0109 02:07:58.090860  8602 pruning_runner.cpp:206] Analysis info found.
I0109 02:07:59.621799  8602 pruning_runner.cpp:237] Start pruning, please wait...
I0109 02:08:06.144572  8602 pruning_runner.cpp:284] Compression complete 0.0250042%
I0109 02:08:12.354379  8602 pruning_runner.cpp:284] Compression complete 0.0499958%
I0109 02:08:18.614151  8602 pruning_runner.cpp:284] Compression complete 0.0999417%
I0109 02:08:24.944371  8602 pruning_runner.cpp:284] Compression complete 0.199684%
I0109 02:08:32.225528  8602 pruning_runner.cpp:284] Compression complete 0.398572%
I0109 02:08:38.558324  8602 pruning_runner.cpp:284] Compression complete 0.793979%
I0109 02:08:44.796820  8602 pruning_runner.cpp:284] Compression complete 50.397%
I0109 02:08:53.337786  8602 pruning_runner.cpp:337] pruning done, output model: pruning/alexnetBNnoLRN/regular_rate_0.7/sparse.caffemodel
I0109 02:08:53.337815  8602 pruning_runner.cpp:351] summary of REGULAR compression with rate 0.7:
+-------------------------------------------------------------------+
| Item           | Baseline       | Compressed     | Delta          |
+-------------------------------------------------------------------+
| Accuracy       | 0.943749785    | 0.954749584    | 0.0109997988   |
+-------------------------------------------------------------------+
| Weights        | 3.7649951 M    | 425.46701 K    | -88.6994019%   |
+-------------------------------------------------------------------+
| Operations     | 2.1539185 G    | 636.272827 M   | -70.4597549%   |
+-------------------------------------------------------------------+
To fine-tune the pruned model, please run:
vai_p_caffe finetune -config /workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/config7.prototxt
(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

W0109 02:08:53.501694  9387 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0109 02:08:53.502072  9387 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0109 02:08:53.502118  9387 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0109 02:08:53.507078  9387 vai_p_caffe.cpp:287] pruning/alexnetBNnoLRN/regular_rate_0.7/net_finetune.prototxt
I0109 02:08:53.674546  9387 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0109 02:08:53.674566  9387 gpu_memory.cpp:55] Total memory: 25620447232, Free: 25022103552, dev_info[0]: total=25620447232 free=25022103552
I0109 02:08:53.675408  9387 caffe_interface.cpp:509] Using GPUs 0
I0109 02:08:53.675659  9387 caffe_interface.cpp:514] GPU 0: Quadro P6000
I0109 02:08:54.538640  9387 solver.cpp:51] Initializing solver from parameters:
test_iter: 80
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 6000
snapshot_prefix: "pruning/alexnetBNnoLRN/regular_rate_0.7/snapshots/"
solver_mode: GPU
device_id: 0
random_seed: 1201
net: "pruning/alexnetBNnoLRN/regular_rate_0.7/net_finetune.prototxt"
type: "Adam"
I0109 02:08:54.538790  9387 solver.cpp:99] Creating training net from net file: pruning/alexnetBNnoLRN/regular_rate_0.7/net_finetune.prototxt
I0109 02:08:54.539083  9387 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0109 02:08:54.539113  9387 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0109 02:08:54.539116  9387 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0109 02:08:54.539121  9387 net.cpp:52] Initializing net from parameters:
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0109 02:08:54.539350  9387 layer_factory.hpp:77] Creating layer data
I0109 02:08:54.539489  9387 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 02:08:54.541059  9387 net.cpp:94] Creating Layer data
I0109 02:08:54.541070  9387 net.cpp:409] data -> data
I0109 02:08:54.541081  9387 net.cpp:409] data -> label
I0109 02:08:54.543227  9424 db_lmdb.cpp:35] Opened lmdb input/lmdb/train_lmdb
I0109 02:08:54.543249  9424 db_lmdb.cpp:38] Items count: 20000
I0109 02:08:54.543270  9424 data_reader.cpp:124] TRAIN: reading data using 1 channel(s)
I0109 02:08:54.543537  9387 data_layer.cpp:78] ReshapePrefetch 256, 3, 227, 227
I0109 02:08:54.543624  9387 data_layer.cpp:83] output data size: 256,3,227,227
I0109 02:08:55.023193  9387 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 02:08:55.023279  9387 net.cpp:144] Setting up data
I0109 02:08:55.023284  9387 net.cpp:151] Top shape: 256 3 227 227 (39574272)
I0109 02:08:55.023308  9387 net.cpp:151] Top shape: 256 (256)
I0109 02:08:55.023313  9387 net.cpp:159] Memory required for data: 158298112
I0109 02:08:55.023319  9387 layer_factory.hpp:77] Creating layer conv1
I0109 02:08:55.023329  9387 net.cpp:94] Creating Layer conv1
I0109 02:08:55.023340  9387 net.cpp:435] conv1 <- data
I0109 02:08:55.023347  9387 net.cpp:409] conv1 -> conv1
I0109 02:08:55.023985  9387 net.cpp:144] Setting up conv1
I0109 02:08:55.023993  9387 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0109 02:08:55.023998  9387 net.cpp:159] Memory required for data: 455667712
I0109 02:08:55.024008  9387 layer_factory.hpp:77] Creating layer bn1
I0109 02:08:55.024016  9387 net.cpp:94] Creating Layer bn1
I0109 02:08:55.024020  9387 net.cpp:435] bn1 <- conv1
I0109 02:08:55.024025  9387 net.cpp:409] bn1 -> bn1
I0109 02:08:55.024538  9387 net.cpp:144] Setting up bn1
I0109 02:08:55.024544  9387 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0109 02:08:55.024550  9387 net.cpp:159] Memory required for data: 753037312
I0109 02:08:55.024559  9387 layer_factory.hpp:77] Creating layer relu1
I0109 02:08:55.024565  9387 net.cpp:94] Creating Layer relu1
I0109 02:08:55.024569  9387 net.cpp:435] relu1 <- bn1
I0109 02:08:55.024574  9387 net.cpp:409] relu1 -> relu1
I0109 02:08:55.024593  9387 net.cpp:144] Setting up relu1
I0109 02:08:55.024610  9387 net.cpp:151] Top shape: 256 96 55 55 (74342400)
I0109 02:08:55.024614  9387 net.cpp:159] Memory required for data: 1050406912
I0109 02:08:55.024618  9387 layer_factory.hpp:77] Creating layer pool1
I0109 02:08:55.024623  9387 net.cpp:94] Creating Layer pool1
I0109 02:08:55.024626  9387 net.cpp:435] pool1 <- relu1
I0109 02:08:55.024631  9387 net.cpp:409] pool1 -> pool1
I0109 02:08:55.024653  9387 net.cpp:144] Setting up pool1
I0109 02:08:55.024658  9387 net.cpp:151] Top shape: 256 96 27 27 (17915904)
I0109 02:08:55.024662  9387 net.cpp:159] Memory required for data: 1122070528
I0109 02:08:55.024667  9387 layer_factory.hpp:77] Creating layer conv2
I0109 02:08:55.024673  9387 net.cpp:94] Creating Layer conv2
I0109 02:08:55.024677  9387 net.cpp:435] conv2 <- pool1
I0109 02:08:55.024682  9387 net.cpp:409] conv2 -> conv2
I0109 02:08:55.039958  9387 net.cpp:144] Setting up conv2
I0109 02:08:55.039973  9387 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0109 02:08:55.039981  9387 net.cpp:159] Memory required for data: 1313173504
I0109 02:08:55.039990  9387 layer_factory.hpp:77] Creating layer bn2
I0109 02:08:55.039997  9387 net.cpp:94] Creating Layer bn2
I0109 02:08:55.040001  9387 net.cpp:435] bn2 <- conv2
I0109 02:08:55.040007  9387 net.cpp:409] bn2 -> bn2
I0109 02:08:55.040460  9387 net.cpp:144] Setting up bn2
I0109 02:08:55.040467  9387 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0109 02:08:55.040472  9387 net.cpp:159] Memory required for data: 1504276480
I0109 02:08:55.040480  9387 layer_factory.hpp:77] Creating layer relu2
I0109 02:08:55.040486  9387 net.cpp:94] Creating Layer relu2
I0109 02:08:55.040489  9387 net.cpp:435] relu2 <- bn2
I0109 02:08:55.040494  9387 net.cpp:409] relu2 -> relu2
I0109 02:08:55.040510  9387 net.cpp:144] Setting up relu2
I0109 02:08:55.040516  9387 net.cpp:151] Top shape: 256 256 27 27 (47775744)
I0109 02:08:55.040521  9387 net.cpp:159] Memory required for data: 1695379456
I0109 02:08:55.040524  9387 layer_factory.hpp:77] Creating layer pool2
I0109 02:08:55.040530  9387 net.cpp:94] Creating Layer pool2
I0109 02:08:55.040534  9387 net.cpp:435] pool2 <- relu2
I0109 02:08:55.040539  9387 net.cpp:409] pool2 -> pool2
I0109 02:08:55.040561  9387 net.cpp:144] Setting up pool2
I0109 02:08:55.040568  9387 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0109 02:08:55.040573  9387 net.cpp:159] Memory required for data: 1739681792
I0109 02:08:55.040577  9387 layer_factory.hpp:77] Creating layer conv3
I0109 02:08:55.040597  9387 net.cpp:94] Creating Layer conv3
I0109 02:08:55.040601  9387 net.cpp:435] conv3 <- pool2
I0109 02:08:55.040606  9387 net.cpp:409] conv3 -> conv3
I0109 02:08:55.053575  9387 net.cpp:144] Setting up conv3
I0109 02:08:55.053613  9387 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0109 02:08:55.053627  9387 net.cpp:159] Memory required for data: 1806135296
I0109 02:08:55.053643  9387 layer_factory.hpp:77] Creating layer relu3
I0109 02:08:55.053655  9387 net.cpp:94] Creating Layer relu3
I0109 02:08:55.053684  9387 net.cpp:435] relu3 <- conv3
I0109 02:08:55.053726  9387 net.cpp:409] relu3 -> relu3
I0109 02:08:55.053795  9387 net.cpp:144] Setting up relu3
I0109 02:08:55.053830  9387 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0109 02:08:55.053865  9387 net.cpp:159] Memory required for data: 1872588800
I0109 02:08:55.053898  9387 layer_factory.hpp:77] Creating layer conv4
I0109 02:08:55.053939  9387 net.cpp:94] Creating Layer conv4
I0109 02:08:55.053977  9387 net.cpp:435] conv4 <- relu3
I0109 02:08:55.054018  9387 net.cpp:409] conv4 -> conv4
I0109 02:08:55.083160  9387 net.cpp:144] Setting up conv4
I0109 02:08:55.083195  9387 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0109 02:08:55.083209  9387 net.cpp:159] Memory required for data: 1939042304
I0109 02:08:55.083231  9387 layer_factory.hpp:77] Creating layer relu4
I0109 02:08:55.083264  9387 net.cpp:94] Creating Layer relu4
I0109 02:08:55.083294  9387 net.cpp:435] relu4 <- conv4
I0109 02:08:55.083321  9387 net.cpp:409] relu4 -> relu4
I0109 02:08:55.083391  9387 net.cpp:144] Setting up relu4
I0109 02:08:55.083416  9387 net.cpp:151] Top shape: 256 384 13 13 (16613376)
I0109 02:08:55.083443  9387 net.cpp:159] Memory required for data: 2005495808
I0109 02:08:55.083482  9387 layer_factory.hpp:77] Creating layer conv5
I0109 02:08:55.083523  9387 net.cpp:94] Creating Layer conv5
I0109 02:08:55.083559  9387 net.cpp:435] conv5 <- relu4
I0109 02:08:55.083593  9387 net.cpp:409] conv5 -> conv5
I0109 02:08:55.103435  9387 net.cpp:144] Setting up conv5
I0109 02:08:55.103456  9387 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0109 02:08:55.103464  9387 net.cpp:159] Memory required for data: 2049798144
I0109 02:08:55.103475  9387 layer_factory.hpp:77] Creating layer relu5
I0109 02:08:55.103487  9387 net.cpp:94] Creating Layer relu5
I0109 02:08:55.103494  9387 net.cpp:435] relu5 <- conv5
I0109 02:08:55.103502  9387 net.cpp:409] relu5 -> relu5
I0109 02:08:55.103538  9387 net.cpp:144] Setting up relu5
I0109 02:08:55.103543  9387 net.cpp:151] Top shape: 256 256 13 13 (11075584)
I0109 02:08:55.103549  9387 net.cpp:159] Memory required for data: 2094100480
I0109 02:08:55.103551  9387 layer_factory.hpp:77] Creating layer pool5
I0109 02:08:55.103560  9387 net.cpp:94] Creating Layer pool5
I0109 02:08:55.103565  9387 net.cpp:435] pool5 <- relu5
I0109 02:08:55.103572  9387 net.cpp:409] pool5 -> pool5
I0109 02:08:55.103603  9387 net.cpp:144] Setting up pool5
I0109 02:08:55.103610  9387 net.cpp:151] Top shape: 256 256 6 6 (2359296)
I0109 02:08:55.103613  9387 net.cpp:159] Memory required for data: 2103537664
I0109 02:08:55.103618  9387 layer_factory.hpp:77] Creating layer fc6
I0109 02:08:55.103629  9387 net.cpp:94] Creating Layer fc6
I0109 02:08:55.103636  9387 net.cpp:435] fc6 <- pool5
I0109 02:08:55.103643  9387 net.cpp:409] fc6 -> fc6
I0109 02:08:55.470939  9387 net.cpp:144] Setting up fc6
I0109 02:08:55.470963  9387 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 02:08:55.470970  9387 net.cpp:159] Memory required for data: 2107731968
I0109 02:08:55.470995  9387 layer_factory.hpp:77] Creating layer relu6
I0109 02:08:55.471002  9387 net.cpp:94] Creating Layer relu6
I0109 02:08:55.471006  9387 net.cpp:435] relu6 <- fc6
I0109 02:08:55.471011  9387 net.cpp:409] relu6 -> relu6
I0109 02:08:55.471026  9387 net.cpp:144] Setting up relu6
I0109 02:08:55.471029  9387 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 02:08:55.471038  9387 net.cpp:159] Memory required for data: 2111926272
I0109 02:08:55.471045  9387 layer_factory.hpp:77] Creating layer drop6
I0109 02:08:55.471062  9387 net.cpp:94] Creating Layer drop6
I0109 02:08:55.471083  9387 net.cpp:435] drop6 <- relu6
I0109 02:08:55.471088  9387 net.cpp:409] drop6 -> drop6
I0109 02:08:55.471114  9387 net.cpp:144] Setting up drop6
I0109 02:08:55.471119  9387 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 02:08:55.471123  9387 net.cpp:159] Memory required for data: 2116120576
I0109 02:08:55.471127  9387 layer_factory.hpp:77] Creating layer fc7
I0109 02:08:55.471133  9387 net.cpp:94] Creating Layer fc7
I0109 02:08:55.471156  9387 net.cpp:435] fc7 <- drop6
I0109 02:08:55.471161  9387 net.cpp:409] fc7 -> fc7
I0109 02:08:55.621903  9387 net.cpp:144] Setting up fc7
I0109 02:08:55.621929  9387 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 02:08:55.621937  9387 net.cpp:159] Memory required for data: 2120314880
I0109 02:08:55.621946  9387 layer_factory.hpp:77] Creating layer bn7
I0109 02:08:55.621956  9387 net.cpp:94] Creating Layer bn7
I0109 02:08:55.621960  9387 net.cpp:435] bn7 <- fc7
I0109 02:08:55.621965  9387 net.cpp:409] bn7 -> bn7
I0109 02:08:55.622432  9387 net.cpp:144] Setting up bn7
I0109 02:08:55.622442  9387 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 02:08:55.622448  9387 net.cpp:159] Memory required for data: 2124509184
I0109 02:08:55.622457  9387 layer_factory.hpp:77] Creating layer relu7
I0109 02:08:55.622465  9387 net.cpp:94] Creating Layer relu7
I0109 02:08:55.622470  9387 net.cpp:435] relu7 <- bn7
I0109 02:08:55.622478  9387 net.cpp:409] relu7 -> relu7
I0109 02:08:55.622503  9387 net.cpp:144] Setting up relu7
I0109 02:08:55.622509  9387 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 02:08:55.622514  9387 net.cpp:159] Memory required for data: 2128703488
I0109 02:08:55.622517  9387 layer_factory.hpp:77] Creating layer drop7
I0109 02:08:55.622524  9387 net.cpp:94] Creating Layer drop7
I0109 02:08:55.622530  9387 net.cpp:435] drop7 <- relu7
I0109 02:08:55.622537  9387 net.cpp:409] drop7 -> drop7
I0109 02:08:55.622578  9387 net.cpp:144] Setting up drop7
I0109 02:08:55.622599  9387 net.cpp:151] Top shape: 256 4096 (1048576)
I0109 02:08:55.622604  9387 net.cpp:159] Memory required for data: 2132897792
I0109 02:08:55.622608  9387 layer_factory.hpp:77] Creating layer fc8
I0109 02:08:55.622617  9387 net.cpp:94] Creating Layer fc8
I0109 02:08:55.622627  9387 net.cpp:435] fc8 <- drop7
I0109 02:08:55.622632  9387 net.cpp:409] fc8 -> fc8
I0109 02:08:55.622792  9387 net.cpp:144] Setting up fc8
I0109 02:08:55.622797  9387 net.cpp:151] Top shape: 256 2 (512)
I0109 02:08:55.622802  9387 net.cpp:159] Memory required for data: 2132899840
I0109 02:08:55.622807  9387 layer_factory.hpp:77] Creating layer loss
I0109 02:08:55.622815  9387 net.cpp:94] Creating Layer loss
I0109 02:08:55.622822  9387 net.cpp:435] loss <- fc8
I0109 02:08:55.622828  9387 net.cpp:435] loss <- label
I0109 02:08:55.622835  9387 net.cpp:409] loss -> loss
I0109 02:08:55.622844  9387 layer_factory.hpp:77] Creating layer loss
I0109 02:08:55.622912  9387 net.cpp:144] Setting up loss
I0109 02:08:55.622917  9387 net.cpp:151] Top shape: (1)
I0109 02:08:55.622922  9387 net.cpp:154]     with loss weight 1
I0109 02:08:55.622938  9387 net.cpp:159] Memory required for data: 2132899844
I0109 02:08:55.622944  9387 net.cpp:220] loss needs backward computation.
I0109 02:08:55.622951  9387 net.cpp:220] fc8 needs backward computation.
I0109 02:08:55.622956  9387 net.cpp:220] drop7 needs backward computation.
I0109 02:08:55.622961  9387 net.cpp:220] relu7 needs backward computation.
I0109 02:08:55.622967  9387 net.cpp:220] bn7 needs backward computation.
I0109 02:08:55.622974  9387 net.cpp:220] fc7 needs backward computation.
I0109 02:08:55.622980  9387 net.cpp:220] drop6 needs backward computation.
I0109 02:08:55.622987  9387 net.cpp:220] relu6 needs backward computation.
I0109 02:08:55.622992  9387 net.cpp:220] fc6 needs backward computation.
I0109 02:08:55.622998  9387 net.cpp:220] pool5 needs backward computation.
I0109 02:08:55.623004  9387 net.cpp:220] relu5 needs backward computation.
I0109 02:08:55.623011  9387 net.cpp:220] conv5 needs backward computation.
I0109 02:08:55.623016  9387 net.cpp:220] relu4 needs backward computation.
I0109 02:08:55.623034  9387 net.cpp:220] conv4 needs backward computation.
I0109 02:08:55.623039  9387 net.cpp:220] relu3 needs backward computation.
I0109 02:08:55.623044  9387 net.cpp:220] conv3 needs backward computation.
I0109 02:08:55.623050  9387 net.cpp:220] pool2 needs backward computation.
I0109 02:08:55.623057  9387 net.cpp:220] relu2 needs backward computation.
I0109 02:08:55.623064  9387 net.cpp:220] bn2 needs backward computation.
I0109 02:08:55.623070  9387 net.cpp:220] conv2 needs backward computation.
I0109 02:08:55.623075  9387 net.cpp:220] pool1 needs backward computation.
I0109 02:08:55.623082  9387 net.cpp:220] relu1 needs backward computation.
I0109 02:08:55.623088  9387 net.cpp:220] bn1 needs backward computation.
I0109 02:08:55.623095  9387 net.cpp:220] conv1 needs backward computation.
I0109 02:08:55.623101  9387 net.cpp:222] data does not need backward computation.
I0109 02:08:55.623107  9387 net.cpp:264] This network produces output loss
I0109 02:08:55.623133  9387 net.cpp:284] Network initialization done.
I0109 02:08:55.623503  9387 solver.cpp:189] Creating test net (#0) specified by net file: pruning/alexnetBNnoLRN/regular_rate_0.7/net_finetune.prototxt
I0109 02:08:55.623544  9387 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0109 02:08:55.623562  9387 net.cpp:52] Initializing net from parameters:
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    compression: PRUNE
  }
  param {
    lr_mult: 2
    decay_mult: 0
    compression: PRUNE
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  param {
    lr_mult: 0
    compression: PRUNE
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0109 02:08:55.623824  9387 layer_factory.hpp:77] Creating layer data
I0109 02:08:55.623872  9387 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 02:08:55.625509  9387 net.cpp:94] Creating Layer data
I0109 02:08:55.625521  9387 net.cpp:409] data -> data
I0109 02:08:55.625532  9387 net.cpp:409] data -> label
I0109 02:08:55.627164  9454 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0109 02:08:55.627187  9454 db_lmdb.cpp:38] Items count: 4000
I0109 02:08:55.627207  9454 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0109 02:08:55.627461  9387 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0109 02:08:55.627558  9387 data_layer.cpp:83] output data size: 50,3,227,227
I0109 02:08:55.726646  9387 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 02:08:55.726747  9387 net.cpp:144] Setting up data
I0109 02:08:55.726756  9387 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0109 02:08:55.726769  9387 net.cpp:151] Top shape: 50 (50)
I0109 02:08:55.726774  9387 net.cpp:159] Memory required for data: 30917600
I0109 02:08:55.726781  9387 layer_factory.hpp:77] Creating layer label_data_1_split
I0109 02:08:55.726814  9387 net.cpp:94] Creating Layer label_data_1_split
I0109 02:08:55.726819  9387 net.cpp:435] label_data_1_split <- label
I0109 02:08:55.726828  9387 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0109 02:08:55.726840  9387 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0109 02:08:55.726850  9387 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0109 02:08:55.726917  9387 net.cpp:144] Setting up label_data_1_split
I0109 02:08:55.726922  9387 net.cpp:151] Top shape: 50 (50)
I0109 02:08:55.726928  9387 net.cpp:151] Top shape: 50 (50)
I0109 02:08:55.726933  9387 net.cpp:151] Top shape: 50 (50)
I0109 02:08:55.726938  9387 net.cpp:159] Memory required for data: 30918200
I0109 02:08:55.726943  9387 layer_factory.hpp:77] Creating layer conv1
I0109 02:08:55.726956  9387 net.cpp:94] Creating Layer conv1
I0109 02:08:55.726965  9387 net.cpp:435] conv1 <- data
I0109 02:08:55.726972  9387 net.cpp:409] conv1 -> conv1
I0109 02:08:55.727596  9387 net.cpp:144] Setting up conv1
I0109 02:08:55.727604  9387 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0109 02:08:55.727610  9387 net.cpp:159] Memory required for data: 88998200
I0109 02:08:55.727623  9387 layer_factory.hpp:77] Creating layer bn1
I0109 02:08:55.727635  9387 net.cpp:94] Creating Layer bn1
I0109 02:08:55.727639  9387 net.cpp:435] bn1 <- conv1
I0109 02:08:55.727648  9387 net.cpp:409] bn1 -> bn1
I0109 02:08:55.728178  9387 net.cpp:144] Setting up bn1
I0109 02:08:55.728184  9387 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0109 02:08:55.728189  9387 net.cpp:159] Memory required for data: 147078200
I0109 02:08:55.728202  9387 layer_factory.hpp:77] Creating layer relu1
I0109 02:08:55.728212  9387 net.cpp:94] Creating Layer relu1
I0109 02:08:55.728216  9387 net.cpp:435] relu1 <- bn1
I0109 02:08:55.728224  9387 net.cpp:409] relu1 -> relu1
I0109 02:08:55.728245  9387 net.cpp:144] Setting up relu1
I0109 02:08:55.728250  9387 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0109 02:08:55.728255  9387 net.cpp:159] Memory required for data: 205158200
I0109 02:08:55.728260  9387 layer_factory.hpp:77] Creating layer pool1
I0109 02:08:55.728267  9387 net.cpp:94] Creating Layer pool1
I0109 02:08:55.728276  9387 net.cpp:435] pool1 <- relu1
I0109 02:08:55.728281  9387 net.cpp:409] pool1 -> pool1
I0109 02:08:55.728310  9387 net.cpp:144] Setting up pool1
I0109 02:08:55.728317  9387 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0109 02:08:55.728322  9387 net.cpp:159] Memory required for data: 219155000
I0109 02:08:55.728325  9387 layer_factory.hpp:77] Creating layer conv2
I0109 02:08:55.728335  9387 net.cpp:94] Creating Layer conv2
I0109 02:08:55.728341  9387 net.cpp:435] conv2 <- pool1
I0109 02:08:55.728349  9387 net.cpp:409] conv2 -> conv2
I0109 02:08:55.735105  9387 net.cpp:144] Setting up conv2
I0109 02:08:55.735123  9387 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0109 02:08:55.735131  9387 net.cpp:159] Memory required for data: 256479800
I0109 02:08:55.735141  9387 layer_factory.hpp:77] Creating layer bn2
I0109 02:08:55.735149  9387 net.cpp:94] Creating Layer bn2
I0109 02:08:55.735154  9387 net.cpp:435] bn2 <- conv2
I0109 02:08:55.735162  9387 net.cpp:409] bn2 -> bn2
I0109 02:08:55.735648  9387 net.cpp:144] Setting up bn2
I0109 02:08:55.735657  9387 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0109 02:08:55.735663  9387 net.cpp:159] Memory required for data: 293804600
I0109 02:08:55.735671  9387 layer_factory.hpp:77] Creating layer relu2
I0109 02:08:55.735682  9387 net.cpp:94] Creating Layer relu2
I0109 02:08:55.735689  9387 net.cpp:435] relu2 <- bn2
I0109 02:08:55.735697  9387 net.cpp:409] relu2 -> relu2
I0109 02:08:55.735723  9387 net.cpp:144] Setting up relu2
I0109 02:08:55.735743  9387 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0109 02:08:55.735749  9387 net.cpp:159] Memory required for data: 331129400
I0109 02:08:55.735752  9387 layer_factory.hpp:77] Creating layer pool2
I0109 02:08:55.735760  9387 net.cpp:94] Creating Layer pool2
I0109 02:08:55.735767  9387 net.cpp:435] pool2 <- relu2
I0109 02:08:55.735774  9387 net.cpp:409] pool2 -> pool2
I0109 02:08:55.735806  9387 net.cpp:144] Setting up pool2
I0109 02:08:55.735814  9387 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0109 02:08:55.735819  9387 net.cpp:159] Memory required for data: 339782200
I0109 02:08:55.735822  9387 layer_factory.hpp:77] Creating layer conv3
I0109 02:08:55.735831  9387 net.cpp:94] Creating Layer conv3
I0109 02:08:55.735833  9387 net.cpp:435] conv3 <- pool2
I0109 02:08:55.735841  9387 net.cpp:409] conv3 -> conv3
I0109 02:08:55.746420  9387 net.cpp:144] Setting up conv3
I0109 02:08:55.746439  9387 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 02:08:55.746448  9387 net.cpp:159] Memory required for data: 352761400
I0109 02:08:55.746457  9387 layer_factory.hpp:77] Creating layer relu3
I0109 02:08:55.746465  9387 net.cpp:94] Creating Layer relu3
I0109 02:08:55.746469  9387 net.cpp:435] relu3 <- conv3
I0109 02:08:55.746476  9387 net.cpp:409] relu3 -> relu3
I0109 02:08:55.746500  9387 net.cpp:144] Setting up relu3
I0109 02:08:55.746503  9387 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 02:08:55.746508  9387 net.cpp:159] Memory required for data: 365740600
I0109 02:08:55.746511  9387 layer_factory.hpp:77] Creating layer conv4
I0109 02:08:55.746520  9387 net.cpp:94] Creating Layer conv4
I0109 02:08:55.746523  9387 net.cpp:435] conv4 <- relu3
I0109 02:08:55.746528  9387 net.cpp:409] conv4 -> conv4
I0109 02:08:55.764101  9387 net.cpp:144] Setting up conv4
I0109 02:08:55.764120  9387 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 02:08:55.764129  9387 net.cpp:159] Memory required for data: 378719800
I0109 02:08:55.764159  9387 layer_factory.hpp:77] Creating layer relu4
I0109 02:08:55.764168  9387 net.cpp:94] Creating Layer relu4
I0109 02:08:55.764178  9387 net.cpp:435] relu4 <- conv4
I0109 02:08:55.764187  9387 net.cpp:409] relu4 -> relu4
I0109 02:08:55.764228  9387 net.cpp:144] Setting up relu4
I0109 02:08:55.764241  9387 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 02:08:55.764250  9387 net.cpp:159] Memory required for data: 391699000
I0109 02:08:55.764256  9387 layer_factory.hpp:77] Creating layer conv5
I0109 02:08:55.764267  9387 net.cpp:94] Creating Layer conv5
I0109 02:08:55.764283  9387 net.cpp:435] conv5 <- relu4
I0109 02:08:55.764290  9387 net.cpp:409] conv5 -> conv5
I0109 02:08:55.774076  9387 net.cpp:144] Setting up conv5
I0109 02:08:55.774106  9387 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0109 02:08:55.774122  9387 net.cpp:159] Memory required for data: 400351800
I0109 02:08:55.774143  9387 layer_factory.hpp:77] Creating layer relu5
I0109 02:08:55.774161  9387 net.cpp:94] Creating Layer relu5
I0109 02:08:55.774173  9387 net.cpp:435] relu5 <- conv5
I0109 02:08:55.774186  9387 net.cpp:409] relu5 -> relu5
I0109 02:08:55.774235  9387 net.cpp:144] Setting up relu5
I0109 02:08:55.774243  9387 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0109 02:08:55.774266  9387 net.cpp:159] Memory required for data: 409004600
I0109 02:08:55.774273  9387 layer_factory.hpp:77] Creating layer pool5
I0109 02:08:55.774296  9387 net.cpp:94] Creating Layer pool5
I0109 02:08:55.774309  9387 net.cpp:435] pool5 <- relu5
I0109 02:08:55.774320  9387 net.cpp:409] pool5 -> pool5
I0109 02:08:55.774379  9387 net.cpp:144] Setting up pool5
I0109 02:08:55.774386  9387 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0109 02:08:55.774394  9387 net.cpp:159] Memory required for data: 410847800
I0109 02:08:55.774399  9387 layer_factory.hpp:77] Creating layer fc6
I0109 02:08:55.774408  9387 net.cpp:94] Creating Layer fc6
I0109 02:08:55.774415  9387 net.cpp:435] fc6 <- pool5
I0109 02:08:55.774421  9387 net.cpp:409] fc6 -> fc6
I0109 02:08:56.124125  9387 net.cpp:144] Setting up fc6
I0109 02:08:56.124148  9387 net.cpp:151] Top shape: 50 4096 (204800)
I0109 02:08:56.124192  9387 net.cpp:159] Memory required for data: 411667000
I0109 02:08:56.124203  9387 layer_factory.hpp:77] Creating layer relu6
I0109 02:08:56.124209  9387 net.cpp:94] Creating Layer relu6
I0109 02:08:56.124213  9387 net.cpp:435] relu6 <- fc6
I0109 02:08:56.124219  9387 net.cpp:409] relu6 -> relu6
I0109 02:08:56.124243  9387 net.cpp:144] Setting up relu6
I0109 02:08:56.124248  9387 net.cpp:151] Top shape: 50 4096 (204800)
I0109 02:08:56.124253  9387 net.cpp:159] Memory required for data: 412486200
I0109 02:08:56.124255  9387 layer_factory.hpp:77] Creating layer drop6
I0109 02:08:56.124261  9387 net.cpp:94] Creating Layer drop6
I0109 02:08:56.124264  9387 net.cpp:435] drop6 <- relu6
I0109 02:08:56.124269  9387 net.cpp:409] drop6 -> drop6
I0109 02:08:56.124289  9387 net.cpp:144] Setting up drop6
I0109 02:08:56.124294  9387 net.cpp:151] Top shape: 50 4096 (204800)
I0109 02:08:56.124297  9387 net.cpp:159] Memory required for data: 413305400
I0109 02:08:56.124300  9387 layer_factory.hpp:77] Creating layer fc7
I0109 02:08:56.124307  9387 net.cpp:94] Creating Layer fc7
I0109 02:08:56.124326  9387 net.cpp:435] fc7 <- drop6
I0109 02:08:56.124332  9387 net.cpp:409] fc7 -> fc7
I0109 02:08:56.269827  9387 net.cpp:144] Setting up fc7
I0109 02:08:56.269853  9387 net.cpp:151] Top shape: 50 4096 (204800)
I0109 02:08:56.269861  9387 net.cpp:159] Memory required for data: 414124600
I0109 02:08:56.269886  9387 layer_factory.hpp:77] Creating layer bn7
I0109 02:08:56.269896  9387 net.cpp:94] Creating Layer bn7
I0109 02:08:56.269899  9387 net.cpp:435] bn7 <- fc7
I0109 02:08:56.269906  9387 net.cpp:409] bn7 -> bn7
I0109 02:08:56.270370  9387 net.cpp:144] Setting up bn7
I0109 02:08:56.270376  9387 net.cpp:151] Top shape: 50 4096 (204800)
I0109 02:08:56.270381  9387 net.cpp:159] Memory required for data: 414943800
I0109 02:08:56.270390  9387 layer_factory.hpp:77] Creating layer relu7
I0109 02:08:56.270395  9387 net.cpp:94] Creating Layer relu7
I0109 02:08:56.270398  9387 net.cpp:435] relu7 <- bn7
I0109 02:08:56.270403  9387 net.cpp:409] relu7 -> relu7
I0109 02:08:56.270421  9387 net.cpp:144] Setting up relu7
I0109 02:08:56.270427  9387 net.cpp:151] Top shape: 50 4096 (204800)
I0109 02:08:56.270433  9387 net.cpp:159] Memory required for data: 415763000
I0109 02:08:56.270437  9387 layer_factory.hpp:77] Creating layer drop7
I0109 02:08:56.270443  9387 net.cpp:94] Creating Layer drop7
I0109 02:08:56.270448  9387 net.cpp:435] drop7 <- relu7
I0109 02:08:56.270453  9387 net.cpp:409] drop7 -> drop7
I0109 02:08:56.270483  9387 net.cpp:144] Setting up drop7
I0109 02:08:56.270491  9387 net.cpp:151] Top shape: 50 4096 (204800)
I0109 02:08:56.270495  9387 net.cpp:159] Memory required for data: 416582200
I0109 02:08:56.270500  9387 layer_factory.hpp:77] Creating layer fc8
I0109 02:08:56.270506  9387 net.cpp:94] Creating Layer fc8
I0109 02:08:56.270509  9387 net.cpp:435] fc8 <- drop7
I0109 02:08:56.270514  9387 net.cpp:409] fc8 -> fc8
I0109 02:08:56.270682  9387 net.cpp:144] Setting up fc8
I0109 02:08:56.270689  9387 net.cpp:151] Top shape: 50 2 (100)
I0109 02:08:56.270692  9387 net.cpp:159] Memory required for data: 416582600
I0109 02:08:56.270699  9387 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0109 02:08:56.270704  9387 net.cpp:94] Creating Layer fc8_fc8_0_split
I0109 02:08:56.270707  9387 net.cpp:435] fc8_fc8_0_split <- fc8
I0109 02:08:56.270712  9387 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0109 02:08:56.270718  9387 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0109 02:08:56.270725  9387 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0109 02:08:56.270757  9387 net.cpp:144] Setting up fc8_fc8_0_split
I0109 02:08:56.270762  9387 net.cpp:151] Top shape: 50 2 (100)
I0109 02:08:56.270767  9387 net.cpp:151] Top shape: 50 2 (100)
I0109 02:08:56.270771  9387 net.cpp:151] Top shape: 50 2 (100)
I0109 02:08:56.270776  9387 net.cpp:159] Memory required for data: 416583800
I0109 02:08:56.270778  9387 layer_factory.hpp:77] Creating layer accuracy
I0109 02:08:56.270785  9387 net.cpp:94] Creating Layer accuracy
I0109 02:08:56.270803  9387 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0109 02:08:56.270808  9387 net.cpp:435] accuracy <- label_data_1_split_0
I0109 02:08:56.270813  9387 net.cpp:409] accuracy -> accuracy
I0109 02:08:56.270819  9387 net.cpp:144] Setting up accuracy
I0109 02:08:56.270823  9387 net.cpp:151] Top shape: (1)
I0109 02:08:56.270828  9387 net.cpp:159] Memory required for data: 416583804
I0109 02:08:56.270830  9387 layer_factory.hpp:77] Creating layer loss
I0109 02:08:56.270836  9387 net.cpp:94] Creating Layer loss
I0109 02:08:56.270840  9387 net.cpp:435] loss <- fc8_fc8_0_split_1
I0109 02:08:56.270846  9387 net.cpp:435] loss <- label_data_1_split_1
I0109 02:08:56.270851  9387 net.cpp:409] loss -> loss
I0109 02:08:56.270881  9387 layer_factory.hpp:77] Creating layer loss
I0109 02:08:56.270957  9387 net.cpp:144] Setting up loss
I0109 02:08:56.270963  9387 net.cpp:151] Top shape: (1)
I0109 02:08:56.270967  9387 net.cpp:154]     with loss weight 1
I0109 02:08:56.270979  9387 net.cpp:159] Memory required for data: 416583808
I0109 02:08:56.270983  9387 layer_factory.hpp:77] Creating layer accuracy-top1
I0109 02:08:56.270989  9387 net.cpp:94] Creating Layer accuracy-top1
I0109 02:08:56.270995  9387 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0109 02:08:56.271000  9387 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0109 02:08:56.271005  9387 net.cpp:409] accuracy-top1 -> top-1
I0109 02:08:56.271011  9387 net.cpp:144] Setting up accuracy-top1
I0109 02:08:56.271015  9387 net.cpp:151] Top shape: (1)
I0109 02:08:56.271019  9387 net.cpp:159] Memory required for data: 416583812
I0109 02:08:56.271023  9387 net.cpp:222] accuracy-top1 does not need backward computation.
I0109 02:08:56.271028  9387 net.cpp:220] loss needs backward computation.
I0109 02:08:56.271031  9387 net.cpp:222] accuracy does not need backward computation.
I0109 02:08:56.271036  9387 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0109 02:08:56.271040  9387 net.cpp:220] fc8 needs backward computation.
I0109 02:08:56.271044  9387 net.cpp:220] drop7 needs backward computation.
I0109 02:08:56.271049  9387 net.cpp:220] relu7 needs backward computation.
I0109 02:08:56.271052  9387 net.cpp:220] bn7 needs backward computation.
I0109 02:08:56.271056  9387 net.cpp:220] fc7 needs backward computation.
I0109 02:08:56.271060  9387 net.cpp:220] drop6 needs backward computation.
I0109 02:08:56.271064  9387 net.cpp:220] relu6 needs backward computation.
I0109 02:08:56.271068  9387 net.cpp:220] fc6 needs backward computation.
I0109 02:08:56.271072  9387 net.cpp:220] pool5 needs backward computation.
I0109 02:08:56.271076  9387 net.cpp:220] relu5 needs backward computation.
I0109 02:08:56.271081  9387 net.cpp:220] conv5 needs backward computation.
I0109 02:08:56.271086  9387 net.cpp:220] relu4 needs backward computation.
I0109 02:08:56.271091  9387 net.cpp:220] conv4 needs backward computation.
I0109 02:08:56.271095  9387 net.cpp:220] relu3 needs backward computation.
I0109 02:08:56.271100  9387 net.cpp:220] conv3 needs backward computation.
I0109 02:08:56.271103  9387 net.cpp:220] pool2 needs backward computation.
I0109 02:08:56.271107  9387 net.cpp:220] relu2 needs backward computation.
I0109 02:08:56.271111  9387 net.cpp:220] bn2 needs backward computation.
I0109 02:08:56.271116  9387 net.cpp:220] conv2 needs backward computation.
I0109 02:08:56.271121  9387 net.cpp:220] pool1 needs backward computation.
I0109 02:08:56.271124  9387 net.cpp:220] relu1 needs backward computation.
I0109 02:08:56.271128  9387 net.cpp:220] bn1 needs backward computation.
I0109 02:08:56.271132  9387 net.cpp:220] conv1 needs backward computation.
I0109 02:08:56.271137  9387 net.cpp:222] label_data_1_split does not need backward computation.
I0109 02:08:56.271142  9387 net.cpp:222] data does not need backward computation.
I0109 02:08:56.271147  9387 net.cpp:264] This network produces output accuracy
I0109 02:08:56.271150  9387 net.cpp:264] This network produces output loss
I0109 02:08:56.271155  9387 net.cpp:264] This network produces output top-1
I0109 02:08:56.271190  9387 net.cpp:284] Network initialization done.
I0109 02:08:56.271270  9387 solver.cpp:63] Solver scaffolding done.
I0109 02:08:56.272289  9387 caffe_interface.cpp:109] Finetuning from pruning/alexnetBNnoLRN/regular_rate_0.7/sparse.caffemodel
I0109 02:08:58.586383  9387 caffe_interface.cpp:543] Starting Optimization
I0109 02:08:58.586406  9387 solver.cpp:341] Solving
I0109 02:08:58.586410  9387 solver.cpp:342] Learning Rate Policy: step
I0109 02:08:58.587803  9387 solver.cpp:424] Iteration 0, Testing net (#0)
I0109 02:09:00.095789  9387 solver.cpp:523]     Test net output #0: accuracy = 0.95475
I0109 02:09:00.095820  9387 solver.cpp:523]     Test net output #1: loss = 0.300998 (* 1 = 0.300998 loss)
I0109 02:09:00.095824  9387 solver.cpp:523]     Test net output #2: top-1 = 0.95475
I0109 02:09:00.350960  9387 solver.cpp:270] Iteration 0 (0 iter/s, 1.76443s/50 iter), loss = 0.0173326, remaining 333333 hours and 20 minutes
I0109 02:09:00.350991  9387 solver.cpp:291]     Train net output #0: loss = 0.0173326 (* 1 = 0.0173326 loss)
I0109 02:09:00.351016  9387 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0109 02:09:12.813011  9387 solver.cpp:270] Iteration 50 (4.01236 iter/s, 12.4615s/50 iter), loss = 0.0878605, remaining 0 hours and 49 minutes
I0109 02:09:12.813043  9387 solver.cpp:291]     Train net output #0: loss = 0.0878605 (* 1 = 0.0878605 loss)
I0109 02:09:12.813050  9387 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0109 02:09:25.358052  9387 solver.cpp:270] Iteration 100 (3.98582 iter/s, 12.5445s/50 iter), loss = 0.043733, remaining 0 hours and 49 minutes
I0109 02:09:25.358098  9387 solver.cpp:291]     Train net output #0: loss = 0.043733 (* 1 = 0.043733 loss)
I0109 02:09:25.358105  9387 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0109 02:09:37.907521  9387 solver.cpp:270] Iteration 150 (3.98441 iter/s, 12.5489s/50 iter), loss = 0.062143, remaining 0 hours and 49 minutes
I0109 02:09:37.907555  9387 solver.cpp:291]     Train net output #0: loss = 0.062143 (* 1 = 0.062143 loss)
I0109 02:09:37.907562  9387 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0109 02:09:50.492164  9387 solver.cpp:270] Iteration 200 (3.97326 iter/s, 12.5841s/50 iter), loss = 0.0577248, remaining 0 hours and 49 minutes
I0109 02:09:50.492197  9387 solver.cpp:291]     Train net output #0: loss = 0.0577248 (* 1 = 0.0577248 loss)
I0109 02:09:50.492220  9387 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0109 02:10:03.103127  9387 solver.cpp:270] Iteration 250 (3.96496 iter/s, 12.6105s/50 iter), loss = 0.0773477, remaining 0 hours and 49 minutes
I0109 02:10:03.103176  9387 solver.cpp:291]     Train net output #0: loss = 0.0773477 (* 1 = 0.0773477 loss)
I0109 02:10:03.103200  9387 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0109 02:10:15.870396  9387 solver.cpp:270] Iteration 300 (3.91642 iter/s, 12.7668s/50 iter), loss = 0.0631721, remaining 0 hours and 49 minutes
I0109 02:10:15.870429  9387 solver.cpp:291]     Train net output #0: loss = 0.0631721 (* 1 = 0.0631721 loss)
I0109 02:10:15.870435  9387 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0109 02:10:28.685706  9387 solver.cpp:270] Iteration 350 (3.90173 iter/s, 12.8148s/50 iter), loss = 0.073874, remaining 0 hours and 49 minutes
I0109 02:10:28.685740  9387 solver.cpp:291]     Train net output #0: loss = 0.073874 (* 1 = 0.073874 loss)
I0109 02:10:28.685746  9387 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0109 02:10:41.532018  9387 solver.cpp:270] Iteration 400 (3.89232 iter/s, 12.8458s/50 iter), loss = 0.104322, remaining 0 hours and 49 minutes
I0109 02:10:41.532064  9387 solver.cpp:291]     Train net output #0: loss = 0.104322 (* 1 = 0.104322 loss)
I0109 02:10:41.532088  9387 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0109 02:10:54.320204  9387 solver.cpp:270] Iteration 450 (3.91002 iter/s, 12.7877s/50 iter), loss = 0.131416, remaining 0 hours and 49 minutes
I0109 02:10:54.320236  9387 solver.cpp:291]     Train net output #0: loss = 0.131416 (* 1 = 0.131416 loss)
I0109 02:10:54.320261  9387 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0109 02:11:07.176591  9387 solver.cpp:270] Iteration 500 (3.88927 iter/s, 12.8559s/50 iter), loss = 0.0791678, remaining 0 hours and 49 minutes
I0109 02:11:07.176625  9387 solver.cpp:291]     Train net output #0: loss = 0.0791678 (* 1 = 0.0791678 loss)
I0109 02:11:07.176632  9387 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0109 02:11:19.965799  9387 solver.cpp:270] Iteration 550 (3.9097 iter/s, 12.7887s/50 iter), loss = 0.0793299, remaining 0 hours and 48 minutes
I0109 02:11:19.965855  9387 solver.cpp:291]     Train net output #0: loss = 0.0793299 (* 1 = 0.0793299 loss)
I0109 02:11:19.965863  9387 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0109 02:11:32.719966  9387 solver.cpp:270] Iteration 600 (3.92045 iter/s, 12.7536s/50 iter), loss = 0.0345688, remaining 0 hours and 48 minutes
I0109 02:11:32.719998  9387 solver.cpp:291]     Train net output #0: loss = 0.0345688 (* 1 = 0.0345688 loss)
I0109 02:11:32.720006  9387 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0109 02:11:45.524724  9387 solver.cpp:270] Iteration 650 (3.90496 iter/s, 12.8042s/50 iter), loss = 0.0703511, remaining 0 hours and 48 minutes
I0109 02:11:45.524757  9387 solver.cpp:291]     Train net output #0: loss = 0.0703511 (* 1 = 0.0703511 loss)
I0109 02:11:45.524765  9387 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0109 02:11:58.349454  9387 solver.cpp:270] Iteration 700 (3.89887 iter/s, 12.8242s/50 iter), loss = 0.0380646, remaining 0 hours and 48 minutes
I0109 02:11:58.349505  9387 solver.cpp:291]     Train net output #0: loss = 0.0380646 (* 1 = 0.0380646 loss)
I0109 02:11:58.349514  9387 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0109 02:12:11.135700  9387 solver.cpp:270] Iteration 750 (3.91061 iter/s, 12.7857s/50 iter), loss = 0.0905796, remaining 0 hours and 47 minutes
I0109 02:12:11.135735  9387 solver.cpp:291]     Train net output #0: loss = 0.0905796 (* 1 = 0.0905796 loss)
I0109 02:12:11.135757  9387 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0109 02:12:23.971292  9387 solver.cpp:270] Iteration 800 (3.89557 iter/s, 12.8351s/50 iter), loss = 0.0620852, remaining 0 hours and 47 minutes
I0109 02:12:23.971326  9387 solver.cpp:291]     Train net output #0: loss = 0.0620853 (* 1 = 0.0620853 loss)
I0109 02:12:23.971333  9387 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0109 02:12:36.767753  9387 solver.cpp:270] Iteration 850 (3.90749 iter/s, 12.7959s/50 iter), loss = 0.035737, remaining 0 hours and 47 minutes
I0109 02:12:36.767809  9387 solver.cpp:291]     Train net output #0: loss = 0.035737 (* 1 = 0.035737 loss)
I0109 02:12:36.767817  9387 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0109 02:12:49.587896  9387 solver.cpp:270] Iteration 900 (3.90027 iter/s, 12.8196s/50 iter), loss = 0.0619181, remaining 0 hours and 47 minutes
I0109 02:12:49.587929  9387 solver.cpp:291]     Train net output #0: loss = 0.0619181 (* 1 = 0.0619181 loss)
I0109 02:12:49.587952  9387 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0109 02:13:02.394495  9387 solver.cpp:270] Iteration 950 (3.90439 iter/s, 12.8061s/50 iter), loss = 0.106728, remaining 0 hours and 47 minutes
I0109 02:13:02.394528  9387 solver.cpp:291]     Train net output #0: loss = 0.106728 (* 1 = 0.106728 loss)
I0109 02:13:02.394536  9387 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0109 02:13:14.917639  9387 solver.cpp:424] Iteration 1000, Testing net (#0)
I0109 02:13:16.408687  9387 solver.cpp:523]     Test net output #0: accuracy = 0.91925
I0109 02:13:16.408715  9387 solver.cpp:523]     Test net output #1: loss = 0.330831 (* 1 = 0.330831 loss)
I0109 02:13:16.408720  9387 solver.cpp:523]     Test net output #2: top-1 = 0.91925
I0109 02:13:16.660239  9387 solver.cpp:270] Iteration 1000 (3.50504 iter/s, 14.2652s/50 iter), loss = 0.0458037, remaining 0 hours and 52 minutes
I0109 02:13:16.660269  9387 solver.cpp:291]     Train net output #0: loss = 0.0458037 (* 1 = 0.0458037 loss)
I0109 02:13:16.660291  9387 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0109 02:13:29.523600  9387 solver.cpp:270] Iteration 1050 (3.88716 iter/s, 12.8629s/50 iter), loss = 0.0993505, remaining 0 hours and 46 minutes
I0109 02:13:29.523631  9387 solver.cpp:291]     Train net output #0: loss = 0.0993505 (* 1 = 0.0993505 loss)
I0109 02:13:29.523638  9387 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0109 02:13:42.353292  9387 solver.cpp:270] Iteration 1100 (3.89736 iter/s, 12.8292s/50 iter), loss = 0.0987226, remaining 0 hours and 46 minutes
I0109 02:13:42.353327  9387 solver.cpp:291]     Train net output #0: loss = 0.0987226 (* 1 = 0.0987226 loss)
I0109 02:13:42.353333  9387 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0109 02:13:55.153396  9387 solver.cpp:270] Iteration 1150 (3.90637 iter/s, 12.7996s/50 iter), loss = 0.0611922, remaining 0 hours and 46 minutes
I0109 02:13:55.153451  9387 solver.cpp:291]     Train net output #0: loss = 0.0611922 (* 1 = 0.0611922 loss)
I0109 02:13:55.153458  9387 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0109 02:14:07.971345  9387 solver.cpp:270] Iteration 1200 (3.90094 iter/s, 12.8174s/50 iter), loss = 0.0409641, remaining 0 hours and 46 minutes
I0109 02:14:07.971377  9387 solver.cpp:291]     Train net output #0: loss = 0.0409641 (* 1 = 0.0409641 loss)
I0109 02:14:07.971383  9387 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0109 02:14:20.753226  9387 solver.cpp:270] Iteration 1250 (3.91194 iter/s, 12.7814s/50 iter), loss = 0.0552138, remaining 0 hours and 45 minutes
I0109 02:14:20.753258  9387 solver.cpp:291]     Train net output #0: loss = 0.0552139 (* 1 = 0.0552139 loss)
I0109 02:14:20.753265  9387 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0109 02:14:33.555546  9387 solver.cpp:270] Iteration 1300 (3.9057 iter/s, 12.8018s/50 iter), loss = 0.0926967, remaining 0 hours and 45 minutes
I0109 02:14:33.555591  9387 solver.cpp:291]     Train net output #0: loss = 0.0926968 (* 1 = 0.0926968 loss)
I0109 02:14:33.555598  9387 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0109 02:14:46.352533  9387 solver.cpp:270] Iteration 1350 (3.90733 iter/s, 12.7965s/50 iter), loss = 0.0827345, remaining 0 hours and 45 minutes
I0109 02:14:46.352568  9387 solver.cpp:291]     Train net output #0: loss = 0.0827345 (* 1 = 0.0827345 loss)
I0109 02:14:46.352576  9387 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0109 02:14:59.140698  9387 solver.cpp:270] Iteration 1400 (3.91002 iter/s, 12.7877s/50 iter), loss = 0.0893085, remaining 0 hours and 45 minutes
I0109 02:14:59.140730  9387 solver.cpp:291]     Train net output #0: loss = 0.0893085 (* 1 = 0.0893085 loss)
I0109 02:14:59.140738  9387 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0109 02:15:11.973614  9387 solver.cpp:270] Iteration 1450 (3.89639 iter/s, 12.8324s/50 iter), loss = 0.100887, remaining 0 hours and 44 minutes
I0109 02:15:11.973664  9387 solver.cpp:291]     Train net output #0: loss = 0.100887 (* 1 = 0.100887 loss)
I0109 02:15:11.973670  9387 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0109 02:15:24.761803  9387 solver.cpp:270] Iteration 1500 (3.91002 iter/s, 12.7877s/50 iter), loss = 0.0511057, remaining 0 hours and 44 minutes
I0109 02:15:24.761834  9387 solver.cpp:291]     Train net output #0: loss = 0.0511057 (* 1 = 0.0511057 loss)
I0109 02:15:24.761842  9387 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0109 02:15:37.583371  9387 solver.cpp:270] Iteration 1550 (3.89983 iter/s, 12.8211s/50 iter), loss = 0.0445379, remaining 0 hours and 44 minutes
I0109 02:15:37.583403  9387 solver.cpp:291]     Train net output #0: loss = 0.0445379 (* 1 = 0.0445379 loss)
I0109 02:15:37.583410  9387 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0109 02:15:50.398118  9387 solver.cpp:270] Iteration 1600 (3.90191 iter/s, 12.8142s/50 iter), loss = 0.0736555, remaining 0 hours and 44 minutes
I0109 02:15:50.398164  9387 solver.cpp:291]     Train net output #0: loss = 0.0736555 (* 1 = 0.0736555 loss)
I0109 02:15:50.398171  9387 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0109 02:16:03.177302  9387 solver.cpp:270] Iteration 1650 (3.91277 iter/s, 12.7787s/50 iter), loss = 0.078572, remaining 0 hours and 43 minutes
I0109 02:16:03.177336  9387 solver.cpp:291]     Train net output #0: loss = 0.078572 (* 1 = 0.078572 loss)
I0109 02:16:03.177343  9387 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0109 02:16:15.974462  9387 solver.cpp:270] Iteration 1700 (3.90727 iter/s, 12.7966s/50 iter), loss = 0.0760873, remaining 0 hours and 43 minutes
I0109 02:16:15.974494  9387 solver.cpp:291]     Train net output #0: loss = 0.0760873 (* 1 = 0.0760873 loss)
I0109 02:16:15.974501  9387 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0109 02:16:28.810791  9387 solver.cpp:270] Iteration 1750 (3.89535 iter/s, 12.8358s/50 iter), loss = 0.0504982, remaining 0 hours and 43 minutes
I0109 02:16:28.810848  9387 solver.cpp:291]     Train net output #0: loss = 0.0504982 (* 1 = 0.0504982 loss)
I0109 02:16:28.810856  9387 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0109 02:16:41.544759  9387 solver.cpp:270] Iteration 1800 (3.92667 iter/s, 12.7334s/50 iter), loss = 0.0588255, remaining 0 hours and 43 minutes
I0109 02:16:41.544790  9387 solver.cpp:291]     Train net output #0: loss = 0.0588255 (* 1 = 0.0588255 loss)
I0109 02:16:41.544797  9387 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0109 02:16:54.329980  9387 solver.cpp:270] Iteration 1850 (3.91092 iter/s, 12.7847s/50 iter), loss = 0.0435028, remaining 0 hours and 43 minutes
I0109 02:16:54.330011  9387 solver.cpp:291]     Train net output #0: loss = 0.0435028 (* 1 = 0.0435028 loss)
I0109 02:16:54.330018  9387 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0109 02:17:07.136303  9387 solver.cpp:270] Iteration 1900 (3.90448 iter/s, 12.8058s/50 iter), loss = 0.0476868, remaining 0 hours and 43 minutes
I0109 02:17:07.136350  9387 solver.cpp:291]     Train net output #0: loss = 0.0476868 (* 1 = 0.0476868 loss)
I0109 02:17:07.136358  9387 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0109 02:17:19.915943  9387 solver.cpp:270] Iteration 1950 (3.91263 iter/s, 12.7791s/50 iter), loss = 0.0564946, remaining 0 hours and 42 minutes
I0109 02:17:19.915975  9387 solver.cpp:291]     Train net output #0: loss = 0.0564946 (* 1 = 0.0564946 loss)
I0109 02:17:19.915997  9387 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0109 02:17:32.466111  9387 solver.cpp:424] Iteration 2000, Testing net (#0)
I0109 02:17:33.973304  9387 solver.cpp:523]     Test net output #0: accuracy = 0.913
I0109 02:17:33.973331  9387 solver.cpp:523]     Test net output #1: loss = 0.32616 (* 1 = 0.32616 loss)
I0109 02:17:33.973335  9387 solver.cpp:523]     Test net output #2: top-1 = 0.913
I0109 02:17:34.218812  9387 solver.cpp:270] Iteration 2000 (3.49594 iter/s, 14.3023s/50 iter), loss = 0.0744081, remaining 0 hours and 47 minutes
I0109 02:17:34.218839  9387 solver.cpp:291]     Train net output #0: loss = 0.0744081 (* 1 = 0.0744081 loss)
I0109 02:17:34.218847  9387 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0109 02:17:46.950414  9387 solver.cpp:270] Iteration 2050 (3.92739 iter/s, 12.7311s/50 iter), loss = 0.0467084, remaining 0 hours and 42 minutes
I0109 02:17:46.950462  9387 solver.cpp:291]     Train net output #0: loss = 0.0467084 (* 1 = 0.0467084 loss)
I0109 02:17:46.950469  9387 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I0109 02:17:59.751734  9387 solver.cpp:270] Iteration 2100 (3.90601 iter/s, 12.8008s/50 iter), loss = 0.0541684, remaining 0 hours and 42 minutes
I0109 02:17:59.751766  9387 solver.cpp:291]     Train net output #0: loss = 0.0541684 (* 1 = 0.0541684 loss)
I0109 02:17:59.751789  9387 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0109 02:18:12.554844  9387 solver.cpp:270] Iteration 2150 (3.90546 iter/s, 12.8026s/50 iter), loss = 0.0899777, remaining 0 hours and 41 minutes
I0109 02:18:12.554877  9387 solver.cpp:291]     Train net output #0: loss = 0.0899778 (* 1 = 0.0899778 loss)
I0109 02:18:12.554883  9387 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I0109 02:18:25.298079  9387 solver.cpp:270] Iteration 2200 (3.92381 iter/s, 12.7427s/50 iter), loss = 0.0466997, remaining 0 hours and 41 minutes
I0109 02:18:25.298131  9387 solver.cpp:291]     Train net output #0: loss = 0.0466997 (* 1 = 0.0466997 loss)
I0109 02:18:25.298138  9387 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0109 02:18:38.119789  9387 solver.cpp:270] Iteration 2250 (3.8998 iter/s, 12.8212s/50 iter), loss = 0.0984767, remaining 0 hours and 41 minutes
I0109 02:18:38.119822  9387 solver.cpp:291]     Train net output #0: loss = 0.0984767 (* 1 = 0.0984767 loss)
I0109 02:18:38.119828  9387 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0109 02:18:50.893353  9387 solver.cpp:270] Iteration 2300 (3.91449 iter/s, 12.7731s/50 iter), loss = 0.0748791, remaining 0 hours and 41 minutes
I0109 02:18:50.893385  9387 solver.cpp:291]     Train net output #0: loss = 0.0748792 (* 1 = 0.0748792 loss)
I0109 02:18:50.893393  9387 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0109 02:19:03.640784  9387 solver.cpp:270] Iteration 2350 (3.92252 iter/s, 12.7469s/50 iter), loss = 0.0713438, remaining 0 hours and 40 minutes
I0109 02:19:03.640832  9387 solver.cpp:291]     Train net output #0: loss = 0.0713438 (* 1 = 0.0713438 loss)
I0109 02:19:03.640839  9387 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I0109 02:19:16.437688  9387 solver.cpp:270] Iteration 2400 (3.90736 iter/s, 12.7964s/50 iter), loss = 0.0762415, remaining 0 hours and 40 minutes
I0109 02:19:16.437721  9387 solver.cpp:291]     Train net output #0: loss = 0.0762416 (* 1 = 0.0762416 loss)
I0109 02:19:16.437744  9387 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0109 02:19:29.212110  9387 solver.cpp:270] Iteration 2450 (3.91423 iter/s, 12.7739s/50 iter), loss = 0.0679407, remaining 0 hours and 40 minutes
I0109 02:19:29.212143  9387 solver.cpp:291]     Train net output #0: loss = 0.0679408 (* 1 = 0.0679408 loss)
I0109 02:19:29.212167  9387 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I0109 02:19:42.012645  9387 solver.cpp:270] Iteration 2500 (3.90624 iter/s, 12.8s/50 iter), loss = 0.106104, remaining 0 hours and 40 minutes
I0109 02:19:42.012689  9387 solver.cpp:291]     Train net output #0: loss = 0.106104 (* 1 = 0.106104 loss)
I0109 02:19:42.012697  9387 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0109 02:19:54.787799  9387 solver.cpp:270] Iteration 2550 (3.91401 iter/s, 12.7746s/50 iter), loss = 0.0328653, remaining 0 hours and 40 minutes
I0109 02:19:54.787832  9387 solver.cpp:291]     Train net output #0: loss = 0.0328653 (* 1 = 0.0328653 loss)
I0109 02:19:54.787854  9387 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0109 02:20:07.571935  9387 solver.cpp:270] Iteration 2600 (3.91125 iter/s, 12.7836s/50 iter), loss = 0.0191061, remaining 0 hours and 39 minutes
I0109 02:20:07.571967  9387 solver.cpp:291]     Train net output #0: loss = 0.0191061 (* 1 = 0.0191061 loss)
I0109 02:20:07.571990  9387 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0109 02:20:20.330171  9387 solver.cpp:270] Iteration 2650 (3.91919 iter/s, 12.7577s/50 iter), loss = 0.029745, remaining 0 hours and 39 minutes
I0109 02:20:20.330219  9387 solver.cpp:291]     Train net output #0: loss = 0.029745 (* 1 = 0.029745 loss)
I0109 02:20:20.330225  9387 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0109 02:20:33.087083  9387 solver.cpp:270] Iteration 2700 (3.91961 iter/s, 12.7564s/50 iter), loss = 0.0175614, remaining 0 hours and 39 minutes
I0109 02:20:33.087116  9387 solver.cpp:291]     Train net output #0: loss = 0.0175615 (* 1 = 0.0175615 loss)
I0109 02:20:33.087138  9387 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0109 02:20:45.879391  9387 solver.cpp:270] Iteration 2750 (3.90875 iter/s, 12.7918s/50 iter), loss = 0.0165523, remaining 0 hours and 39 minutes
I0109 02:20:45.879424  9387 solver.cpp:291]     Train net output #0: loss = 0.0165524 (* 1 = 0.0165524 loss)
I0109 02:20:45.879447  9387 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0109 02:20:58.692723  9387 solver.cpp:270] Iteration 2800 (3.90234 iter/s, 12.8128s/50 iter), loss = 0.0643689, remaining 0 hours and 39 minutes
I0109 02:20:58.692770  9387 solver.cpp:291]     Train net output #0: loss = 0.064369 (* 1 = 0.064369 loss)
I0109 02:20:58.692776  9387 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0109 02:21:11.457283  9387 solver.cpp:270] Iteration 2850 (3.91726 iter/s, 12.764s/50 iter), loss = 0.0470555, remaining 0 hours and 38 minutes
I0109 02:21:11.457319  9387 solver.cpp:291]     Train net output #0: loss = 0.0470555 (* 1 = 0.0470555 loss)
I0109 02:21:11.457324  9387 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0109 02:21:24.229710  9387 solver.cpp:270] Iteration 2900 (3.91484 iter/s, 12.7719s/50 iter), loss = 0.0148936, remaining 0 hours and 38 minutes
I0109 02:21:24.229743  9387 solver.cpp:291]     Train net output #0: loss = 0.0148937 (* 1 = 0.0148937 loss)
I0109 02:21:24.229750  9387 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0109 02:21:37.001006  9387 solver.cpp:270] Iteration 2950 (3.91519 iter/s, 12.7708s/50 iter), loss = 0.0250298, remaining 0 hours and 38 minutes
I0109 02:21:37.001055  9387 solver.cpp:291]     Train net output #0: loss = 0.0250299 (* 1 = 0.0250299 loss)
I0109 02:21:37.001078  9387 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0109 02:21:49.502106  9387 solver.cpp:424] Iteration 3000, Testing net (#0)
I0109 02:21:51.010215  9387 solver.cpp:523]     Test net output #0: accuracy = 0.95025
I0109 02:21:51.010242  9387 solver.cpp:523]     Test net output #1: loss = 0.141847 (* 1 = 0.141847 loss)
I0109 02:21:51.010249  9387 solver.cpp:523]     Test net output #2: top-1 = 0.95025
I0109 02:21:51.256022  9387 solver.cpp:270] Iteration 3000 (3.50768 iter/s, 14.2544s/50 iter), loss = 0.0052957, remaining 0 hours and 42 minutes
I0109 02:21:51.256048  9387 solver.cpp:291]     Train net output #0: loss = 0.00529576 (* 1 = 0.00529576 loss)
I0109 02:21:51.256072  9387 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0109 02:22:04.043898  9387 solver.cpp:270] Iteration 3050 (3.91011 iter/s, 12.7874s/50 iter), loss = 0.0260343, remaining 0 hours and 38 minutes
I0109 02:22:04.043929  9387 solver.cpp:291]     Train net output #0: loss = 0.0260343 (* 1 = 0.0260343 loss)
I0109 02:22:04.043952  9387 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0109 02:22:16.781482  9387 solver.cpp:270] Iteration 3100 (3.92555 iter/s, 12.7371s/50 iter), loss = 0.00921937, remaining 0 hours and 37 minutes
I0109 02:22:16.781529  9387 solver.cpp:291]     Train net output #0: loss = 0.00921943 (* 1 = 0.00921943 loss)
I0109 02:22:16.781536  9387 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0109 02:22:29.570291  9387 solver.cpp:270] Iteration 3150 (3.90983 iter/s, 12.7883s/50 iter), loss = 0.0246852, remaining 0 hours and 37 minutes
I0109 02:22:29.570320  9387 solver.cpp:291]     Train net output #0: loss = 0.0246853 (* 1 = 0.0246853 loss)
I0109 02:22:29.570327  9387 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0109 02:22:42.401381  9387 solver.cpp:270] Iteration 3200 (3.89694 iter/s, 12.8306s/50 iter), loss = 0.040147, remaining 0 hours and 37 minutes
I0109 02:22:42.401414  9387 solver.cpp:291]     Train net output #0: loss = 0.040147 (* 1 = 0.040147 loss)
I0109 02:22:42.401437  9387 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0109 02:22:55.155248  9387 solver.cpp:270] Iteration 3250 (3.92054 iter/s, 12.7534s/50 iter), loss = 0.0194043, remaining 0 hours and 36 minutes
I0109 02:22:55.155294  9387 solver.cpp:291]     Train net output #0: loss = 0.0194044 (* 1 = 0.0194044 loss)
I0109 02:22:55.155301  9387 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0109 02:23:07.912987  9387 solver.cpp:270] Iteration 3300 (3.91935 iter/s, 12.7572s/50 iter), loss = 0.00571228, remaining 0 hours and 36 minutes
I0109 02:23:07.913020  9387 solver.cpp:291]     Train net output #0: loss = 0.00571235 (* 1 = 0.00571235 loss)
I0109 02:23:07.913026  9387 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0109 02:23:20.761803  9387 solver.cpp:270] Iteration 3350 (3.89156 iter/s, 12.8483s/50 iter), loss = 0.039784, remaining 0 hours and 37 minutes
I0109 02:23:20.761837  9387 solver.cpp:291]     Train net output #0: loss = 0.0397841 (* 1 = 0.0397841 loss)
I0109 02:23:20.761842  9387 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0109 02:23:33.520243  9387 solver.cpp:270] Iteration 3400 (3.91913 iter/s, 12.7579s/50 iter), loss = 0.0388417, remaining 0 hours and 36 minutes
I0109 02:23:33.520296  9387 solver.cpp:291]     Train net output #0: loss = 0.0388417 (* 1 = 0.0388417 loss)
I0109 02:23:33.520304  9387 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0109 02:23:46.318893  9387 solver.cpp:270] Iteration 3450 (3.90682 iter/s, 12.7981s/50 iter), loss = 0.0208059, remaining 0 hours and 36 minutes
I0109 02:23:46.318926  9387 solver.cpp:291]     Train net output #0: loss = 0.0208059 (* 1 = 0.0208059 loss)
I0109 02:23:46.318949  9387 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0109 02:23:59.052546  9387 solver.cpp:270] Iteration 3500 (3.92676 iter/s, 12.7331s/50 iter), loss = 0.025068, remaining 0 hours and 35 minutes
I0109 02:23:59.052579  9387 solver.cpp:291]     Train net output #0: loss = 0.025068 (* 1 = 0.025068 loss)
I0109 02:23:59.052587  9387 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0109 02:24:11.820154  9387 solver.cpp:270] Iteration 3550 (3.91632 iter/s, 12.7671s/50 iter), loss = 0.0273041, remaining 0 hours and 35 minutes
I0109 02:24:11.820201  9387 solver.cpp:291]     Train net output #0: loss = 0.0273042 (* 1 = 0.0273042 loss)
I0109 02:24:11.820209  9387 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0109 02:24:24.607386  9387 solver.cpp:270] Iteration 3600 (3.91031 iter/s, 12.7867s/50 iter), loss = 0.0262224, remaining 0 hours and 35 minutes
I0109 02:24:24.607419  9387 solver.cpp:291]     Train net output #0: loss = 0.0262225 (* 1 = 0.0262225 loss)
I0109 02:24:24.607426  9387 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0109 02:24:37.349757  9387 solver.cpp:270] Iteration 3650 (3.92407 iter/s, 12.7419s/50 iter), loss = 0.0292294, remaining 0 hours and 35 minutes
I0109 02:24:37.349787  9387 solver.cpp:291]     Train net output #0: loss = 0.0292294 (* 1 = 0.0292294 loss)
I0109 02:24:37.349794  9387 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0109 02:24:50.129560  9387 solver.cpp:270] Iteration 3700 (3.91258 iter/s, 12.7793s/50 iter), loss = 0.0112949, remaining 0 hours and 35 minutes
I0109 02:24:50.129607  9387 solver.cpp:291]     Train net output #0: loss = 0.011295 (* 1 = 0.011295 loss)
I0109 02:24:50.129616  9387 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0109 02:25:02.895613  9387 solver.cpp:270] Iteration 3750 (3.9168 iter/s, 12.7655s/50 iter), loss = 0.00453636, remaining 0 hours and 34 minutes
I0109 02:25:02.895645  9387 solver.cpp:291]     Train net output #0: loss = 0.00453642 (* 1 = 0.00453642 loss)
I0109 02:25:02.895668  9387 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0109 02:25:15.700577  9387 solver.cpp:270] Iteration 3800 (3.90489 iter/s, 12.8045s/50 iter), loss = 0.0116593, remaining 0 hours and 34 minutes
I0109 02:25:15.700608  9387 solver.cpp:291]     Train net output #0: loss = 0.0116594 (* 1 = 0.0116594 loss)
I0109 02:25:15.700615  9387 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0109 02:25:28.403823  9387 solver.cpp:270] Iteration 3850 (3.93616 iter/s, 12.7027s/50 iter), loss = 0.00612983, remaining 0 hours and 34 minutes
I0109 02:25:28.403867  9387 solver.cpp:291]     Train net output #0: loss = 0.0061299 (* 1 = 0.0061299 loss)
I0109 02:25:28.403890  9387 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0109 02:25:41.147956  9387 solver.cpp:270] Iteration 3900 (3.92353 iter/s, 12.7436s/50 iter), loss = 0.005599, remaining 0 hours and 34 minutes
I0109 02:25:41.147989  9387 solver.cpp:291]     Train net output #0: loss = 0.00559908 (* 1 = 0.00559908 loss)
I0109 02:25:41.147996  9387 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0109 02:25:53.874243  9387 solver.cpp:270] Iteration 3950 (3.92903 iter/s, 12.7258s/50 iter), loss = 0.014997, remaining 0 hours and 34 minutes
I0109 02:25:53.874277  9387 solver.cpp:291]     Train net output #0: loss = 0.0149971 (* 1 = 0.0149971 loss)
I0109 02:25:53.874284  9387 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0109 02:26:06.343801  9387 solver.cpp:424] Iteration 4000, Testing net (#0)
I0109 02:26:07.836011  9387 solver.cpp:523]     Test net output #0: accuracy = 0.94425
I0109 02:26:07.836041  9387 solver.cpp:523]     Test net output #1: loss = 0.172398 (* 1 = 0.172398 loss)
I0109 02:26:07.836046  9387 solver.cpp:523]     Test net output #2: top-1 = 0.94425
I0109 02:26:08.083269  9387 solver.cpp:270] Iteration 4000 (3.51903 iter/s, 14.2085s/50 iter), loss = 0.0140791, remaining 0 hours and 37 minutes
I0109 02:26:08.083297  9387 solver.cpp:291]     Train net output #0: loss = 0.0140792 (* 1 = 0.0140792 loss)
I0109 02:26:08.083303  9387 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0109 02:26:20.809568  9387 solver.cpp:270] Iteration 4050 (3.92903 iter/s, 12.7258s/50 iter), loss = 0.0239854, remaining 0 hours and 33 minutes
I0109 02:26:20.809600  9387 solver.cpp:291]     Train net output #0: loss = 0.0239855 (* 1 = 0.0239855 loss)
I0109 02:26:20.809624  9387 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0109 02:26:33.566074  9387 solver.cpp:270] Iteration 4100 (3.91973 iter/s, 12.756s/50 iter), loss = 0.0183573, remaining 0 hours and 33 minutes
I0109 02:26:33.566107  9387 solver.cpp:291]     Train net output #0: loss = 0.0183574 (* 1 = 0.0183574 loss)
I0109 02:26:33.566130  9387 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0109 02:26:46.317503  9387 solver.cpp:270] Iteration 4150 (3.92129 iter/s, 12.7509s/50 iter), loss = 0.00930009, remaining 0 hours and 33 minutes
I0109 02:26:46.317559  9387 solver.cpp:291]     Train net output #0: loss = 0.00930016 (* 1 = 0.00930016 loss)
I0109 02:26:46.317565  9387 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0109 02:26:59.064798  9387 solver.cpp:270] Iteration 4200 (3.92256 iter/s, 12.7468s/50 iter), loss = 0.0274866, remaining 0 hours and 33 minutes
I0109 02:26:59.064831  9387 solver.cpp:291]     Train net output #0: loss = 0.0274866 (* 1 = 0.0274866 loss)
I0109 02:26:59.064837  9387 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0109 02:27:11.829069  9387 solver.cpp:270] Iteration 4250 (3.91734 iter/s, 12.7638s/50 iter), loss = 0.00829144, remaining 0 hours and 32 minutes
I0109 02:27:11.829102  9387 solver.cpp:291]     Train net output #0: loss = 0.00829151 (* 1 = 0.00829151 loss)
I0109 02:27:11.829109  9387 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0109 02:27:24.573423  9387 solver.cpp:270] Iteration 4300 (3.92346 iter/s, 12.7438s/50 iter), loss = 0.0131662, remaining 0 hours and 32 minutes
I0109 02:27:24.573473  9387 solver.cpp:291]     Train net output #0: loss = 0.0131662 (* 1 = 0.0131662 loss)
I0109 02:27:24.573482  9387 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0109 02:27:37.304505  9387 solver.cpp:270] Iteration 4350 (3.92756 iter/s, 12.7306s/50 iter), loss = 0.00103385, remaining 0 hours and 32 minutes
I0109 02:27:37.304538  9387 solver.cpp:291]     Train net output #0: loss = 0.00103392 (* 1 = 0.00103392 loss)
I0109 02:27:37.304545  9387 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0109 02:27:50.029327  9387 solver.cpp:270] Iteration 4400 (3.92949 iter/s, 12.7243s/50 iter), loss = 0.0150976, remaining 0 hours and 32 minutes
I0109 02:27:50.029359  9387 solver.cpp:291]     Train net output #0: loss = 0.0150976 (* 1 = 0.0150976 loss)
I0109 02:27:50.029381  9387 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0109 02:28:02.818331  9387 solver.cpp:270] Iteration 4450 (3.90976 iter/s, 12.7885s/50 iter), loss = 0.0193343, remaining 0 hours and 31 minutes
I0109 02:28:02.818377  9387 solver.cpp:291]     Train net output #0: loss = 0.0193344 (* 1 = 0.0193344 loss)
I0109 02:28:02.818384  9387 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0109 02:28:15.576855  9387 solver.cpp:270] Iteration 4500 (3.91911 iter/s, 12.758s/50 iter), loss = 0.01196, remaining 0 hours and 31 minutes
I0109 02:28:15.576889  9387 solver.cpp:291]     Train net output #0: loss = 0.0119601 (* 1 = 0.0119601 loss)
I0109 02:28:15.576895  9387 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0109 02:28:28.349819  9387 solver.cpp:270] Iteration 4550 (3.91467 iter/s, 12.7725s/50 iter), loss = 0.00782046, remaining 0 hours and 31 minutes
I0109 02:28:28.349849  9387 solver.cpp:291]     Train net output #0: loss = 0.00782054 (* 1 = 0.00782054 loss)
I0109 02:28:28.349855  9387 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0109 02:28:41.067945  9387 solver.cpp:270] Iteration 4600 (3.93155 iter/s, 12.7176s/50 iter), loss = 0.00352444, remaining 0 hours and 31 minutes
I0109 02:28:41.068001  9387 solver.cpp:291]     Train net output #0: loss = 0.00352451 (* 1 = 0.00352451 loss)
I0109 02:28:41.068008  9387 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0109 02:28:53.808858  9387 solver.cpp:270] Iteration 4650 (3.92453 iter/s, 12.7404s/50 iter), loss = 0.0156122, remaining 0 hours and 31 minutes
I0109 02:28:53.808892  9387 solver.cpp:291]     Train net output #0: loss = 0.0156123 (* 1 = 0.0156123 loss)
I0109 02:28:53.808897  9387 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0109 02:29:06.541415  9387 solver.cpp:270] Iteration 4700 (3.9271 iter/s, 12.732s/50 iter), loss = 0.00564844, remaining 0 hours and 30 minutes
I0109 02:29:06.541447  9387 solver.cpp:291]     Train net output #0: loss = 0.00564852 (* 1 = 0.00564852 loss)
I0109 02:29:06.541455  9387 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0109 02:29:19.264884  9387 solver.cpp:270] Iteration 4750 (3.9299 iter/s, 12.723s/50 iter), loss = 0.0158332, remaining 0 hours and 30 minutes
I0109 02:29:19.264931  9387 solver.cpp:291]     Train net output #0: loss = 0.0158333 (* 1 = 0.0158333 loss)
I0109 02:29:19.264955  9387 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0109 02:29:32.038054  9387 solver.cpp:270] Iteration 4800 (3.91462 iter/s, 12.7726s/50 iter), loss = 0.0103791, remaining 0 hours and 30 minutes
I0109 02:29:32.038086  9387 solver.cpp:291]     Train net output #0: loss = 0.0103792 (* 1 = 0.0103792 loss)
I0109 02:29:32.038110  9387 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0109 02:29:44.786269  9387 solver.cpp:270] Iteration 4850 (3.92227 iter/s, 12.7477s/50 iter), loss = 0.0335194, remaining 0 hours and 30 minutes
I0109 02:29:44.786301  9387 solver.cpp:291]     Train net output #0: loss = 0.0335195 (* 1 = 0.0335195 loss)
I0109 02:29:44.786307  9387 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0109 02:29:57.563495  9387 solver.cpp:270] Iteration 4900 (3.91337 iter/s, 12.7767s/50 iter), loss = 0.0107627, remaining 0 hours and 30 minutes
I0109 02:29:57.563542  9387 solver.cpp:291]     Train net output #0: loss = 0.0107628 (* 1 = 0.0107628 loss)
I0109 02:29:57.563549  9387 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0109 02:30:10.313832  9387 solver.cpp:270] Iteration 4950 (3.92163 iter/s, 12.7498s/50 iter), loss = 0.013013, remaining 0 hours and 29 minutes
I0109 02:30:10.313863  9387 solver.cpp:291]     Train net output #0: loss = 0.0130131 (* 1 = 0.0130131 loss)
I0109 02:30:10.313870  9387 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0109 02:30:22.808744  9387 solver.cpp:424] Iteration 5000, Testing net (#0)
I0109 02:30:24.299633  9387 solver.cpp:523]     Test net output #0: accuracy = 0.943
I0109 02:30:24.299664  9387 solver.cpp:523]     Test net output #1: loss = 0.177602 (* 1 = 0.177602 loss)
I0109 02:30:24.299670  9387 solver.cpp:523]     Test net output #2: top-1 = 0.943
I0109 02:30:24.542270  9387 solver.cpp:270] Iteration 5000 (3.51423 iter/s, 14.2279s/50 iter), loss = 0.0119092, remaining 0 hours and 33 minutes
I0109 02:30:24.542296  9387 solver.cpp:291]     Train net output #0: loss = 0.0119092 (* 1 = 0.0119092 loss)
I0109 02:30:24.542304  9387 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0109 02:30:37.330926  9387 solver.cpp:270] Iteration 5050 (3.90987 iter/s, 12.7882s/50 iter), loss = 0.00902106, remaining 0 hours and 29 minutes
I0109 02:30:37.330973  9387 solver.cpp:291]     Train net output #0: loss = 0.00902113 (* 1 = 0.00902113 loss)
I0109 02:30:37.330981  9387 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0109 02:30:50.034368  9387 solver.cpp:270] Iteration 5100 (3.9361 iter/s, 12.7029s/50 iter), loss = 0.00220603, remaining 0 hours and 29 minutes
I0109 02:30:50.034401  9387 solver.cpp:291]     Train net output #0: loss = 0.00220611 (* 1 = 0.00220611 loss)
I0109 02:30:50.034409  9387 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0109 02:31:02.850889  9387 solver.cpp:270] Iteration 5150 (3.90137 iter/s, 12.816s/50 iter), loss = 0.00407563, remaining 0 hours and 29 minutes
I0109 02:31:02.850924  9387 solver.cpp:291]     Train net output #0: loss = 0.00407571 (* 1 = 0.00407571 loss)
I0109 02:31:02.850930  9387 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0109 02:31:15.584738  9387 solver.cpp:270] Iteration 5200 (3.9267 iter/s, 12.7333s/50 iter), loss = 0.00300854, remaining 0 hours and 28 minutes
I0109 02:31:15.584791  9387 solver.cpp:291]     Train net output #0: loss = 0.00300861 (* 1 = 0.00300861 loss)
I0109 02:31:15.584800  9387 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0109 02:31:28.331976  9387 solver.cpp:270] Iteration 5250 (3.92258 iter/s, 12.7467s/50 iter), loss = 0.00916077, remaining 0 hours and 28 minutes
I0109 02:31:28.332008  9387 solver.cpp:291]     Train net output #0: loss = 0.00916084 (* 1 = 0.00916084 loss)
I0109 02:31:28.332032  9387 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0109 02:31:41.071039  9387 solver.cpp:270] Iteration 5300 (3.92509 iter/s, 12.7386s/50 iter), loss = 0.017249, remaining 0 hours and 28 minutes
I0109 02:31:41.071074  9387 solver.cpp:291]     Train net output #0: loss = 0.0172491 (* 1 = 0.0172491 loss)
I0109 02:31:41.071097  9387 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0109 02:31:53.821146  9387 solver.cpp:270] Iteration 5350 (3.92169 iter/s, 12.7496s/50 iter), loss = 0.00276145, remaining 0 hours and 28 minutes
I0109 02:31:53.821190  9387 solver.cpp:291]     Train net output #0: loss = 0.00276152 (* 1 = 0.00276152 loss)
I0109 02:31:53.821213  9387 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0109 02:32:06.573014  9387 solver.cpp:270] Iteration 5400 (3.92115 iter/s, 12.7513s/50 iter), loss = 0.00630734, remaining 0 hours and 28 minutes
I0109 02:32:06.573045  9387 solver.cpp:291]     Train net output #0: loss = 0.00630741 (* 1 = 0.00630741 loss)
I0109 02:32:06.573050  9387 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0109 02:32:19.351529  9387 solver.cpp:270] Iteration 5450 (3.91297 iter/s, 12.778s/50 iter), loss = 0.00399268, remaining 0 hours and 27 minutes
I0109 02:32:19.351562  9387 solver.cpp:291]     Train net output #0: loss = 0.00399275 (* 1 = 0.00399275 loss)
I0109 02:32:19.351583  9387 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0109 02:32:32.078613  9387 solver.cpp:270] Iteration 5500 (3.92879 iter/s, 12.7266s/50 iter), loss = 0.000812221, remaining 0 hours and 27 minutes
I0109 02:32:32.078662  9387 solver.cpp:291]     Train net output #0: loss = 0.000812296 (* 1 = 0.000812296 loss)
I0109 02:32:32.078670  9387 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0109 02:32:44.842182  9387 solver.cpp:270] Iteration 5550 (3.91756 iter/s, 12.763s/50 iter), loss = 0.00484916, remaining 0 hours and 27 minutes
I0109 02:32:44.842214  9387 solver.cpp:291]     Train net output #0: loss = 0.00484924 (* 1 = 0.00484924 loss)
I0109 02:32:44.842221  9387 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0109 02:32:57.607252  9387 solver.cpp:270] Iteration 5600 (3.9171 iter/s, 12.7646s/50 iter), loss = 0.00132491, remaining 0 hours and 27 minutes
I0109 02:32:57.607285  9387 solver.cpp:291]     Train net output #0: loss = 0.00132498 (* 1 = 0.00132498 loss)
I0109 02:32:57.607308  9387 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0109 02:33:10.377090  9387 solver.cpp:270] Iteration 5650 (3.91563 iter/s, 12.7693s/50 iter), loss = 0.00199044, remaining 0 hours and 26 minutes
I0109 02:33:10.377153  9387 solver.cpp:291]     Train net output #0: loss = 0.00199052 (* 1 = 0.00199052 loss)
I0109 02:33:10.377161  9387 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0109 02:33:23.104687  9387 solver.cpp:270] Iteration 5700 (3.92863 iter/s, 12.7271s/50 iter), loss = 0.00290581, remaining 0 hours and 26 minutes
I0109 02:33:23.104718  9387 solver.cpp:291]     Train net output #0: loss = 0.00290588 (* 1 = 0.00290588 loss)
I0109 02:33:23.104725  9387 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0109 02:33:35.889358  9387 solver.cpp:270] Iteration 5750 (3.91109 iter/s, 12.7842s/50 iter), loss = 0.00425287, remaining 0 hours and 26 minutes
I0109 02:33:35.889390  9387 solver.cpp:291]     Train net output #0: loss = 0.00425294 (* 1 = 0.00425294 loss)
I0109 02:33:35.889397  9387 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0109 02:33:48.652056  9387 solver.cpp:270] Iteration 5800 (3.91782 iter/s, 12.7622s/50 iter), loss = 0.000132759, remaining 0 hours and 26 minutes
I0109 02:33:48.652112  9387 solver.cpp:291]     Train net output #0: loss = 0.000132834 (* 1 = 0.000132834 loss)
I0109 02:33:48.652118  9387 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0109 02:34:01.446254  9387 solver.cpp:270] Iteration 5850 (3.90818 iter/s, 12.7937s/50 iter), loss = 0.0133811, remaining 0 hours and 26 minutes
I0109 02:34:01.446286  9387 solver.cpp:291]     Train net output #0: loss = 0.0133811 (* 1 = 0.0133811 loss)
I0109 02:34:01.446293  9387 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0109 02:34:14.188180  9387 solver.cpp:270] Iteration 5900 (3.92421 iter/s, 12.7414s/50 iter), loss = 0.0121859, remaining 0 hours and 25 minutes
I0109 02:34:14.188215  9387 solver.cpp:291]     Train net output #0: loss = 0.012186 (* 1 = 0.012186 loss)
I0109 02:34:14.188221  9387 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0109 02:34:26.955237  9387 solver.cpp:270] Iteration 5950 (3.91649 iter/s, 12.7665s/50 iter), loss = 0.00176997, remaining 0 hours and 25 minutes
I0109 02:34:26.955286  9387 solver.cpp:291]     Train net output #0: loss = 0.00177005 (* 1 = 0.00177005 loss)
I0109 02:34:26.955308  9387 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0109 02:34:39.437889  9387 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.7/snapshots/_iter_6000.caffemodel
I0109 02:34:41.973970  9387 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.7/snapshots/_iter_6000.solverstate
I0109 02:34:42.200697  9387 solver.cpp:424] Iteration 6000, Testing net (#0)
I0109 02:34:43.659586  9387 solver.cpp:523]     Test net output #0: accuracy = 0.95075
I0109 02:34:43.659615  9387 solver.cpp:523]     Test net output #1: loss = 0.207304 (* 1 = 0.207304 loss)
I0109 02:34:43.659619  9387 solver.cpp:523]     Test net output #2: top-1 = 0.95075
I0109 02:34:43.899416  9387 solver.cpp:270] Iteration 6000 (2.95098 iter/s, 16.9435s/50 iter), loss = 0.000901039, remaining 0 hours and 33 minutes
I0109 02:34:43.899443  9387 solver.cpp:291]     Train net output #0: loss = 0.000901112 (* 1 = 0.000901112 loss)
I0109 02:34:43.899451  9387 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0109 02:34:56.529546  9387 solver.cpp:270] Iteration 6050 (3.95894 iter/s, 12.6296s/50 iter), loss = 0.000676003, remaining 0 hours and 25 minutes
I0109 02:34:56.529577  9387 solver.cpp:291]     Train net output #0: loss = 0.000676078 (* 1 = 0.000676078 loss)
I0109 02:34:56.529584  9387 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0109 02:35:09.192153  9387 solver.cpp:270] Iteration 6100 (3.94879 iter/s, 12.6621s/50 iter), loss = 0.00110421, remaining 0 hours and 24 minutes
I0109 02:35:09.192203  9387 solver.cpp:291]     Train net output #0: loss = 0.00110428 (* 1 = 0.00110428 loss)
I0109 02:35:09.192227  9387 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0109 02:35:21.902616  9387 solver.cpp:270] Iteration 6150 (3.93393 iter/s, 12.7099s/50 iter), loss = 0.00169134, remaining 0 hours and 24 minutes
I0109 02:35:21.902649  9387 solver.cpp:291]     Train net output #0: loss = 0.00169141 (* 1 = 0.00169141 loss)
I0109 02:35:21.902657  9387 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0109 02:35:34.676755  9387 solver.cpp:270] Iteration 6200 (3.91431 iter/s, 12.7736s/50 iter), loss = 0.001599, remaining 0 hours and 24 minutes
I0109 02:35:34.676787  9387 solver.cpp:291]     Train net output #0: loss = 0.00159908 (* 1 = 0.00159908 loss)
I0109 02:35:34.676795  9387 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0109 02:35:47.431555  9387 solver.cpp:270] Iteration 6250 (3.92025 iter/s, 12.7543s/50 iter), loss = 0.000387063, remaining 0 hours and 24 minutes
I0109 02:35:47.431600  9387 solver.cpp:291]     Train net output #0: loss = 0.000387131 (* 1 = 0.000387131 loss)
I0109 02:35:47.431607  9387 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0109 02:36:00.205878  9387 solver.cpp:270] Iteration 6300 (3.91426 iter/s, 12.7738s/50 iter), loss = 0.000750013, remaining 0 hours and 24 minutes
I0109 02:36:00.205909  9387 solver.cpp:291]     Train net output #0: loss = 0.00075008 (* 1 = 0.00075008 loss)
I0109 02:36:00.205915  9387 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0109 02:36:12.973759  9387 solver.cpp:270] Iteration 6350 (3.91623 iter/s, 12.7674s/50 iter), loss = 0.00272136, remaining 0 hours and 24 minutes
I0109 02:36:12.973793  9387 solver.cpp:291]     Train net output #0: loss = 0.00272142 (* 1 = 0.00272142 loss)
I0109 02:36:12.973799  9387 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0109 02:36:25.780987  9387 solver.cpp:270] Iteration 6400 (3.9042 iter/s, 12.8067s/50 iter), loss = 0.00507629, remaining 0 hours and 23 minutes
I0109 02:36:25.781039  9387 solver.cpp:291]     Train net output #0: loss = 0.00507635 (* 1 = 0.00507635 loss)
I0109 02:36:25.781046  9387 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0109 02:36:38.586730  9387 solver.cpp:270] Iteration 6450 (3.90466 iter/s, 12.8052s/50 iter), loss = 0.00143319, remaining 0 hours and 23 minutes
I0109 02:36:38.586762  9387 solver.cpp:291]     Train net output #0: loss = 0.00143325 (* 1 = 0.00143325 loss)
I0109 02:36:38.586786  9387 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0109 02:36:51.315244  9387 solver.cpp:270] Iteration 6500 (3.92834 iter/s, 12.728s/50 iter), loss = 0.00328792, remaining 0 hours and 23 minutes
I0109 02:36:51.315277  9387 solver.cpp:291]     Train net output #0: loss = 0.00328799 (* 1 = 0.00328799 loss)
I0109 02:36:51.315284  9387 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0109 02:37:04.072350  9387 solver.cpp:270] Iteration 6550 (3.91954 iter/s, 12.7566s/50 iter), loss = 0.00336712, remaining 0 hours and 22 minutes
I0109 02:37:04.072399  9387 solver.cpp:291]     Train net output #0: loss = 0.00336718 (* 1 = 0.00336718 loss)
I0109 02:37:04.072407  9387 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0109 02:37:16.863993  9387 solver.cpp:270] Iteration 6600 (3.90896 iter/s, 12.7911s/50 iter), loss = 0.00303916, remaining 0 hours and 23 minutes
I0109 02:37:16.864027  9387 solver.cpp:291]     Train net output #0: loss = 0.00303923 (* 1 = 0.00303923 loss)
I0109 02:37:16.864033  9387 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0109 02:37:29.648907  9387 solver.cpp:270] Iteration 6650 (3.91102 iter/s, 12.7844s/50 iter), loss = 0.00045693, remaining 0 hours and 22 minutes
I0109 02:37:29.648939  9387 solver.cpp:291]     Train net output #0: loss = 0.000457003 (* 1 = 0.000457003 loss)
I0109 02:37:29.648947  9387 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0109 02:37:42.418648  9387 solver.cpp:270] Iteration 6700 (3.91566 iter/s, 12.7692s/50 iter), loss = 0.00218607, remaining 0 hours and 22 minutes
I0109 02:37:42.418694  9387 solver.cpp:291]     Train net output #0: loss = 0.00218614 (* 1 = 0.00218614 loss)
I0109 02:37:42.418702  9387 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0109 02:37:55.195614  9387 solver.cpp:270] Iteration 6750 (3.91345 iter/s, 12.7764s/50 iter), loss = 0.00141648, remaining 0 hours and 22 minutes
I0109 02:37:55.195649  9387 solver.cpp:291]     Train net output #0: loss = 0.00141655 (* 1 = 0.00141655 loss)
I0109 02:37:55.195672  9387 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0109 02:38:07.974812  9387 solver.cpp:270] Iteration 6800 (3.91277 iter/s, 12.7787s/50 iter), loss = 0.00656753, remaining 0 hours and 21 minutes
I0109 02:38:07.974843  9387 solver.cpp:291]     Train net output #0: loss = 0.0065676 (* 1 = 0.0065676 loss)
I0109 02:38:07.974866  9387 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0109 02:38:20.738831  9387 solver.cpp:270] Iteration 6850 (3.91742 iter/s, 12.7635s/50 iter), loss = 0.000281189, remaining 0 hours and 21 minutes
I0109 02:38:20.738880  9387 solver.cpp:291]     Train net output #0: loss = 0.000281257 (* 1 = 0.000281257 loss)
I0109 02:38:20.738888  9387 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0109 02:38:33.515583  9387 solver.cpp:270] Iteration 6900 (3.91352 iter/s, 12.7762s/50 iter), loss = 0.0118739, remaining 0 hours and 21 minutes
I0109 02:38:33.515615  9387 solver.cpp:291]     Train net output #0: loss = 0.011874 (* 1 = 0.011874 loss)
I0109 02:38:33.515640  9387 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0109 02:38:46.294580  9387 solver.cpp:270] Iteration 6950 (3.91283 iter/s, 12.7785s/50 iter), loss = 0.00353916, remaining 0 hours and 21 minutes
I0109 02:38:46.294613  9387 solver.cpp:291]     Train net output #0: loss = 0.00353923 (* 1 = 0.00353923 loss)
I0109 02:38:46.294620  9387 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0109 02:38:58.819900  9387 solver.cpp:424] Iteration 7000, Testing net (#0)
I0109 02:39:00.308884  9387 solver.cpp:523]     Test net output #0: accuracy = 0.95325
I0109 02:39:00.308912  9387 solver.cpp:523]     Test net output #1: loss = 0.243548 (* 1 = 0.243548 loss)
I0109 02:39:00.308917  9387 solver.cpp:523]     Test net output #2: top-1 = 0.95325
I0109 02:39:00.557444  9387 solver.cpp:270] Iteration 7000 (3.50575 iter/s, 14.2623s/50 iter), loss = 0.0112415, remaining 0 hours and 23 minutes
I0109 02:39:00.557474  9387 solver.cpp:291]     Train net output #0: loss = 0.0112415 (* 1 = 0.0112415 loss)
I0109 02:39:00.557482  9387 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0109 02:39:13.313143  9387 solver.cpp:270] Iteration 7050 (3.91997 iter/s, 12.7552s/50 iter), loss = 0.000613458, remaining 0 hours and 20 minutes
I0109 02:39:13.313174  9387 solver.cpp:291]     Train net output #0: loss = 0.000613531 (* 1 = 0.000613531 loss)
I0109 02:39:13.313181  9387 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0109 02:39:26.101565  9387 solver.cpp:270] Iteration 7100 (3.90994 iter/s, 12.7879s/50 iter), loss = 0.00164362, remaining 0 hours and 20 minutes
I0109 02:39:26.101598  9387 solver.cpp:291]     Train net output #0: loss = 0.00164369 (* 1 = 0.00164369 loss)
I0109 02:39:26.101605  9387 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0109 02:39:38.874876  9387 solver.cpp:270] Iteration 7150 (3.91457 iter/s, 12.7728s/50 iter), loss = 0.00525391, remaining 0 hours and 20 minutes
I0109 02:39:38.874922  9387 solver.cpp:291]     Train net output #0: loss = 0.00525398 (* 1 = 0.00525398 loss)
I0109 02:39:38.874944  9387 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0109 02:39:51.633271  9387 solver.cpp:270] Iteration 7200 (3.91915 iter/s, 12.7579s/50 iter), loss = 0.00653404, remaining 0 hours and 20 minutes
I0109 02:39:51.633304  9387 solver.cpp:291]     Train net output #0: loss = 0.00653411 (* 1 = 0.00653411 loss)
I0109 02:39:51.633311  9387 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0109 02:40:04.399618  9387 solver.cpp:270] Iteration 7250 (3.9167 iter/s, 12.7658s/50 iter), loss = 0.0205183, remaining 0 hours and 20 minutes
I0109 02:40:04.399650  9387 solver.cpp:291]     Train net output #0: loss = 0.0205184 (* 1 = 0.0205184 loss)
I0109 02:40:04.399657  9387 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0109 02:40:17.214215  9387 solver.cpp:270] Iteration 7300 (3.90196 iter/s, 12.8141s/50 iter), loss = 0.00559142, remaining 0 hours and 19 minutes
I0109 02:40:17.214260  9387 solver.cpp:291]     Train net output #0: loss = 0.00559149 (* 1 = 0.00559149 loss)
I0109 02:40:17.214283  9387 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0109 02:40:29.961794  9387 solver.cpp:270] Iteration 7350 (3.92247 iter/s, 12.7471s/50 iter), loss = 0.0287737, remaining 0 hours and 19 minutes
I0109 02:40:29.961827  9387 solver.cpp:291]     Train net output #0: loss = 0.0287738 (* 1 = 0.0287738 loss)
I0109 02:40:29.961835  9387 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0109 02:40:42.716964  9387 solver.cpp:270] Iteration 7400 (3.92014 iter/s, 12.7547s/50 iter), loss = 0.00792817, remaining 0 hours and 19 minutes
I0109 02:40:42.716996  9387 solver.cpp:291]     Train net output #0: loss = 0.00792824 (* 1 = 0.00792824 loss)
I0109 02:40:42.717020  9387 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0109 02:40:55.493079  9387 solver.cpp:270] Iteration 7450 (3.91371 iter/s, 12.7756s/50 iter), loss = 0.0117536, remaining 0 hours and 19 minutes
I0109 02:40:55.493130  9387 solver.cpp:291]     Train net output #0: loss = 0.0117537 (* 1 = 0.0117537 loss)
I0109 02:40:55.493153  9387 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0109 02:41:08.264379  9387 solver.cpp:270] Iteration 7500 (3.91519 iter/s, 12.7708s/50 iter), loss = 0.0125233, remaining 0 hours and 19 minutes
I0109 02:41:08.264411  9387 solver.cpp:291]     Train net output #0: loss = 0.0125234 (* 1 = 0.0125234 loss)
I0109 02:41:08.264436  9387 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0109 02:41:21.026648  9387 solver.cpp:270] Iteration 7550 (3.91795 iter/s, 12.7618s/50 iter), loss = 0.00401916, remaining 0 hours and 18 minutes
I0109 02:41:21.026680  9387 solver.cpp:291]     Train net output #0: loss = 0.00401923 (* 1 = 0.00401923 loss)
I0109 02:41:21.026705  9387 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0109 02:41:33.829422  9387 solver.cpp:270] Iteration 7600 (3.90556 iter/s, 12.8023s/50 iter), loss = 0.00131913, remaining 0 hours and 18 minutes
I0109 02:41:33.829468  9387 solver.cpp:291]     Train net output #0: loss = 0.0013192 (* 1 = 0.0013192 loss)
I0109 02:41:33.829490  9387 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0109 02:41:46.601473  9387 solver.cpp:270] Iteration 7650 (3.91496 iter/s, 12.7715s/50 iter), loss = 0.000988668, remaining 0 hours and 18 minutes
I0109 02:41:46.601507  9387 solver.cpp:291]     Train net output #0: loss = 0.000988741 (* 1 = 0.000988741 loss)
I0109 02:41:46.601514  9387 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0109 02:41:59.408368  9387 solver.cpp:270] Iteration 7700 (3.9043 iter/s, 12.8064s/50 iter), loss = 0.00122525, remaining 0 hours and 18 minutes
I0109 02:41:59.408401  9387 solver.cpp:291]     Train net output #0: loss = 0.00122532 (* 1 = 0.00122532 loss)
I0109 02:41:59.408407  9387 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0109 02:42:12.213886  9387 solver.cpp:270] Iteration 7750 (3.90472 iter/s, 12.805s/50 iter), loss = 0.00821088, remaining 0 hours and 17 minutes
I0109 02:42:12.213932  9387 solver.cpp:291]     Train net output #0: loss = 0.00821096 (* 1 = 0.00821096 loss)
I0109 02:42:12.213938  9387 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0109 02:42:24.948935  9387 solver.cpp:270] Iteration 7800 (3.92633 iter/s, 12.7345s/50 iter), loss = 0.00257424, remaining 0 hours and 17 minutes
I0109 02:42:24.948968  9387 solver.cpp:291]     Train net output #0: loss = 0.00257431 (* 1 = 0.00257431 loss)
I0109 02:42:24.948976  9387 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0109 02:42:37.712230  9387 solver.cpp:270] Iteration 7850 (3.91764 iter/s, 12.7628s/50 iter), loss = 0.00162728, remaining 0 hours and 17 minutes
I0109 02:42:37.712262  9387 solver.cpp:291]     Train net output #0: loss = 0.00162736 (* 1 = 0.00162736 loss)
I0109 02:42:37.712270  9387 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0109 02:42:50.507624  9387 solver.cpp:270] Iteration 7900 (3.90781 iter/s, 12.7949s/50 iter), loss = 0.0157988, remaining 0 hours and 17 minutes
I0109 02:42:50.507670  9387 solver.cpp:291]     Train net output #0: loss = 0.0157988 (* 1 = 0.0157988 loss)
I0109 02:42:50.507678  9387 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0109 02:43:03.296394  9387 solver.cpp:270] Iteration 7950 (3.90984 iter/s, 12.7882s/50 iter), loss = 0.000975349, remaining 0 hours and 17 minutes
I0109 02:43:03.296427  9387 solver.cpp:291]     Train net output #0: loss = 0.000975432 (* 1 = 0.000975432 loss)
I0109 02:43:03.296435  9387 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0109 02:43:15.828675  9387 solver.cpp:424] Iteration 8000, Testing net (#0)
I0109 02:43:17.316030  9387 solver.cpp:523]     Test net output #0: accuracy = 0.9525
I0109 02:43:17.316057  9387 solver.cpp:523]     Test net output #1: loss = 0.268955 (* 1 = 0.268955 loss)
I0109 02:43:17.316062  9387 solver.cpp:523]     Test net output #2: top-1 = 0.9525
I0109 02:43:17.563819  9387 solver.cpp:270] Iteration 8000 (3.50462 iter/s, 14.2669s/50 iter), loss = 0.000683291, remaining 0 hours and 18 minutes
I0109 02:43:17.563845  9387 solver.cpp:291]     Train net output #0: loss = 0.000683375 (* 1 = 0.000683375 loss)
I0109 02:43:17.563869  9387 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0109 02:43:30.332237  9387 solver.cpp:270] Iteration 8050 (3.91607 iter/s, 12.7679s/50 iter), loss = 0.00534458, remaining 0 hours and 16 minutes
I0109 02:43:30.332288  9387 solver.cpp:291]     Train net output #0: loss = 0.00534467 (* 1 = 0.00534467 loss)
I0109 02:43:30.332296  9387 sgd_solver.cpp:106] Iteration 8050, lr = 1e-06
I0109 02:43:43.115675  9387 solver.cpp:270] Iteration 8100 (3.91147 iter/s, 12.7829s/50 iter), loss = 0.00780985, remaining 0 hours and 16 minutes
I0109 02:43:43.115706  9387 solver.cpp:291]     Train net output #0: loss = 0.00780994 (* 1 = 0.00780994 loss)
I0109 02:43:43.115731  9387 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0109 02:43:55.872540  9387 solver.cpp:270] Iteration 8150 (3.91961 iter/s, 12.7564s/50 iter), loss = 0.00329892, remaining 0 hours and 16 minutes
I0109 02:43:55.872570  9387 solver.cpp:291]     Train net output #0: loss = 0.00329901 (* 1 = 0.00329901 loss)
I0109 02:43:55.872594  9387 sgd_solver.cpp:106] Iteration 8150, lr = 1e-06
I0109 02:44:08.657405  9387 solver.cpp:270] Iteration 8200 (3.91103 iter/s, 12.7844s/50 iter), loss = 0.00148414, remaining 0 hours and 16 minutes
I0109 02:44:08.657450  9387 solver.cpp:291]     Train net output #0: loss = 0.00148423 (* 1 = 0.00148423 loss)
I0109 02:44:08.657459  9387 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0109 02:44:21.443351  9387 solver.cpp:270] Iteration 8250 (3.9107 iter/s, 12.7854s/50 iter), loss = 0.000486782, remaining 0 hours and 15 minutes
I0109 02:44:21.443382  9387 solver.cpp:291]     Train net output #0: loss = 0.000486867 (* 1 = 0.000486867 loss)
I0109 02:44:21.443405  9387 sgd_solver.cpp:106] Iteration 8250, lr = 1e-06
I0109 02:44:34.191862  9387 solver.cpp:270] Iteration 8300 (3.92218 iter/s, 12.748s/50 iter), loss = 0.0020211, remaining 0 hours and 15 minutes
I0109 02:44:34.191893  9387 solver.cpp:291]     Train net output #0: loss = 0.00202119 (* 1 = 0.00202119 loss)
I0109 02:44:34.191901  9387 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0109 02:44:46.988554  9387 solver.cpp:270] Iteration 8350 (3.90742 iter/s, 12.7962s/50 iter), loss = 0.00364549, remaining 0 hours and 15 minutes
I0109 02:44:46.988600  9387 solver.cpp:291]     Train net output #0: loss = 0.00364558 (* 1 = 0.00364558 loss)
I0109 02:44:46.988608  9387 sgd_solver.cpp:106] Iteration 8350, lr = 1e-06
I0109 02:44:59.769465  9387 solver.cpp:270] Iteration 8400 (3.91224 iter/s, 12.7804s/50 iter), loss = 0.00447132, remaining 0 hours and 15 minutes
I0109 02:44:59.769500  9387 solver.cpp:291]     Train net output #0: loss = 0.00447141 (* 1 = 0.00447141 loss)
I0109 02:44:59.769506  9387 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0109 02:45:12.523742  9387 solver.cpp:270] Iteration 8450 (3.92041 iter/s, 12.7538s/50 iter), loss = 0.00142104, remaining 0 hours and 15 minutes
I0109 02:45:12.523775  9387 solver.cpp:291]     Train net output #0: loss = 0.00142113 (* 1 = 0.00142113 loss)
I0109 02:45:12.523782  9387 sgd_solver.cpp:106] Iteration 8450, lr = 1e-06
I0109 02:45:25.349236  9387 solver.cpp:270] Iteration 8500 (3.89864 iter/s, 12.825s/50 iter), loss = 0.00517418, remaining 0 hours and 14 minutes
I0109 02:45:25.349282  9387 solver.cpp:291]     Train net output #0: loss = 0.00517427 (* 1 = 0.00517427 loss)
I0109 02:45:25.349289  9387 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0109 02:45:38.175654  9387 solver.cpp:270] Iteration 8550 (3.89836 iter/s, 12.8259s/50 iter), loss = 0.00915452, remaining 0 hours and 14 minutes
I0109 02:45:38.175688  9387 solver.cpp:291]     Train net output #0: loss = 0.00915461 (* 1 = 0.00915461 loss)
I0109 02:45:38.175710  9387 sgd_solver.cpp:106] Iteration 8550, lr = 1e-06
I0109 02:45:50.922989  9387 solver.cpp:270] Iteration 8600 (3.92254 iter/s, 12.7468s/50 iter), loss = 0.00216352, remaining 0 hours and 14 minutes
I0109 02:45:50.923020  9387 solver.cpp:291]     Train net output #0: loss = 0.00216361 (* 1 = 0.00216361 loss)
I0109 02:45:50.923027  9387 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0109 02:46:03.706709  9387 solver.cpp:270] Iteration 8650 (3.91138 iter/s, 12.7832s/50 iter), loss = 0.00625643, remaining 0 hours and 14 minutes
I0109 02:46:03.706763  9387 solver.cpp:291]     Train net output #0: loss = 0.00625652 (* 1 = 0.00625652 loss)
I0109 02:46:03.706770  9387 sgd_solver.cpp:106] Iteration 8650, lr = 1e-06
I0109 02:46:16.490988  9387 solver.cpp:270] Iteration 8700 (3.91122 iter/s, 12.7837s/50 iter), loss = 0.00383467, remaining 0 hours and 14 minutes
I0109 02:46:16.491017  9387 solver.cpp:291]     Train net output #0: loss = 0.00383476 (* 1 = 0.00383476 loss)
I0109 02:46:16.491040  9387 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0109 02:46:29.283576  9387 solver.cpp:270] Iteration 8750 (3.90867 iter/s, 12.7921s/50 iter), loss = 0.000733393, remaining 0 hours and 13 minutes
I0109 02:46:29.283608  9387 solver.cpp:291]     Train net output #0: loss = 0.000733484 (* 1 = 0.000733484 loss)
I0109 02:46:29.283617  9387 sgd_solver.cpp:106] Iteration 8750, lr = 1e-06
I0109 02:46:42.051069  9387 solver.cpp:270] Iteration 8800 (3.91635 iter/s, 12.767s/50 iter), loss = 0.0014446, remaining 0 hours and 13 minutes
I0109 02:46:42.051115  9387 solver.cpp:291]     Train net output #0: loss = 0.00144468 (* 1 = 0.00144468 loss)
I0109 02:46:42.051137  9387 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0109 02:46:54.840204  9387 solver.cpp:270] Iteration 8850 (3.90973 iter/s, 12.7886s/50 iter), loss = 0.000459582, remaining 0 hours and 13 minutes
I0109 02:46:54.840238  9387 solver.cpp:291]     Train net output #0: loss = 0.000459666 (* 1 = 0.000459666 loss)
I0109 02:46:54.840245  9387 sgd_solver.cpp:106] Iteration 8850, lr = 1e-06
I0109 02:47:07.656229  9387 solver.cpp:270] Iteration 8900 (3.90152 iter/s, 12.8155s/50 iter), loss = 0.0126639, remaining 0 hours and 13 minutes
I0109 02:47:07.656265  9387 solver.cpp:291]     Train net output #0: loss = 0.0126639 (* 1 = 0.0126639 loss)
I0109 02:47:07.656272  9387 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0109 02:47:20.439030  9387 solver.cpp:270] Iteration 8950 (3.91166 iter/s, 12.7823s/50 iter), loss = 0.00392856, remaining 0 hours and 12 minutes
I0109 02:47:20.439075  9387 solver.cpp:291]     Train net output #0: loss = 0.00392864 (* 1 = 0.00392864 loss)
I0109 02:47:20.439083  9387 sgd_solver.cpp:106] Iteration 8950, lr = 1e-06
I0109 02:47:32.977392  9387 solver.cpp:424] Iteration 9000, Testing net (#0)
I0109 02:47:34.488042  9387 solver.cpp:523]     Test net output #0: accuracy = 0.953
I0109 02:47:34.488071  9387 solver.cpp:523]     Test net output #1: loss = 0.290438 (* 1 = 0.290438 loss)
I0109 02:47:34.488075  9387 solver.cpp:523]     Test net output #2: top-1 = 0.953
I0109 02:47:34.732133  9387 solver.cpp:270] Iteration 9000 (3.49833 iter/s, 14.2925s/50 iter), loss = 0.000814479, remaining 0 hours and 14 minutes
I0109 02:47:34.732159  9387 solver.cpp:291]     Train net output #0: loss = 0.000814557 (* 1 = 0.000814557 loss)
I0109 02:47:34.732183  9387 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0109 02:47:47.529026  9387 solver.cpp:270] Iteration 9050 (3.90735 iter/s, 12.7964s/50 iter), loss = 0.000363224, remaining 0 hours and 12 minutes
I0109 02:47:47.529058  9387 solver.cpp:291]     Train net output #0: loss = 0.000363299 (* 1 = 0.000363299 loss)
I0109 02:47:47.529081  9387 sgd_solver.cpp:106] Iteration 9050, lr = 1e-06
I0109 02:48:00.276576  9387 solver.cpp:270] Iteration 9100 (3.92248 iter/s, 12.747s/50 iter), loss = 0.00927401, remaining 0 hours and 12 minutes
I0109 02:48:00.276623  9387 solver.cpp:291]     Train net output #0: loss = 0.00927408 (* 1 = 0.00927408 loss)
I0109 02:48:00.276631  9387 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0109 02:48:13.065723  9387 solver.cpp:270] Iteration 9150 (3.90973 iter/s, 12.7886s/50 iter), loss = 0.000430423, remaining 0 hours and 12 minutes
I0109 02:48:13.065755  9387 solver.cpp:291]     Train net output #0: loss = 0.000430495 (* 1 = 0.000430495 loss)
I0109 02:48:13.065762  9387 sgd_solver.cpp:106] Iteration 9150, lr = 1e-06
I0109 02:48:25.841061  9387 solver.cpp:270] Iteration 9200 (3.91395 iter/s, 12.7748s/50 iter), loss = 0.00438153, remaining 0 hours and 11 minutes
I0109 02:48:25.841095  9387 solver.cpp:291]     Train net output #0: loss = 0.0043816 (* 1 = 0.0043816 loss)
I0109 02:48:25.841102  9387 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0109 02:48:38.638310  9387 solver.cpp:270] Iteration 9250 (3.90725 iter/s, 12.7967s/50 iter), loss = 0.00139558, remaining 0 hours and 11 minutes
I0109 02:48:38.638355  9387 solver.cpp:291]     Train net output #0: loss = 0.00139565 (* 1 = 0.00139565 loss)
I0109 02:48:38.638378  9387 sgd_solver.cpp:106] Iteration 9250, lr = 1e-06
I0109 02:48:51.440798  9387 solver.cpp:270] Iteration 9300 (3.90565 iter/s, 12.802s/50 iter), loss = 0.00763577, remaining 0 hours and 11 minutes
I0109 02:48:51.440829  9387 solver.cpp:291]     Train net output #0: loss = 0.00763584 (* 1 = 0.00763584 loss)
I0109 02:48:51.440836  9387 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0109 02:49:04.204936  9387 solver.cpp:270] Iteration 9350 (3.91738 iter/s, 12.7636s/50 iter), loss = 0.000678025, remaining 0 hours and 11 minutes
I0109 02:49:04.204968  9387 solver.cpp:291]     Train net output #0: loss = 0.000678098 (* 1 = 0.000678098 loss)
I0109 02:49:04.204975  9387 sgd_solver.cpp:106] Iteration 9350, lr = 1e-06
I0109 02:49:16.914706  9387 solver.cpp:270] Iteration 9400 (3.93414 iter/s, 12.7093s/50 iter), loss = 0.00112946, remaining 0 hours and 10 minutes
I0109 02:49:16.914750  9387 solver.cpp:291]     Train net output #0: loss = 0.00112953 (* 1 = 0.00112953 loss)
I0109 02:49:16.914758  9387 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0109 02:49:29.720391  9387 solver.cpp:270] Iteration 9450 (3.90467 iter/s, 12.8052s/50 iter), loss = 0.00318313, remaining 0 hours and 10 minutes
I0109 02:49:29.720424  9387 solver.cpp:291]     Train net output #0: loss = 0.0031832 (* 1 = 0.0031832 loss)
I0109 02:49:29.720432  9387 sgd_solver.cpp:106] Iteration 9450, lr = 1e-06
I0109 02:49:42.532521  9387 solver.cpp:270] Iteration 9500 (3.90271 iter/s, 12.8116s/50 iter), loss = 0.00333824, remaining 0 hours and 10 minutes
I0109 02:49:42.532552  9387 solver.cpp:291]     Train net output #0: loss = 0.00333831 (* 1 = 0.00333831 loss)
I0109 02:49:42.532577  9387 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0109 02:49:55.316598  9387 solver.cpp:270] Iteration 9550 (3.91127 iter/s, 12.7836s/50 iter), loss = 0.000144887, remaining 0 hours and 10 minutes
I0109 02:49:55.316643  9387 solver.cpp:291]     Train net output #0: loss = 0.000144958 (* 1 = 0.000144958 loss)
I0109 02:49:55.316650  9387 sgd_solver.cpp:106] Iteration 9550, lr = 1e-06
I0109 02:50:08.123406  9387 solver.cpp:270] Iteration 9600 (3.90433 iter/s, 12.8063s/50 iter), loss = 0.00566722, remaining 0 hours and 10 minutes
I0109 02:50:08.123438  9387 solver.cpp:291]     Train net output #0: loss = 0.00566729 (* 1 = 0.00566729 loss)
I0109 02:50:08.123462  9387 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0109 02:50:20.890421  9387 solver.cpp:270] Iteration 9650 (3.9165 iter/s, 12.7665s/50 iter), loss = 0.0436719, remaining 0 hours and 9 minutes
I0109 02:50:20.890455  9387 solver.cpp:291]     Train net output #0: loss = 0.043672 (* 1 = 0.043672 loss)
I0109 02:50:20.890462  9387 sgd_solver.cpp:106] Iteration 9650, lr = 1e-06
I0109 02:50:33.626338  9387 solver.cpp:270] Iteration 9700 (3.92606 iter/s, 12.7354s/50 iter), loss = 0.00641254, remaining 0 hours and 9 minutes
I0109 02:50:33.626385  9387 solver.cpp:291]     Train net output #0: loss = 0.00641261 (* 1 = 0.00641261 loss)
I0109 02:50:33.626392  9387 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0109 02:50:46.431393  9387 solver.cpp:270] Iteration 9750 (3.90487 iter/s, 12.8045s/50 iter), loss = 0.00183511, remaining 0 hours and 9 minutes
I0109 02:50:46.431425  9387 solver.cpp:291]     Train net output #0: loss = 0.00183518 (* 1 = 0.00183518 loss)
I0109 02:50:46.431432  9387 sgd_solver.cpp:106] Iteration 9750, lr = 1e-06
I0109 02:50:59.197587  9387 solver.cpp:270] Iteration 9800 (3.91675 iter/s, 12.7657s/50 iter), loss = 0.0032908, remaining 0 hours and 9 minutes
I0109 02:50:59.197620  9387 solver.cpp:291]     Train net output #0: loss = 0.00329087 (* 1 = 0.00329087 loss)
I0109 02:50:59.197628  9387 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0109 02:51:11.959707  9387 solver.cpp:270] Iteration 9850 (3.918 iter/s, 12.7616s/50 iter), loss = 0.00209142, remaining 0 hours and 8 minutes
I0109 02:51:11.959759  9387 solver.cpp:291]     Train net output #0: loss = 0.00209149 (* 1 = 0.00209149 loss)
I0109 02:51:11.959782  9387 sgd_solver.cpp:106] Iteration 9850, lr = 1e-06
I0109 02:51:24.752192  9387 solver.cpp:270] Iteration 9900 (3.90871 iter/s, 12.792s/50 iter), loss = 0.00305031, remaining 0 hours and 8 minutes
I0109 02:51:24.752223  9387 solver.cpp:291]     Train net output #0: loss = 0.00305037 (* 1 = 0.00305037 loss)
I0109 02:51:24.752245  9387 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0109 02:51:37.544441  9387 solver.cpp:270] Iteration 9950 (3.90877 iter/s, 12.7917s/50 iter), loss = 0.00357306, remaining 0 hours and 8 minutes
I0109 02:51:37.544474  9387 solver.cpp:291]     Train net output #0: loss = 0.00357313 (* 1 = 0.00357313 loss)
I0109 02:51:37.544481  9387 sgd_solver.cpp:106] Iteration 9950, lr = 1e-06
I0109 02:51:50.084113  9387 solver.cpp:424] Iteration 10000, Testing net (#0)
I0109 02:51:51.570875  9387 solver.cpp:523]     Test net output #0: accuracy = 0.95325
I0109 02:51:51.570904  9387 solver.cpp:523]     Test net output #1: loss = 0.30293 (* 1 = 0.30293 loss)
I0109 02:51:51.570909  9387 solver.cpp:523]     Test net output #2: top-1 = 0.95325
I0109 02:51:51.817931  9387 solver.cpp:270] Iteration 10000 (3.50314 iter/s, 14.2729s/50 iter), loss = 0.000386185, remaining 0 hours and 9 minutes
I0109 02:51:51.817957  9387 solver.cpp:291]     Train net output #0: loss = 0.000386253 (* 1 = 0.000386253 loss)
I0109 02:51:51.817965  9387 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0109 02:52:04.622674  9387 solver.cpp:270] Iteration 10050 (3.90496 iter/s, 12.8042s/50 iter), loss = 0.00141358, remaining 0 hours and 8 minutes
I0109 02:52:04.622705  9387 solver.cpp:291]     Train net output #0: loss = 0.00141365 (* 1 = 0.00141365 loss)
I0109 02:52:04.622728  9387 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0109 02:52:17.411728  9387 solver.cpp:270] Iteration 10100 (3.90975 iter/s, 12.7885s/50 iter), loss = 0.00502489, remaining 0 hours and 7 minutes
I0109 02:52:17.411761  9387 solver.cpp:291]     Train net output #0: loss = 0.00502496 (* 1 = 0.00502496 loss)
I0109 02:52:17.411783  9387 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0109 02:52:30.221359  9387 solver.cpp:270] Iteration 10150 (3.90347 iter/s, 12.8091s/50 iter), loss = 0.000705755, remaining 0 hours and 7 minutes
I0109 02:52:30.221403  9387 solver.cpp:291]     Train net output #0: loss = 0.000705832 (* 1 = 0.000705832 loss)
I0109 02:52:30.221411  9387 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0109 02:52:43.013114  9387 solver.cpp:270] Iteration 10200 (3.90893 iter/s, 12.7912s/50 iter), loss = 0.00324276, remaining 0 hours and 7 minutes
I0109 02:52:43.013145  9387 solver.cpp:291]     Train net output #0: loss = 0.00324284 (* 1 = 0.00324284 loss)
I0109 02:52:43.013154  9387 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0109 02:52:55.801000  9387 solver.cpp:270] Iteration 10250 (3.91011 iter/s, 12.7874s/50 iter), loss = 0.0112057, remaining 0 hours and 7 minutes
I0109 02:52:55.801033  9387 solver.cpp:291]     Train net output #0: loss = 0.0112058 (* 1 = 0.0112058 loss)
I0109 02:52:55.801040  9387 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0109 02:53:08.559640  9387 solver.cpp:270] Iteration 10300 (3.91907 iter/s, 12.7581s/50 iter), loss = 0.00600004, remaining 0 hours and 7 minutes
I0109 02:53:08.559702  9387 solver.cpp:291]     Train net output #0: loss = 0.00600011 (* 1 = 0.00600011 loss)
I0109 02:53:08.559710  9387 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0109 02:53:21.357290  9387 solver.cpp:270] Iteration 10350 (3.90713 iter/s, 12.7971s/50 iter), loss = 0.000856931, remaining 0 hours and 6 minutes
I0109 02:53:21.357322  9387 solver.cpp:291]     Train net output #0: loss = 0.000857008 (* 1 = 0.000857008 loss)
I0109 02:53:21.357329  9387 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0109 02:53:34.138746  9387 solver.cpp:270] Iteration 10400 (3.91207 iter/s, 12.7809s/50 iter), loss = 0.00806399, remaining 0 hours and 6 minutes
I0109 02:53:34.138777  9387 solver.cpp:291]     Train net output #0: loss = 0.00806407 (* 1 = 0.00806407 loss)
I0109 02:53:34.138784  9387 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0109 02:53:46.969944  9387 solver.cpp:270] Iteration 10450 (3.89691 iter/s, 12.8307s/50 iter), loss = 0.000514757, remaining 0 hours and 6 minutes
I0109 02:53:46.969998  9387 solver.cpp:291]     Train net output #0: loss = 0.000514841 (* 1 = 0.000514841 loss)
I0109 02:53:46.970007  9387 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0109 02:53:59.729570  9387 solver.cpp:270] Iteration 10500 (3.91877 iter/s, 12.7591s/50 iter), loss = 0.000702505, remaining 0 hours and 6 minutes
I0109 02:53:59.729600  9387 solver.cpp:291]     Train net output #0: loss = 0.000702589 (* 1 = 0.000702589 loss)
I0109 02:53:59.729609  9387 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0109 02:54:12.520707  9387 solver.cpp:270] Iteration 10550 (3.90911 iter/s, 12.7906s/50 iter), loss = 0.000964301, remaining 0 hours and 6 minutes
I0109 02:54:12.520740  9387 solver.cpp:291]     Train net output #0: loss = 0.000964385 (* 1 = 0.000964385 loss)
I0109 02:54:12.520747  9387 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0109 02:54:25.346954  9387 solver.cpp:270] Iteration 10600 (3.89841 iter/s, 12.8257s/50 iter), loss = 0.00068369, remaining 0 hours and 5 minutes
I0109 02:54:25.347000  9387 solver.cpp:291]     Train net output #0: loss = 0.000683773 (* 1 = 0.000683773 loss)
I0109 02:54:25.347023  9387 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0109 02:54:38.113353  9387 solver.cpp:270] Iteration 10650 (3.91669 iter/s, 12.7659s/50 iter), loss = 0.00369448, remaining 0 hours and 5 minutes
I0109 02:54:38.113384  9387 solver.cpp:291]     Train net output #0: loss = 0.00369456 (* 1 = 0.00369456 loss)
I0109 02:54:38.113392  9387 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0109 02:54:50.918521  9387 solver.cpp:270] Iteration 10700 (3.90483 iter/s, 12.8047s/50 iter), loss = 0.00188337, remaining 0 hours and 5 minutes
I0109 02:54:50.918555  9387 solver.cpp:291]     Train net output #0: loss = 0.00188346 (* 1 = 0.00188346 loss)
I0109 02:54:50.918561  9387 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0109 02:55:03.680702  9387 solver.cpp:270] Iteration 10750 (3.91798 iter/s, 12.7617s/50 iter), loss = 0.00525105, remaining 0 hours and 5 minutes
I0109 02:55:03.680750  9387 solver.cpp:291]     Train net output #0: loss = 0.00525113 (* 1 = 0.00525113 loss)
I0109 02:55:03.680758  9387 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0109 02:55:16.465065  9387 solver.cpp:270] Iteration 10800 (3.91119 iter/s, 12.7838s/50 iter), loss = 0.000899249, remaining 0 hours and 5 minutes
I0109 02:55:16.465097  9387 solver.cpp:291]     Train net output #0: loss = 0.000899329 (* 1 = 0.000899329 loss)
I0109 02:55:16.465104  9387 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0109 02:55:29.217311  9387 solver.cpp:270] Iteration 10850 (3.92103 iter/s, 12.7517s/50 iter), loss = 0.000720878, remaining 0 hours and 4 minutes
I0109 02:55:29.217344  9387 solver.cpp:291]     Train net output #0: loss = 0.000720956 (* 1 = 0.000720956 loss)
I0109 02:55:29.217351  9387 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0109 02:55:42.029881  9387 solver.cpp:270] Iteration 10900 (3.90257 iter/s, 12.8121s/50 iter), loss = 0.00188505, remaining 0 hours and 4 minutes
I0109 02:55:42.029927  9387 solver.cpp:291]     Train net output #0: loss = 0.00188512 (* 1 = 0.00188512 loss)
I0109 02:55:42.029950  9387 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0109 02:55:54.821240  9387 solver.cpp:270] Iteration 10950 (3.90905 iter/s, 12.7908s/50 iter), loss = 0.00404986, remaining 0 hours and 4 minutes
I0109 02:55:54.821274  9387 solver.cpp:291]     Train net output #0: loss = 0.00404994 (* 1 = 0.00404994 loss)
I0109 02:55:54.821297  9387 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0109 02:56:07.350767  9387 solver.cpp:424] Iteration 11000, Testing net (#0)
I0109 02:56:08.857528  9387 solver.cpp:523]     Test net output #0: accuracy = 0.9535
I0109 02:56:08.857556  9387 solver.cpp:523]     Test net output #1: loss = 0.310886 (* 1 = 0.310886 loss)
I0109 02:56:08.857561  9387 solver.cpp:523]     Test net output #2: top-1 = 0.9535
I0109 02:56:09.100912  9387 solver.cpp:270] Iteration 11000 (3.50162 iter/s, 14.2791s/50 iter), loss = 0.00671053, remaining 0 hours and 4 minutes
I0109 02:56:09.100939  9387 solver.cpp:291]     Train net output #0: loss = 0.0067106 (* 1 = 0.0067106 loss)
I0109 02:56:09.100948  9387 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0109 02:56:21.883808  9387 solver.cpp:270] Iteration 11050 (3.91163 iter/s, 12.7824s/50 iter), loss = 0.00119259, remaining 0 hours and 3 minutes
I0109 02:56:21.883862  9387 solver.cpp:291]     Train net output #0: loss = 0.00119265 (* 1 = 0.00119265 loss)
I0109 02:56:21.883869  9387 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0109 02:56:34.641814  9387 solver.cpp:270] Iteration 11100 (3.91927 iter/s, 12.7575s/50 iter), loss = 0.00130125, remaining 0 hours and 3 minutes
I0109 02:56:34.641849  9387 solver.cpp:291]     Train net output #0: loss = 0.00130132 (* 1 = 0.00130132 loss)
I0109 02:56:34.641856  9387 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0109 02:56:47.466334  9387 solver.cpp:270] Iteration 11150 (3.89894 iter/s, 12.824s/50 iter), loss = 0.000714473, remaining 0 hours and 3 minutes
I0109 02:56:47.466368  9387 solver.cpp:291]     Train net output #0: loss = 0.00071454 (* 1 = 0.00071454 loss)
I0109 02:56:47.466375  9387 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0109 02:57:00.258067  9387 solver.cpp:270] Iteration 11200 (3.90893 iter/s, 12.7912s/50 iter), loss = 0.00298313, remaining 0 hours and 3 minutes
I0109 02:57:00.258113  9387 solver.cpp:291]     Train net output #0: loss = 0.00298319 (* 1 = 0.00298319 loss)
I0109 02:57:00.258121  9387 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0109 02:57:13.015208  9387 solver.cpp:270] Iteration 11250 (3.91953 iter/s, 12.7566s/50 iter), loss = 0.00147753, remaining 0 hours and 3 minutes
I0109 02:57:13.015239  9387 solver.cpp:291]     Train net output #0: loss = 0.00147759 (* 1 = 0.00147759 loss)
I0109 02:57:13.015247  9387 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0109 02:57:25.812835  9387 solver.cpp:270] Iteration 11300 (3.90713 iter/s, 12.7971s/50 iter), loss = 0.00843206, remaining 0 hours and 2 minutes
I0109 02:57:25.812870  9387 solver.cpp:291]     Train net output #0: loss = 0.00843212 (* 1 = 0.00843212 loss)
I0109 02:57:25.812877  9387 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0109 02:57:38.571166  9387 solver.cpp:270] Iteration 11350 (3.91916 iter/s, 12.7578s/50 iter), loss = 0.0023146, remaining 0 hours and 2 minutes
I0109 02:57:38.571211  9387 solver.cpp:291]     Train net output #0: loss = 0.00231467 (* 1 = 0.00231467 loss)
I0109 02:57:38.571234  9387 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0109 02:57:51.347847  9387 solver.cpp:270] Iteration 11400 (3.91354 iter/s, 12.7762s/50 iter), loss = 0.00695395, remaining 0 hours and 2 minutes
I0109 02:57:51.347882  9387 solver.cpp:291]     Train net output #0: loss = 0.00695402 (* 1 = 0.00695402 loss)
I0109 02:57:51.347888  9387 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0109 02:58:04.124101  9387 solver.cpp:270] Iteration 11450 (3.91367 iter/s, 12.7757s/50 iter), loss = 0.0123951, remaining 0 hours and 2 minutes
I0109 02:58:04.124135  9387 solver.cpp:291]     Train net output #0: loss = 0.0123952 (* 1 = 0.0123952 loss)
I0109 02:58:04.124142  9387 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0109 02:58:16.904489  9387 solver.cpp:270] Iteration 11500 (3.9124 iter/s, 12.7799s/50 iter), loss = 0.00519478, remaining 0 hours and 2 minutes
I0109 02:58:16.904536  9387 solver.cpp:291]     Train net output #0: loss = 0.00519484 (* 1 = 0.00519484 loss)
I0109 02:58:16.904543  9387 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0109 02:58:29.665832  9387 solver.cpp:270] Iteration 11550 (3.91824 iter/s, 12.7608s/50 iter), loss = 0.00288322, remaining 0 hours and 1 minutes
I0109 02:58:29.665865  9387 solver.cpp:291]     Train net output #0: loss = 0.00288328 (* 1 = 0.00288328 loss)
I0109 02:58:29.665889  9387 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0109 02:58:42.476006  9387 solver.cpp:270] Iteration 11600 (3.9033 iter/s, 12.8097s/50 iter), loss = 0.00161986, remaining 0 hours and 1 minutes
I0109 02:58:42.476040  9387 solver.cpp:291]     Train net output #0: loss = 0.00161992 (* 1 = 0.00161992 loss)
I0109 02:58:42.476047  9387 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0109 02:58:55.259757  9387 solver.cpp:270] Iteration 11650 (3.91137 iter/s, 12.7832s/50 iter), loss = 0.0122733, remaining 0 hours and 1 minutes
I0109 02:58:55.259809  9387 solver.cpp:291]     Train net output #0: loss = 0.0122734 (* 1 = 0.0122734 loss)
I0109 02:58:55.259817  9387 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0109 02:59:08.053036  9387 solver.cpp:270] Iteration 11700 (3.90846 iter/s, 12.7928s/50 iter), loss = 0.00379038, remaining 0 hours and 1 minutes
I0109 02:59:08.053069  9387 solver.cpp:291]     Train net output #0: loss = 0.00379044 (* 1 = 0.00379044 loss)
I0109 02:59:08.053076  9387 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0109 02:59:20.857367  9387 solver.cpp:270] Iteration 11750 (3.90508 iter/s, 12.8038s/50 iter), loss = 0.000558083, remaining 0 hours and 1 minutes
I0109 02:59:20.857398  9387 solver.cpp:291]     Train net output #0: loss = 0.000558147 (* 1 = 0.000558147 loss)
I0109 02:59:20.857421  9387 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0109 02:59:33.585762  9387 solver.cpp:270] Iteration 11800 (3.92838 iter/s, 12.7279s/50 iter), loss = 0.00855234, remaining 0 hours and 0 minutes
I0109 02:59:33.585808  9387 solver.cpp:291]     Train net output #0: loss = 0.0085524 (* 1 = 0.0085524 loss)
I0109 02:59:33.585830  9387 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0109 02:59:46.425412  9387 solver.cpp:270] Iteration 11850 (3.89435 iter/s, 12.8391s/50 iter), loss = 0.00360593, remaining 0 hours and 0 minutes
I0109 02:59:46.425446  9387 solver.cpp:291]     Train net output #0: loss = 0.003606 (* 1 = 0.003606 loss)
I0109 02:59:46.425468  9387 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0109 02:59:59.193374  9387 solver.cpp:270] Iteration 11900 (3.91621 iter/s, 12.7675s/50 iter), loss = 0.00199647, remaining 0 hours and 0 minutes
I0109 02:59:59.193408  9387 solver.cpp:291]     Train net output #0: loss = 0.00199653 (* 1 = 0.00199653 loss)
I0109 02:59:59.193415  9387 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0109 03:00:11.939007  9387 solver.cpp:270] Iteration 11950 (3.92307 iter/s, 12.7451s/50 iter), loss = 0.000566491, remaining 0 hours and 0 minutes
I0109 03:00:11.939051  9387 solver.cpp:291]     Train net output #0: loss = 0.00056655 (* 1 = 0.00056655 loss)
I0109 03:00:11.939059  9387 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0109 03:00:24.501579  9387 solver.cpp:935] Snapshotting to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.7/snapshots/_iter_12000.caffemodel
I0109 03:00:26.958348  9387 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pruning/alexnetBNnoLRN/regular_rate_0.7/snapshots/_iter_12000.solverstate
I0109 03:00:27.274621  9387 solver.cpp:384] Iteration 12000, loss = 0.00430275
I0109 03:00:27.274647  9387 solver.cpp:424] Iteration 12000, Testing net (#0)
I0109 03:00:28.725749  9387 solver.cpp:523]     Test net output #0: accuracy = 0.9535
I0109 03:00:28.725777  9387 solver.cpp:523]     Test net output #1: loss = 0.31405 (* 1 = 0.31405 loss)
I0109 03:00:28.725781  9387 solver.cpp:523]     Test net output #2: top-1 = 0.9535
I0109 03:00:28.725785  9387 solver.cpp:392] Optimization Done (3.90469 iter/s).
I0109 03:00:28.725790  9387 caffe_interface.cpp:546] Optimization Done.
(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

I0109 03:00:30.520066  9484 gpu_memory.cpp:53] GPUMemory::Manager initialized with Plain CUDA GPU Allocator
I0109 03:00:30.520263  9484 caffe_interface.cpp:91] Use CPU.
W0109 03:00:31.444972  9484 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 3, it will be converted to NVCaffe Format.
W0109 03:00:31.445132  9484 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 7, it will be converted to NVCaffe Format.
W0109 03:00:31.445147  9484 utils.cpp:177] BVLC BatchNormLayer without ScaleLayer detected: 21, it will be converted to NVCaffe Format.
I0109 03:00:31.445228  9484 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0109 03:00:31.445242  9484 net.cpp:52] Initializing net from parameters:
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0109 03:00:31.445468  9484 layer_factory.hpp:77] Creating layer data
I0109 03:00:31.446557  9484 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 03:00:31.447026  9484 net.cpp:94] Creating Layer data
I0109 03:00:31.447036  9484 net.cpp:409] data -> data
I0109 03:00:31.447046  9484 net.cpp:409] data -> label
I0109 03:00:31.449671  9517 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0109 03:00:31.449694  9517 db_lmdb.cpp:38] Items count: 4000
I0109 03:00:31.449715  9517 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0109 03:00:31.449993  9484 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0109 03:00:31.450006  9484 data_layer.cpp:83] output data size: 50,3,227,227
I0109 03:00:31.545507  9484 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 03:00:31.545608  9484 net.cpp:144] Setting up data
I0109 03:00:31.545615  9484 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0109 03:00:31.545624  9484 net.cpp:151] Top shape: 50 (50)
I0109 03:00:31.545629  9484 net.cpp:159] Memory required for data: 30917600
I0109 03:00:31.545634  9484 layer_factory.hpp:77] Creating layer label_data_1_split
I0109 03:00:31.545642  9484 net.cpp:94] Creating Layer label_data_1_split
I0109 03:00:31.545646  9484 net.cpp:435] label_data_1_split <- label
I0109 03:00:31.545652  9484 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0109 03:00:31.545662  9484 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0109 03:00:31.545671  9484 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0109 03:00:31.545680  9484 net.cpp:144] Setting up label_data_1_split
I0109 03:00:31.545684  9484 net.cpp:151] Top shape: 50 (50)
I0109 03:00:31.545687  9484 net.cpp:151] Top shape: 50 (50)
I0109 03:00:31.545691  9484 net.cpp:151] Top shape: 50 (50)
I0109 03:00:31.545694  9484 net.cpp:159] Memory required for data: 30918200
I0109 03:00:31.545697  9484 layer_factory.hpp:77] Creating layer conv1
I0109 03:00:31.545712  9484 net.cpp:94] Creating Layer conv1
I0109 03:00:31.545727  9484 net.cpp:435] conv1 <- data
I0109 03:00:31.545732  9484 net.cpp:409] conv1 -> conv1
I0109 03:00:31.546187  9484 net.cpp:144] Setting up conv1
I0109 03:00:31.546193  9484 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0109 03:00:31.546200  9484 net.cpp:159] Memory required for data: 88998200
I0109 03:00:31.546211  9484 layer_factory.hpp:77] Creating layer bn1
I0109 03:00:31.546224  9484 net.cpp:94] Creating Layer bn1
I0109 03:00:31.546231  9484 net.cpp:435] bn1 <- conv1
I0109 03:00:31.546236  9484 net.cpp:409] bn1 -> bn1
I0109 03:00:31.546279  9484 net.cpp:144] Setting up bn1
I0109 03:00:31.546284  9484 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0109 03:00:31.546289  9484 net.cpp:159] Memory required for data: 147078200
I0109 03:00:31.546298  9484 layer_factory.hpp:77] Creating layer relu1
I0109 03:00:31.546304  9484 net.cpp:94] Creating Layer relu1
I0109 03:00:31.546308  9484 net.cpp:435] relu1 <- bn1
I0109 03:00:31.546314  9484 net.cpp:409] relu1 -> relu1
I0109 03:00:31.546326  9484 net.cpp:144] Setting up relu1
I0109 03:00:31.546331  9484 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0109 03:00:31.546336  9484 net.cpp:159] Memory required for data: 205158200
I0109 03:00:31.546339  9484 layer_factory.hpp:77] Creating layer pool1
I0109 03:00:31.546345  9484 net.cpp:94] Creating Layer pool1
I0109 03:00:31.546350  9484 net.cpp:435] pool1 <- relu1
I0109 03:00:31.546355  9484 net.cpp:409] pool1 -> pool1
I0109 03:00:31.546363  9484 net.cpp:144] Setting up pool1
I0109 03:00:31.546368  9484 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0109 03:00:31.546373  9484 net.cpp:159] Memory required for data: 219155000
I0109 03:00:31.546376  9484 layer_factory.hpp:77] Creating layer conv2
I0109 03:00:31.546386  9484 net.cpp:94] Creating Layer conv2
I0109 03:00:31.546388  9484 net.cpp:435] conv2 <- pool1
I0109 03:00:31.546393  9484 net.cpp:409] conv2 -> conv2
I0109 03:00:31.553339  9484 net.cpp:144] Setting up conv2
I0109 03:00:31.553350  9484 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0109 03:00:31.553356  9484 net.cpp:159] Memory required for data: 256479800
I0109 03:00:31.553365  9484 layer_factory.hpp:77] Creating layer bn2
I0109 03:00:31.553373  9484 net.cpp:94] Creating Layer bn2
I0109 03:00:31.553377  9484 net.cpp:435] bn2 <- conv2
I0109 03:00:31.553382  9484 net.cpp:409] bn2 -> bn2
I0109 03:00:31.553411  9484 net.cpp:144] Setting up bn2
I0109 03:00:31.553416  9484 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0109 03:00:31.553419  9484 net.cpp:159] Memory required for data: 293804600
I0109 03:00:31.553426  9484 layer_factory.hpp:77] Creating layer relu2
I0109 03:00:31.553432  9484 net.cpp:94] Creating Layer relu2
I0109 03:00:31.553436  9484 net.cpp:435] relu2 <- bn2
I0109 03:00:31.553440  9484 net.cpp:409] relu2 -> relu2
I0109 03:00:31.553447  9484 net.cpp:144] Setting up relu2
I0109 03:00:31.553449  9484 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0109 03:00:31.553454  9484 net.cpp:159] Memory required for data: 331129400
I0109 03:00:31.553457  9484 layer_factory.hpp:77] Creating layer pool2
I0109 03:00:31.553462  9484 net.cpp:94] Creating Layer pool2
I0109 03:00:31.553465  9484 net.cpp:435] pool2 <- relu2
I0109 03:00:31.553472  9484 net.cpp:409] pool2 -> pool2
I0109 03:00:31.553478  9484 net.cpp:144] Setting up pool2
I0109 03:00:31.553480  9484 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0109 03:00:31.553485  9484 net.cpp:159] Memory required for data: 339782200
I0109 03:00:31.553489  9484 layer_factory.hpp:77] Creating layer conv3
I0109 03:00:31.553498  9484 net.cpp:94] Creating Layer conv3
I0109 03:00:31.553501  9484 net.cpp:435] conv3 <- pool2
I0109 03:00:31.553522  9484 net.cpp:409] conv3 -> conv3
I0109 03:00:31.562978  9484 net.cpp:144] Setting up conv3
I0109 03:00:31.562989  9484 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 03:00:31.562995  9484 net.cpp:159] Memory required for data: 352761400
I0109 03:00:31.563001  9484 layer_factory.hpp:77] Creating layer relu3
I0109 03:00:31.563007  9484 net.cpp:94] Creating Layer relu3
I0109 03:00:31.563011  9484 net.cpp:435] relu3 <- conv3
I0109 03:00:31.563026  9484 net.cpp:409] relu3 -> relu3
I0109 03:00:31.563050  9484 net.cpp:144] Setting up relu3
I0109 03:00:31.563052  9484 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 03:00:31.563057  9484 net.cpp:159] Memory required for data: 365740600
I0109 03:00:31.563061  9484 layer_factory.hpp:77] Creating layer conv4
I0109 03:00:31.563069  9484 net.cpp:94] Creating Layer conv4
I0109 03:00:31.563072  9484 net.cpp:435] conv4 <- relu3
I0109 03:00:31.563077  9484 net.cpp:409] conv4 -> conv4
I0109 03:00:31.576428  9484 net.cpp:144] Setting up conv4
I0109 03:00:31.576443  9484 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 03:00:31.576450  9484 net.cpp:159] Memory required for data: 378719800
I0109 03:00:31.576460  9484 layer_factory.hpp:77] Creating layer relu4
I0109 03:00:31.576467  9484 net.cpp:94] Creating Layer relu4
I0109 03:00:31.576470  9484 net.cpp:435] relu4 <- conv4
I0109 03:00:31.576475  9484 net.cpp:409] relu4 -> relu4
I0109 03:00:31.576483  9484 net.cpp:144] Setting up relu4
I0109 03:00:31.576489  9484 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 03:00:31.576493  9484 net.cpp:159] Memory required for data: 391699000
I0109 03:00:31.576496  9484 layer_factory.hpp:77] Creating layer conv5
I0109 03:00:31.576505  9484 net.cpp:94] Creating Layer conv5
I0109 03:00:31.576508  9484 net.cpp:435] conv5 <- relu4
I0109 03:00:31.576512  9484 net.cpp:409] conv5 -> conv5
I0109 03:00:31.585332  9484 net.cpp:144] Setting up conv5
I0109 03:00:31.585345  9484 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0109 03:00:31.585350  9484 net.cpp:159] Memory required for data: 400351800
I0109 03:00:31.585357  9484 layer_factory.hpp:77] Creating layer relu5
I0109 03:00:31.585362  9484 net.cpp:94] Creating Layer relu5
I0109 03:00:31.585366  9484 net.cpp:435] relu5 <- conv5
I0109 03:00:31.585371  9484 net.cpp:409] relu5 -> relu5
I0109 03:00:31.585393  9484 net.cpp:144] Setting up relu5
I0109 03:00:31.585398  9484 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0109 03:00:31.585403  9484 net.cpp:159] Memory required for data: 409004600
I0109 03:00:31.585407  9484 layer_factory.hpp:77] Creating layer pool5
I0109 03:00:31.585412  9484 net.cpp:94] Creating Layer pool5
I0109 03:00:31.585415  9484 net.cpp:435] pool5 <- relu5
I0109 03:00:31.585419  9484 net.cpp:409] pool5 -> pool5
I0109 03:00:31.585427  9484 net.cpp:144] Setting up pool5
I0109 03:00:31.585430  9484 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0109 03:00:31.585433  9484 net.cpp:159] Memory required for data: 410847800
I0109 03:00:31.585438  9484 layer_factory.hpp:77] Creating layer fc6
I0109 03:00:31.585443  9484 net.cpp:94] Creating Layer fc6
I0109 03:00:31.585445  9484 net.cpp:435] fc6 <- pool5
I0109 03:00:31.585450  9484 net.cpp:409] fc6 -> fc6
I0109 03:00:31.943125  9484 net.cpp:144] Setting up fc6
I0109 03:00:31.943148  9484 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:31.943156  9484 net.cpp:159] Memory required for data: 411667000
I0109 03:00:31.943181  9484 layer_factory.hpp:77] Creating layer relu6
I0109 03:00:31.943189  9484 net.cpp:94] Creating Layer relu6
I0109 03:00:31.943193  9484 net.cpp:435] relu6 <- fc6
I0109 03:00:31.943202  9484 net.cpp:409] relu6 -> relu6
I0109 03:00:31.943213  9484 net.cpp:144] Setting up relu6
I0109 03:00:31.943217  9484 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:31.943219  9484 net.cpp:159] Memory required for data: 412486200
I0109 03:00:31.943222  9484 layer_factory.hpp:77] Creating layer drop6
I0109 03:00:31.943233  9484 net.cpp:94] Creating Layer drop6
I0109 03:00:31.943238  9484 net.cpp:435] drop6 <- relu6
I0109 03:00:31.943240  9484 net.cpp:409] drop6 -> drop6
I0109 03:00:31.943248  9484 net.cpp:144] Setting up drop6
I0109 03:00:31.943250  9484 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:31.943254  9484 net.cpp:159] Memory required for data: 413305400
I0109 03:00:31.943257  9484 layer_factory.hpp:77] Creating layer fc7
I0109 03:00:31.943264  9484 net.cpp:94] Creating Layer fc7
I0109 03:00:31.943267  9484 net.cpp:435] fc7 <- drop6
I0109 03:00:31.943271  9484 net.cpp:409] fc7 -> fc7
I0109 03:00:32.104430  9484 net.cpp:144] Setting up fc7
I0109 03:00:32.104450  9484 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:32.104460  9484 net.cpp:159] Memory required for data: 414124600
I0109 03:00:32.104468  9484 layer_factory.hpp:77] Creating layer bn7
I0109 03:00:32.104476  9484 net.cpp:94] Creating Layer bn7
I0109 03:00:32.104480  9484 net.cpp:435] bn7 <- fc7
I0109 03:00:32.104487  9484 net.cpp:409] bn7 -> bn7
I0109 03:00:32.104599  9484 net.cpp:144] Setting up bn7
I0109 03:00:32.104605  9484 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:32.104609  9484 net.cpp:159] Memory required for data: 414943800
I0109 03:00:32.104615  9484 layer_factory.hpp:77] Creating layer relu7
I0109 03:00:32.104619  9484 net.cpp:94] Creating Layer relu7
I0109 03:00:32.104622  9484 net.cpp:435] relu7 <- bn7
I0109 03:00:32.104626  9484 net.cpp:409] relu7 -> relu7
I0109 03:00:32.104633  9484 net.cpp:144] Setting up relu7
I0109 03:00:32.104636  9484 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:32.104640  9484 net.cpp:159] Memory required for data: 415763000
I0109 03:00:32.104643  9484 layer_factory.hpp:77] Creating layer drop7
I0109 03:00:32.104648  9484 net.cpp:94] Creating Layer drop7
I0109 03:00:32.104652  9484 net.cpp:435] drop7 <- relu7
I0109 03:00:32.104655  9484 net.cpp:409] drop7 -> drop7
I0109 03:00:32.104661  9484 net.cpp:144] Setting up drop7
I0109 03:00:32.104665  9484 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:32.104668  9484 net.cpp:159] Memory required for data: 416582200
I0109 03:00:32.104671  9484 layer_factory.hpp:77] Creating layer fc8
I0109 03:00:32.104676  9484 net.cpp:94] Creating Layer fc8
I0109 03:00:32.104679  9484 net.cpp:435] fc8 <- drop7
I0109 03:00:32.104684  9484 net.cpp:409] fc8 -> fc8
I0109 03:00:32.104797  9484 net.cpp:144] Setting up fc8
I0109 03:00:32.104802  9484 net.cpp:151] Top shape: 50 2 (100)
I0109 03:00:32.104807  9484 net.cpp:159] Memory required for data: 416582600
I0109 03:00:32.104812  9484 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0109 03:00:32.104818  9484 net.cpp:94] Creating Layer fc8_fc8_0_split
I0109 03:00:32.104821  9484 net.cpp:435] fc8_fc8_0_split <- fc8
I0109 03:00:32.104826  9484 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0109 03:00:32.104831  9484 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0109 03:00:32.104837  9484 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0109 03:00:32.104846  9484 net.cpp:144] Setting up fc8_fc8_0_split
I0109 03:00:32.104848  9484 net.cpp:151] Top shape: 50 2 (100)
I0109 03:00:32.104852  9484 net.cpp:151] Top shape: 50 2 (100)
I0109 03:00:32.104856  9484 net.cpp:151] Top shape: 50 2 (100)
I0109 03:00:32.104861  9484 net.cpp:159] Memory required for data: 416583800
I0109 03:00:32.104864  9484 layer_factory.hpp:77] Creating layer accuracy
I0109 03:00:32.104869  9484 net.cpp:94] Creating Layer accuracy
I0109 03:00:32.104873  9484 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0109 03:00:32.104877  9484 net.cpp:435] accuracy <- label_data_1_split_0
I0109 03:00:32.104883  9484 net.cpp:409] accuracy -> accuracy
I0109 03:00:32.104889  9484 net.cpp:144] Setting up accuracy
I0109 03:00:32.104892  9484 net.cpp:151] Top shape: (1)
I0109 03:00:32.104897  9484 net.cpp:159] Memory required for data: 416583804
I0109 03:00:32.104899  9484 layer_factory.hpp:77] Creating layer loss
I0109 03:00:32.104907  9484 net.cpp:94] Creating Layer loss
I0109 03:00:32.104909  9484 net.cpp:435] loss <- fc8_fc8_0_split_1
I0109 03:00:32.104914  9484 net.cpp:435] loss <- label_data_1_split_1
I0109 03:00:32.104919  9484 net.cpp:409] loss -> loss
I0109 03:00:32.104928  9484 layer_factory.hpp:77] Creating layer loss
I0109 03:00:32.104944  9484 net.cpp:144] Setting up loss
I0109 03:00:32.104949  9484 net.cpp:151] Top shape: (1)
I0109 03:00:32.104954  9484 net.cpp:154]     with loss weight 1
I0109 03:00:32.104987  9484 net.cpp:159] Memory required for data: 416583808
I0109 03:00:32.104990  9484 layer_factory.hpp:77] Creating layer accuracy-top1
I0109 03:00:32.104995  9484 net.cpp:94] Creating Layer accuracy-top1
I0109 03:00:32.105010  9484 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0109 03:00:32.105015  9484 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0109 03:00:32.105036  9484 net.cpp:409] accuracy-top1 -> top-1
I0109 03:00:32.105041  9484 net.cpp:144] Setting up accuracy-top1
I0109 03:00:32.105044  9484 net.cpp:151] Top shape: (1)
I0109 03:00:32.105048  9484 net.cpp:159] Memory required for data: 416583812
I0109 03:00:32.105051  9484 net.cpp:222] accuracy-top1 does not need backward computation.
I0109 03:00:32.105057  9484 net.cpp:220] loss needs backward computation.
I0109 03:00:32.105060  9484 net.cpp:222] accuracy does not need backward computation.
I0109 03:00:32.105065  9484 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0109 03:00:32.105069  9484 net.cpp:220] fc8 needs backward computation.
I0109 03:00:32.105073  9484 net.cpp:220] drop7 needs backward computation.
I0109 03:00:32.105077  9484 net.cpp:220] relu7 needs backward computation.
I0109 03:00:32.105080  9484 net.cpp:220] bn7 needs backward computation.
I0109 03:00:32.105084  9484 net.cpp:220] fc7 needs backward computation.
I0109 03:00:32.105088  9484 net.cpp:220] drop6 needs backward computation.
I0109 03:00:32.105093  9484 net.cpp:220] relu6 needs backward computation.
I0109 03:00:32.105096  9484 net.cpp:220] fc6 needs backward computation.
I0109 03:00:32.105100  9484 net.cpp:220] pool5 needs backward computation.
I0109 03:00:32.105104  9484 net.cpp:220] relu5 needs backward computation.
I0109 03:00:32.105108  9484 net.cpp:220] conv5 needs backward computation.
I0109 03:00:32.105113  9484 net.cpp:220] relu4 needs backward computation.
I0109 03:00:32.105118  9484 net.cpp:220] conv4 needs backward computation.
I0109 03:00:32.105121  9484 net.cpp:220] relu3 needs backward computation.
I0109 03:00:32.105125  9484 net.cpp:220] conv3 needs backward computation.
I0109 03:00:32.105129  9484 net.cpp:220] pool2 needs backward computation.
I0109 03:00:32.105134  9484 net.cpp:220] relu2 needs backward computation.
I0109 03:00:32.105139  9484 net.cpp:220] bn2 needs backward computation.
I0109 03:00:32.105142  9484 net.cpp:220] conv2 needs backward computation.
I0109 03:00:32.105146  9484 net.cpp:220] pool1 needs backward computation.
I0109 03:00:32.105150  9484 net.cpp:220] relu1 needs backward computation.
I0109 03:00:32.105154  9484 net.cpp:220] bn1 needs backward computation.
I0109 03:00:32.105159  9484 net.cpp:220] conv1 needs backward computation.
I0109 03:00:32.105163  9484 net.cpp:222] label_data_1_split does not need backward computation.
I0109 03:00:32.105168  9484 net.cpp:222] data does not need backward computation.
I0109 03:00:32.105172  9484 net.cpp:264] This network produces output accuracy
I0109 03:00:32.105176  9484 net.cpp:264] This network produces output loss
I0109 03:00:32.105180  9484 net.cpp:264] This network produces output top-1
I0109 03:00:32.105206  9484 net.cpp:284] Network initialization done.
I0109 03:00:32.180186  9484 model_transformer.cpp:96] layer: data
I0109 03:00:32.180207  9484 model_transformer.cpp:96] layer: conv1
I0109 03:00:32.180572  9484 model_transformer.cpp:96] layer: bn1
I0109 03:00:32.180595  9484 model_transformer.cpp:96] layer: relu1
I0109 03:00:32.180603  9484 model_transformer.cpp:96] layer: pool1
I0109 03:00:32.180608  9484 model_transformer.cpp:96] layer: conv2
I0109 03:00:32.184379  9484 model_transformer.cpp:96] layer: bn2
I0109 03:00:32.184422  9484 model_transformer.cpp:96] layer: relu2
I0109 03:00:32.184429  9484 model_transformer.cpp:96] layer: pool2
I0109 03:00:32.184434  9484 model_transformer.cpp:96] layer: conv3
I0109 03:00:32.186324  9484 model_transformer.cpp:96] layer: relu3
I0109 03:00:32.186336  9484 model_transformer.cpp:96] layer: conv4
I0109 03:00:32.190304  9484 model_transformer.cpp:96] layer: relu4
I0109 03:00:32.190315  9484 model_transformer.cpp:96] layer: conv5
I0109 03:00:32.192008  9484 model_transformer.cpp:96] layer: relu5
I0109 03:00:32.192019  9484 model_transformer.cpp:96] layer: pool5
I0109 03:00:32.192024  9484 model_transformer.cpp:96] layer: fc6
I0109 03:00:34.101181  9484 model_transformer.cpp:96] layer: relu6
I0109 03:00:34.101227  9484 model_transformer.cpp:96] layer: drop6
I0109 03:00:34.101250  9484 model_transformer.cpp:96] layer: fc7
I0109 03:00:34.364070  9484 model_transformer.cpp:96] layer: bn7
I0109 03:00:34.364204  9484 model_transformer.cpp:96] layer: relu7
I0109 03:00:34.364215  9484 model_transformer.cpp:96] layer: drop7
I0109 03:00:34.364220  9484 model_transformer.cpp:96] layer: fc8
I0109 03:00:34.364327  9484 model_transformer.cpp:96] layer: loss
Output transformed caffemodel: transformed.caffemodel
(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

I0109 03:00:35.795918  9520 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0109 03:00:35.796136  9520 net.cpp:52] Initializing net from parameters:
name: "alexnetBNnoLRN m2 (as m3 but less DROP and less BN)"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0109 03:00:35.796418  9520 layer_factory.hpp:77] Creating layer data
I0109 03:00:35.797443  9520 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 03:00:35.797924  9520 net.cpp:94] Creating Layer data
I0109 03:00:35.797933  9520 net.cpp:409] data -> data
I0109 03:00:35.797948  9520 net.cpp:409] data -> label
I0109 03:00:35.800536  9553 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0109 03:00:35.800559  9553 db_lmdb.cpp:38] Items count: 4000
I0109 03:00:35.800580  9553 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0109 03:00:35.800788  9520 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0109 03:00:35.800799  9520 data_layer.cpp:83] output data size: 50,3,227,227
I0109 03:00:35.895970  9520 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 03:00:35.896075  9520 net.cpp:144] Setting up data
I0109 03:00:35.896080  9520 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0109 03:00:35.896090  9520 net.cpp:151] Top shape: 50 (50)
I0109 03:00:35.896096  9520 net.cpp:159] Memory required for data: 30917600
I0109 03:00:35.896102  9520 layer_factory.hpp:77] Creating layer label_data_1_split
I0109 03:00:35.896112  9520 net.cpp:94] Creating Layer label_data_1_split
I0109 03:00:35.896117  9520 net.cpp:435] label_data_1_split <- label
I0109 03:00:35.896126  9520 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0109 03:00:35.896136  9520 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0109 03:00:35.896147  9520 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0109 03:00:35.896157  9520 net.cpp:144] Setting up label_data_1_split
I0109 03:00:35.896159  9520 net.cpp:151] Top shape: 50 (50)
I0109 03:00:35.896163  9520 net.cpp:151] Top shape: 50 (50)
I0109 03:00:35.896169  9520 net.cpp:151] Top shape: 50 (50)
I0109 03:00:35.896174  9520 net.cpp:159] Memory required for data: 30918200
I0109 03:00:35.896178  9520 layer_factory.hpp:77] Creating layer conv1
I0109 03:00:35.896195  9520 net.cpp:94] Creating Layer conv1
I0109 03:00:35.896200  9520 net.cpp:435] conv1 <- data
I0109 03:00:35.896206  9520 net.cpp:409] conv1 -> conv1
I0109 03:00:35.896638  9520 net.cpp:144] Setting up conv1
I0109 03:00:35.896644  9520 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0109 03:00:35.896649  9520 net.cpp:159] Memory required for data: 88998200
I0109 03:00:35.896661  9520 layer_factory.hpp:77] Creating layer bn1
I0109 03:00:35.896667  9520 net.cpp:94] Creating Layer bn1
I0109 03:00:35.896672  9520 net.cpp:435] bn1 <- conv1
I0109 03:00:35.896678  9520 net.cpp:409] bn1 -> bn1
I0109 03:00:35.896726  9520 net.cpp:144] Setting up bn1
I0109 03:00:35.896733  9520 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0109 03:00:35.896737  9520 net.cpp:159] Memory required for data: 147078200
I0109 03:00:35.896746  9520 layer_factory.hpp:77] Creating layer relu1
I0109 03:00:35.896754  9520 net.cpp:94] Creating Layer relu1
I0109 03:00:35.896759  9520 net.cpp:435] relu1 <- bn1
I0109 03:00:35.896764  9520 net.cpp:409] relu1 -> relu1
I0109 03:00:35.896777  9520 net.cpp:144] Setting up relu1
I0109 03:00:35.896785  9520 net.cpp:151] Top shape: 50 96 55 55 (14520000)
I0109 03:00:35.896791  9520 net.cpp:159] Memory required for data: 205158200
I0109 03:00:35.896795  9520 layer_factory.hpp:77] Creating layer pool1
I0109 03:00:35.896800  9520 net.cpp:94] Creating Layer pool1
I0109 03:00:35.896806  9520 net.cpp:435] pool1 <- relu1
I0109 03:00:35.896811  9520 net.cpp:409] pool1 -> pool1
I0109 03:00:35.896822  9520 net.cpp:144] Setting up pool1
I0109 03:00:35.896829  9520 net.cpp:151] Top shape: 50 96 27 27 (3499200)
I0109 03:00:35.896836  9520 net.cpp:159] Memory required for data: 219155000
I0109 03:00:35.896840  9520 layer_factory.hpp:77] Creating layer conv2
I0109 03:00:35.896863  9520 net.cpp:94] Creating Layer conv2
I0109 03:00:35.896873  9520 net.cpp:435] conv2 <- pool1
I0109 03:00:35.896880  9520 net.cpp:409] conv2 -> conv2
I0109 03:00:35.903731  9520 net.cpp:144] Setting up conv2
I0109 03:00:35.903743  9520 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0109 03:00:35.903749  9520 net.cpp:159] Memory required for data: 256479800
I0109 03:00:35.903757  9520 layer_factory.hpp:77] Creating layer bn2
I0109 03:00:35.903764  9520 net.cpp:94] Creating Layer bn2
I0109 03:00:35.903767  9520 net.cpp:435] bn2 <- conv2
I0109 03:00:35.903774  9520 net.cpp:409] bn2 -> bn2
I0109 03:00:35.903803  9520 net.cpp:144] Setting up bn2
I0109 03:00:35.903810  9520 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0109 03:00:35.903815  9520 net.cpp:159] Memory required for data: 293804600
I0109 03:00:35.903837  9520 layer_factory.hpp:77] Creating layer relu2
I0109 03:00:35.903844  9520 net.cpp:94] Creating Layer relu2
I0109 03:00:35.903854  9520 net.cpp:435] relu2 <- bn2
I0109 03:00:35.903861  9520 net.cpp:409] relu2 -> relu2
I0109 03:00:35.903867  9520 net.cpp:144] Setting up relu2
I0109 03:00:35.903872  9520 net.cpp:151] Top shape: 50 256 27 27 (9331200)
I0109 03:00:35.903877  9520 net.cpp:159] Memory required for data: 331129400
I0109 03:00:35.903882  9520 layer_factory.hpp:77] Creating layer pool2
I0109 03:00:35.903889  9520 net.cpp:94] Creating Layer pool2
I0109 03:00:35.903894  9520 net.cpp:435] pool2 <- relu2
I0109 03:00:35.903901  9520 net.cpp:409] pool2 -> pool2
I0109 03:00:35.903910  9520 net.cpp:144] Setting up pool2
I0109 03:00:35.903915  9520 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0109 03:00:35.903920  9520 net.cpp:159] Memory required for data: 339782200
I0109 03:00:35.903925  9520 layer_factory.hpp:77] Creating layer conv3
I0109 03:00:35.903936  9520 net.cpp:94] Creating Layer conv3
I0109 03:00:35.903941  9520 net.cpp:435] conv3 <- pool2
I0109 03:00:35.903949  9520 net.cpp:409] conv3 -> conv3
I0109 03:00:35.913386  9520 net.cpp:144] Setting up conv3
I0109 03:00:35.913398  9520 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 03:00:35.913404  9520 net.cpp:159] Memory required for data: 352761400
I0109 03:00:35.913411  9520 layer_factory.hpp:77] Creating layer relu3
I0109 03:00:35.913416  9520 net.cpp:94] Creating Layer relu3
I0109 03:00:35.913419  9520 net.cpp:435] relu3 <- conv3
I0109 03:00:35.913424  9520 net.cpp:409] relu3 -> relu3
I0109 03:00:35.913431  9520 net.cpp:144] Setting up relu3
I0109 03:00:35.913435  9520 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 03:00:35.913441  9520 net.cpp:159] Memory required for data: 365740600
I0109 03:00:35.913445  9520 layer_factory.hpp:77] Creating layer conv4
I0109 03:00:35.913453  9520 net.cpp:94] Creating Layer conv4
I0109 03:00:35.913458  9520 net.cpp:435] conv4 <- relu3
I0109 03:00:35.913465  9520 net.cpp:409] conv4 -> conv4
I0109 03:00:35.927024  9520 net.cpp:144] Setting up conv4
I0109 03:00:35.927050  9520 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 03:00:35.927057  9520 net.cpp:159] Memory required for data: 378719800
I0109 03:00:35.927067  9520 layer_factory.hpp:77] Creating layer relu4
I0109 03:00:35.927073  9520 net.cpp:94] Creating Layer relu4
I0109 03:00:35.927078  9520 net.cpp:435] relu4 <- conv4
I0109 03:00:35.927083  9520 net.cpp:409] relu4 -> relu4
I0109 03:00:35.927096  9520 net.cpp:144] Setting up relu4
I0109 03:00:35.927101  9520 net.cpp:151] Top shape: 50 384 13 13 (3244800)
I0109 03:00:35.927109  9520 net.cpp:159] Memory required for data: 391699000
I0109 03:00:35.927114  9520 layer_factory.hpp:77] Creating layer conv5
I0109 03:00:35.927122  9520 net.cpp:94] Creating Layer conv5
I0109 03:00:35.927127  9520 net.cpp:435] conv5 <- relu4
I0109 03:00:35.927134  9520 net.cpp:409] conv5 -> conv5
I0109 03:00:35.936020  9520 net.cpp:144] Setting up conv5
I0109 03:00:35.936033  9520 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0109 03:00:35.936038  9520 net.cpp:159] Memory required for data: 400351800
I0109 03:00:35.936045  9520 layer_factory.hpp:77] Creating layer relu5
I0109 03:00:35.936053  9520 net.cpp:94] Creating Layer relu5
I0109 03:00:35.936055  9520 net.cpp:435] relu5 <- conv5
I0109 03:00:35.936060  9520 net.cpp:409] relu5 -> relu5
I0109 03:00:35.936066  9520 net.cpp:144] Setting up relu5
I0109 03:00:35.936070  9520 net.cpp:151] Top shape: 50 256 13 13 (2163200)
I0109 03:00:35.936076  9520 net.cpp:159] Memory required for data: 409004600
I0109 03:00:35.936080  9520 layer_factory.hpp:77] Creating layer pool5
I0109 03:00:35.936089  9520 net.cpp:94] Creating Layer pool5
I0109 03:00:35.936092  9520 net.cpp:435] pool5 <- relu5
I0109 03:00:35.936100  9520 net.cpp:409] pool5 -> pool5
I0109 03:00:35.936107  9520 net.cpp:144] Setting up pool5
I0109 03:00:35.936112  9520 net.cpp:151] Top shape: 50 256 6 6 (460800)
I0109 03:00:35.936117  9520 net.cpp:159] Memory required for data: 410847800
I0109 03:00:35.936122  9520 layer_factory.hpp:77] Creating layer fc6
I0109 03:00:35.936131  9520 net.cpp:94] Creating Layer fc6
I0109 03:00:35.936154  9520 net.cpp:435] fc6 <- pool5
I0109 03:00:35.936161  9520 net.cpp:409] fc6 -> fc6
I0109 03:00:36.303690  9520 net.cpp:144] Setting up fc6
I0109 03:00:36.303711  9520 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:36.303719  9520 net.cpp:159] Memory required for data: 411667000
I0109 03:00:36.303730  9520 layer_factory.hpp:77] Creating layer relu6
I0109 03:00:36.303736  9520 net.cpp:94] Creating Layer relu6
I0109 03:00:36.303740  9520 net.cpp:435] relu6 <- fc6
I0109 03:00:36.303746  9520 net.cpp:409] relu6 -> relu6
I0109 03:00:36.303757  9520 net.cpp:144] Setting up relu6
I0109 03:00:36.303761  9520 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:36.303764  9520 net.cpp:159] Memory required for data: 412486200
I0109 03:00:36.303767  9520 layer_factory.hpp:77] Creating layer drop6
I0109 03:00:36.303772  9520 net.cpp:94] Creating Layer drop6
I0109 03:00:36.303776  9520 net.cpp:435] drop6 <- relu6
I0109 03:00:36.303781  9520 net.cpp:409] drop6 -> drop6
I0109 03:00:36.303786  9520 net.cpp:144] Setting up drop6
I0109 03:00:36.303788  9520 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:36.303792  9520 net.cpp:159] Memory required for data: 413305400
I0109 03:00:36.303812  9520 layer_factory.hpp:77] Creating layer fc7
I0109 03:00:36.303817  9520 net.cpp:94] Creating Layer fc7
I0109 03:00:36.303819  9520 net.cpp:435] fc7 <- drop6
I0109 03:00:36.303824  9520 net.cpp:409] fc7 -> fc7
I0109 03:00:36.459699  9520 net.cpp:144] Setting up fc7
I0109 03:00:36.459720  9520 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:36.459728  9520 net.cpp:159] Memory required for data: 414124600
I0109 03:00:36.459753  9520 layer_factory.hpp:77] Creating layer bn7
I0109 03:00:36.459761  9520 net.cpp:94] Creating Layer bn7
I0109 03:00:36.459766  9520 net.cpp:435] bn7 <- fc7
I0109 03:00:36.459775  9520 net.cpp:409] bn7 -> bn7
I0109 03:00:36.459877  9520 net.cpp:144] Setting up bn7
I0109 03:00:36.459885  9520 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:36.459921  9520 net.cpp:159] Memory required for data: 414943800
I0109 03:00:36.459930  9520 layer_factory.hpp:77] Creating layer relu7
I0109 03:00:36.459935  9520 net.cpp:94] Creating Layer relu7
I0109 03:00:36.459939  9520 net.cpp:435] relu7 <- bn7
I0109 03:00:36.459942  9520 net.cpp:409] relu7 -> relu7
I0109 03:00:36.459949  9520 net.cpp:144] Setting up relu7
I0109 03:00:36.459952  9520 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:36.459956  9520 net.cpp:159] Memory required for data: 415763000
I0109 03:00:36.459959  9520 layer_factory.hpp:77] Creating layer drop7
I0109 03:00:36.459964  9520 net.cpp:94] Creating Layer drop7
I0109 03:00:36.459971  9520 net.cpp:435] drop7 <- relu7
I0109 03:00:36.459977  9520 net.cpp:409] drop7 -> drop7
I0109 03:00:36.459985  9520 net.cpp:144] Setting up drop7
I0109 03:00:36.459990  9520 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:36.459995  9520 net.cpp:159] Memory required for data: 416582200
I0109 03:00:36.460000  9520 layer_factory.hpp:77] Creating layer fc8
I0109 03:00:36.460007  9520 net.cpp:94] Creating Layer fc8
I0109 03:00:36.460012  9520 net.cpp:435] fc8 <- drop7
I0109 03:00:36.460018  9520 net.cpp:409] fc8 -> fc8
I0109 03:00:36.460146  9520 net.cpp:144] Setting up fc8
I0109 03:00:36.460152  9520 net.cpp:151] Top shape: 50 2 (100)
I0109 03:00:36.460156  9520 net.cpp:159] Memory required for data: 416582600
I0109 03:00:36.460161  9520 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0109 03:00:36.460167  9520 net.cpp:94] Creating Layer fc8_fc8_0_split
I0109 03:00:36.460170  9520 net.cpp:435] fc8_fc8_0_split <- fc8
I0109 03:00:36.460175  9520 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0109 03:00:36.460182  9520 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0109 03:00:36.460188  9520 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0109 03:00:36.460196  9520 net.cpp:144] Setting up fc8_fc8_0_split
I0109 03:00:36.460199  9520 net.cpp:151] Top shape: 50 2 (100)
I0109 03:00:36.460204  9520 net.cpp:151] Top shape: 50 2 (100)
I0109 03:00:36.460211  9520 net.cpp:151] Top shape: 50 2 (100)
I0109 03:00:36.460216  9520 net.cpp:159] Memory required for data: 416583800
I0109 03:00:36.460220  9520 layer_factory.hpp:77] Creating layer accuracy
I0109 03:00:36.460227  9520 net.cpp:94] Creating Layer accuracy
I0109 03:00:36.460232  9520 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0109 03:00:36.460238  9520 net.cpp:435] accuracy <- label_data_1_split_0
I0109 03:00:36.460245  9520 net.cpp:409] accuracy -> accuracy
I0109 03:00:36.460255  9520 net.cpp:144] Setting up accuracy
I0109 03:00:36.460268  9520 net.cpp:151] Top shape: (1)
I0109 03:00:36.460273  9520 net.cpp:159] Memory required for data: 416583804
I0109 03:00:36.460278  9520 layer_factory.hpp:77] Creating layer loss
I0109 03:00:36.460285  9520 net.cpp:94] Creating Layer loss
I0109 03:00:36.460290  9520 net.cpp:435] loss <- fc8_fc8_0_split_1
I0109 03:00:36.460312  9520 net.cpp:435] loss <- label_data_1_split_1
I0109 03:00:36.460317  9520 net.cpp:409] loss -> loss
I0109 03:00:36.460327  9520 layer_factory.hpp:77] Creating layer loss
I0109 03:00:36.460350  9520 net.cpp:144] Setting up loss
I0109 03:00:36.460355  9520 net.cpp:151] Top shape: (1)
I0109 03:00:36.460361  9520 net.cpp:154]     with loss weight 1
I0109 03:00:36.460394  9520 net.cpp:159] Memory required for data: 416583808
I0109 03:00:36.460398  9520 layer_factory.hpp:77] Creating layer accuracy-top1
I0109 03:00:36.460404  9520 net.cpp:94] Creating Layer accuracy-top1
I0109 03:00:36.460407  9520 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0109 03:00:36.460412  9520 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0109 03:00:36.460417  9520 net.cpp:409] accuracy-top1 -> top-1
I0109 03:00:36.460424  9520 net.cpp:144] Setting up accuracy-top1
I0109 03:00:36.460433  9520 net.cpp:151] Top shape: (1)
I0109 03:00:36.460438  9520 net.cpp:159] Memory required for data: 416583812
I0109 03:00:36.460443  9520 net.cpp:222] accuracy-top1 does not need backward computation.
I0109 03:00:36.460448  9520 net.cpp:220] loss needs backward computation.
I0109 03:00:36.460461  9520 net.cpp:222] accuracy does not need backward computation.
I0109 03:00:36.460466  9520 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0109 03:00:36.460472  9520 net.cpp:220] fc8 needs backward computation.
I0109 03:00:36.460476  9520 net.cpp:220] drop7 needs backward computation.
I0109 03:00:36.460484  9520 net.cpp:220] relu7 needs backward computation.
I0109 03:00:36.460489  9520 net.cpp:220] bn7 needs backward computation.
I0109 03:00:36.460494  9520 net.cpp:220] fc7 needs backward computation.
I0109 03:00:36.460498  9520 net.cpp:220] drop6 needs backward computation.
I0109 03:00:36.460503  9520 net.cpp:220] relu6 needs backward computation.
I0109 03:00:36.460507  9520 net.cpp:220] fc6 needs backward computation.
I0109 03:00:36.460511  9520 net.cpp:220] pool5 needs backward computation.
I0109 03:00:36.460515  9520 net.cpp:220] relu5 needs backward computation.
I0109 03:00:36.460520  9520 net.cpp:220] conv5 needs backward computation.
I0109 03:00:36.460523  9520 net.cpp:220] relu4 needs backward computation.
I0109 03:00:36.460527  9520 net.cpp:220] conv4 needs backward computation.
I0109 03:00:36.460531  9520 net.cpp:220] relu3 needs backward computation.
I0109 03:00:36.460536  9520 net.cpp:220] conv3 needs backward computation.
I0109 03:00:36.460539  9520 net.cpp:220] pool2 needs backward computation.
I0109 03:00:36.460544  9520 net.cpp:220] relu2 needs backward computation.
I0109 03:00:36.460551  9520 net.cpp:220] bn2 needs backward computation.
I0109 03:00:36.460556  9520 net.cpp:220] conv2 needs backward computation.
I0109 03:00:36.460561  9520 net.cpp:220] pool1 needs backward computation.
I0109 03:00:36.460564  9520 net.cpp:220] relu1 needs backward computation.
I0109 03:00:36.460568  9520 net.cpp:220] bn1 needs backward computation.
I0109 03:00:36.460573  9520 net.cpp:220] conv1 needs backward computation.
I0109 03:00:36.460579  9520 net.cpp:222] label_data_1_split does not need backward computation.
I0109 03:00:36.460585  9520 net.cpp:222] data does not need backward computation.
I0109 03:00:36.460590  9520 net.cpp:264] This network produces output accuracy
I0109 03:00:36.460594  9520 net.cpp:264] This network produces output loss
I0109 03:00:36.460600  9520 net.cpp:264] This network produces output top-1
I0109 03:00:36.460630  9520 net.cpp:284] Network initialization done.
I0109 03:00:36.460712  9520 net_counter.cpp:74] Convolution layer conv1 ops: 211120800
I0109 03:00:36.460719  9520 net_counter.cpp:78] Convolution layer conv1 params: 34944
I0109 03:00:36.460723  9520 net_counter.cpp:78] BatchNorm layer bn1 params: 385
I0109 03:00:36.460729  9520 net_counter.cpp:74] Convolution layer conv2 ops: 895981824
I0109 03:00:36.460733  9520 net_counter.cpp:78] Convolution layer conv2 params: 614656
I0109 03:00:36.460737  9520 net_counter.cpp:78] BatchNorm layer bn2 params: 1025
I0109 03:00:36.460741  9520 net_counter.cpp:74] Convolution layer conv3 ops: 299105664
I0109 03:00:36.460744  9520 net_counter.cpp:78] Convolution layer conv3 params: 885120
I0109 03:00:36.460748  9520 net_counter.cpp:74] Convolution layer conv4 ops: 448626048
I0109 03:00:36.460752  9520 net_counter.cpp:78] Convolution layer conv4 params: 1327488
I0109 03:00:36.460757  9520 net_counter.cpp:74] Convolution layer conv5 ops: 299084032
I0109 03:00:36.460759  9520 net_counter.cpp:78] Convolution layer conv5 params: 884992
I0109 03:00:36.460767  9520 net_counter.cpp:78] BatchNorm layer bn7 params: 16385
I0109 03:00:36.460772  9520 net_counter.cpp:84] Total operations: 2153918368
I0109 03:00:36.460777  9520 net_counter.cpp:85] Total params: 3764995
(c) Copyright 2016–2019 Xilinx, Inc. All rights reserved.

I0109 03:00:37.621917  9556 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0109 03:00:37.622138  9556 net.cpp:52] Initializing net from parameters:
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 78
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 154
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 26
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0109 03:00:37.622387  9556 layer_factory.hpp:77] Creating layer data
I0109 03:00:37.623394  9556 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 03:00:37.623901  9556 net.cpp:94] Creating Layer data
I0109 03:00:37.623910  9556 net.cpp:409] data -> data
I0109 03:00:37.623921  9556 net.cpp:409] data -> label
I0109 03:00:37.626521  9589 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0109 03:00:37.626545  9589 db_lmdb.cpp:38] Items count: 4000
I0109 03:00:37.626574  9589 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0109 03:00:37.626811  9556 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0109 03:00:37.626822  9556 data_layer.cpp:83] output data size: 50,3,227,227
I0109 03:00:37.722193  9556 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 03:00:37.722298  9556 net.cpp:144] Setting up data
I0109 03:00:37.722304  9556 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0109 03:00:37.722313  9556 net.cpp:151] Top shape: 50 (50)
I0109 03:00:37.722317  9556 net.cpp:159] Memory required for data: 30917600
I0109 03:00:37.722322  9556 layer_factory.hpp:77] Creating layer label_data_1_split
I0109 03:00:37.722330  9556 net.cpp:94] Creating Layer label_data_1_split
I0109 03:00:37.722335  9556 net.cpp:435] label_data_1_split <- label
I0109 03:00:37.722342  9556 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0109 03:00:37.722349  9556 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0109 03:00:37.722354  9556 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0109 03:00:37.722365  9556 net.cpp:144] Setting up label_data_1_split
I0109 03:00:37.722373  9556 net.cpp:151] Top shape: 50 (50)
I0109 03:00:37.722376  9556 net.cpp:151] Top shape: 50 (50)
I0109 03:00:37.722380  9556 net.cpp:151] Top shape: 50 (50)
I0109 03:00:37.722383  9556 net.cpp:159] Memory required for data: 30918200
I0109 03:00:37.722386  9556 layer_factory.hpp:77] Creating layer conv1
I0109 03:00:37.722400  9556 net.cpp:94] Creating Layer conv1
I0109 03:00:37.722405  9556 net.cpp:435] conv1 <- data
I0109 03:00:37.722410  9556 net.cpp:409] conv1 -> conv1
I0109 03:00:37.722744  9556 net.cpp:144] Setting up conv1
I0109 03:00:37.722751  9556 net.cpp:151] Top shape: 50 78 55 55 (11797500)
I0109 03:00:37.722756  9556 net.cpp:159] Memory required for data: 78108200
I0109 03:00:37.722767  9556 layer_factory.hpp:77] Creating layer bn1
I0109 03:00:37.722777  9556 net.cpp:94] Creating Layer bn1
I0109 03:00:37.722781  9556 net.cpp:435] bn1 <- conv1
I0109 03:00:37.722786  9556 net.cpp:409] bn1 -> bn1
I0109 03:00:37.722812  9556 net.cpp:144] Setting up bn1
I0109 03:00:37.722829  9556 net.cpp:151] Top shape: 50 78 55 55 (11797500)
I0109 03:00:37.722834  9556 net.cpp:159] Memory required for data: 125298200
I0109 03:00:37.722843  9556 layer_factory.hpp:77] Creating layer relu1
I0109 03:00:37.722849  9556 net.cpp:94] Creating Layer relu1
I0109 03:00:37.722853  9556 net.cpp:435] relu1 <- bn1
I0109 03:00:37.722857  9556 net.cpp:409] relu1 -> relu1
I0109 03:00:37.722864  9556 net.cpp:144] Setting up relu1
I0109 03:00:37.722868  9556 net.cpp:151] Top shape: 50 78 55 55 (11797500)
I0109 03:00:37.722873  9556 net.cpp:159] Memory required for data: 172488200
I0109 03:00:37.722877  9556 layer_factory.hpp:77] Creating layer pool1
I0109 03:00:37.722882  9556 net.cpp:94] Creating Layer pool1
I0109 03:00:37.722887  9556 net.cpp:435] pool1 <- relu1
I0109 03:00:37.722890  9556 net.cpp:409] pool1 -> pool1
I0109 03:00:37.722898  9556 net.cpp:144] Setting up pool1
I0109 03:00:37.722903  9556 net.cpp:151] Top shape: 50 78 27 27 (2843100)
I0109 03:00:37.722908  9556 net.cpp:159] Memory required for data: 183860600
I0109 03:00:37.722910  9556 layer_factory.hpp:77] Creating layer conv2
I0109 03:00:37.722918  9556 net.cpp:94] Creating Layer conv2
I0109 03:00:37.722920  9556 net.cpp:435] conv2 <- pool1
I0109 03:00:37.722925  9556 net.cpp:409] conv2 -> conv2
I0109 03:00:37.725639  9556 net.cpp:144] Setting up conv2
I0109 03:00:37.725648  9556 net.cpp:151] Top shape: 50 154 27 27 (5613300)
I0109 03:00:37.725654  9556 net.cpp:159] Memory required for data: 206313800
I0109 03:00:37.725662  9556 layer_factory.hpp:77] Creating layer bn2
I0109 03:00:37.725669  9556 net.cpp:94] Creating Layer bn2
I0109 03:00:37.725673  9556 net.cpp:435] bn2 <- conv2
I0109 03:00:37.725678  9556 net.cpp:409] bn2 -> bn2
I0109 03:00:37.725703  9556 net.cpp:144] Setting up bn2
I0109 03:00:37.725708  9556 net.cpp:151] Top shape: 50 154 27 27 (5613300)
I0109 03:00:37.725713  9556 net.cpp:159] Memory required for data: 228767000
I0109 03:00:37.725718  9556 layer_factory.hpp:77] Creating layer relu2
I0109 03:00:37.725723  9556 net.cpp:94] Creating Layer relu2
I0109 03:00:37.725728  9556 net.cpp:435] relu2 <- bn2
I0109 03:00:37.725731  9556 net.cpp:409] relu2 -> relu2
I0109 03:00:37.725737  9556 net.cpp:144] Setting up relu2
I0109 03:00:37.725741  9556 net.cpp:151] Top shape: 50 154 27 27 (5613300)
I0109 03:00:37.725745  9556 net.cpp:159] Memory required for data: 251220200
I0109 03:00:37.725749  9556 layer_factory.hpp:77] Creating layer pool2
I0109 03:00:37.725754  9556 net.cpp:94] Creating Layer pool2
I0109 03:00:37.725759  9556 net.cpp:435] pool2 <- relu2
I0109 03:00:37.725762  9556 net.cpp:409] pool2 -> pool2
I0109 03:00:37.725769  9556 net.cpp:144] Setting up pool2
I0109 03:00:37.725771  9556 net.cpp:151] Top shape: 50 154 13 13 (1301300)
I0109 03:00:37.725776  9556 net.cpp:159] Memory required for data: 256425400
I0109 03:00:37.725780  9556 layer_factory.hpp:77] Creating layer conv3
I0109 03:00:37.725803  9556 net.cpp:94] Creating Layer conv3
I0109 03:00:37.725806  9556 net.cpp:435] conv3 <- pool2
I0109 03:00:37.725811  9556 net.cpp:409] conv3 -> conv3
I0109 03:00:37.726518  9556 net.cpp:144] Setting up conv3
I0109 03:00:37.726526  9556 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0109 03:00:37.726531  9556 net.cpp:159] Memory required for data: 257777400
I0109 03:00:37.726536  9556 layer_factory.hpp:77] Creating layer relu3
I0109 03:00:37.726541  9556 net.cpp:94] Creating Layer relu3
I0109 03:00:37.726545  9556 net.cpp:435] relu3 <- conv3
I0109 03:00:37.726550  9556 net.cpp:409] relu3 -> relu3
I0109 03:00:37.726557  9556 net.cpp:144] Setting up relu3
I0109 03:00:37.726560  9556 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0109 03:00:37.726565  9556 net.cpp:159] Memory required for data: 259129400
I0109 03:00:37.726569  9556 layer_factory.hpp:77] Creating layer conv4
I0109 03:00:37.726575  9556 net.cpp:94] Creating Layer conv4
I0109 03:00:37.726579  9556 net.cpp:435] conv4 <- relu3
I0109 03:00:37.726584  9556 net.cpp:409] conv4 -> conv4
I0109 03:00:37.726733  9556 net.cpp:144] Setting up conv4
I0109 03:00:37.726739  9556 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0109 03:00:37.726752  9556 net.cpp:159] Memory required for data: 260481400
I0109 03:00:37.726760  9556 layer_factory.hpp:77] Creating layer relu4
I0109 03:00:37.726764  9556 net.cpp:94] Creating Layer relu4
I0109 03:00:37.726768  9556 net.cpp:435] relu4 <- conv4
I0109 03:00:37.726773  9556 net.cpp:409] relu4 -> relu4
I0109 03:00:37.726779  9556 net.cpp:144] Setting up relu4
I0109 03:00:37.726783  9556 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0109 03:00:37.726788  9556 net.cpp:159] Memory required for data: 261833400
I0109 03:00:37.726791  9556 layer_factory.hpp:77] Creating layer conv5
I0109 03:00:37.726799  9556 net.cpp:94] Creating Layer conv5
I0109 03:00:37.726802  9556 net.cpp:435] conv5 <- relu4
I0109 03:00:37.726807  9556 net.cpp:409] conv5 -> conv5
I0109 03:00:37.726936  9556 net.cpp:144] Setting up conv5
I0109 03:00:37.726941  9556 net.cpp:151] Top shape: 50 26 13 13 (219700)
I0109 03:00:37.726946  9556 net.cpp:159] Memory required for data: 262712200
I0109 03:00:37.726953  9556 layer_factory.hpp:77] Creating layer relu5
I0109 03:00:37.726958  9556 net.cpp:94] Creating Layer relu5
I0109 03:00:37.726960  9556 net.cpp:435] relu5 <- conv5
I0109 03:00:37.726965  9556 net.cpp:409] relu5 -> relu5
I0109 03:00:37.726971  9556 net.cpp:144] Setting up relu5
I0109 03:00:37.726975  9556 net.cpp:151] Top shape: 50 26 13 13 (219700)
I0109 03:00:37.726980  9556 net.cpp:159] Memory required for data: 263591000
I0109 03:00:37.726984  9556 layer_factory.hpp:77] Creating layer pool5
I0109 03:00:37.726989  9556 net.cpp:94] Creating Layer pool5
I0109 03:00:37.726994  9556 net.cpp:435] pool5 <- relu5
I0109 03:00:37.726997  9556 net.cpp:409] pool5 -> pool5
I0109 03:00:37.727005  9556 net.cpp:144] Setting up pool5
I0109 03:00:37.727007  9556 net.cpp:151] Top shape: 50 26 6 6 (46800)
I0109 03:00:37.727013  9556 net.cpp:159] Memory required for data: 263778200
I0109 03:00:37.727017  9556 layer_factory.hpp:77] Creating layer fc6
I0109 03:00:37.727023  9556 net.cpp:94] Creating Layer fc6
I0109 03:00:37.727027  9556 net.cpp:435] fc6 <- pool5
I0109 03:00:37.727031  9556 net.cpp:409] fc6 -> fc6
I0109 03:00:37.770010  9556 net.cpp:144] Setting up fc6
I0109 03:00:37.770027  9556 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:37.770035  9556 net.cpp:159] Memory required for data: 264597400
I0109 03:00:37.770046  9556 layer_factory.hpp:77] Creating layer relu6
I0109 03:00:37.770053  9556 net.cpp:94] Creating Layer relu6
I0109 03:00:37.770057  9556 net.cpp:435] relu6 <- fc6
I0109 03:00:37.770063  9556 net.cpp:409] relu6 -> relu6
I0109 03:00:37.770074  9556 net.cpp:144] Setting up relu6
I0109 03:00:37.770077  9556 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:37.770082  9556 net.cpp:159] Memory required for data: 265416600
I0109 03:00:37.770085  9556 layer_factory.hpp:77] Creating layer drop6
I0109 03:00:37.770092  9556 net.cpp:94] Creating Layer drop6
I0109 03:00:37.770095  9556 net.cpp:435] drop6 <- relu6
I0109 03:00:37.770099  9556 net.cpp:409] drop6 -> drop6
I0109 03:00:37.770107  9556 net.cpp:144] Setting up drop6
I0109 03:00:37.770109  9556 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:37.770114  9556 net.cpp:159] Memory required for data: 266235800
I0109 03:00:37.770117  9556 layer_factory.hpp:77] Creating layer fc7
I0109 03:00:37.770124  9556 net.cpp:94] Creating Layer fc7
I0109 03:00:37.770128  9556 net.cpp:435] fc7 <- drop6
I0109 03:00:37.770134  9556 net.cpp:409] fc7 -> fc7
I0109 03:00:37.932171  9556 net.cpp:144] Setting up fc7
I0109 03:00:37.932194  9556 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:37.932201  9556 net.cpp:159] Memory required for data: 267055000
I0109 03:00:37.932226  9556 layer_factory.hpp:77] Creating layer bn7
I0109 03:00:37.932235  9556 net.cpp:94] Creating Layer bn7
I0109 03:00:37.932238  9556 net.cpp:435] bn7 <- fc7
I0109 03:00:37.932245  9556 net.cpp:409] bn7 -> bn7
I0109 03:00:37.932341  9556 net.cpp:144] Setting up bn7
I0109 03:00:37.932348  9556 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:37.932366  9556 net.cpp:159] Memory required for data: 267874200
I0109 03:00:37.932386  9556 layer_factory.hpp:77] Creating layer relu7
I0109 03:00:37.932394  9556 net.cpp:94] Creating Layer relu7
I0109 03:00:37.932397  9556 net.cpp:435] relu7 <- bn7
I0109 03:00:37.932401  9556 net.cpp:409] relu7 -> relu7
I0109 03:00:37.932408  9556 net.cpp:144] Setting up relu7
I0109 03:00:37.932411  9556 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:37.932415  9556 net.cpp:159] Memory required for data: 268693400
I0109 03:00:37.932418  9556 layer_factory.hpp:77] Creating layer drop7
I0109 03:00:37.932423  9556 net.cpp:94] Creating Layer drop7
I0109 03:00:37.932426  9556 net.cpp:435] drop7 <- relu7
I0109 03:00:37.932431  9556 net.cpp:409] drop7 -> drop7
I0109 03:00:37.932437  9556 net.cpp:144] Setting up drop7
I0109 03:00:37.932440  9556 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:37.932444  9556 net.cpp:159] Memory required for data: 269512600
I0109 03:00:37.932447  9556 layer_factory.hpp:77] Creating layer fc8
I0109 03:00:37.932452  9556 net.cpp:94] Creating Layer fc8
I0109 03:00:37.932456  9556 net.cpp:435] fc8 <- drop7
I0109 03:00:37.932461  9556 net.cpp:409] fc8 -> fc8
I0109 03:00:37.932571  9556 net.cpp:144] Setting up fc8
I0109 03:00:37.932576  9556 net.cpp:151] Top shape: 50 2 (100)
I0109 03:00:37.932581  9556 net.cpp:159] Memory required for data: 269513000
I0109 03:00:37.932586  9556 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0109 03:00:37.932592  9556 net.cpp:94] Creating Layer fc8_fc8_0_split
I0109 03:00:37.932595  9556 net.cpp:435] fc8_fc8_0_split <- fc8
I0109 03:00:37.932600  9556 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0109 03:00:37.932606  9556 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0109 03:00:37.932612  9556 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0109 03:00:37.932621  9556 net.cpp:144] Setting up fc8_fc8_0_split
I0109 03:00:37.932626  9556 net.cpp:151] Top shape: 50 2 (100)
I0109 03:00:37.932629  9556 net.cpp:151] Top shape: 50 2 (100)
I0109 03:00:37.932633  9556 net.cpp:151] Top shape: 50 2 (100)
I0109 03:00:37.932638  9556 net.cpp:159] Memory required for data: 269514200
I0109 03:00:37.932641  9556 layer_factory.hpp:77] Creating layer accuracy
I0109 03:00:37.932647  9556 net.cpp:94] Creating Layer accuracy
I0109 03:00:37.932651  9556 net.cpp:435] accuracy <- fc8_fc8_0_split_0
I0109 03:00:37.932655  9556 net.cpp:435] accuracy <- label_data_1_split_0
I0109 03:00:37.932660  9556 net.cpp:409] accuracy -> accuracy
I0109 03:00:37.932667  9556 net.cpp:144] Setting up accuracy
I0109 03:00:37.932670  9556 net.cpp:151] Top shape: (1)
I0109 03:00:37.932673  9556 net.cpp:159] Memory required for data: 269514204
I0109 03:00:37.932677  9556 layer_factory.hpp:77] Creating layer loss
I0109 03:00:37.932684  9556 net.cpp:94] Creating Layer loss
I0109 03:00:37.932688  9556 net.cpp:435] loss <- fc8_fc8_0_split_1
I0109 03:00:37.932693  9556 net.cpp:435] loss <- label_data_1_split_1
I0109 03:00:37.932696  9556 net.cpp:409] loss -> loss
I0109 03:00:37.932705  9556 layer_factory.hpp:77] Creating layer loss
I0109 03:00:37.932737  9556 net.cpp:144] Setting up loss
I0109 03:00:37.932744  9556 net.cpp:151] Top shape: (1)
I0109 03:00:37.932747  9556 net.cpp:154]     with loss weight 1
I0109 03:00:37.932782  9556 net.cpp:159] Memory required for data: 269514208
I0109 03:00:37.932786  9556 layer_factory.hpp:77] Creating layer accuracy-top1
I0109 03:00:37.932792  9556 net.cpp:94] Creating Layer accuracy-top1
I0109 03:00:37.932796  9556 net.cpp:435] accuracy-top1 <- fc8_fc8_0_split_2
I0109 03:00:37.932801  9556 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0109 03:00:37.932806  9556 net.cpp:409] accuracy-top1 -> top-1
I0109 03:00:37.932811  9556 net.cpp:144] Setting up accuracy-top1
I0109 03:00:37.932814  9556 net.cpp:151] Top shape: (1)
I0109 03:00:37.932818  9556 net.cpp:159] Memory required for data: 269514212
I0109 03:00:37.932822  9556 net.cpp:222] accuracy-top1 does not need backward computation.
I0109 03:00:37.932826  9556 net.cpp:220] loss needs backward computation.
I0109 03:00:37.932832  9556 net.cpp:222] accuracy does not need backward computation.
I0109 03:00:37.932842  9556 net.cpp:220] fc8_fc8_0_split needs backward computation.
I0109 03:00:37.932845  9556 net.cpp:220] fc8 needs backward computation.
I0109 03:00:37.932849  9556 net.cpp:220] drop7 needs backward computation.
I0109 03:00:37.932853  9556 net.cpp:220] relu7 needs backward computation.
I0109 03:00:37.932857  9556 net.cpp:220] bn7 needs backward computation.
I0109 03:00:37.932862  9556 net.cpp:220] fc7 needs backward computation.
I0109 03:00:37.932865  9556 net.cpp:220] drop6 needs backward computation.
I0109 03:00:37.932869  9556 net.cpp:220] relu6 needs backward computation.
I0109 03:00:37.932873  9556 net.cpp:220] fc6 needs backward computation.
I0109 03:00:37.932878  9556 net.cpp:220] pool5 needs backward computation.
I0109 03:00:37.932883  9556 net.cpp:220] relu5 needs backward computation.
I0109 03:00:37.932886  9556 net.cpp:220] conv5 needs backward computation.
I0109 03:00:37.932890  9556 net.cpp:220] relu4 needs backward computation.
I0109 03:00:37.932894  9556 net.cpp:220] conv4 needs backward computation.
I0109 03:00:37.932898  9556 net.cpp:220] relu3 needs backward computation.
I0109 03:00:37.932902  9556 net.cpp:220] conv3 needs backward computation.
I0109 03:00:37.932906  9556 net.cpp:220] pool2 needs backward computation.
I0109 03:00:37.932910  9556 net.cpp:220] relu2 needs backward computation.
I0109 03:00:37.932914  9556 net.cpp:220] bn2 needs backward computation.
I0109 03:00:37.932919  9556 net.cpp:220] conv2 needs backward computation.
I0109 03:00:37.932924  9556 net.cpp:220] pool1 needs backward computation.
I0109 03:00:37.932929  9556 net.cpp:220] relu1 needs backward computation.
I0109 03:00:37.932932  9556 net.cpp:220] bn1 needs backward computation.
I0109 03:00:37.932936  9556 net.cpp:220] conv1 needs backward computation.
I0109 03:00:37.932941  9556 net.cpp:222] label_data_1_split does not need backward computation.
I0109 03:00:37.932946  9556 net.cpp:222] data does not need backward computation.
I0109 03:00:37.932950  9556 net.cpp:264] This network produces output accuracy
I0109 03:00:37.932953  9556 net.cpp:264] This network produces output loss
I0109 03:00:37.932957  9556 net.cpp:264] This network produces output top-1
I0109 03:00:37.932981  9556 net.cpp:284] Network initialization done.
I0109 03:00:37.933060  9556 net_counter.cpp:74] Convolution layer conv1 ops: 171535650
I0109 03:00:37.933065  9556 net_counter.cpp:78] Convolution layer conv1 params: 28392
I0109 03:00:37.933071  9556 net_counter.cpp:78] BatchNorm layer bn1 params: 313
I0109 03:00:37.933075  9556 net_counter.cpp:74] Convolution layer conv2 ops: 437949666
I0109 03:00:37.933079  9556 net_counter.cpp:78] Convolution layer conv2 params: 300454
I0109 03:00:37.933082  9556 net_counter.cpp:78] BatchNorm layer bn2 params: 617
I0109 03:00:37.933086  9556 net_counter.cpp:74] Convolution layer conv3 ops: 18745480
I0109 03:00:37.933090  9556 net_counter.cpp:78] Convolution layer conv3 params: 55480
I0109 03:00:37.933094  9556 net_counter.cpp:74] Convolution layer conv4 ops: 4873960
I0109 03:00:37.933097  9556 net_counter.cpp:78] Convolution layer conv4 params: 14440
I0109 03:00:37.933101  9556 net_counter.cpp:74] Convolution layer conv5 ops: 3168074
I0109 03:00:37.933104  9556 net_counter.cpp:78] Convolution layer conv5 params: 9386
I0109 03:00:37.933109  9556 net_counter.cpp:78] BatchNorm layer bn7 params: 16385
I0109 03:00:37.933112  9556 net_counter.cpp:84] Total operations: 636272830
I0109 03:00:37.933116  9556 net_counter.cpp:85] Total params: 425467
mv: '/workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/transformed.caffemodel' and '/workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/pruning/alexnetBNnoLRN/transformed.caffemodel' are the same file
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0109 03:00:38.851976  9648 gpu_memory.cpp:53] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0109 03:00:38.852010  9648 gpu_memory.cpp:55] Total memory: 25620447232, Free: 25038880768, dev_info[0]: total=25620447232 free=25038880768
I0109 03:00:38.852815  9648 vai_q.cpp:260] Using GPUs 0
I0109 03:00:38.853075  9648 vai_q.cpp:265] GPU 0: Quadro P6000
I0109 03:00:40.292085  9648 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0109 03:00:40.292112  9648 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0109 03:00:40.292115  9648 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0109 03:00:40.292119  9648 net.cpp:52] Initializing net from parameters:
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  image_data_param {
    source: "deploy/alexnetBNnoLRN/pruned/data/calib/calibration.txt"
    batch_size: 10
    shuffle: true
    root_folder: "deploy/alexnetBNnoLRN/pruned/data/calib/"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 78
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 154
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 26
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "relu6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "relu7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0109 03:00:40.292310  9648 layer_factory.hpp:77] Creating layer data
I0109 03:00:40.292333  9648 net.cpp:94] Creating Layer data
I0109 03:00:40.292340  9648 net.cpp:409] data -> data
I0109 03:00:40.292352  9648 net.cpp:409] data -> label
I0109 03:00:40.292718  9648 image_data_layer.cpp:41] Opening file deploy/alexnetBNnoLRN/pruned/data/calib/calibration.txt
I0109 03:00:40.292842  9648 image_data_layer.cpp:51] Shuffling data
I0109 03:00:40.292857  9648 image_data_layer.cpp:56] A total of 200 images.
I0109 03:00:40.294188  9648 image_data_layer.cpp:84] output data size: 10,3,227,227
I0109 03:00:40.315536  9648 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 03:00:40.315598  9648 net.cpp:144] Setting up data
I0109 03:00:40.315603  9648 net.cpp:151] Top shape: 10 3 227 227 (1545870)
I0109 03:00:40.315611  9648 net.cpp:151] Top shape: 10 (10)
I0109 03:00:40.315615  9648 net.cpp:159] Memory required for data: 6183520
I0109 03:00:40.315619  9648 layer_factory.hpp:77] Creating layer conv1
I0109 03:00:40.315635  9648 net.cpp:94] Creating Layer conv1
I0109 03:00:40.315639  9648 net.cpp:435] conv1 <- data
I0109 03:00:40.315645  9648 net.cpp:409] conv1 -> conv1
I0109 03:00:40.316154  9648 net.cpp:144] Setting up conv1
I0109 03:00:40.316160  9648 net.cpp:151] Top shape: 10 78 55 55 (2359500)
I0109 03:00:40.316165  9648 net.cpp:159] Memory required for data: 15621520
I0109 03:00:40.316185  9648 layer_factory.hpp:77] Creating layer bn1
I0109 03:00:40.316196  9648 net.cpp:94] Creating Layer bn1
I0109 03:00:40.316200  9648 net.cpp:435] bn1 <- conv1
I0109 03:00:40.316203  9648 net.cpp:409] bn1 -> bn1
I0109 03:00:40.316705  9648 net.cpp:144] Setting up bn1
I0109 03:00:40.316710  9648 net.cpp:151] Top shape: 10 78 55 55 (2359500)
I0109 03:00:40.316715  9648 net.cpp:159] Memory required for data: 25059520
I0109 03:00:40.316723  9648 layer_factory.hpp:77] Creating layer relu1
I0109 03:00:40.316730  9648 net.cpp:94] Creating Layer relu1
I0109 03:00:40.316732  9648 net.cpp:435] relu1 <- bn1
I0109 03:00:40.316735  9648 net.cpp:409] relu1 -> relu1
I0109 03:00:40.316753  9648 net.cpp:144] Setting up relu1
I0109 03:00:40.316758  9648 net.cpp:151] Top shape: 10 78 55 55 (2359500)
I0109 03:00:40.316763  9648 net.cpp:159] Memory required for data: 34497520
I0109 03:00:40.316766  9648 layer_factory.hpp:77] Creating layer pool1
I0109 03:00:40.316771  9648 net.cpp:94] Creating Layer pool1
I0109 03:00:40.316774  9648 net.cpp:435] pool1 <- relu1
I0109 03:00:40.316777  9648 net.cpp:409] pool1 -> pool1
I0109 03:00:40.316802  9648 net.cpp:144] Setting up pool1
I0109 03:00:40.316809  9648 net.cpp:151] Top shape: 10 78 27 27 (568620)
I0109 03:00:40.316813  9648 net.cpp:159] Memory required for data: 36772000
I0109 03:00:40.316817  9648 layer_factory.hpp:77] Creating layer conv2
I0109 03:00:40.316823  9648 net.cpp:94] Creating Layer conv2
I0109 03:00:40.316828  9648 net.cpp:435] conv2 <- pool1
I0109 03:00:40.316831  9648 net.cpp:409] conv2 -> conv2
I0109 03:00:40.319949  9648 net.cpp:144] Setting up conv2
I0109 03:00:40.319962  9648 net.cpp:151] Top shape: 10 154 27 27 (1122660)
I0109 03:00:40.319968  9648 net.cpp:159] Memory required for data: 41262640
I0109 03:00:40.319975  9648 layer_factory.hpp:77] Creating layer bn2
I0109 03:00:40.319983  9648 net.cpp:94] Creating Layer bn2
I0109 03:00:40.320004  9648 net.cpp:435] bn2 <- conv2
I0109 03:00:40.320010  9648 net.cpp:409] bn2 -> bn2
I0109 03:00:40.320535  9648 net.cpp:144] Setting up bn2
I0109 03:00:40.320541  9648 net.cpp:151] Top shape: 10 154 27 27 (1122660)
I0109 03:00:40.320545  9648 net.cpp:159] Memory required for data: 45753280
I0109 03:00:40.320552  9648 layer_factory.hpp:77] Creating layer relu2
I0109 03:00:40.320557  9648 net.cpp:94] Creating Layer relu2
I0109 03:00:40.320560  9648 net.cpp:435] relu2 <- bn2
I0109 03:00:40.320564  9648 net.cpp:409] relu2 -> relu2
I0109 03:00:40.320580  9648 net.cpp:144] Setting up relu2
I0109 03:00:40.320585  9648 net.cpp:151] Top shape: 10 154 27 27 (1122660)
I0109 03:00:40.320588  9648 net.cpp:159] Memory required for data: 50243920
I0109 03:00:40.320591  9648 layer_factory.hpp:77] Creating layer pool2
I0109 03:00:40.320595  9648 net.cpp:94] Creating Layer pool2
I0109 03:00:40.320598  9648 net.cpp:435] pool2 <- relu2
I0109 03:00:40.320603  9648 net.cpp:409] pool2 -> pool2
I0109 03:00:40.320624  9648 net.cpp:144] Setting up pool2
I0109 03:00:40.320628  9648 net.cpp:151] Top shape: 10 154 13 13 (260260)
I0109 03:00:40.320633  9648 net.cpp:159] Memory required for data: 51284960
I0109 03:00:40.320636  9648 layer_factory.hpp:77] Creating layer conv3
I0109 03:00:40.320643  9648 net.cpp:94] Creating Layer conv3
I0109 03:00:40.320647  9648 net.cpp:435] conv3 <- pool2
I0109 03:00:40.320650  9648 net.cpp:409] conv3 -> conv3
I0109 03:00:40.321846  9648 net.cpp:144] Setting up conv3
I0109 03:00:40.321853  9648 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0109 03:00:40.321859  9648 net.cpp:159] Memory required for data: 51555360
I0109 03:00:40.321864  9648 layer_factory.hpp:77] Creating layer relu3
I0109 03:00:40.321869  9648 net.cpp:94] Creating Layer relu3
I0109 03:00:40.321872  9648 net.cpp:435] relu3 <- conv3
I0109 03:00:40.321877  9648 net.cpp:409] relu3 -> relu3
I0109 03:00:40.321889  9648 net.cpp:144] Setting up relu3
I0109 03:00:40.321894  9648 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0109 03:00:40.321898  9648 net.cpp:159] Memory required for data: 51825760
I0109 03:00:40.321900  9648 layer_factory.hpp:77] Creating layer conv4
I0109 03:00:40.321907  9648 net.cpp:94] Creating Layer conv4
I0109 03:00:40.321910  9648 net.cpp:435] conv4 <- relu3
I0109 03:00:40.321914  9648 net.cpp:409] conv4 -> conv4
I0109 03:00:40.322233  9648 net.cpp:144] Setting up conv4
I0109 03:00:40.322239  9648 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0109 03:00:40.322243  9648 net.cpp:159] Memory required for data: 52096160
I0109 03:00:40.322261  9648 layer_factory.hpp:77] Creating layer relu4
I0109 03:00:40.322266  9648 net.cpp:94] Creating Layer relu4
I0109 03:00:40.322269  9648 net.cpp:435] relu4 <- conv4
I0109 03:00:40.322273  9648 net.cpp:409] relu4 -> relu4
I0109 03:00:40.322288  9648 net.cpp:144] Setting up relu4
I0109 03:00:40.322293  9648 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0109 03:00:40.322297  9648 net.cpp:159] Memory required for data: 52366560
I0109 03:00:40.322300  9648 layer_factory.hpp:77] Creating layer conv5
I0109 03:00:40.322305  9648 net.cpp:94] Creating Layer conv5
I0109 03:00:40.322309  9648 net.cpp:435] conv5 <- relu4
I0109 03:00:40.322312  9648 net.cpp:409] conv5 -> conv5
I0109 03:00:40.322573  9648 net.cpp:144] Setting up conv5
I0109 03:00:40.322578  9648 net.cpp:151] Top shape: 10 26 13 13 (43940)
I0109 03:00:40.322584  9648 net.cpp:159] Memory required for data: 52542320
I0109 03:00:40.322588  9648 layer_factory.hpp:77] Creating layer relu5
I0109 03:00:40.322592  9648 net.cpp:94] Creating Layer relu5
I0109 03:00:40.322595  9648 net.cpp:435] relu5 <- conv5
I0109 03:00:40.322598  9648 net.cpp:409] relu5 -> relu5
I0109 03:00:40.322613  9648 net.cpp:144] Setting up relu5
I0109 03:00:40.322618  9648 net.cpp:151] Top shape: 10 26 13 13 (43940)
I0109 03:00:40.322621  9648 net.cpp:159] Memory required for data: 52718080
I0109 03:00:40.322624  9648 layer_factory.hpp:77] Creating layer pool5
I0109 03:00:40.322628  9648 net.cpp:94] Creating Layer pool5
I0109 03:00:40.322631  9648 net.cpp:435] pool5 <- relu5
I0109 03:00:40.322635  9648 net.cpp:409] pool5 -> pool5
I0109 03:00:40.322659  9648 net.cpp:144] Setting up pool5
I0109 03:00:40.322662  9648 net.cpp:151] Top shape: 10 26 6 6 (9360)
I0109 03:00:40.322667  9648 net.cpp:159] Memory required for data: 52755520
I0109 03:00:40.322669  9648 layer_factory.hpp:77] Creating layer fc6
I0109 03:00:40.322681  9648 net.cpp:94] Creating Layer fc6
I0109 03:00:40.322685  9648 net.cpp:435] fc6 <- pool5
I0109 03:00:40.322688  9648 net.cpp:409] fc6 -> fc6
I0109 03:00:40.355661  9648 net.cpp:144] Setting up fc6
I0109 03:00:40.355681  9648 net.cpp:151] Top shape: 10 4096 (40960)
I0109 03:00:40.355688  9648 net.cpp:159] Memory required for data: 52919360
I0109 03:00:40.355700  9648 layer_factory.hpp:77] Creating layer relu6
I0109 03:00:40.355707  9648 net.cpp:94] Creating Layer relu6
I0109 03:00:40.355711  9648 net.cpp:435] relu6 <- fc6
I0109 03:00:40.355717  9648 net.cpp:409] relu6 -> relu6
I0109 03:00:40.355741  9648 net.cpp:144] Setting up relu6
I0109 03:00:40.355744  9648 net.cpp:151] Top shape: 10 4096 (40960)
I0109 03:00:40.355748  9648 net.cpp:159] Memory required for data: 53083200
I0109 03:00:40.355751  9648 layer_factory.hpp:77] Creating layer fc7
I0109 03:00:40.355758  9648 net.cpp:94] Creating Layer fc7
I0109 03:00:40.355762  9648 net.cpp:435] fc7 <- relu6
I0109 03:00:40.355765  9648 net.cpp:409] fc7 -> fc7
I0109 03:00:40.493579  9648 net.cpp:144] Setting up fc7
I0109 03:00:40.493599  9648 net.cpp:151] Top shape: 10 4096 (40960)
I0109 03:00:40.493607  9648 net.cpp:159] Memory required for data: 53247040
I0109 03:00:40.493616  9648 layer_factory.hpp:77] Creating layer bn7
I0109 03:00:40.493628  9648 net.cpp:94] Creating Layer bn7
I0109 03:00:40.493630  9648 net.cpp:435] bn7 <- fc7
I0109 03:00:40.493636  9648 net.cpp:409] bn7 -> bn7
I0109 03:00:40.494081  9648 net.cpp:144] Setting up bn7
I0109 03:00:40.494087  9648 net.cpp:151] Top shape: 10 4096 (40960)
I0109 03:00:40.494091  9648 net.cpp:159] Memory required for data: 53410880
I0109 03:00:40.494113  9648 layer_factory.hpp:77] Creating layer relu7
I0109 03:00:40.494118  9648 net.cpp:94] Creating Layer relu7
I0109 03:00:40.494122  9648 net.cpp:435] relu7 <- bn7
I0109 03:00:40.494125  9648 net.cpp:409] relu7 -> relu7
I0109 03:00:40.494140  9648 net.cpp:144] Setting up relu7
I0109 03:00:40.494145  9648 net.cpp:151] Top shape: 10 4096 (40960)
I0109 03:00:40.494149  9648 net.cpp:159] Memory required for data: 53574720
I0109 03:00:40.494153  9648 layer_factory.hpp:77] Creating layer fc8
I0109 03:00:40.494158  9648 net.cpp:94] Creating Layer fc8
I0109 03:00:40.494161  9648 net.cpp:435] fc8 <- relu7
I0109 03:00:40.494166  9648 net.cpp:409] fc8 -> fc8
I0109 03:00:40.494324  9648 net.cpp:144] Setting up fc8
I0109 03:00:40.494330  9648 net.cpp:151] Top shape: 10 2 (20)
I0109 03:00:40.494333  9648 net.cpp:159] Memory required for data: 53574800
I0109 03:00:40.494338  9648 layer_factory.hpp:77] Creating layer loss
I0109 03:00:40.494351  9648 net.cpp:94] Creating Layer loss
I0109 03:00:40.494354  9648 net.cpp:435] loss <- fc8
I0109 03:00:40.494357  9648 net.cpp:435] loss <- label
I0109 03:00:40.494362  9648 net.cpp:409] loss -> loss
I0109 03:00:40.494371  9648 layer_factory.hpp:77] Creating layer loss
I0109 03:00:40.494444  9648 net.cpp:144] Setting up loss
I0109 03:00:40.494449  9648 net.cpp:151] Top shape: (1)
I0109 03:00:40.494452  9648 net.cpp:154]     with loss weight 1
I0109 03:00:40.494478  9648 net.cpp:159] Memory required for data: 53574804
I0109 03:00:40.494482  9648 net.cpp:220] loss needs backward computation.
I0109 03:00:40.494485  9648 net.cpp:220] fc8 needs backward computation.
I0109 03:00:40.494489  9648 net.cpp:220] relu7 needs backward computation.
I0109 03:00:40.494493  9648 net.cpp:220] bn7 needs backward computation.
I0109 03:00:40.494495  9648 net.cpp:220] fc7 needs backward computation.
I0109 03:00:40.494498  9648 net.cpp:220] relu6 needs backward computation.
I0109 03:00:40.494501  9648 net.cpp:220] fc6 needs backward computation.
I0109 03:00:40.494505  9648 net.cpp:220] pool5 needs backward computation.
I0109 03:00:40.494508  9648 net.cpp:220] relu5 needs backward computation.
I0109 03:00:40.494513  9648 net.cpp:220] conv5 needs backward computation.
I0109 03:00:40.494515  9648 net.cpp:220] relu4 needs backward computation.
I0109 03:00:40.494518  9648 net.cpp:220] conv4 needs backward computation.
I0109 03:00:40.494522  9648 net.cpp:220] relu3 needs backward computation.
I0109 03:00:40.494525  9648 net.cpp:220] conv3 needs backward computation.
I0109 03:00:40.494529  9648 net.cpp:220] pool2 needs backward computation.
I0109 03:00:40.494532  9648 net.cpp:220] relu2 needs backward computation.
I0109 03:00:40.494535  9648 net.cpp:220] bn2 needs backward computation.
I0109 03:00:40.494540  9648 net.cpp:220] conv2 needs backward computation.
I0109 03:00:40.494544  9648 net.cpp:220] pool1 needs backward computation.
I0109 03:00:40.494546  9648 net.cpp:220] relu1 needs backward computation.
I0109 03:00:40.494550  9648 net.cpp:220] bn1 needs backward computation.
I0109 03:00:40.494554  9648 net.cpp:220] conv1 needs backward computation.
I0109 03:00:40.494557  9648 net.cpp:222] data does not need backward computation.
I0109 03:00:40.494560  9648 net.cpp:264] This network produces output loss
I0109 03:00:40.494575  9648 net.cpp:284] Network initialization done.
W0109 03:00:40.494853  9648 net.cpp:860] Force copying param 0 weights from layer 'bn1'; shape mismatch.  Source param shape is 78 (78); target param shape is 1 78 1 1 (78).
W0109 03:00:40.494973  9648 net.cpp:860] Force copying param 1 weights from layer 'bn1'; shape mismatch.  Source param shape is 78 (78); target param shape is 1 78 1 1 (78).
W0109 03:00:40.495081  9648 net.cpp:860] Force copying param 2 weights from layer 'bn1'; shape mismatch.  Source param shape is 78 (78); target param shape is 1 78 1 1 (78).
W0109 03:00:40.495185  9648 net.cpp:860] Force copying param 3 weights from layer 'bn1'; shape mismatch.  Source param shape is 78 (78); target param shape is 1 78 1 1 (78).
W0109 03:00:40.495314  9648 net.cpp:860] Force copying param 4 weights from layer 'bn1'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0109 03:00:40.495669  9648 net.cpp:860] Force copying param 0 weights from layer 'bn2'; shape mismatch.  Source param shape is 154 (154); target param shape is 1 154 1 1 (154).
W0109 03:00:40.495785  9648 net.cpp:860] Force copying param 1 weights from layer 'bn2'; shape mismatch.  Source param shape is 154 (154); target param shape is 1 154 1 1 (154).
W0109 03:00:40.495889  9648 net.cpp:860] Force copying param 2 weights from layer 'bn2'; shape mismatch.  Source param shape is 154 (154); target param shape is 1 154 1 1 (154).
W0109 03:00:40.495991  9648 net.cpp:860] Force copying param 3 weights from layer 'bn2'; shape mismatch.  Source param shape is 154 (154); target param shape is 1 154 1 1 (154).
W0109 03:00:40.496100  9648 net.cpp:860] Force copying param 4 weights from layer 'bn2'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
W0109 03:00:40.508047  9648 net.cpp:860] Force copying param 0 weights from layer 'bn7'; shape mismatch.  Source param shape is 4096 (4096); target param shape is 1 4096 1 1 (4096).
W0109 03:00:40.508167  9648 net.cpp:860] Force copying param 1 weights from layer 'bn7'; shape mismatch.  Source param shape is 4096 (4096); target param shape is 1 4096 1 1 (4096).
W0109 03:00:40.508276  9648 net.cpp:860] Force copying param 2 weights from layer 'bn7'; shape mismatch.  Source param shape is 4096 (4096); target param shape is 1 4096 1 1 (4096).
W0109 03:00:40.508384  9648 net.cpp:860] Force copying param 3 weights from layer 'bn7'; shape mismatch.  Source param shape is 4096 (4096); target param shape is 1 4096 1 1 (4096).
W0109 03:00:40.508491  9648 net.cpp:860] Force copying param 4 weights from layer 'bn7'; shape mismatch.  Source param shape is 1 (1); target param shape is 1 1 1 1 (1).
I0109 03:00:40.554144  9648 convert_proto.cpp:184] Opening file deploy/alexnetBNnoLRN/pruned/data/calib/calibration.txt
I0109 03:00:40.554255  9648 convert_proto.cpp:195] A total of 200 images.
I0109 03:00:40.582087  9648 convert_proto.cpp:2710]  Merge InnerProductBatchNorm -> InnerProduct: fc7 + bn7
I0109 03:00:40.667021  9648 convert_proto.cpp:2710]  Merge InnerProductBatchNorm -> InnerProduct: fc7 + bn7
I0109 03:00:40.896044  9648 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0109 03:00:40.896112  9648 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0109 03:00:40.896121  9648 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0109 03:00:40.896128  9648 net.cpp:52] Initializing net from parameters:
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  image_data_param {
    source: "deploy/alexnetBNnoLRN/pruned/data/calib/calibration.txt"
    batch_size: 10
    shuffle: true
    root_folder: "deploy/alexnetBNnoLRN/pruned/data/calib/"
  }
}
layer {
  name: "data_fixed"
  type: "FixedNeuron"
  bottom: "data"
  top: "data"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: OVER_FLOW
    bit_width: 8
    follow_data_layer: true
  }
}
layer {
  name: "conv1"
  type: "ConvolutionFixed"
  bottom: "data"
  top: "bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 78
    bias_term: true
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool1_fixed"
  type: "FixedNeuron"
  bottom: "pool1"
  top: "pool1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv2"
  type: "ConvolutionFixed"
  bottom: "pool1"
  top: "bn2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 154
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool2_fixed"
  type: "FixedNeuron"
  bottom: "pool2"
  top: "pool2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv3"
  type: "ConvolutionFixed"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "relu3_fixed"
  type: "FixedNeuron"
  bottom: "relu3"
  top: "relu3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv4"
  type: "ConvolutionFixed"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "relu4_fixed"
  type: "FixedNeuron"
  bottom: "relu4"
  top: "relu4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv5"
  type: "ConvolutionFixed"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 26
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool5_fixed"
  type: "FixedNeuron"
  bottom: "pool5"
  top: "pool5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc6"
  type: "InnerProductFixed"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "relu6_fixed"
  type: "FixedNeuron"
  bottom: "relu6"
  top: "relu6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc7"
  type: "InnerProductFixed"
  bottom: "relu6"
  top: "bn7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    bias_term: true
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "relu7_fixed"
  type: "FixedNeuron"
  bottom: "relu7"
  top: "relu7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc8"
  type: "InnerProductFixed"
  bottom: "relu7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc8_fixed"
  type: "FixedNeuron"
  bottom: "fc8"
  top: "fc8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0109 03:00:40.896525  9648 layer_factory.hpp:77] Creating layer data
I0109 03:00:40.896550  9648 net.cpp:94] Creating Layer data
I0109 03:00:40.896559  9648 net.cpp:409] data -> data
I0109 03:00:40.896575  9648 net.cpp:409] data -> label
I0109 03:00:40.896597  9648 image_data_layer.cpp:41] Opening file deploy/alexnetBNnoLRN/pruned/data/calib/calibration.txt
I0109 03:00:40.896752  9648 image_data_layer.cpp:51] Shuffling data
I0109 03:00:40.896806  9648 image_data_layer.cpp:56] A total of 200 images.
I0109 03:00:40.900110  9648 image_data_layer.cpp:84] output data size: 10,3,227,227
I0109 03:00:40.929054  9648 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 03:00:40.929143  9648 net.cpp:144] Setting up data
I0109 03:00:40.929148  9648 net.cpp:151] Top shape: 10 3 227 227 (1545870)
I0109 03:00:40.929157  9648 net.cpp:151] Top shape: 10 (10)
I0109 03:00:40.929162  9648 net.cpp:159] Memory required for data: 6183520
I0109 03:00:40.929167  9648 layer_factory.hpp:77] Creating layer data_fixed
I0109 03:00:40.929184  9648 net.cpp:94] Creating Layer data_fixed
I0109 03:00:40.929190  9648 net.cpp:435] data_fixed <- data
I0109 03:00:40.929196  9648 net.cpp:396] data_fixed -> data (in-place)
I0109 03:00:40.929250  9648 net.cpp:144] Setting up data_fixed
I0109 03:00:40.929255  9648 net.cpp:151] Top shape: 10 3 227 227 (1545870)
I0109 03:00:40.929260  9648 net.cpp:159] Memory required for data: 12367000
I0109 03:00:40.929267  9648 layer_factory.hpp:77] Creating layer conv1
I0109 03:00:40.929278  9648 net.cpp:94] Creating Layer conv1
I0109 03:00:40.929283  9648 net.cpp:435] conv1 <- data
I0109 03:00:40.929287  9648 net.cpp:409] conv1 -> bn1
I0109 03:00:40.929738  9648 layer_factory.hpp:77] Creating layer conv1
I0109 03:00:40.930207  9648 net.cpp:144] Setting up conv1
I0109 03:00:40.930212  9648 net.cpp:151] Top shape: 10 78 55 55 (2359500)
I0109 03:00:40.930217  9648 net.cpp:159] Memory required for data: 21805000
I0109 03:00:40.930225  9648 layer_factory.hpp:77] Creating layer relu1
I0109 03:00:40.930230  9648 net.cpp:94] Creating Layer relu1
I0109 03:00:40.930234  9648 net.cpp:435] relu1 <- bn1
I0109 03:00:40.930238  9648 net.cpp:409] relu1 -> relu1
I0109 03:00:40.930263  9648 net.cpp:144] Setting up relu1
I0109 03:00:40.930269  9648 net.cpp:151] Top shape: 10 78 55 55 (2359500)
I0109 03:00:40.930272  9648 net.cpp:159] Memory required for data: 31243000
I0109 03:00:40.930275  9648 layer_factory.hpp:77] Creating layer pool1
I0109 03:00:40.930281  9648 net.cpp:94] Creating Layer pool1
I0109 03:00:40.930284  9648 net.cpp:435] pool1 <- relu1
I0109 03:00:40.930289  9648 net.cpp:409] pool1 -> pool1
I0109 03:00:40.930312  9648 net.cpp:144] Setting up pool1
I0109 03:00:40.930316  9648 net.cpp:151] Top shape: 10 78 27 27 (568620)
I0109 03:00:40.930320  9648 net.cpp:159] Memory required for data: 33517480
I0109 03:00:40.930323  9648 layer_factory.hpp:77] Creating layer pool1_fixed
I0109 03:00:40.930328  9648 net.cpp:94] Creating Layer pool1_fixed
I0109 03:00:40.930331  9648 net.cpp:435] pool1_fixed <- pool1
I0109 03:00:40.930335  9648 net.cpp:396] pool1_fixed -> pool1 (in-place)
I0109 03:00:40.930356  9648 net.cpp:144] Setting up pool1_fixed
I0109 03:00:40.930361  9648 net.cpp:151] Top shape: 10 78 27 27 (568620)
I0109 03:00:40.930364  9648 net.cpp:159] Memory required for data: 35791960
I0109 03:00:40.930368  9648 layer_factory.hpp:77] Creating layer conv2
I0109 03:00:40.930374  9648 net.cpp:94] Creating Layer conv2
I0109 03:00:40.930378  9648 net.cpp:435] conv2 <- pool1
I0109 03:00:40.930382  9648 net.cpp:409] conv2 -> bn2
I0109 03:00:40.933282  9648 layer_factory.hpp:77] Creating layer conv2
I0109 03:00:40.936802  9648 net.cpp:144] Setting up conv2
I0109 03:00:40.936815  9648 net.cpp:151] Top shape: 10 154 27 27 (1122660)
I0109 03:00:40.936820  9648 net.cpp:159] Memory required for data: 40282600
I0109 03:00:40.936828  9648 layer_factory.hpp:77] Creating layer relu2
I0109 03:00:40.936833  9648 net.cpp:94] Creating Layer relu2
I0109 03:00:40.936836  9648 net.cpp:435] relu2 <- bn2
I0109 03:00:40.936841  9648 net.cpp:409] relu2 -> relu2
I0109 03:00:40.936854  9648 net.cpp:144] Setting up relu2
I0109 03:00:40.936857  9648 net.cpp:151] Top shape: 10 154 27 27 (1122660)
I0109 03:00:40.936861  9648 net.cpp:159] Memory required for data: 44773240
I0109 03:00:40.936862  9648 layer_factory.hpp:77] Creating layer pool2
I0109 03:00:40.936867  9648 net.cpp:94] Creating Layer pool2
I0109 03:00:40.936872  9648 net.cpp:435] pool2 <- relu2
I0109 03:00:40.936875  9648 net.cpp:409] pool2 -> pool2
I0109 03:00:40.936893  9648 net.cpp:144] Setting up pool2
I0109 03:00:40.936897  9648 net.cpp:151] Top shape: 10 154 13 13 (260260)
I0109 03:00:40.936899  9648 net.cpp:159] Memory required for data: 45814280
I0109 03:00:40.936902  9648 layer_factory.hpp:77] Creating layer pool2_fixed
I0109 03:00:40.936908  9648 net.cpp:94] Creating Layer pool2_fixed
I0109 03:00:40.936909  9648 net.cpp:435] pool2_fixed <- pool2
I0109 03:00:40.936913  9648 net.cpp:396] pool2_fixed -> pool2 (in-place)
I0109 03:00:40.936930  9648 net.cpp:144] Setting up pool2_fixed
I0109 03:00:40.936934  9648 net.cpp:151] Top shape: 10 154 13 13 (260260)
I0109 03:00:40.936937  9648 net.cpp:159] Memory required for data: 46855320
I0109 03:00:40.936940  9648 layer_factory.hpp:77] Creating layer conv3
I0109 03:00:40.936946  9648 net.cpp:94] Creating Layer conv3
I0109 03:00:40.936949  9648 net.cpp:435] conv3 <- pool2
I0109 03:00:40.936952  9648 net.cpp:409] conv3 -> conv3
I0109 03:00:40.937541  9648 layer_factory.hpp:77] Creating layer conv3
I0109 03:00:40.938226  9648 net.cpp:144] Setting up conv3
I0109 03:00:40.938232  9648 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0109 03:00:40.938237  9648 net.cpp:159] Memory required for data: 47125720
I0109 03:00:40.938244  9648 layer_factory.hpp:77] Creating layer relu3
I0109 03:00:40.938257  9648 net.cpp:94] Creating Layer relu3
I0109 03:00:40.938261  9648 net.cpp:435] relu3 <- conv3
I0109 03:00:40.938267  9648 net.cpp:409] relu3 -> relu3
I0109 03:00:40.938282  9648 net.cpp:144] Setting up relu3
I0109 03:00:40.938287  9648 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0109 03:00:40.938290  9648 net.cpp:159] Memory required for data: 47396120
I0109 03:00:40.938309  9648 layer_factory.hpp:77] Creating layer relu3_fixed
I0109 03:00:40.938314  9648 net.cpp:94] Creating Layer relu3_fixed
I0109 03:00:40.938318  9648 net.cpp:435] relu3_fixed <- relu3
I0109 03:00:40.938321  9648 net.cpp:396] relu3_fixed -> relu3 (in-place)
I0109 03:00:40.938344  9648 net.cpp:144] Setting up relu3_fixed
I0109 03:00:40.938347  9648 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0109 03:00:40.938351  9648 net.cpp:159] Memory required for data: 47666520
I0109 03:00:40.938355  9648 layer_factory.hpp:77] Creating layer conv4
I0109 03:00:40.938361  9648 net.cpp:94] Creating Layer conv4
I0109 03:00:40.938364  9648 net.cpp:435] conv4 <- relu3
I0109 03:00:40.938369  9648 net.cpp:409] conv4 -> conv4
I0109 03:00:40.938622  9648 layer_factory.hpp:77] Creating layer conv4
I0109 03:00:40.938973  9648 net.cpp:144] Setting up conv4
I0109 03:00:40.938978  9648 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0109 03:00:40.938982  9648 net.cpp:159] Memory required for data: 47936920
I0109 03:00:40.938987  9648 layer_factory.hpp:77] Creating layer relu4
I0109 03:00:40.938992  9648 net.cpp:94] Creating Layer relu4
I0109 03:00:40.938994  9648 net.cpp:435] relu4 <- conv4
I0109 03:00:40.938998  9648 net.cpp:409] relu4 -> relu4
I0109 03:00:40.939013  9648 net.cpp:144] Setting up relu4
I0109 03:00:40.939018  9648 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0109 03:00:40.939023  9648 net.cpp:159] Memory required for data: 48207320
I0109 03:00:40.939025  9648 layer_factory.hpp:77] Creating layer relu4_fixed
I0109 03:00:40.939029  9648 net.cpp:94] Creating Layer relu4_fixed
I0109 03:00:40.939033  9648 net.cpp:435] relu4_fixed <- relu4
I0109 03:00:40.939036  9648 net.cpp:396] relu4_fixed -> relu4 (in-place)
I0109 03:00:40.939057  9648 net.cpp:144] Setting up relu4_fixed
I0109 03:00:40.939062  9648 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0109 03:00:40.939066  9648 net.cpp:159] Memory required for data: 48477720
I0109 03:00:40.939070  9648 layer_factory.hpp:77] Creating layer conv5
I0109 03:00:40.939077  9648 net.cpp:94] Creating Layer conv5
I0109 03:00:40.939080  9648 net.cpp:435] conv5 <- relu4
I0109 03:00:40.939085  9648 net.cpp:409] conv5 -> conv5
I0109 03:00:40.939296  9648 layer_factory.hpp:77] Creating layer conv5
I0109 03:00:40.939612  9648 net.cpp:144] Setting up conv5
I0109 03:00:40.939618  9648 net.cpp:151] Top shape: 10 26 13 13 (43940)
I0109 03:00:40.939622  9648 net.cpp:159] Memory required for data: 48653480
I0109 03:00:40.939627  9648 layer_factory.hpp:77] Creating layer relu5
I0109 03:00:40.939631  9648 net.cpp:94] Creating Layer relu5
I0109 03:00:40.939635  9648 net.cpp:435] relu5 <- conv5
I0109 03:00:40.939637  9648 net.cpp:409] relu5 -> relu5
I0109 03:00:40.939652  9648 net.cpp:144] Setting up relu5
I0109 03:00:40.939657  9648 net.cpp:151] Top shape: 10 26 13 13 (43940)
I0109 03:00:40.939661  9648 net.cpp:159] Memory required for data: 48829240
I0109 03:00:40.939664  9648 layer_factory.hpp:77] Creating layer pool5
I0109 03:00:40.939668  9648 net.cpp:94] Creating Layer pool5
I0109 03:00:40.939671  9648 net.cpp:435] pool5 <- relu5
I0109 03:00:40.939675  9648 net.cpp:409] pool5 -> pool5
I0109 03:00:40.939698  9648 net.cpp:144] Setting up pool5
I0109 03:00:40.939702  9648 net.cpp:151] Top shape: 10 26 6 6 (9360)
I0109 03:00:40.939707  9648 net.cpp:159] Memory required for data: 48866680
I0109 03:00:40.939709  9648 layer_factory.hpp:77] Creating layer pool5_fixed
I0109 03:00:40.939714  9648 net.cpp:94] Creating Layer pool5_fixed
I0109 03:00:40.939718  9648 net.cpp:435] pool5_fixed <- pool5
I0109 03:00:40.939720  9648 net.cpp:396] pool5_fixed -> pool5 (in-place)
I0109 03:00:40.939743  9648 net.cpp:144] Setting up pool5_fixed
I0109 03:00:40.939747  9648 net.cpp:151] Top shape: 10 26 6 6 (9360)
I0109 03:00:40.939751  9648 net.cpp:159] Memory required for data: 48904120
I0109 03:00:40.939755  9648 layer_factory.hpp:77] Creating layer fc6
I0109 03:00:40.939761  9648 net.cpp:94] Creating Layer fc6
I0109 03:00:40.939764  9648 net.cpp:435] fc6 <- pool5
I0109 03:00:40.939769  9648 net.cpp:409] fc6 -> fc6
I0109 03:00:40.971837  9648 layer_factory.hpp:77] Creating layer fc6
I0109 03:00:41.004264  9648 net.cpp:144] Setting up fc6
I0109 03:00:41.004284  9648 net.cpp:151] Top shape: 10 4096 (40960)
I0109 03:00:41.004289  9648 net.cpp:159] Memory required for data: 49067960
I0109 03:00:41.004302  9648 layer_factory.hpp:77] Creating layer relu6
I0109 03:00:41.004309  9648 net.cpp:94] Creating Layer relu6
I0109 03:00:41.004312  9648 net.cpp:435] relu6 <- fc6
I0109 03:00:41.004318  9648 net.cpp:409] relu6 -> relu6
I0109 03:00:41.004335  9648 net.cpp:144] Setting up relu6
I0109 03:00:41.004338  9648 net.cpp:151] Top shape: 10 4096 (40960)
I0109 03:00:41.004341  9648 net.cpp:159] Memory required for data: 49231800
I0109 03:00:41.004344  9648 layer_factory.hpp:77] Creating layer relu6_fixed
I0109 03:00:41.004350  9648 net.cpp:94] Creating Layer relu6_fixed
I0109 03:00:41.004352  9648 net.cpp:435] relu6_fixed <- relu6
I0109 03:00:41.004356  9648 net.cpp:396] relu6_fixed -> relu6 (in-place)
I0109 03:00:41.004374  9648 net.cpp:144] Setting up relu6_fixed
I0109 03:00:41.004379  9648 net.cpp:151] Top shape: 10 4096 (40960)
I0109 03:00:41.004381  9648 net.cpp:159] Memory required for data: 49395640
I0109 03:00:41.004385  9648 layer_factory.hpp:77] Creating layer fc7
I0109 03:00:41.004391  9648 net.cpp:94] Creating Layer fc7
I0109 03:00:41.004393  9648 net.cpp:435] fc7 <- relu6
I0109 03:00:41.004397  9648 net.cpp:409] fc7 -> bn7
I0109 03:00:41.141741  9648 layer_factory.hpp:77] Creating layer fc7
I0109 03:00:41.273715  9648 net.cpp:144] Setting up fc7
I0109 03:00:41.273738  9648 net.cpp:151] Top shape: 10 4096 (40960)
I0109 03:00:41.273744  9648 net.cpp:159] Memory required for data: 49559480
I0109 03:00:41.273772  9648 layer_factory.hpp:77] Creating layer relu7
I0109 03:00:41.273778  9648 net.cpp:94] Creating Layer relu7
I0109 03:00:41.273782  9648 net.cpp:435] relu7 <- bn7
I0109 03:00:41.273789  9648 net.cpp:409] relu7 -> relu7
I0109 03:00:41.273806  9648 net.cpp:144] Setting up relu7
I0109 03:00:41.273809  9648 net.cpp:151] Top shape: 10 4096 (40960)
I0109 03:00:41.273813  9648 net.cpp:159] Memory required for data: 49723320
I0109 03:00:41.273814  9648 layer_factory.hpp:77] Creating layer relu7_fixed
I0109 03:00:41.273820  9648 net.cpp:94] Creating Layer relu7_fixed
I0109 03:00:41.273823  9648 net.cpp:435] relu7_fixed <- relu7
I0109 03:00:41.273826  9648 net.cpp:396] relu7_fixed -> relu7 (in-place)
I0109 03:00:41.273845  9648 net.cpp:144] Setting up relu7_fixed
I0109 03:00:41.273850  9648 net.cpp:151] Top shape: 10 4096 (40960)
I0109 03:00:41.273854  9648 net.cpp:159] Memory required for data: 49887160
I0109 03:00:41.273856  9648 layer_factory.hpp:77] Creating layer fc8
I0109 03:00:41.273862  9648 net.cpp:94] Creating Layer fc8
I0109 03:00:41.273865  9648 net.cpp:435] fc8 <- relu7
I0109 03:00:41.273869  9648 net.cpp:409] fc8 -> fc8
I0109 03:00:41.273988  9648 layer_factory.hpp:77] Creating layer fc8
I0109 03:00:41.274144  9648 net.cpp:144] Setting up fc8
I0109 03:00:41.274149  9648 net.cpp:151] Top shape: 10 2 (20)
I0109 03:00:41.274153  9648 net.cpp:159] Memory required for data: 49887240
I0109 03:00:41.274158  9648 layer_factory.hpp:77] Creating layer fc8_fixed
I0109 03:00:41.274161  9648 net.cpp:94] Creating Layer fc8_fixed
I0109 03:00:41.274164  9648 net.cpp:435] fc8_fixed <- fc8
I0109 03:00:41.274168  9648 net.cpp:396] fc8_fixed -> fc8 (in-place)
I0109 03:00:41.274188  9648 net.cpp:144] Setting up fc8_fixed
I0109 03:00:41.274191  9648 net.cpp:151] Top shape: 10 2 (20)
I0109 03:00:41.274194  9648 net.cpp:159] Memory required for data: 49887320
I0109 03:00:41.274199  9648 layer_factory.hpp:77] Creating layer loss
I0109 03:00:41.274204  9648 net.cpp:94] Creating Layer loss
I0109 03:00:41.274206  9648 net.cpp:435] loss <- fc8
I0109 03:00:41.274209  9648 net.cpp:435] loss <- label
I0109 03:00:41.274214  9648 net.cpp:409] loss -> loss
I0109 03:00:41.274219  9648 layer_factory.hpp:77] Creating layer loss
I0109 03:00:41.274292  9648 net.cpp:144] Setting up loss
I0109 03:00:41.274297  9648 net.cpp:151] Top shape: (1)
I0109 03:00:41.274300  9648 net.cpp:154]     with loss weight 1
I0109 03:00:41.274330  9648 net.cpp:159] Memory required for data: 49887324
I0109 03:00:41.274333  9648 net.cpp:220] loss needs backward computation.
I0109 03:00:41.274336  9648 net.cpp:220] fc8_fixed needs backward computation.
I0109 03:00:41.274339  9648 net.cpp:220] fc8 needs backward computation.
I0109 03:00:41.274343  9648 net.cpp:220] relu7_fixed needs backward computation.
I0109 03:00:41.274346  9648 net.cpp:220] relu7 needs backward computation.
I0109 03:00:41.274349  9648 net.cpp:220] fc7 needs backward computation.
I0109 03:00:41.274353  9648 net.cpp:220] relu6_fixed needs backward computation.
I0109 03:00:41.274356  9648 net.cpp:220] relu6 needs backward computation.
I0109 03:00:41.274359  9648 net.cpp:220] fc6 needs backward computation.
I0109 03:00:41.274363  9648 net.cpp:220] pool5_fixed needs backward computation.
I0109 03:00:41.274366  9648 net.cpp:220] pool5 needs backward computation.
I0109 03:00:41.274369  9648 net.cpp:220] relu5 needs backward computation.
I0109 03:00:41.274374  9648 net.cpp:220] conv5 needs backward computation.
I0109 03:00:41.274376  9648 net.cpp:220] relu4_fixed needs backward computation.
I0109 03:00:41.274380  9648 net.cpp:220] relu4 needs backward computation.
I0109 03:00:41.274384  9648 net.cpp:220] conv4 needs backward computation.
I0109 03:00:41.274387  9648 net.cpp:220] relu3_fixed needs backward computation.
I0109 03:00:41.274390  9648 net.cpp:220] relu3 needs backward computation.
I0109 03:00:41.274394  9648 net.cpp:220] conv3 needs backward computation.
I0109 03:00:41.274397  9648 net.cpp:220] pool2_fixed needs backward computation.
I0109 03:00:41.274400  9648 net.cpp:220] pool2 needs backward computation.
I0109 03:00:41.274403  9648 net.cpp:220] relu2 needs backward computation.
I0109 03:00:41.274407  9648 net.cpp:220] conv2 needs backward computation.
I0109 03:00:41.274410  9648 net.cpp:220] pool1_fixed needs backward computation.
I0109 03:00:41.274413  9648 net.cpp:220] pool1 needs backward computation.
I0109 03:00:41.274417  9648 net.cpp:220] relu1 needs backward computation.
I0109 03:00:41.274420  9648 net.cpp:220] conv1 needs backward computation.
I0109 03:00:41.274425  9648 net.cpp:222] data_fixed does not need backward computation.
I0109 03:00:41.274427  9648 net.cpp:222] data does not need backward computation.
I0109 03:00:41.274430  9648 net.cpp:264] This network produces output loss
I0109 03:00:41.274446  9648 net.cpp:284] Network initialization done.
I0109 03:00:41.286170  9648 vai_q.cpp:182] Start Calibration
I0109 03:00:41.324998  9648 vai_q.cpp:206] Calibration iter: 1/100 ,loss: 78.6029
I0109 03:00:41.329897  9648 vai_q.cpp:206] Calibration iter: 2/100 ,loss: 61.1356
I0109 03:00:41.334782  9648 vai_q.cpp:206] Calibration iter: 3/100 ,loss: 78.6029
I0109 03:00:41.340934  9648 vai_q.cpp:206] Calibration iter: 4/100 ,loss: 79.4279
I0109 03:00:41.346302  9648 vai_q.cpp:206] Calibration iter: 5/100 ,loss: 78.6029
I0109 03:00:41.351145  9648 vai_q.cpp:206] Calibration iter: 6/100 ,loss: 61.1356
I0109 03:00:41.356014  9648 vai_q.cpp:206] Calibration iter: 7/100 ,loss: 69.8692
I0109 03:00:41.361423  9648 vai_q.cpp:206] Calibration iter: 8/100 ,loss: 43.6683
I0109 03:00:41.366322  9648 vai_q.cpp:206] Calibration iter: 9/100 ,loss: 69.8692
I0109 03:00:41.371167  9648 vai_q.cpp:206] Calibration iter: 10/100 ,loss: 87.3365
I0109 03:00:41.377029  9648 vai_q.cpp:206] Calibration iter: 11/100 ,loss: 78.6029
I0109 03:00:41.382408  9648 vai_q.cpp:206] Calibration iter: 12/100 ,loss: 87.3365
I0109 03:00:41.387264  9648 vai_q.cpp:206] Calibration iter: 13/100 ,loss: 71.1442
I0109 03:00:41.392104  9648 vai_q.cpp:206] Calibration iter: 14/100 ,loss: 87.3365
I0109 03:00:41.392117  9648 blocking_queue.cpp:50] Data layer prefetch queue empty
I0109 03:00:41.398284  9648 vai_q.cpp:206] Calibration iter: 15/100 ,loss: 62.7606
I0109 03:00:41.414209  9648 vai_q.cpp:206] Calibration iter: 16/100 ,loss: 87.3365
I0109 03:00:41.431080  9648 vai_q.cpp:206] Calibration iter: 17/100 ,loss: 61.1356
I0109 03:00:41.448259  9648 vai_q.cpp:206] Calibration iter: 18/100 ,loss: 87.3365
I0109 03:00:41.464115  9648 vai_q.cpp:206] Calibration iter: 19/100 ,loss: 87.3365
I0109 03:00:41.480551  9648 vai_q.cpp:206] Calibration iter: 20/100 ,loss: 81.0029
I0109 03:00:41.495579  9648 vai_q.cpp:206] Calibration iter: 21/100 ,loss: 78.6029
I0109 03:00:41.512307  9648 vai_q.cpp:206] Calibration iter: 22/100 ,loss: 69.8692
I0109 03:00:41.527563  9648 vai_q.cpp:206] Calibration iter: 23/100 ,loss: 69.8692
I0109 03:00:41.544401  9648 vai_q.cpp:206] Calibration iter: 24/100 ,loss: 69.8692
I0109 03:00:41.559523  9648 vai_q.cpp:206] Calibration iter: 25/100 ,loss: 71.9942
I0109 03:00:41.576095  9648 vai_q.cpp:206] Calibration iter: 26/100 ,loss: 54.8519
I0109 03:00:41.591446  9648 vai_q.cpp:206] Calibration iter: 27/100 ,loss: 87.3365
I0109 03:00:41.606869  9648 vai_q.cpp:206] Calibration iter: 28/100 ,loss: 87.3365
I0109 03:00:41.622483  9648 vai_q.cpp:206] Calibration iter: 29/100 ,loss: 71.7692
I0109 03:00:41.637593  9648 vai_q.cpp:206] Calibration iter: 30/100 ,loss: 87.3365
I0109 03:00:41.653370  9648 vai_q.cpp:206] Calibration iter: 31/100 ,loss: 61.1356
I0109 03:00:41.668663  9648 vai_q.cpp:206] Calibration iter: 32/100 ,loss: 78.6029
I0109 03:00:41.684819  9648 vai_q.cpp:206] Calibration iter: 33/100 ,loss: 78.6029
I0109 03:00:41.699892  9648 vai_q.cpp:206] Calibration iter: 34/100 ,loss: 52.4019
I0109 03:00:41.717113  9648 vai_q.cpp:206] Calibration iter: 35/100 ,loss: 87.3365
I0109 03:00:41.731863  9648 vai_q.cpp:206] Calibration iter: 36/100 ,loss: 78.6029
I0109 03:00:41.748267  9648 vai_q.cpp:206] Calibration iter: 37/100 ,loss: 78.6029
I0109 03:00:41.762742  9648 vai_q.cpp:206] Calibration iter: 38/100 ,loss: 62.5606
I0109 03:00:41.777957  9648 vai_q.cpp:206] Calibration iter: 39/100 ,loss: 69.8692
I0109 03:00:41.794548  9648 vai_q.cpp:206] Calibration iter: 40/100 ,loss: 78.6029
I0109 03:00:41.810209  9648 vai_q.cpp:206] Calibration iter: 41/100 ,loss: 78.6029
I0109 03:00:41.826807  9648 vai_q.cpp:206] Calibration iter: 42/100 ,loss: 69.8692
I0109 03:00:41.841840  9648 vai_q.cpp:206] Calibration iter: 43/100 ,loss: 69.8692
I0109 03:00:41.858242  9648 vai_q.cpp:206] Calibration iter: 44/100 ,loss: 78.6029
I0109 03:00:41.873476  9648 vai_q.cpp:206] Calibration iter: 45/100 ,loss: 78.6029
I0109 03:00:41.889540  9648 vai_q.cpp:206] Calibration iter: 46/100 ,loss: 69.8692
I0109 03:00:41.905974  9648 vai_q.cpp:206] Calibration iter: 47/100 ,loss: 71.8692
I0109 03:00:41.921967  9648 vai_q.cpp:206] Calibration iter: 48/100 ,loss: 78.6029
I0109 03:00:41.937181  9648 vai_q.cpp:206] Calibration iter: 49/100 ,loss: 87.3365
I0109 03:00:41.954411  9648 vai_q.cpp:206] Calibration iter: 50/100 ,loss: 61.1356
I0109 03:00:41.968145  9648 vai_q.cpp:206] Calibration iter: 51/100 ,loss: 78.6029
I0109 03:00:41.983798  9648 vai_q.cpp:206] Calibration iter: 52/100 ,loss: 63.2106
I0109 03:00:41.999253  9648 vai_q.cpp:206] Calibration iter: 53/100 ,loss: 69.8692
I0109 03:00:42.014878  9648 vai_q.cpp:206] Calibration iter: 54/100 ,loss: 78.6029
I0109 03:00:42.031306  9648 vai_q.cpp:206] Calibration iter: 55/100 ,loss: 78.6029
I0109 03:00:42.046136  9648 vai_q.cpp:206] Calibration iter: 56/100 ,loss: 69.8692
I0109 03:00:42.061805  9648 vai_q.cpp:206] Calibration iter: 57/100 ,loss: 87.3365
I0109 03:00:42.076797  9648 vai_q.cpp:206] Calibration iter: 58/100 ,loss: 87.3365
I0109 03:00:42.092981  9648 vai_q.cpp:206] Calibration iter: 59/100 ,loss: 78.6029
I0109 03:00:42.108158  9648 vai_q.cpp:206] Calibration iter: 60/100 ,loss: 53.6269
I0109 03:00:42.125464  9648 vai_q.cpp:206] Calibration iter: 61/100 ,loss: 69.8696
I0109 03:00:42.140203  9648 vai_q.cpp:206] Calibration iter: 62/100 ,loss: 69.8692
I0109 03:00:42.155694  9648 vai_q.cpp:206] Calibration iter: 63/100 ,loss: 78.6029
I0109 03:00:42.171085  9648 vai_q.cpp:206] Calibration iter: 64/100 ,loss: 78.6029
I0109 03:00:42.186398  9648 vai_q.cpp:206] Calibration iter: 65/100 ,loss: 78.6029
I0109 03:00:42.201877  9648 vai_q.cpp:206] Calibration iter: 66/100 ,loss: 87.3365
I0109 03:00:42.217687  9648 vai_q.cpp:206] Calibration iter: 67/100 ,loss: 69.8692
I0109 03:00:42.233662  9648 vai_q.cpp:206] Calibration iter: 68/100 ,loss: 62.1856
I0109 03:00:42.249418  9648 vai_q.cpp:206] Calibration iter: 69/100 ,loss: 61.1356
I0109 03:00:42.266013  9648 vai_q.cpp:206] Calibration iter: 70/100 ,loss: 69.8692
I0109 03:00:42.280256  9648 vai_q.cpp:206] Calibration iter: 71/100 ,loss: 72.3944
I0109 03:00:42.296707  9648 vai_q.cpp:206] Calibration iter: 72/100 ,loss: 69.8692
I0109 03:00:42.311329  9648 vai_q.cpp:206] Calibration iter: 73/100 ,loss: 61.1356
I0109 03:00:42.327016  9648 vai_q.cpp:206] Calibration iter: 74/100 ,loss: 87.3365
I0109 03:00:42.342623  9648 vai_q.cpp:206] Calibration iter: 75/100 ,loss: 87.3365
I0109 03:00:42.358744  9648 vai_q.cpp:206] Calibration iter: 76/100 ,loss: 78.6029
I0109 03:00:42.374502  9648 vai_q.cpp:206] Calibration iter: 77/100 ,loss: 87.3365
I0109 03:00:42.390401  9648 vai_q.cpp:206] Calibration iter: 78/100 ,loss: 61.1356
I0109 03:00:42.406631  9648 vai_q.cpp:206] Calibration iter: 79/100 ,loss: 87.3365
I0109 03:00:42.422089  9648 vai_q.cpp:206] Calibration iter: 80/100 ,loss: 87.3365
I0109 03:00:42.439414  9648 vai_q.cpp:206] Calibration iter: 81/100 ,loss: 61.1356
I0109 03:00:42.454138  9648 vai_q.cpp:206] Calibration iter: 82/100 ,loss: 61.1356
I0109 03:00:42.470909  9648 vai_q.cpp:206] Calibration iter: 83/100 ,loss: 62.4856
I0109 03:00:42.485623  9648 vai_q.cpp:206] Calibration iter: 84/100 ,loss: 87.3365
I0109 03:00:42.501083  9648 vai_q.cpp:206] Calibration iter: 85/100 ,loss: 69.8692
I0109 03:00:42.517084  9648 vai_q.cpp:206] Calibration iter: 86/100 ,loss: 73.1942
I0109 03:00:42.532840  9648 vai_q.cpp:206] Calibration iter: 87/100 ,loss: 69.8693
I0109 03:00:42.548353  9648 vai_q.cpp:206] Calibration iter: 88/100 ,loss: 78.6029
I0109 03:00:42.563606  9648 vai_q.cpp:206] Calibration iter: 89/100 ,loss: 78.6029
I0109 03:00:42.578516  9648 vai_q.cpp:206] Calibration iter: 90/100 ,loss: 78.6029
I0109 03:00:42.593477  9648 vai_q.cpp:206] Calibration iter: 91/100 ,loss: 72.4567
I0109 03:00:42.610258  9648 vai_q.cpp:206] Calibration iter: 92/100 ,loss: 78.6029
I0109 03:00:42.624105  9648 vai_q.cpp:206] Calibration iter: 93/100 ,loss: 78.6029
I0109 03:00:42.640980  9648 vai_q.cpp:206] Calibration iter: 94/100 ,loss: 61.1356
I0109 03:00:42.655930  9648 vai_q.cpp:206] Calibration iter: 95/100 ,loss: 61.1356
I0109 03:00:42.671903  9648 vai_q.cpp:206] Calibration iter: 96/100 ,loss: 87.3365
I0109 03:00:42.687492  9648 vai_q.cpp:206] Calibration iter: 97/100 ,loss: 78.6029
I0109 03:00:42.703672  9648 vai_q.cpp:206] Calibration iter: 98/100 ,loss: 52.4019
I0109 03:00:42.719208  9648 vai_q.cpp:206] Calibration iter: 99/100 ,loss: 72.0692
I0109 03:00:42.734758  9648 vai_q.cpp:206] Calibration iter: 100/100 ,loss: 78.6029
I0109 03:00:42.734786  9648 vai_q.cpp:211] Calibration Done!
I0109 03:00:42.963595  9648 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0109 03:00:42.963626  9648 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0109 03:00:42.963629  9648 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy-top1
I0109 03:00:42.963649  9648 net.cpp:52] Initializing net from parameters:
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  image_data_param {
    source: "deploy/alexnetBNnoLRN/pruned/data/calib/calibration.txt"
    batch_size: 10
    shuffle: true
    root_folder: "deploy/alexnetBNnoLRN/pruned/data/calib/"
  }
}
layer {
  name: "data_fixed"
  type: "FixedNeuron"
  bottom: "data"
  top: "data"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: OVER_FLOW
    bit_width: 8
    follow_data_layer: true
  }
}
layer {
  name: "conv1"
  type: "ConvolutionFixed"
  bottom: "data"
  top: "bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 78
    bias_term: true
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool1_fixed"
  type: "FixedNeuron"
  bottom: "pool1"
  top: "pool1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv2"
  type: "ConvolutionFixed"
  bottom: "pool1"
  top: "bn2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 154
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool2_fixed"
  type: "FixedNeuron"
  bottom: "pool2"
  top: "pool2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv3"
  type: "ConvolutionFixed"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "relu3_fixed"
  type: "FixedNeuron"
  bottom: "relu3"
  top: "relu3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv4"
  type: "ConvolutionFixed"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "relu4_fixed"
  type: "FixedNeuron"
  bottom: "relu4"
  top: "relu4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv5"
  type: "ConvolutionFixed"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 26
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool5_fixed"
  type: "FixedNeuron"
  bottom: "pool5"
  top: "pool5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc6"
  type: "InnerProductFixed"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "relu6_fixed"
  type: "FixedNeuron"
  bottom: "relu6"
  top: "relu6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc7"
  type: "InnerProductFixed"
  bottom: "relu6"
  top: "bn7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    bias_term: true
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "relu7_fixed"
  type: "FixedNeuron"
  bottom: "relu7"
  top: "relu7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc8"
  type: "InnerProductFixed"
  bottom: "relu7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc8_fixed"
  type: "FixedNeuron"
  bottom: "fc8"
  top: "fc8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0109 03:00:42.963851  9648 layer_factory.hpp:77] Creating layer data
I0109 03:00:42.963881  9648 net.cpp:94] Creating Layer data
I0109 03:00:42.963888  9648 net.cpp:409] data -> data
I0109 03:00:42.963898  9648 net.cpp:409] data -> label
I0109 03:00:42.963910  9648 image_data_layer.cpp:41] Opening file deploy/alexnetBNnoLRN/pruned/data/calib/calibration.txt
I0109 03:00:42.963989  9648 image_data_layer.cpp:51] Shuffling data
I0109 03:00:42.964001  9648 image_data_layer.cpp:56] A total of 200 images.
I0109 03:00:42.965306  9648 image_data_layer.cpp:84] output data size: 10,3,227,227
I0109 03:00:42.987483  9648 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 03:00:42.987527  9648 net.cpp:144] Setting up data
I0109 03:00:42.987531  9648 net.cpp:151] Top shape: 10 3 227 227 (1545870)
I0109 03:00:42.987540  9648 net.cpp:151] Top shape: 10 (10)
I0109 03:00:42.987560  9648 net.cpp:159] Memory required for data: 6183520
I0109 03:00:42.987565  9648 layer_factory.hpp:77] Creating layer data_fixed
I0109 03:00:42.987576  9648 net.cpp:94] Creating Layer data_fixed
I0109 03:00:42.987581  9648 net.cpp:435] data_fixed <- data
I0109 03:00:42.987586  9648 net.cpp:396] data_fixed -> data (in-place)
I0109 03:00:42.987640  9648 net.cpp:144] Setting up data_fixed
I0109 03:00:42.987644  9648 net.cpp:151] Top shape: 10 3 227 227 (1545870)
I0109 03:00:42.987648  9648 net.cpp:159] Memory required for data: 12367000
I0109 03:00:42.987658  9648 layer_factory.hpp:77] Creating layer conv1
I0109 03:00:42.987666  9648 net.cpp:94] Creating Layer conv1
I0109 03:00:42.987670  9648 net.cpp:435] conv1 <- data
I0109 03:00:42.987675  9648 net.cpp:409] conv1 -> bn1
I0109 03:00:42.988121  9648 layer_factory.hpp:77] Creating layer conv1
I0109 03:00:42.988593  9648 net.cpp:144] Setting up conv1
I0109 03:00:42.988600  9648 net.cpp:151] Top shape: 10 78 55 55 (2359500)
I0109 03:00:42.988605  9648 net.cpp:159] Memory required for data: 21805000
I0109 03:00:42.988613  9648 layer_factory.hpp:77] Creating layer relu1
I0109 03:00:42.988618  9648 net.cpp:94] Creating Layer relu1
I0109 03:00:42.988621  9648 net.cpp:435] relu1 <- bn1
I0109 03:00:42.988626  9648 net.cpp:409] relu1 -> relu1
I0109 03:00:42.988641  9648 net.cpp:144] Setting up relu1
I0109 03:00:42.988646  9648 net.cpp:151] Top shape: 10 78 55 55 (2359500)
I0109 03:00:42.988651  9648 net.cpp:159] Memory required for data: 31243000
I0109 03:00:42.988653  9648 layer_factory.hpp:77] Creating layer pool1
I0109 03:00:42.988659  9648 net.cpp:94] Creating Layer pool1
I0109 03:00:42.988662  9648 net.cpp:435] pool1 <- relu1
I0109 03:00:42.988667  9648 net.cpp:409] pool1 -> pool1
I0109 03:00:42.988690  9648 net.cpp:144] Setting up pool1
I0109 03:00:42.988694  9648 net.cpp:151] Top shape: 10 78 27 27 (568620)
I0109 03:00:42.988698  9648 net.cpp:159] Memory required for data: 33517480
I0109 03:00:42.988701  9648 layer_factory.hpp:77] Creating layer pool1_fixed
I0109 03:00:42.988706  9648 net.cpp:94] Creating Layer pool1_fixed
I0109 03:00:42.988709  9648 net.cpp:435] pool1_fixed <- pool1
I0109 03:00:42.988713  9648 net.cpp:396] pool1_fixed -> pool1 (in-place)
I0109 03:00:42.988734  9648 net.cpp:144] Setting up pool1_fixed
I0109 03:00:42.988739  9648 net.cpp:151] Top shape: 10 78 27 27 (568620)
I0109 03:00:42.988742  9648 net.cpp:159] Memory required for data: 35791960
I0109 03:00:42.988746  9648 layer_factory.hpp:77] Creating layer conv2
I0109 03:00:42.988754  9648 net.cpp:94] Creating Layer conv2
I0109 03:00:42.988756  9648 net.cpp:435] conv2 <- pool1
I0109 03:00:42.988761  9648 net.cpp:409] conv2 -> bn2
I0109 03:00:42.991778  9648 layer_factory.hpp:77] Creating layer conv2
I0109 03:00:42.995577  9648 net.cpp:144] Setting up conv2
I0109 03:00:42.995590  9648 net.cpp:151] Top shape: 10 154 27 27 (1122660)
I0109 03:00:42.995597  9648 net.cpp:159] Memory required for data: 40282600
I0109 03:00:42.995605  9648 layer_factory.hpp:77] Creating layer relu2
I0109 03:00:42.995612  9648 net.cpp:94] Creating Layer relu2
I0109 03:00:42.995615  9648 net.cpp:435] relu2 <- bn2
I0109 03:00:42.995620  9648 net.cpp:409] relu2 -> relu2
I0109 03:00:42.995635  9648 net.cpp:144] Setting up relu2
I0109 03:00:42.995640  9648 net.cpp:151] Top shape: 10 154 27 27 (1122660)
I0109 03:00:42.995643  9648 net.cpp:159] Memory required for data: 44773240
I0109 03:00:42.995646  9648 layer_factory.hpp:77] Creating layer pool2
I0109 03:00:42.995652  9648 net.cpp:94] Creating Layer pool2
I0109 03:00:42.995656  9648 net.cpp:435] pool2 <- relu2
I0109 03:00:42.995658  9648 net.cpp:409] pool2 -> pool2
I0109 03:00:42.995682  9648 net.cpp:144] Setting up pool2
I0109 03:00:42.995687  9648 net.cpp:151] Top shape: 10 154 13 13 (260260)
I0109 03:00:42.995690  9648 net.cpp:159] Memory required for data: 45814280
I0109 03:00:42.995693  9648 layer_factory.hpp:77] Creating layer pool2_fixed
I0109 03:00:42.995698  9648 net.cpp:94] Creating Layer pool2_fixed
I0109 03:00:42.995700  9648 net.cpp:435] pool2_fixed <- pool2
I0109 03:00:42.995704  9648 net.cpp:396] pool2_fixed -> pool2 (in-place)
I0109 03:00:42.995725  9648 net.cpp:144] Setting up pool2_fixed
I0109 03:00:42.995729  9648 net.cpp:151] Top shape: 10 154 13 13 (260260)
I0109 03:00:42.995733  9648 net.cpp:159] Memory required for data: 46855320
I0109 03:00:42.995738  9648 layer_factory.hpp:77] Creating layer conv3
I0109 03:00:42.995744  9648 net.cpp:94] Creating Layer conv3
I0109 03:00:42.995748  9648 net.cpp:435] conv3 <- pool2
I0109 03:00:42.995751  9648 net.cpp:409] conv3 -> conv3
I0109 03:00:42.996315  9648 layer_factory.hpp:77] Creating layer conv3
I0109 03:00:42.997037  9648 net.cpp:144] Setting up conv3
I0109 03:00:42.997045  9648 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0109 03:00:42.997051  9648 net.cpp:159] Memory required for data: 47125720
I0109 03:00:42.997057  9648 layer_factory.hpp:77] Creating layer relu3
I0109 03:00:42.997062  9648 net.cpp:94] Creating Layer relu3
I0109 03:00:42.997066  9648 net.cpp:435] relu3 <- conv3
I0109 03:00:42.997071  9648 net.cpp:409] relu3 -> relu3
I0109 03:00:42.997084  9648 net.cpp:144] Setting up relu3
I0109 03:00:42.997089  9648 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0109 03:00:42.997093  9648 net.cpp:159] Memory required for data: 47396120
I0109 03:00:42.997097  9648 layer_factory.hpp:77] Creating layer relu3_fixed
I0109 03:00:42.997102  9648 net.cpp:94] Creating Layer relu3_fixed
I0109 03:00:42.997104  9648 net.cpp:435] relu3_fixed <- relu3
I0109 03:00:42.997107  9648 net.cpp:396] relu3_fixed -> relu3 (in-place)
I0109 03:00:42.997128  9648 net.cpp:144] Setting up relu3_fixed
I0109 03:00:42.997133  9648 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0109 03:00:42.997135  9648 net.cpp:159] Memory required for data: 47666520
I0109 03:00:42.997139  9648 layer_factory.hpp:77] Creating layer conv4
I0109 03:00:42.997146  9648 net.cpp:94] Creating Layer conv4
I0109 03:00:42.997149  9648 net.cpp:435] conv4 <- relu3
I0109 03:00:42.997153  9648 net.cpp:409] conv4 -> conv4
I0109 03:00:42.997393  9648 layer_factory.hpp:77] Creating layer conv4
I0109 03:00:42.997756  9648 net.cpp:144] Setting up conv4
I0109 03:00:42.997761  9648 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0109 03:00:42.997766  9648 net.cpp:159] Memory required for data: 47936920
I0109 03:00:42.997771  9648 layer_factory.hpp:77] Creating layer relu4
I0109 03:00:42.997774  9648 net.cpp:94] Creating Layer relu4
I0109 03:00:42.997777  9648 net.cpp:435] relu4 <- conv4
I0109 03:00:42.997781  9648 net.cpp:409] relu4 -> relu4
I0109 03:00:42.997797  9648 net.cpp:144] Setting up relu4
I0109 03:00:42.997802  9648 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0109 03:00:42.997807  9648 net.cpp:159] Memory required for data: 48207320
I0109 03:00:42.997808  9648 layer_factory.hpp:77] Creating layer relu4_fixed
I0109 03:00:42.997812  9648 net.cpp:94] Creating Layer relu4_fixed
I0109 03:00:42.997815  9648 net.cpp:435] relu4_fixed <- relu4
I0109 03:00:42.997819  9648 net.cpp:396] relu4_fixed -> relu4 (in-place)
I0109 03:00:42.997841  9648 net.cpp:144] Setting up relu4_fixed
I0109 03:00:42.997846  9648 net.cpp:151] Top shape: 10 40 13 13 (67600)
I0109 03:00:42.997850  9648 net.cpp:159] Memory required for data: 48477720
I0109 03:00:42.997854  9648 layer_factory.hpp:77] Creating layer conv5
I0109 03:00:42.997860  9648 net.cpp:94] Creating Layer conv5
I0109 03:00:42.997864  9648 net.cpp:435] conv5 <- relu4
I0109 03:00:42.997869  9648 net.cpp:409] conv5 -> conv5
I0109 03:00:42.998085  9648 layer_factory.hpp:77] Creating layer conv5
I0109 03:00:42.998411  9648 net.cpp:144] Setting up conv5
I0109 03:00:42.998417  9648 net.cpp:151] Top shape: 10 26 13 13 (43940)
I0109 03:00:42.998422  9648 net.cpp:159] Memory required for data: 48653480
I0109 03:00:42.998427  9648 layer_factory.hpp:77] Creating layer relu5
I0109 03:00:42.998431  9648 net.cpp:94] Creating Layer relu5
I0109 03:00:42.998435  9648 net.cpp:435] relu5 <- conv5
I0109 03:00:42.998438  9648 net.cpp:409] relu5 -> relu5
I0109 03:00:42.998452  9648 net.cpp:144] Setting up relu5
I0109 03:00:42.998458  9648 net.cpp:151] Top shape: 10 26 13 13 (43940)
I0109 03:00:42.998461  9648 net.cpp:159] Memory required for data: 48829240
I0109 03:00:42.998466  9648 layer_factory.hpp:77] Creating layer pool5
I0109 03:00:42.998469  9648 net.cpp:94] Creating Layer pool5
I0109 03:00:42.998472  9648 net.cpp:435] pool5 <- relu5
I0109 03:00:42.998476  9648 net.cpp:409] pool5 -> pool5
I0109 03:00:42.998498  9648 net.cpp:144] Setting up pool5
I0109 03:00:42.998503  9648 net.cpp:151] Top shape: 10 26 6 6 (9360)
I0109 03:00:42.998507  9648 net.cpp:159] Memory required for data: 48866680
I0109 03:00:42.998510  9648 layer_factory.hpp:77] Creating layer pool5_fixed
I0109 03:00:42.998514  9648 net.cpp:94] Creating Layer pool5_fixed
I0109 03:00:42.998517  9648 net.cpp:435] pool5_fixed <- pool5
I0109 03:00:42.998522  9648 net.cpp:396] pool5_fixed -> pool5 (in-place)
I0109 03:00:42.998543  9648 net.cpp:144] Setting up pool5_fixed
I0109 03:00:42.998548  9648 net.cpp:151] Top shape: 10 26 6 6 (9360)
I0109 03:00:42.998613  9648 net.cpp:159] Memory required for data: 48904120
I0109 03:00:42.998617  9648 layer_factory.hpp:77] Creating layer fc6
I0109 03:00:42.998623  9648 net.cpp:94] Creating Layer fc6
I0109 03:00:42.998626  9648 net.cpp:435] fc6 <- pool5
I0109 03:00:42.998631  9648 net.cpp:409] fc6 -> fc6
I0109 03:00:43.035658  9648 layer_factory.hpp:77] Creating layer fc6
I0109 03:00:43.069586  9648 net.cpp:144] Setting up fc6
I0109 03:00:43.069605  9648 net.cpp:151] Top shape: 10 4096 (40960)
I0109 03:00:43.069612  9648 net.cpp:159] Memory required for data: 49067960
I0109 03:00:43.069623  9648 layer_factory.hpp:77] Creating layer relu6
I0109 03:00:43.069631  9648 net.cpp:94] Creating Layer relu6
I0109 03:00:43.069634  9648 net.cpp:435] relu6 <- fc6
I0109 03:00:43.069640  9648 net.cpp:409] relu6 -> relu6
I0109 03:00:43.069660  9648 net.cpp:144] Setting up relu6
I0109 03:00:43.069664  9648 net.cpp:151] Top shape: 10 4096 (40960)
I0109 03:00:43.069666  9648 net.cpp:159] Memory required for data: 49231800
I0109 03:00:43.069669  9648 layer_factory.hpp:77] Creating layer relu6_fixed
I0109 03:00:43.069674  9648 net.cpp:94] Creating Layer relu6_fixed
I0109 03:00:43.069676  9648 net.cpp:435] relu6_fixed <- relu6
I0109 03:00:43.069679  9648 net.cpp:396] relu6_fixed -> relu6 (in-place)
I0109 03:00:43.069716  9648 net.cpp:144] Setting up relu6_fixed
I0109 03:00:43.069721  9648 net.cpp:151] Top shape: 10 4096 (40960)
I0109 03:00:43.069725  9648 net.cpp:159] Memory required for data: 49395640
I0109 03:00:43.069728  9648 layer_factory.hpp:77] Creating layer fc7
I0109 03:00:43.069736  9648 net.cpp:94] Creating Layer fc7
I0109 03:00:43.069738  9648 net.cpp:435] fc7 <- relu6
I0109 03:00:43.069743  9648 net.cpp:409] fc7 -> bn7
I0109 03:00:43.210791  9648 layer_factory.hpp:77] Creating layer fc7
I0109 03:00:43.347575  9648 net.cpp:144] Setting up fc7
I0109 03:00:43.347599  9648 net.cpp:151] Top shape: 10 4096 (40960)
I0109 03:00:43.347605  9648 net.cpp:159] Memory required for data: 49559480
I0109 03:00:43.347616  9648 layer_factory.hpp:77] Creating layer relu7
I0109 03:00:43.347623  9648 net.cpp:94] Creating Layer relu7
I0109 03:00:43.347627  9648 net.cpp:435] relu7 <- bn7
I0109 03:00:43.347633  9648 net.cpp:409] relu7 -> relu7
I0109 03:00:43.347651  9648 net.cpp:144] Setting up relu7
I0109 03:00:43.347653  9648 net.cpp:151] Top shape: 10 4096 (40960)
I0109 03:00:43.347656  9648 net.cpp:159] Memory required for data: 49723320
I0109 03:00:43.347658  9648 layer_factory.hpp:77] Creating layer relu7_fixed
I0109 03:00:43.347666  9648 net.cpp:94] Creating Layer relu7_fixed
I0109 03:00:43.347667  9648 net.cpp:435] relu7_fixed <- relu7
I0109 03:00:43.347671  9648 net.cpp:396] relu7_fixed -> relu7 (in-place)
I0109 03:00:43.347707  9648 net.cpp:144] Setting up relu7_fixed
I0109 03:00:43.347712  9648 net.cpp:151] Top shape: 10 4096 (40960)
I0109 03:00:43.347715  9648 net.cpp:159] Memory required for data: 49887160
I0109 03:00:43.347718  9648 layer_factory.hpp:77] Creating layer fc8
I0109 03:00:43.347724  9648 net.cpp:94] Creating Layer fc8
I0109 03:00:43.347726  9648 net.cpp:435] fc8 <- relu7
I0109 03:00:43.347730  9648 net.cpp:409] fc8 -> fc8
I0109 03:00:43.347836  9648 layer_factory.hpp:77] Creating layer fc8
I0109 03:00:43.347995  9648 net.cpp:144] Setting up fc8
I0109 03:00:43.347999  9648 net.cpp:151] Top shape: 10 2 (20)
I0109 03:00:43.348003  9648 net.cpp:159] Memory required for data: 49887240
I0109 03:00:43.348007  9648 layer_factory.hpp:77] Creating layer fc8_fixed
I0109 03:00:43.348011  9648 net.cpp:94] Creating Layer fc8_fixed
I0109 03:00:43.348014  9648 net.cpp:435] fc8_fixed <- fc8
I0109 03:00:43.348017  9648 net.cpp:396] fc8_fixed -> fc8 (in-place)
I0109 03:00:43.348037  9648 net.cpp:144] Setting up fc8_fixed
I0109 03:00:43.348042  9648 net.cpp:151] Top shape: 10 2 (20)
I0109 03:00:43.348045  9648 net.cpp:159] Memory required for data: 49887320
I0109 03:00:43.348048  9648 layer_factory.hpp:77] Creating layer loss
I0109 03:00:43.348053  9648 net.cpp:94] Creating Layer loss
I0109 03:00:43.348057  9648 net.cpp:435] loss <- fc8
I0109 03:00:43.348059  9648 net.cpp:435] loss <- label
I0109 03:00:43.348063  9648 net.cpp:409] loss -> loss
I0109 03:00:43.348068  9648 layer_factory.hpp:77] Creating layer loss
I0109 03:00:43.348129  9648 net.cpp:144] Setting up loss
I0109 03:00:43.348134  9648 net.cpp:151] Top shape: (1)
I0109 03:00:43.348137  9648 net.cpp:154]     with loss weight 1
I0109 03:00:43.348148  9648 net.cpp:159] Memory required for data: 49887324
I0109 03:00:43.348151  9648 net.cpp:220] loss needs backward computation.
I0109 03:00:43.348155  9648 net.cpp:220] fc8_fixed needs backward computation.
I0109 03:00:43.348157  9648 net.cpp:220] fc8 needs backward computation.
I0109 03:00:43.348160  9648 net.cpp:220] relu7_fixed needs backward computation.
I0109 03:00:43.348162  9648 net.cpp:220] relu7 needs backward computation.
I0109 03:00:43.348165  9648 net.cpp:220] fc7 needs backward computation.
I0109 03:00:43.348168  9648 net.cpp:220] relu6_fixed needs backward computation.
I0109 03:00:43.348171  9648 net.cpp:220] relu6 needs backward computation.
I0109 03:00:43.348191  9648 net.cpp:220] fc6 needs backward computation.
I0109 03:00:43.348196  9648 net.cpp:220] pool5_fixed needs backward computation.
I0109 03:00:43.348199  9648 net.cpp:220] pool5 needs backward computation.
I0109 03:00:43.348202  9648 net.cpp:220] relu5 needs backward computation.
I0109 03:00:43.348206  9648 net.cpp:220] conv5 needs backward computation.
I0109 03:00:43.348209  9648 net.cpp:220] relu4_fixed needs backward computation.
I0109 03:00:43.348212  9648 net.cpp:220] relu4 needs backward computation.
I0109 03:00:43.348217  9648 net.cpp:220] conv4 needs backward computation.
I0109 03:00:43.348219  9648 net.cpp:220] relu3_fixed needs backward computation.
I0109 03:00:43.348222  9648 net.cpp:220] relu3 needs backward computation.
I0109 03:00:43.348227  9648 net.cpp:220] conv3 needs backward computation.
I0109 03:00:43.348230  9648 net.cpp:220] pool2_fixed needs backward computation.
I0109 03:00:43.348233  9648 net.cpp:220] pool2 needs backward computation.
I0109 03:00:43.348237  9648 net.cpp:220] relu2 needs backward computation.
I0109 03:00:43.348240  9648 net.cpp:220] conv2 needs backward computation.
I0109 03:00:43.348243  9648 net.cpp:220] pool1_fixed needs backward computation.
I0109 03:00:43.348246  9648 net.cpp:220] pool1 needs backward computation.
I0109 03:00:43.348249  9648 net.cpp:220] relu1 needs backward computation.
I0109 03:00:43.348253  9648 net.cpp:220] conv1 needs backward computation.
I0109 03:00:43.348256  9648 net.cpp:222] data_fixed does not need backward computation.
I0109 03:00:43.348259  9648 net.cpp:222] data does not need backward computation.
I0109 03:00:43.348263  9648 net.cpp:264] This network produces output loss
I0109 03:00:43.348278  9648 net.cpp:284] Network initialization done.
I0109 03:00:43.390894  9648 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0109 03:00:43.390933  9648 net.cpp:52] Initializing net from parameters:
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 106
    mean_value: 116
    mean_value: 124
  }
  data_param {
    source: "input/lmdb/valid_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "data_fixed"
  type: "FixedNeuron"
  bottom: "data"
  top: "data"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: OVER_FLOW
    bit_width: 8
    follow_data_layer: true
  }
}
layer {
  name: "conv1"
  type: "ConvolutionFixed"
  bottom: "data"
  top: "bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 78
    bias_term: true
    pad: 1
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool1_fixed"
  type: "FixedNeuron"
  bottom: "pool1"
  top: "pool1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv2"
  type: "ConvolutionFixed"
  bottom: "pool1"
  top: "bn2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 154
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool2_fixed"
  type: "FixedNeuron"
  bottom: "pool2"
  top: "pool2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv3"
  type: "ConvolutionFixed"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "relu3_fixed"
  type: "FixedNeuron"
  bottom: "relu3"
  top: "relu3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv4"
  type: "ConvolutionFixed"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "relu4_fixed"
  type: "FixedNeuron"
  bottom: "relu4"
  top: "relu4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "conv5"
  type: "ConvolutionFixed"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 26
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool5_fixed"
  type: "FixedNeuron"
  bottom: "pool5"
  top: "pool5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc6"
  type: "InnerProductFixed"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "relu6_fixed"
  type: "FixedNeuron"
  bottom: "relu6"
  top: "relu6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc7"
  type: "InnerProductFixed"
  bottom: "relu6"
  top: "bn7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    bias_term: true
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "relu7"
}
layer {
  name: "relu7_fixed"
  type: "FixedNeuron"
  bottom: "relu7"
  top: "relu7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc8"
  type: "InnerProductFixed"
  bottom: "relu7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "fc8_fixed"
  type: "FixedNeuron"
  bottom: "fc8"
  top: "fc8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy-top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "top-1"
  include {
    phase: TEST
  }
}
I0109 03:00:43.391340  9648 layer_factory.hpp:77] Creating layer data
I0109 03:00:43.391376  9648 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 03:00:43.392055  9648 net.cpp:94] Creating Layer data
I0109 03:00:43.392064  9648 net.cpp:409] data -> data
I0109 03:00:43.392073  9648 net.cpp:409] data -> label
I0109 03:00:43.393740  9682 db_lmdb.cpp:35] Opened lmdb input/lmdb/valid_lmdb
I0109 03:00:43.393759  9682 db_lmdb.cpp:38] Items count: 4000
I0109 03:00:43.393777  9682 data_reader.cpp:124] TEST: reading data using 1 channel(s)
I0109 03:00:43.393962  9648 data_layer.cpp:78] ReshapePrefetch 50, 3, 227, 227
I0109 03:00:43.394058  9648 data_layer.cpp:83] output data size: 50,3,227,227
I0109 03:00:43.492270  9648 internal_thread.cpp:27] Starting internal thread(s) on GPU 0
I0109 03:00:43.492337  9648 net.cpp:144] Setting up data
I0109 03:00:43.492342  9648 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0109 03:00:43.492352  9648 net.cpp:151] Top shape: 50 (50)
I0109 03:00:43.492355  9648 net.cpp:159] Memory required for data: 30917600
I0109 03:00:43.492359  9648 layer_factory.hpp:77] Creating layer label_data_1_split
I0109 03:00:43.492372  9648 net.cpp:94] Creating Layer label_data_1_split
I0109 03:00:43.492377  9648 net.cpp:435] label_data_1_split <- label
I0109 03:00:43.492383  9648 net.cpp:409] label_data_1_split -> label_data_1_split_0
I0109 03:00:43.492390  9648 net.cpp:409] label_data_1_split -> label_data_1_split_1
I0109 03:00:43.492394  9648 net.cpp:409] label_data_1_split -> label_data_1_split_2
I0109 03:00:43.492440  9648 net.cpp:144] Setting up label_data_1_split
I0109 03:00:43.492460  9648 net.cpp:151] Top shape: 50 (50)
I0109 03:00:43.492465  9648 net.cpp:151] Top shape: 50 (50)
I0109 03:00:43.492467  9648 net.cpp:151] Top shape: 50 (50)
I0109 03:00:43.492470  9648 net.cpp:159] Memory required for data: 30918200
I0109 03:00:43.492473  9648 layer_factory.hpp:77] Creating layer data_fixed
I0109 03:00:43.492480  9648 net.cpp:94] Creating Layer data_fixed
I0109 03:00:43.492484  9648 net.cpp:435] data_fixed <- data
I0109 03:00:43.492488  9648 net.cpp:396] data_fixed -> data (in-place)
I0109 03:00:43.492543  9648 net.cpp:144] Setting up data_fixed
I0109 03:00:43.492547  9648 net.cpp:151] Top shape: 50 3 227 227 (7729350)
I0109 03:00:43.492553  9648 net.cpp:159] Memory required for data: 61835600
I0109 03:00:43.492561  9648 layer_factory.hpp:77] Creating layer conv1
I0109 03:00:43.492571  9648 net.cpp:94] Creating Layer conv1
I0109 03:00:43.492574  9648 net.cpp:435] conv1 <- data
I0109 03:00:43.492578  9648 net.cpp:409] conv1 -> bn1
I0109 03:00:43.492998  9648 layer_factory.hpp:77] Creating layer conv1
I0109 03:00:43.493472  9648 net.cpp:144] Setting up conv1
I0109 03:00:43.493477  9648 net.cpp:151] Top shape: 50 78 55 55 (11797500)
I0109 03:00:43.493484  9648 net.cpp:159] Memory required for data: 109025600
I0109 03:00:43.493490  9648 layer_factory.hpp:77] Creating layer relu1
I0109 03:00:43.493497  9648 net.cpp:94] Creating Layer relu1
I0109 03:00:43.493500  9648 net.cpp:435] relu1 <- bn1
I0109 03:00:43.493505  9648 net.cpp:409] relu1 -> relu1
I0109 03:00:43.493520  9648 net.cpp:144] Setting up relu1
I0109 03:00:43.493525  9648 net.cpp:151] Top shape: 50 78 55 55 (11797500)
I0109 03:00:43.493530  9648 net.cpp:159] Memory required for data: 156215600
I0109 03:00:43.493532  9648 layer_factory.hpp:77] Creating layer pool1
I0109 03:00:43.493538  9648 net.cpp:94] Creating Layer pool1
I0109 03:00:43.493541  9648 net.cpp:435] pool1 <- relu1
I0109 03:00:43.493546  9648 net.cpp:409] pool1 -> pool1
I0109 03:00:43.493568  9648 net.cpp:144] Setting up pool1
I0109 03:00:43.493573  9648 net.cpp:151] Top shape: 50 78 27 27 (2843100)
I0109 03:00:43.493577  9648 net.cpp:159] Memory required for data: 167588000
I0109 03:00:43.493580  9648 layer_factory.hpp:77] Creating layer pool1_fixed
I0109 03:00:43.493585  9648 net.cpp:94] Creating Layer pool1_fixed
I0109 03:00:43.493588  9648 net.cpp:435] pool1_fixed <- pool1
I0109 03:00:43.493592  9648 net.cpp:396] pool1_fixed -> pool1 (in-place)
I0109 03:00:43.493613  9648 net.cpp:144] Setting up pool1_fixed
I0109 03:00:43.493618  9648 net.cpp:151] Top shape: 50 78 27 27 (2843100)
I0109 03:00:43.493623  9648 net.cpp:159] Memory required for data: 178960400
I0109 03:00:43.493626  9648 layer_factory.hpp:77] Creating layer conv2
I0109 03:00:43.493633  9648 net.cpp:94] Creating Layer conv2
I0109 03:00:43.493635  9648 net.cpp:435] conv2 <- pool1
I0109 03:00:43.493640  9648 net.cpp:409] conv2 -> bn2
I0109 03:00:43.498690  9648 layer_factory.hpp:77] Creating layer conv2
I0109 03:00:43.502715  9648 net.cpp:144] Setting up conv2
I0109 03:00:43.502732  9648 net.cpp:151] Top shape: 50 154 27 27 (5613300)
I0109 03:00:43.502739  9648 net.cpp:159] Memory required for data: 201413600
I0109 03:00:43.502750  9648 layer_factory.hpp:77] Creating layer relu2
I0109 03:00:43.502759  9648 net.cpp:94] Creating Layer relu2
I0109 03:00:43.502763  9648 net.cpp:435] relu2 <- bn2
I0109 03:00:43.502770  9648 net.cpp:409] relu2 -> relu2
I0109 03:00:43.502789  9648 net.cpp:144] Setting up relu2
I0109 03:00:43.502794  9648 net.cpp:151] Top shape: 50 154 27 27 (5613300)
I0109 03:00:43.502797  9648 net.cpp:159] Memory required for data: 223866800
I0109 03:00:43.502800  9648 layer_factory.hpp:77] Creating layer pool2
I0109 03:00:43.502806  9648 net.cpp:94] Creating Layer pool2
I0109 03:00:43.502810  9648 net.cpp:435] pool2 <- relu2
I0109 03:00:43.502815  9648 net.cpp:409] pool2 -> pool2
I0109 03:00:43.502840  9648 net.cpp:144] Setting up pool2
I0109 03:00:43.502843  9648 net.cpp:151] Top shape: 50 154 13 13 (1301300)
I0109 03:00:43.502847  9648 net.cpp:159] Memory required for data: 229072000
I0109 03:00:43.502851  9648 layer_factory.hpp:77] Creating layer pool2_fixed
I0109 03:00:43.502856  9648 net.cpp:94] Creating Layer pool2_fixed
I0109 03:00:43.502859  9648 net.cpp:435] pool2_fixed <- pool2
I0109 03:00:43.502863  9648 net.cpp:396] pool2_fixed -> pool2 (in-place)
I0109 03:00:43.502885  9648 net.cpp:144] Setting up pool2_fixed
I0109 03:00:43.502890  9648 net.cpp:151] Top shape: 50 154 13 13 (1301300)
I0109 03:00:43.502894  9648 net.cpp:159] Memory required for data: 234277200
I0109 03:00:43.502898  9648 layer_factory.hpp:77] Creating layer conv3
I0109 03:00:43.502907  9648 net.cpp:94] Creating Layer conv3
I0109 03:00:43.502910  9648 net.cpp:435] conv3 <- pool2
I0109 03:00:43.502915  9648 net.cpp:409] conv3 -> conv3
I0109 03:00:43.503512  9648 layer_factory.hpp:77] Creating layer conv3
I0109 03:00:43.504220  9648 net.cpp:144] Setting up conv3
I0109 03:00:43.504227  9648 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0109 03:00:43.504231  9648 net.cpp:159] Memory required for data: 235629200
I0109 03:00:43.504238  9648 layer_factory.hpp:77] Creating layer relu3
I0109 03:00:43.504243  9648 net.cpp:94] Creating Layer relu3
I0109 03:00:43.504246  9648 net.cpp:435] relu3 <- conv3
I0109 03:00:43.504251  9648 net.cpp:409] relu3 -> relu3
I0109 03:00:43.504266  9648 net.cpp:144] Setting up relu3
I0109 03:00:43.504271  9648 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0109 03:00:43.504274  9648 net.cpp:159] Memory required for data: 236981200
I0109 03:00:43.504276  9648 layer_factory.hpp:77] Creating layer relu3_fixed
I0109 03:00:43.504281  9648 net.cpp:94] Creating Layer relu3_fixed
I0109 03:00:43.504284  9648 net.cpp:435] relu3_fixed <- relu3
I0109 03:00:43.504288  9648 net.cpp:396] relu3_fixed -> relu3 (in-place)
I0109 03:00:43.504308  9648 net.cpp:144] Setting up relu3_fixed
I0109 03:00:43.504312  9648 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0109 03:00:43.504317  9648 net.cpp:159] Memory required for data: 238333200
I0109 03:00:43.504319  9648 layer_factory.hpp:77] Creating layer conv4
I0109 03:00:43.504341  9648 net.cpp:94] Creating Layer conv4
I0109 03:00:43.504344  9648 net.cpp:435] conv4 <- relu3
I0109 03:00:43.504348  9648 net.cpp:409] conv4 -> conv4
I0109 03:00:43.504602  9648 layer_factory.hpp:77] Creating layer conv4
I0109 03:00:43.504957  9648 net.cpp:144] Setting up conv4
I0109 03:00:43.504962  9648 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0109 03:00:43.504966  9648 net.cpp:159] Memory required for data: 239685200
I0109 03:00:43.504971  9648 layer_factory.hpp:77] Creating layer relu4
I0109 03:00:43.504976  9648 net.cpp:94] Creating Layer relu4
I0109 03:00:43.504978  9648 net.cpp:435] relu4 <- conv4
I0109 03:00:43.504983  9648 net.cpp:409] relu4 -> relu4
I0109 03:00:43.504997  9648 net.cpp:144] Setting up relu4
I0109 03:00:43.505000  9648 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0109 03:00:43.505004  9648 net.cpp:159] Memory required for data: 241037200
I0109 03:00:43.505007  9648 layer_factory.hpp:77] Creating layer relu4_fixed
I0109 03:00:43.505013  9648 net.cpp:94] Creating Layer relu4_fixed
I0109 03:00:43.505017  9648 net.cpp:435] relu4_fixed <- relu4
I0109 03:00:43.505020  9648 net.cpp:396] relu4_fixed -> relu4 (in-place)
I0109 03:00:43.505043  9648 net.cpp:144] Setting up relu4_fixed
I0109 03:00:43.505046  9648 net.cpp:151] Top shape: 50 40 13 13 (338000)
I0109 03:00:43.505050  9648 net.cpp:159] Memory required for data: 242389200
I0109 03:00:43.505054  9648 layer_factory.hpp:77] Creating layer conv5
I0109 03:00:43.505060  9648 net.cpp:94] Creating Layer conv5
I0109 03:00:43.505064  9648 net.cpp:435] conv5 <- relu4
I0109 03:00:43.505067  9648 net.cpp:409] conv5 -> conv5
I0109 03:00:43.505280  9648 layer_factory.hpp:77] Creating layer conv5
I0109 03:00:43.505594  9648 net.cpp:144] Setting up conv5
I0109 03:00:43.505599  9648 net.cpp:151] Top shape: 50 26 13 13 (219700)
I0109 03:00:43.505604  9648 net.cpp:159] Memory required for data: 243268000
I0109 03:00:43.505607  9648 layer_factory.hpp:77] Creating layer relu5
I0109 03:00:43.505611  9648 net.cpp:94] Creating Layer relu5
I0109 03:00:43.505614  9648 net.cpp:435] relu5 <- conv5
I0109 03:00:43.505617  9648 net.cpp:409] relu5 -> relu5
I0109 03:00:43.505632  9648 net.cpp:144] Setting up relu5
I0109 03:00:43.505636  9648 net.cpp:151] Top shape: 50 26 13 13 (219700)
I0109 03:00:43.505641  9648 net.cpp:159] Memory required for data: 244146800
I0109 03:00:43.505645  9648 layer_factory.hpp:77] Creating layer pool5
I0109 03:00:43.505648  9648 net.cpp:94] Creating Layer pool5
I0109 03:00:43.505651  9648 net.cpp:435] pool5 <- relu5
I0109 03:00:43.505656  9648 net.cpp:409] pool5 -> pool5
I0109 03:00:43.505676  9648 net.cpp:144] Setting up pool5
I0109 03:00:43.505681  9648 net.cpp:151] Top shape: 50 26 6 6 (46800)
I0109 03:00:43.505684  9648 net.cpp:159] Memory required for data: 244334000
I0109 03:00:43.505687  9648 layer_factory.hpp:77] Creating layer pool5_fixed
I0109 03:00:43.505692  9648 net.cpp:94] Creating Layer pool5_fixed
I0109 03:00:43.505694  9648 net.cpp:435] pool5_fixed <- pool5
I0109 03:00:43.505698  9648 net.cpp:396] pool5_fixed -> pool5 (in-place)
I0109 03:00:43.505722  9648 net.cpp:144] Setting up pool5_fixed
I0109 03:00:43.505725  9648 net.cpp:151] Top shape: 50 26 6 6 (46800)
I0109 03:00:43.505745  9648 net.cpp:159] Memory required for data: 244521200
I0109 03:00:43.505749  9648 layer_factory.hpp:77] Creating layer fc6
I0109 03:00:43.505757  9648 net.cpp:94] Creating Layer fc6
I0109 03:00:43.505760  9648 net.cpp:435] fc6 <- pool5
I0109 03:00:43.505764  9648 net.cpp:409] fc6 -> fc6
I0109 03:00:43.541191  9648 layer_factory.hpp:77] Creating layer fc6
I0109 03:00:43.576126  9648 net.cpp:144] Setting up fc6
I0109 03:00:43.576149  9648 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:43.576156  9648 net.cpp:159] Memory required for data: 245340400
I0109 03:00:43.576184  9648 layer_factory.hpp:77] Creating layer relu6
I0109 03:00:43.576191  9648 net.cpp:94] Creating Layer relu6
I0109 03:00:43.576195  9648 net.cpp:435] relu6 <- fc6
I0109 03:00:43.576205  9648 net.cpp:409] relu6 -> relu6
I0109 03:00:43.576223  9648 net.cpp:144] Setting up relu6
I0109 03:00:43.576226  9648 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:43.576229  9648 net.cpp:159] Memory required for data: 246159600
I0109 03:00:43.576231  9648 layer_factory.hpp:77] Creating layer relu6_fixed
I0109 03:00:43.576236  9648 net.cpp:94] Creating Layer relu6_fixed
I0109 03:00:43.576239  9648 net.cpp:435] relu6_fixed <- relu6
I0109 03:00:43.576242  9648 net.cpp:396] relu6_fixed -> relu6 (in-place)
I0109 03:00:43.576262  9648 net.cpp:144] Setting up relu6_fixed
I0109 03:00:43.576267  9648 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:43.576270  9648 net.cpp:159] Memory required for data: 246978800
I0109 03:00:43.576273  9648 layer_factory.hpp:77] Creating layer fc7
I0109 03:00:43.576279  9648 net.cpp:94] Creating Layer fc7
I0109 03:00:43.576282  9648 net.cpp:435] fc7 <- relu6
I0109 03:00:43.576285  9648 net.cpp:409] fc7 -> bn7
I0109 03:00:43.712977  9648 layer_factory.hpp:77] Creating layer fc7
I0109 03:00:43.850041  9648 net.cpp:144] Setting up fc7
I0109 03:00:43.850064  9648 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:43.850072  9648 net.cpp:159] Memory required for data: 247798000
I0109 03:00:43.850082  9648 layer_factory.hpp:77] Creating layer relu7
I0109 03:00:43.850090  9648 net.cpp:94] Creating Layer relu7
I0109 03:00:43.850093  9648 net.cpp:435] relu7 <- bn7
I0109 03:00:43.850100  9648 net.cpp:409] relu7 -> relu7
I0109 03:00:43.850118  9648 net.cpp:144] Setting up relu7
I0109 03:00:43.850121  9648 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:43.850124  9648 net.cpp:159] Memory required for data: 248617200
I0109 03:00:43.850127  9648 layer_factory.hpp:77] Creating layer relu7_fixed
I0109 03:00:43.850133  9648 net.cpp:94] Creating Layer relu7_fixed
I0109 03:00:43.850136  9648 net.cpp:435] relu7_fixed <- relu7
I0109 03:00:43.850139  9648 net.cpp:396] relu7_fixed -> relu7 (in-place)
I0109 03:00:43.850174  9648 net.cpp:144] Setting up relu7_fixed
I0109 03:00:43.850179  9648 net.cpp:151] Top shape: 50 4096 (204800)
I0109 03:00:43.850183  9648 net.cpp:159] Memory required for data: 249436400
I0109 03:00:43.850186  9648 layer_factory.hpp:77] Creating layer fc8
I0109 03:00:43.850193  9648 net.cpp:94] Creating Layer fc8
I0109 03:00:43.850194  9648 net.cpp:435] fc8 <- relu7
I0109 03:00:43.850198  9648 net.cpp:409] fc8 -> fc8
I0109 03:00:43.850312  9648 layer_factory.hpp:77] Creating layer fc8
I0109 03:00:43.850477  9648 net.cpp:144] Setting up fc8
I0109 03:00:43.850482  9648 net.cpp:151] Top shape: 50 2 (100)
I0109 03:00:43.850486  9648 net.cpp:159] Memory required for data: 249436800
I0109 03:00:43.850490  9648 layer_factory.hpp:77] Creating layer fc8_fixed
I0109 03:00:43.850512  9648 net.cpp:94] Creating Layer fc8_fixed
I0109 03:00:43.850514  9648 net.cpp:435] fc8_fixed <- fc8
I0109 03:00:43.850518  9648 net.cpp:396] fc8_fixed -> fc8 (in-place)
I0109 03:00:43.850540  9648 net.cpp:144] Setting up fc8_fixed
I0109 03:00:43.850544  9648 net.cpp:151] Top shape: 50 2 (100)
I0109 03:00:43.850548  9648 net.cpp:159] Memory required for data: 249437200
I0109 03:00:43.850553  9648 layer_factory.hpp:77] Creating layer fc8_fc8_fixed_0_split
I0109 03:00:43.850558  9648 net.cpp:94] Creating Layer fc8_fc8_fixed_0_split
I0109 03:00:43.850560  9648 net.cpp:435] fc8_fc8_fixed_0_split <- fc8
I0109 03:00:43.850564  9648 net.cpp:409] fc8_fc8_fixed_0_split -> fc8_fc8_fixed_0_split_0
I0109 03:00:43.850569  9648 net.cpp:409] fc8_fc8_fixed_0_split -> fc8_fc8_fixed_0_split_1
I0109 03:00:43.850574  9648 net.cpp:409] fc8_fc8_fixed_0_split -> fc8_fc8_fixed_0_split_2
I0109 03:00:43.850605  9648 net.cpp:144] Setting up fc8_fc8_fixed_0_split
I0109 03:00:43.850610  9648 net.cpp:151] Top shape: 50 2 (100)
I0109 03:00:43.850612  9648 net.cpp:151] Top shape: 50 2 (100)
I0109 03:00:43.850616  9648 net.cpp:151] Top shape: 50 2 (100)
I0109 03:00:43.850620  9648 net.cpp:159] Memory required for data: 249438400
I0109 03:00:43.850622  9648 layer_factory.hpp:77] Creating layer accuracy
I0109 03:00:43.850630  9648 net.cpp:94] Creating Layer accuracy
I0109 03:00:43.850632  9648 net.cpp:435] accuracy <- fc8_fc8_fixed_0_split_0
I0109 03:00:43.850636  9648 net.cpp:435] accuracy <- label_data_1_split_0
I0109 03:00:43.850641  9648 net.cpp:409] accuracy -> accuracy
I0109 03:00:43.850646  9648 net.cpp:144] Setting up accuracy
I0109 03:00:43.850649  9648 net.cpp:151] Top shape: (1)
I0109 03:00:43.850652  9648 net.cpp:159] Memory required for data: 249438404
I0109 03:00:43.850656  9648 layer_factory.hpp:77] Creating layer loss
I0109 03:00:43.850661  9648 net.cpp:94] Creating Layer loss
I0109 03:00:43.850663  9648 net.cpp:435] loss <- fc8_fc8_fixed_0_split_1
I0109 03:00:43.850667  9648 net.cpp:435] loss <- label_data_1_split_1
I0109 03:00:43.850672  9648 net.cpp:409] loss -> loss
I0109 03:00:43.850678  9648 layer_factory.hpp:77] Creating layer loss
I0109 03:00:43.850744  9648 net.cpp:144] Setting up loss
I0109 03:00:43.850749  9648 net.cpp:151] Top shape: (1)
I0109 03:00:43.850751  9648 net.cpp:154]     with loss weight 1
I0109 03:00:43.850766  9648 net.cpp:159] Memory required for data: 249438408
I0109 03:00:43.850769  9648 layer_factory.hpp:77] Creating layer accuracy-top1
I0109 03:00:43.850776  9648 net.cpp:94] Creating Layer accuracy-top1
I0109 03:00:43.850780  9648 net.cpp:435] accuracy-top1 <- fc8_fc8_fixed_0_split_2
I0109 03:00:43.850783  9648 net.cpp:435] accuracy-top1 <- label_data_1_split_2
I0109 03:00:43.850788  9648 net.cpp:409] accuracy-top1 -> top-1
I0109 03:00:43.850793  9648 net.cpp:144] Setting up accuracy-top1
I0109 03:00:43.850796  9648 net.cpp:151] Top shape: (1)
I0109 03:00:43.850800  9648 net.cpp:159] Memory required for data: 249438412
I0109 03:00:43.850802  9648 net.cpp:222] accuracy-top1 does not need backward computation.
I0109 03:00:43.850806  9648 net.cpp:220] loss needs backward computation.
I0109 03:00:43.850809  9648 net.cpp:222] accuracy does not need backward computation.
I0109 03:00:43.850813  9648 net.cpp:220] fc8_fc8_fixed_0_split needs backward computation.
I0109 03:00:43.850816  9648 net.cpp:220] fc8_fixed needs backward computation.
I0109 03:00:43.850819  9648 net.cpp:220] fc8 needs backward computation.
I0109 03:00:43.850822  9648 net.cpp:220] relu7_fixed needs backward computation.
I0109 03:00:43.850826  9648 net.cpp:220] relu7 needs backward computation.
I0109 03:00:43.850828  9648 net.cpp:220] fc7 needs backward computation.
I0109 03:00:43.850832  9648 net.cpp:220] relu6_fixed needs backward computation.
I0109 03:00:43.850836  9648 net.cpp:220] relu6 needs backward computation.
I0109 03:00:43.850838  9648 net.cpp:220] fc6 needs backward computation.
I0109 03:00:43.850841  9648 net.cpp:220] pool5_fixed needs backward computation.
I0109 03:00:43.850845  9648 net.cpp:220] pool5 needs backward computation.
I0109 03:00:43.850848  9648 net.cpp:220] relu5 needs backward computation.
I0109 03:00:43.850852  9648 net.cpp:220] conv5 needs backward computation.
I0109 03:00:43.850854  9648 net.cpp:220] relu4_fixed needs backward computation.
I0109 03:00:43.850859  9648 net.cpp:220] relu4 needs backward computation.
I0109 03:00:43.850862  9648 net.cpp:220] conv4 needs backward computation.
I0109 03:00:43.850865  9648 net.cpp:220] relu3_fixed needs backward computation.
I0109 03:00:43.850868  9648 net.cpp:220] relu3 needs backward computation.
I0109 03:00:43.850872  9648 net.cpp:220] conv3 needs backward computation.
I0109 03:00:43.850875  9648 net.cpp:220] pool2_fixed needs backward computation.
I0109 03:00:43.850879  9648 net.cpp:220] pool2 needs backward computation.
I0109 03:00:43.850883  9648 net.cpp:220] relu2 needs backward computation.
I0109 03:00:43.850885  9648 net.cpp:220] conv2 needs backward computation.
I0109 03:00:43.850888  9648 net.cpp:220] pool1_fixed needs backward computation.
I0109 03:00:43.850891  9648 net.cpp:220] pool1 needs backward computation.
I0109 03:00:43.850894  9648 net.cpp:220] relu1 needs backward computation.
I0109 03:00:43.850898  9648 net.cpp:220] conv1 needs backward computation.
I0109 03:00:43.850903  9648 net.cpp:222] data_fixed does not need backward computation.
I0109 03:00:43.850905  9648 net.cpp:222] label_data_1_split does not need backward computation.
I0109 03:00:43.850909  9648 net.cpp:222] data does not need backward computation.
I0109 03:00:43.850912  9648 net.cpp:264] This network produces output accuracy
I0109 03:00:43.850915  9648 net.cpp:264] This network produces output loss
I0109 03:00:43.850919  9648 net.cpp:264] This network produces output top-1
I0109 03:00:43.850936  9648 net.cpp:284] Network initialization done.
I0109 03:00:43.863183  9648 net_test.cpp:431] Net type: other
I0109 03:00:43.863194  9648 net_test.cpp:439] Test Start, total iterations: 50
I0109 03:00:43.863199  9648 net_test.cpp:372] Testing ...
I0109 03:00:43.906932  9648 net_test.cpp:394] Test iter: 1/50, accuracy = 0.98
I0109 03:00:43.906952  9648 net_test.cpp:394] Test iter: 1/50, loss = 0.0239758
I0109 03:00:43.906956  9648 net_test.cpp:394] Test iter: 1/50, top-1 = 0.98
I0109 03:00:43.933037  9648 net_test.cpp:394] Test iter: 2/50, accuracy = 0.96
I0109 03:00:43.933053  9648 net_test.cpp:394] Test iter: 2/50, loss = 0.29487
I0109 03:00:43.933055  9648 net_test.cpp:394] Test iter: 2/50, top-1 = 0.96
I0109 03:00:43.958954  9648 net_test.cpp:394] Test iter: 3/50, accuracy = 0.94
I0109 03:00:43.958971  9648 net_test.cpp:394] Test iter: 3/50, loss = 0.312043
I0109 03:00:43.958973  9648 net_test.cpp:394] Test iter: 3/50, top-1 = 0.94
I0109 03:00:43.983741  9648 net_test.cpp:394] Test iter: 4/50, accuracy = 0.96
I0109 03:00:43.983757  9648 net_test.cpp:394] Test iter: 4/50, loss = 0.267734
I0109 03:00:43.983759  9648 net_test.cpp:394] Test iter: 4/50, top-1 = 0.96
I0109 03:00:44.008679  9648 net_test.cpp:394] Test iter: 5/50, accuracy = 0.9
I0109 03:00:44.008694  9648 net_test.cpp:394] Test iter: 5/50, loss = 0.507491
I0109 03:00:44.008698  9648 net_test.cpp:394] Test iter: 5/50, top-1 = 0.9
I0109 03:00:44.034610  9648 net_test.cpp:394] Test iter: 6/50, accuracy = 0.98
I0109 03:00:44.034626  9648 net_test.cpp:394] Test iter: 6/50, loss = 0.0233457
I0109 03:00:44.034629  9648 net_test.cpp:394] Test iter: 6/50, top-1 = 0.98
I0109 03:00:44.059574  9648 net_test.cpp:394] Test iter: 7/50, accuracy = 0.98
I0109 03:00:44.059589  9648 net_test.cpp:394] Test iter: 7/50, loss = 0.191104
I0109 03:00:44.059592  9648 net_test.cpp:394] Test iter: 7/50, top-1 = 0.98
I0109 03:00:44.084411  9648 net_test.cpp:394] Test iter: 8/50, accuracy = 0.96
I0109 03:00:44.084429  9648 net_test.cpp:394] Test iter: 8/50, loss = 0.304531
I0109 03:00:44.084431  9648 net_test.cpp:394] Test iter: 8/50, top-1 = 0.96
I0109 03:00:44.110502  9648 net_test.cpp:394] Test iter: 9/50, accuracy = 0.98
I0109 03:00:44.110517  9648 net_test.cpp:394] Test iter: 9/50, loss = 0.0476387
I0109 03:00:44.110520  9648 net_test.cpp:394] Test iter: 9/50, top-1 = 0.98
I0109 03:00:44.136937  9648 net_test.cpp:394] Test iter: 10/50, accuracy = 0.96
I0109 03:00:44.136952  9648 net_test.cpp:394] Test iter: 10/50, loss = 0.258323
I0109 03:00:44.136955  9648 net_test.cpp:394] Test iter: 10/50, top-1 = 0.96
I0109 03:00:44.162019  9648 net_test.cpp:394] Test iter: 11/50, accuracy = 0.92
I0109 03:00:44.162034  9648 net_test.cpp:394] Test iter: 11/50, loss = 0.453223
I0109 03:00:44.162037  9648 net_test.cpp:394] Test iter: 11/50, top-1 = 0.92
I0109 03:00:44.187513  9648 net_test.cpp:394] Test iter: 12/50, accuracy = 0.98
I0109 03:00:44.187528  9648 net_test.cpp:394] Test iter: 12/50, loss = 0.101737
I0109 03:00:44.187531  9648 net_test.cpp:394] Test iter: 12/50, top-1 = 0.98
I0109 03:00:44.213490  9648 net_test.cpp:394] Test iter: 13/50, accuracy = 0.96
I0109 03:00:44.213506  9648 net_test.cpp:394] Test iter: 13/50, loss = 0.163727
I0109 03:00:44.213510  9648 net_test.cpp:394] Test iter: 13/50, top-1 = 0.96
I0109 03:00:44.239346  9648 net_test.cpp:394] Test iter: 14/50, accuracy = 0.98
I0109 03:00:44.239362  9648 net_test.cpp:394] Test iter: 14/50, loss = 0.0285471
I0109 03:00:44.239364  9648 net_test.cpp:394] Test iter: 14/50, top-1 = 0.98
I0109 03:00:44.264145  9648 net_test.cpp:394] Test iter: 15/50, accuracy = 0.9
I0109 03:00:44.264160  9648 net_test.cpp:394] Test iter: 15/50, loss = 0.816892
I0109 03:00:44.264164  9648 net_test.cpp:394] Test iter: 15/50, top-1 = 0.9
I0109 03:00:44.290027  9648 net_test.cpp:394] Test iter: 16/50, accuracy = 0.92
I0109 03:00:44.290043  9648 net_test.cpp:394] Test iter: 16/50, loss = 0.451192
I0109 03:00:44.290046  9648 net_test.cpp:394] Test iter: 16/50, top-1 = 0.92
I0109 03:00:44.316066  9648 net_test.cpp:394] Test iter: 17/50, accuracy = 0.94
I0109 03:00:44.316079  9648 net_test.cpp:394] Test iter: 17/50, loss = 0.652594
I0109 03:00:44.316082  9648 net_test.cpp:394] Test iter: 17/50, top-1 = 0.94
I0109 03:00:44.341361  9648 net_test.cpp:394] Test iter: 18/50, accuracy = 0.98
I0109 03:00:44.341377  9648 net_test.cpp:394] Test iter: 18/50, loss = 0.34519
I0109 03:00:44.341379  9648 net_test.cpp:394] Test iter: 18/50, top-1 = 0.98
I0109 03:00:44.366158  9648 net_test.cpp:394] Test iter: 19/50, accuracy = 0.96
I0109 03:00:44.366173  9648 net_test.cpp:394] Test iter: 19/50, loss = 0.25816
I0109 03:00:44.366176  9648 net_test.cpp:394] Test iter: 19/50, top-1 = 0.96
I0109 03:00:44.392200  9648 net_test.cpp:394] Test iter: 20/50, accuracy = 0.96
I0109 03:00:44.392215  9648 net_test.cpp:394] Test iter: 20/50, loss = 0.188204
I0109 03:00:44.392217  9648 net_test.cpp:394] Test iter: 20/50, top-1 = 0.96
I0109 03:00:44.418093  9648 net_test.cpp:394] Test iter: 21/50, accuracy = 0.96
I0109 03:00:44.418108  9648 net_test.cpp:394] Test iter: 21/50, loss = 0.267363
I0109 03:00:44.418112  9648 net_test.cpp:394] Test iter: 21/50, top-1 = 0.96
I0109 03:00:44.442924  9648 net_test.cpp:394] Test iter: 22/50, accuracy = 0.98
I0109 03:00:44.442939  9648 net_test.cpp:394] Test iter: 22/50, loss = 0.0951834
I0109 03:00:44.442943  9648 net_test.cpp:394] Test iter: 22/50, top-1 = 0.98
I0109 03:00:44.467787  9648 net_test.cpp:394] Test iter: 23/50, accuracy = 0.96
I0109 03:00:44.467800  9648 net_test.cpp:394] Test iter: 23/50, loss = 0.418
I0109 03:00:44.467803  9648 net_test.cpp:394] Test iter: 23/50, top-1 = 0.96
I0109 03:00:44.493676  9648 net_test.cpp:394] Test iter: 24/50, accuracy = 0.96
I0109 03:00:44.493692  9648 net_test.cpp:394] Test iter: 24/50, loss = 0.304741
I0109 03:00:44.493695  9648 net_test.cpp:394] Test iter: 24/50, top-1 = 0.96
I0109 03:00:44.518680  9648 net_test.cpp:394] Test iter: 25/50, accuracy = 0.98
I0109 03:00:44.518694  9648 net_test.cpp:394] Test iter: 25/50, loss = 0.366387
I0109 03:00:44.518697  9648 net_test.cpp:394] Test iter: 25/50, top-1 = 0.98
I0109 03:00:44.543498  9648 net_test.cpp:394] Test iter: 26/50, accuracy = 0.98
I0109 03:00:44.543514  9648 net_test.cpp:394] Test iter: 26/50, loss = 0.305873
I0109 03:00:44.543516  9648 net_test.cpp:394] Test iter: 26/50, top-1 = 0.98
I0109 03:00:44.569705  9648 net_test.cpp:394] Test iter: 27/50, accuracy = 0.98
I0109 03:00:44.569720  9648 net_test.cpp:394] Test iter: 27/50, loss = 0.321286
I0109 03:00:44.569722  9648 net_test.cpp:394] Test iter: 27/50, top-1 = 0.98
I0109 03:00:44.595654  9648 net_test.cpp:394] Test iter: 28/50, accuracy = 0.96
I0109 03:00:44.595685  9648 net_test.cpp:394] Test iter: 28/50, loss = 0.129567
I0109 03:00:44.595690  9648 net_test.cpp:394] Test iter: 28/50, top-1 = 0.96
I0109 03:00:44.620455  9648 net_test.cpp:394] Test iter: 29/50, accuracy = 0.94
I0109 03:00:44.620468  9648 net_test.cpp:394] Test iter: 29/50, loss = 0.238945
I0109 03:00:44.620472  9648 net_test.cpp:394] Test iter: 29/50, top-1 = 0.94
I0109 03:00:44.645344  9648 net_test.cpp:394] Test iter: 30/50, accuracy = 0.96
I0109 03:00:44.645359  9648 net_test.cpp:394] Test iter: 30/50, loss = 0.194755
I0109 03:00:44.645361  9648 net_test.cpp:394] Test iter: 30/50, top-1 = 0.96
I0109 03:00:44.671176  9648 net_test.cpp:394] Test iter: 31/50, accuracy = 0.9
I0109 03:00:44.671191  9648 net_test.cpp:394] Test iter: 31/50, loss = 0.640639
I0109 03:00:44.671195  9648 net_test.cpp:394] Test iter: 31/50, top-1 = 0.9
I0109 03:00:44.696151  9648 net_test.cpp:394] Test iter: 32/50, accuracy = 0.92
I0109 03:00:44.696166  9648 net_test.cpp:394] Test iter: 32/50, loss = 0.774878
I0109 03:00:44.696168  9648 net_test.cpp:394] Test iter: 32/50, top-1 = 0.92
I0109 03:00:44.720947  9648 net_test.cpp:394] Test iter: 33/50, accuracy = 0.94
I0109 03:00:44.720961  9648 net_test.cpp:394] Test iter: 33/50, loss = 0.5751
I0109 03:00:44.720964  9648 net_test.cpp:394] Test iter: 33/50, top-1 = 0.94
I0109 03:00:44.747102  9648 net_test.cpp:394] Test iter: 34/50, accuracy = 0.98
I0109 03:00:44.747117  9648 net_test.cpp:394] Test iter: 34/50, loss = 0.159884
I0109 03:00:44.747119  9648 net_test.cpp:394] Test iter: 34/50, top-1 = 0.98
I0109 03:00:44.772997  9648 net_test.cpp:394] Test iter: 35/50, accuracy = 0.96
I0109 03:00:44.773012  9648 net_test.cpp:394] Test iter: 35/50, loss = 0.236679
I0109 03:00:44.773015  9648 net_test.cpp:394] Test iter: 35/50, top-1 = 0.96
I0109 03:00:44.797822  9648 net_test.cpp:394] Test iter: 36/50, accuracy = 0.96
I0109 03:00:44.797838  9648 net_test.cpp:394] Test iter: 36/50, loss = 0.0759002
I0109 03:00:44.797842  9648 net_test.cpp:394] Test iter: 36/50, top-1 = 0.96
I0109 03:00:44.822830  9648 net_test.cpp:394] Test iter: 37/50, accuracy = 0.96
I0109 03:00:44.822845  9648 net_test.cpp:394] Test iter: 37/50, loss = 0.25531
I0109 03:00:44.822849  9648 net_test.cpp:394] Test iter: 37/50, top-1 = 0.96
I0109 03:00:44.848680  9648 net_test.cpp:394] Test iter: 38/50, accuracy = 0.98
I0109 03:00:44.848695  9648 net_test.cpp:394] Test iter: 38/50, loss = 0.0904018
I0109 03:00:44.848699  9648 net_test.cpp:394] Test iter: 38/50, top-1 = 0.98
I0109 03:00:44.873698  9648 net_test.cpp:394] Test iter: 39/50, accuracy = 0.96
I0109 03:00:44.873713  9648 net_test.cpp:394] Test iter: 39/50, loss = 0.298578
I0109 03:00:44.873718  9648 net_test.cpp:394] Test iter: 39/50, top-1 = 0.96
I0109 03:00:44.898527  9648 net_test.cpp:394] Test iter: 40/50, accuracy = 0.92
I0109 03:00:44.898542  9648 net_test.cpp:394] Test iter: 40/50, loss = 0.261413
I0109 03:00:44.898545  9648 net_test.cpp:394] Test iter: 40/50, top-1 = 0.92
I0109 03:00:44.924878  9648 net_test.cpp:394] Test iter: 41/50, accuracy = 0.94
I0109 03:00:44.924894  9648 net_test.cpp:394] Test iter: 41/50, loss = 0.266424
I0109 03:00:44.924898  9648 net_test.cpp:394] Test iter: 41/50, top-1 = 0.94
I0109 03:00:44.951493  9648 net_test.cpp:394] Test iter: 42/50, accuracy = 0.98
I0109 03:00:44.951509  9648 net_test.cpp:394] Test iter: 42/50, loss = 0.0270395
I0109 03:00:44.951512  9648 net_test.cpp:394] Test iter: 42/50, top-1 = 0.98
I0109 03:00:44.976300  9648 net_test.cpp:394] Test iter: 43/50, accuracy = 0.94
I0109 03:00:44.976315  9648 net_test.cpp:394] Test iter: 43/50, loss = 0.291818
I0109 03:00:44.976318  9648 net_test.cpp:394] Test iter: 43/50, top-1 = 0.94
I0109 03:00:45.001113  9648 net_test.cpp:394] Test iter: 44/50, accuracy = 0.96
I0109 03:00:45.001128  9648 net_test.cpp:394] Test iter: 44/50, loss = 0.113652
I0109 03:00:45.001132  9648 net_test.cpp:394] Test iter: 44/50, top-1 = 0.96
I0109 03:00:45.027063  9648 net_test.cpp:394] Test iter: 45/50, accuracy = 0.98
I0109 03:00:45.027077  9648 net_test.cpp:394] Test iter: 45/50, loss = 0.0894757
I0109 03:00:45.027081  9648 net_test.cpp:394] Test iter: 45/50, top-1 = 0.98
I0109 03:00:45.051935  9648 net_test.cpp:394] Test iter: 46/50, accuracy = 0.98
I0109 03:00:45.051949  9648 net_test.cpp:394] Test iter: 46/50, loss = 0.136449
I0109 03:00:45.051952  9648 net_test.cpp:394] Test iter: 46/50, top-1 = 0.98
I0109 03:00:45.076750  9648 net_test.cpp:394] Test iter: 47/50, accuracy = 0.96
I0109 03:00:45.076764  9648 net_test.cpp:394] Test iter: 47/50, loss = 0.120455
I0109 03:00:45.076767  9648 net_test.cpp:394] Test iter: 47/50, top-1 = 0.96
I0109 03:00:45.102932  9648 net_test.cpp:394] Test iter: 48/50, accuracy = 0.94
I0109 03:00:45.102948  9648 net_test.cpp:394] Test iter: 48/50, loss = 0.478166
I0109 03:00:45.102952  9648 net_test.cpp:394] Test iter: 48/50, top-1 = 0.94
I0109 03:00:45.128819  9648 net_test.cpp:394] Test iter: 49/50, accuracy = 0.98
I0109 03:00:45.128834  9648 net_test.cpp:394] Test iter: 49/50, loss = 0.0795761
I0109 03:00:45.128837  9648 net_test.cpp:394] Test iter: 49/50, top-1 = 0.98
I0109 03:00:45.153506  9648 net_test.cpp:394] Test iter: 50/50, accuracy = 0.94
I0109 03:00:45.153519  9648 net_test.cpp:394] Test iter: 50/50, loss = 0.406905
I0109 03:00:45.153523  9648 net_test.cpp:394] Test iter: 50/50, top-1 = 0.94
I0109 03:00:45.153527  9648 net_test.cpp:405] Test Results:
I0109 03:00:45.153528  9648 net_test.cpp:406] Loss: 0.274227
I0109 03:00:45.153532  9648 net_test.cpp:421] accuracy = 0.9568
I0109 03:00:45.153538  9648 net_test.cpp:421] loss = 0.274227 (* 1 = 0.274227 loss)
I0109 03:00:45.153542  9648 net_test.cpp:421] top-1 = 0.9568
I0109 03:00:45.153543  9648 net_test.cpp:450] Test Done!
I0109 03:00:45.252143  9648 vai_q.cpp:360] Start Deploy
I0109 03:00:45.530946  9648 vai_q.cpp:368] Deploy Done!
--------------------------------------------------
Output Quantized Train&Test Model:   "/workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/quantize_train_test.prototxt"
Output Quantized Train&Test Weights: "/workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/quantize_train_test.caffemodel"
Output Deploy Weights: "/workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/deploy.caffemodel"
Output Deploy Model:   "/workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/deploy.prototxt"
Compiling network: alexnetBNnoLRN
[INFO] parse raw model     :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] parse raw model     : 38%|███▊      | 11/29 [00:00<00:00, 104.45it/s]                 [INFO] parse raw model     : 72%|███████▏  | 21/29 [00:01<00:00, 25.73it/s]                  [INFO] parse raw model     : 83%|████████▎ | 24/29 [00:05<00:02,  2.02it/s]                  [INFO] parse raw model     :100%|██████████| 29/29 [00:05<00:00,  4.95it/s]
[INFO] infer shape (NCHW)  :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] infer shape (NCHW)  :100%|██████████| 29/29 [00:00<00:00, 35524.19it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|██████████| 29/29 [00:00<00:00, 729.65it/s]
[INFO] generate xmodel     :  0%|          | 0/29 [00:00<?, ?it/s]                           [INFO] generate xmodel     : 83%|████████▎ | 24/29 [00:00<00:00, 209.90it/s]                 [INFO] generate xmodel     :100%|██████████| 29/29 [00:00<00:00, 252.48it/s]
[INFO] Namespace(inputs_shape=None, layout='NCHW', model_files=['/workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/deploy.caffemodel'], model_type='caffe', out_filename='/workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaic_output/alexnetBNnoLRN_org.xmodel', proto='/workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/deploy.prototxt')
[INFO] caffe model: /workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/deploy.caffemodel
[INFO] caffe model: /workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaiq_output/deploy.prototxt
[INFO] generate xmodel: /workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaic_output/alexnetBNnoLRN_org.xmodel
[UNILOG][INFO] The compiler log will be dumped at "/tmp/vitis-ai-user/log/xcompiler-20210109-030052-9749"
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Graph name: deploy, with op num: 61
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaic_output/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaic_output/alexnetBNnoLRN.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is 763084a27c0fb82c30d60b7d57bd6b5d, and been saved to "/workspace/tutorials/VAI-Caffe-ML-CATSvsDOGS/files/deploy/alexnetBNnoLRN/pruned/vaic_output/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************
 copying xmodel file into /../zcu102/baseline/model/arm64_4096
 copying the test images to be used by the ZCU102
